[
  {
    "path": "posts/2023-11-13-den-andre-posten/",
    "title": "Den andre posten",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2023-11-13",
    "categories": [],
    "contents": "\r\nDistill is a publication format for scientific and technical writing, native to the web.\r\nLearn more about using Distill at https://rstudio.github.io/distill.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-13T22:46:07+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2023-11-13-den-tredje-posten-med-i-tittelen/",
    "title": "Den tredje posten med å i tittelen",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2023-11-13",
    "categories": [],
    "contents": "\r\nDistill is a publication format for scientific and technical writing, native to the web.\r\nLearn more about using Distill at https://rstudio.github.io/distill.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-13T22:45:53+01:00",
    "input_file": {}
  },
  {
    "path": "posts/welcome/",
    "title": "Welcome to Suppe og analyse",
    "description": "Welcome to our new blog, Suppe og analyse. We hope you enjoy \nreading what we have to say!",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2023-11-13",
    "categories": [],
    "contents": "\r\nHer er det litt tekst. Også med æ, ø og å.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-13T22:41:30+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-09-17-hvor-like-er-to-variabler/",
    "title": "Hvor like er to variabler",
    "description": "En kikk på noen ulike teknikker for å sammenlikne variabler/caser, når du vil vite hvor god prognosa di var",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2019-09-17",
    "categories": [],
    "contents": "\r\nHva er den beste måte å sammenlikne dataserier på?\r\nSom eksempel lager jeg meg et datasett fra en prognosekonkurranse, der 10 personer har forsøkt å gjette på valgresultatet til 10 partier. Jeg har også resultatet - og to spørsmål:\r\nHvor like er folk?\r\nHvem er nærmest fasiten? Hvem hadde rett? Antakeligvis er tilfeldig tallgenerering ganske langt fra fasiten - men teknikkene kan brukes også på faktiske bidrag.\r\n\r\n\r\nsuppressPackageStartupMessages(library(tidyverse))\r\nlibrary(broom)\r\nlibrary(here)\r\n\r\n#settings\r\ntheme_set(theme_minimal())\r\nset.seed(1106)\r\n\r\n#data\r\nresultatliste = data.frame()\r\n\r\n#lite eksperiment med å generere tilfeldige valgresultater\r\nrand_nr = function(a, b, n, k){\r\n  #finner n tilfeldige heltall mellom a og b, som summerer til k\r\n  while(TRUE){\r\n    x = sample(1:(k - n*a), n - 1, replace = TRUE)\r\n    x = sort(x)\r\n    x = c(x, k-n*a) - c(0, x)\r\n    if(max(x) <= b-a) {return(a+x)}\r\n  }\r\n}\r\n\r\ntest_df = data.frame(parti = c(\"Rødt\", \"SV\", \"Ap\", \"Sp\", \"MDG\", \"KrF\", \"V\", \"H\", \"FrP\", \"Andre\"),\r\n                     resultat = c(0.038, 0.061, 0.248, 0.144, 0.068, 0.04, 0.039, 0.201, 0.082, 0.079)\r\n                     )\r\ntest_df$resultat = test_df$resultat*100\r\n\r\nfor(i in 1:10){\r\n  temp = data.frame(deltaker = rand_nr(0, 30, 10, 100))\r\n  names(temp) = paste0(\"deltaker_\", i)\r\n  test_df = bind_cols(test_df, temp)\r\n}\r\n\r\ndf = test_df\r\n\r\n\r\nHvor nærme var folk?\r\nRein visuell inspeksjon\r\n\r\nparti\r\nresultat\r\ndeltaker_1\r\ndeltaker_2\r\ndeltaker_3\r\ndeltaker_4\r\ndeltaker_5\r\ndeltaker_6\r\ndeltaker_7\r\ndeltaker_8\r\ndeltaker_9\r\ndeltaker_10\r\nRødt\r\n3,8\r\n6\r\n9\r\n30\r\n16\r\n22\r\n23\r\n13\r\n4\r\n25\r\n20\r\nSV\r\n6,1\r\n2\r\n3\r\n2\r\n4\r\n20\r\n13\r\n9\r\n17\r\n7\r\n27\r\nAp\r\n24,8\r\n29\r\n11\r\n12\r\n24\r\n16\r\n9\r\n7\r\n10\r\n6\r\n6\r\nSp\r\n14,4\r\n8\r\n18\r\n5\r\n4\r\n3\r\n5\r\n24\r\n5\r\n5\r\n1\r\nMDG\r\n6,8\r\n4\r\n0\r\n11\r\n25\r\n1\r\n30\r\n11\r\n15\r\n14\r\n5\r\nKrF\r\n4,0\r\n24\r\n15\r\n1\r\n8\r\n3\r\n1\r\n6\r\n5\r\n4\r\n4\r\nV\r\n3,9\r\n16\r\n16\r\n0\r\n1\r\n8\r\n6\r\n14\r\n3\r\n11\r\n19\r\nH\r\n20,1\r\n1\r\n8\r\n2\r\n2\r\n11\r\n4\r\n7\r\n11\r\n12\r\n1\r\nFrP\r\n8,2\r\n4\r\n0\r\n28\r\n9\r\n9\r\n0\r\n1\r\n20\r\n8\r\n17\r\nAndre\r\n7,9\r\n6\r\n20\r\n9\r\n7\r\n7\r\n9\r\n8\r\n10\r\n8\r\n0\r\n\r\nNoen ganske utenomjordiske gjettinger her, som forventa - men også ganske vanskelig å si hvilken av dem som har gjort det minst ille relativt til valgresultatet i den venstre kolonna.\r\nEn bedre måte å vise det på er grafisk med en graf:\r\n\r\n\r\ntemp = gather(df, person, prognose, resultat:deltaker_10) %>%\r\n  mutate(type = ifelse(person == \"resultat\", \"resultat\", \"prognose\"))\r\n\r\nggplot() + \r\n  geom_point(data = filter(temp, type == \"resultat\"), aes(x = prognose, y = fct_reorder(parti, prognose)), colour = \"black\") +\r\n  labs(x = \"Oppslutning\", y = \"Parti\", colour = \"Prognose eller resultat?\")\r\n\r\n\r\n\r\nAller først ser vi på de faktiske valgresultatene. Ap er størst, fulgt av Høyre og Senterpartiet. FrP er ganske små, og bolken “Andre” er temmelig svær. Rødt er minst, men ikke langt unna Venstre og KrF.\r\nHva så når vi legger på prognosene?\r\n\r\n\r\nggplot() + \r\n  geom_point(data = filter(temp, type == \"prognose\"), aes(x = prognose, y = fct_reorder(parti, prognose)), colour = \"grey\") +\r\n  geom_point(data = filter(temp, type == \"resultat\"), aes(x = prognose, y = fct_reorder(parti, prognose)), colour = \"black\") +\r\n  labs(x = \"Oppslutning\", y = \"Parti\", colour = \"Prognose eller resultat?\")\r\n\r\n\r\n\r\nSkikkelig tilfeldig spredning utover! Allikevel ser det ut til å være en del overplotting - det er få av linjene som har 10 hele grå punkter. Dermed lønner det seg å bruke en anne geome - en som teller opp litt. Små prikker er en observasjon, medium to og de største er tre observasjoner.\r\n\r\n\r\nggplot() + \r\n  geom_count(data = filter(temp, type == \"prognose\"), aes(x = prognose, y = fct_reorder(parti, prognose)), colour = \"grey\", show.legend = FALSE) +\r\n  geom_point(data = filter(temp, type == \"resultat\"), aes(x = prognose, y = fct_reorder(parti, prognose)), colour = \"black\") +\r\n  labs(x = \"Oppslutning\", y = \"Parti\", colour = \"Prognose eller resultat?\")\r\n\r\n\r\n\r\nVanskelig - for ikke å si umulig -å si med ett blikk hvem av de ti seriene som er nærmest fasiten, totalt sett. Vi trenger ett mål. Her går jeg igjennom:\r\nEvklidiansk distanse\r\nKorrelasjonsmatrise\r\nR2\r\nRMSE\r\nMAE\r\nEuklidiansk distanse\r\nEvklidiansk distanse er et fancy navn på avstand i et flatt plan mellom to punkter. For avstanden mellom to vektorer (eller to variabler) er denne definert som den kvardratroten av den kvadrerte forskjellen mellom punktene i de to seriene. Hvorfor kvadrere? Fordi summen av forskjeller mellom to serier ikke alltid er informativt, hvis negative og positive forskjeller nuller hverandre ut.\r\nLav avstand er bra, stor avstand er dårlig:\r\n\r\n\r\ntemp = t(select(df, -parti))\r\nevklid = dist(temp)\r\nprint(evklid, digits = 1)\r\n\r\n            resultat deltaker_1 deltaker_2 deltaker_3 deltaker_4\r\ndeltaker_1        32                                            \r\ndeltaker_2        30         28                                 \r\ndeltaker_3        41         48         46                      \r\ndeltaker_4        31         33         40         31           \r\ndeltaker_5        29         38         34         32         33\r\ndeltaker_6        40         46         42         37         23\r\ndeltaker_7        29         36         21         41         34\r\ndeltaker_8        27         40         37         33         29\r\ndeltaker_9        33         40         32         27         27\r\ndeltaker_10       44         45         44         37         42\r\n            deltaker_5 deltaker_6 deltaker_7 deltaker_8 deltaker_9\r\ndeltaker_1                                                        \r\ndeltaker_2                                                        \r\ndeltaker_3                                                        \r\ndeltaker_4                                                        \r\ndeltaker_5                                                        \r\ndeltaker_6          33                                            \r\ndeltaker_7          31         31                                 \r\ndeltaker_8          27         33         32                      \r\ndeltaker_9          22         22         25         28           \r\ndeltaker_10         23         38         36         31         29\r\n\r\nUt ifra dette målet ser vi at deltaker_4 var nærmest resultatet, fulgt av deltaker 1 og 3.\r\nHvis vi var interessert i alle forskjellene mellom alle, kunne dette vært visualisert med ett heatmap. Men det er vi ikke - vi er kun interessert i forskjellen mellom deltakerne og det faktiske resultatet.\r\n\r\n\r\ntemp = dist(t(select(df, -parti)))\r\ntemp = tidy(temp) %>%\r\n  filter(. , item2 == \"resultat\")\r\n\r\nggplot(data = temp) + \r\n  geom_col(aes(x = fct_reorder(item1, distance), y = distance)) +\r\n  labs(x = \"Hvor langt unna fasiten?\", y = \"Avstand\")\r\n\r\n\r\nresultatliste = select(temp, person = item1, evklid = distance)\r\n\r\n\r\nKorrelasjon (Pearson)\r\nMen evklidiansk distanse er ikke det eneste målet - vi har også klassikeren korrelasjon. Korrelasjon er ikke veldig ulikt et avstandsmål, men mens evklidiansk avstand forutsetter at de to vektorene (eller variablene) X og Y er på samme skala, skalerer korrelasjon (Pearsons, i dette tilfellet) først med standardavviket til X og Y. Pearson er i bunn og grunn et gjennomsnittlig produkt av x og Y.\r\n\r\n\r\ntemp = select(df, -parti)\r\nkorr_matrise = cor(temp)\r\n\r\ntemp = data.frame(korr_matrise) %>%\r\n  rownames_to_column(., var = \"id2\") %>%\r\n  gather(., \"id1\", \"korrelasjon\", resultat:deltaker_10) %>%\r\n  filter(., id1 == \"resultat\", id2 != \"resultat\")\r\n\r\nggplot(data = temp) + \r\n  geom_col(aes(x = fct_reorder(id2, korrelasjon), y = korrelasjon)) +\r\n  labs(x = \"Hvor langt unna fasiten?\", y = \"Korrelasjon\")\r\n\r\n\r\n\r\nDeltaker_4 og deltaker_1 er fortsatt nærmest. Her ser vi faktisk at deltaker_6 og deltaker_8 har en betydelig negativ korrelasjon.\r\nForklart variasjon - R2\r\nHer brukes også kvadrert R som et mål på forklart variasjon. Dette er jo bare den kvadrerte korrelasjonskoeffisienten fra Pearsons over, og rangeringa blir dermed ikke annerledes. Men merk! Her blir det en liten feil. Over så vi negative korrelasjoner. I tilfellet valgresultat er ikke det ønskelig - det betyr jo at når deltakeren har gjettet høyere, så har resultatet blitt lavere. I matematisk forstand kan dette fortsatt forklare variasjon, men ikke i noen meningsfull form her.\r\n\r\n\r\ntemp$r.kvadrert = temp$korrelasjon^2\r\n\r\nggplot(data = temp) + \r\n  geom_col(aes(x = fct_reorder(id2, r.kvadrert), y = r.kvadrert)) +\r\n  labs(x = \"Hvor langt unna fasiten?\", y = \"Forklart variasjon\")\r\n\r\n\r\nresultatliste = left_join(resultatliste, select(temp, -id1), by = c(\"person\" = \"id2\"))\r\n\r\n\r\nDeltaker_4 har i hvert fall klart å forklare noe av variasjonen i de faktiske valgresultatene.\r\nVanlige prognosemål - Root mean square error (RMSE) og Mean average error (MAE)\r\nRMSE gir større straff til store feil: hvis det å ta feil med 10 er mer enn dobbelt så ille som å ta feil med 5, så er RMSE riktig mål. Hvis det å ta feil med 10 er akkurat dobbelt så ille som å ta feil med 5, så er MAE riktigere.\r\n\r\n\r\n#RMSE\r\nrmse <- function(feil){\r\n    sqrt(mean(feil^2))\r\n}\r\n \r\n#MAE\r\nmae <- function(feil){\r\n    mean(abs(feil))\r\n}\r\n\r\n\r\nSjølve utregninga skjuler jeg - den er temmelig stygg, ettersom kopiering gikk raskere enn funksjoner.\r\n\r\n\r\nqplot(data = temp, x = fct_reorder(person, rmse), y = rmse, geom = \"col\") + \r\n  labs(x = \"Person\", y = \"RMSE\")\r\n\r\n\r\nqplot(data = temp, x = fct_reorder(person, mae), y = mae, geom = \"col\") + \r\n  labs(x = \"Person\", y = \"MAE\")\r\n\r\n\r\nresultatliste = left_join(resultatliste, temp)\r\n\r\n\r\nOppsummering\r\nSå for å oppsummere, hvem var best? Ut ifra de ulike målene vi har sett her, ser resultatene relativt entydige ut: deltaker_4 har en lavere evklidiansk avstand til resultatet, har en høyere korrelasjon, en høyere forklart variasjon, en lavere RMSE og en lavere MAE.\r\n\r\n\r\nknitr::kable(arrange(resultatliste, evklid), digits = 1)\r\n\r\nperson\r\nevklid\r\nkorrelasjon\r\nr.kvadrert\r\nrmse\r\nmae\r\n\r\nHvordan ser dette ut i plottet vårt fra over?\r\n\r\n\r\ntemp = gather(df, person, prognose, resultat:deltaker_10) %>%\r\n  mutate(type = ifelse(person == \"resultat\", \"resultat\", \"prognose\"))\r\n\r\nggplot() + \r\n  geom_count(data = filter(temp, type == \"prognose\"), aes(x = prognose, y = fct_reorder(parti, prognose)), colour = \"grey\", show.legend = FALSE) +\r\n  geom_point(data = filter(temp, type == \"resultat\"), aes(x = prognose, y = fct_reorder(parti, prognose)), colour = \"black\") +\r\n  geom_point(data = filter(temp, person == \"deltaker_4\"), aes(x = prognose, y = fct_reorder(parti, prognose)), colour = \"red\") +\r\n  labs(x = \"Oppslutning\", y = \"Parti\", colour = \"Prognose eller resultat?\")\r\n\r\n\r\n\r\nMen hvilke valgresultater var de ulike deltakerne nærmest?\r\nEn måte å snu på dette på, er ved å finne ut hvilke faktiske valgresultater de ulike deltakerne var nærmest. Valgresultatene hentes fra valgresultat.no.\r\nEtter litt bearbeiding får jeg denne tabellen:\r\n\r\nDeltaker\r\nNærmeste kommune\r\nAvstand\r\ndeltaker_1\r\n1874_Moskenes\r\n12.2\r\ndeltaker_2\r\n4633_Fedje\r\n23.8\r\ndeltaker_3\r\n1874_Moskenes\r\n18.7\r\ndeltaker_4\r\n1874_Moskenes\r\n16.2\r\ndeltaker_5\r\n3039_Flå\r\n15.2\r\ndeltaker_6\r\n3436_Nord-Fron\r\n15.3\r\ndeltaker_7\r\n4633_Fedje\r\n15.0\r\ndeltaker_8\r\n4643_Årdal\r\n20.6\r\ndeltaker_9\r\n3819_Hjartdal\r\n14.9\r\ndeltaker_10\r\n3039_Flå\r\n2.6\r\n\r\nDeltaker 3, 4 og 9 har lavest avstand til valgresultatet for hele landet. Avstanden er imidlertid ikke spesielt lav. 1, 2 og 5 ligger nærmest Flå. Deltaker 10 er veldig overraskende nærme tre små kommuner.\r\n\r\n\r\n\r\n",
    "preview": "posts/2019-09-17-hvor-like-er-to-variabler/hvor-like-er-to-variabler_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2023-11-19T21:56:03+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-09-04-stemningsanalyse-av-partiprogram/",
    "title": "Stemningsanalyse av partiprogram",
    "description": "En kikk på valgprogrammene for kommunevalget i Oslo, og hvilke stemninger som finnes der",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2019-09-04",
    "categories": [],
    "contents": "\r\nHvordan kan man maskinelt forstå en tekst? I den forrige artikkelen såg jeg på hvilke ord som var mest brukt, i ulike varianter. Hvor godt likner det på en menneskelig måte å lese noe på? Kanskje litt - en legger jo merke til hvilke ord som går igjen, og særlig når det er beskrivelser av emner.\r\nEn anna menneskelig måte å lese en tekst på, er å se på stemningen i en tekst: hvilke følelser brukes her - positive eller negative? Eller noe mer komplisert? Noe mer komplisert klarer jeg ikke her, så det snakker jeg ikke mer om.\r\nVi bruker AFINN-koda ordbok for å si noe om stemningen i partiprogrammene. Gitt at den ordboka gir et godt bilde av stemningen i programmene (noe som ikke er gitt), så ser vi på følgende:\r\nHva er den gjennomsnittlige stemninga i tekstene?\r\nHvordan ser variasjonen ut mellom partiene?\r\n\r\n\r\nsuppressPackageStartupMessages(library(tidyverse))\r\nlibrary(tidytext)\r\nlibrary(here)\r\nlibrary(tm)\r\n\r\n#settings\r\ntheme_set(theme_minimal())\r\nset.seed(1106)\r\n\r\n\r\n##Datagrunnlaget\r\nAlle partiene har PDF-filer av valgprogrammene sine for Oslo tilgjengelig. PDF-filer lar seg lese inn, men krever litt tygging for å få fjerna punktsetting, nummer og lignende.\r\n\r\n\r\n#med TM\r\n\r\n# lag et korpus fra pdf-filene\r\nconverted <- VCorpus(DirSource(\"valgprogram\"), readerControl = list(reader = readPDF, language = \"nb\")) %>% \r\n  DocumentTermMatrix(., control = list(language = \"nb\", \r\n                                       removePunctuation = TRUE,\r\n                                       removeNumbers = TRUE, \r\n                                       stopwords = stopwords(\"no\")\r\n                                       ))\r\n\r\n#opprydding\r\n#fjerner .pdf-suffixet\r\ndf_programmer = tidy(converted) %>%\r\n  mutate(., document = gsub(\".pdf\", \"\", document, fixed = TRUE))\r\n\r\n#setter bedre navn på variablene\r\nnames(df_programmer) = c(\"parti\", \"term\", \"antall\")\r\n\r\n\r\nEn tekst består av summen av ord, og en teksts stemning består av summen av ordenes stemning. For å fastslå stemning er en mulig tilnærming å bruke et leksikon eller ordbok: noen har koda et sett med ord, og hvilken stemning de utgjør. For norsk har jeg funnet Finn Årup Nielsens ordbok fra 2011 på Github, AFINN (fork her). Den kan leses inn på denne litt clunky måten (regex er ikke min sterke side).\r\nDisse dataene koder ord på en skala fra -5 (mest negativ) til +5 (mest positiv)\r\n\r\n\r\n#sentiment-data\r\nsentiment <- read_delim(\"AFINN-no-165.txt\", \"|\", escape_double = FALSE, col_names = FALSE, trim_ws = TRUE)\r\nsentiment$verdi = parse_number(sentiment$X1)\r\nsentiment$tekst = gsub(pattern = \"[-][012345]|[012345]\", replacement = \"\", x = sentiment$X1)\r\nsentiment$tekst = gsub(pattern = \"\\t\", replacement = \"\", x = sentiment$tekst)\r\nsentiment = select(sentiment, -X1)\r\n\r\n#fjerner litt krøll - manglende verdier og ett ord med verdi 8\r\nsentiment = filter(sentiment, is.na(verdi) == FALSE) %>%\r\n  filter(., verdi < 6)\r\n\r\n\r\nDet er 3 211 ord i ordboka. Tabellen under lister opp antallet ord i hver verdi-kategori. Det er kun 13 ord som er mest negative, og 4 ord i den mest positive kategorien. De fleste ordene er å finne i -2-kategorien. Faktisk ser det ut til at om lag 2 000 av ordene er negative, mens nærmere 1 000 er positive. Er dette en trend ved det norske språket, eller ved ordboka? Jeg vil anta det siste.\r\n\r\n\r\n\r\nVi tar et tilfeldig utvalg på ett ord fra hver verdikategori:\r\n\r\n\r\ntemp = group_by(sentiment, verdi) %>%\r\n  sample_n(., 1)\r\nknitr::kable(temp)\r\n\r\nverdi\r\ntekst\r\n-5\r\ntispe\r\n-4\r\nterningkast en\r\n-3\r\nskyld\r\n-2\r\ndruknet\r\n-1\r\ndump\r\n0\r\nnb\r\n1\r\nforlenge\r\n2\r\nbehagelig\r\n3\r\nriktig retning\r\n4\r\nrofl\r\n5\r\nbegeistret\r\n\r\nDette er definitivt ord som brukes - men i et politisk program? Neppe relevant med de mest negative ordene, i hvert fall, og neppe heller de mest positive. Ved første iterasjon fant jeg også at ordet “som” er kodet med +2. “Som” er jo ikke et spesielt positivt ord, det er et pauseord, et stoppord - og dermed må stoppordene fjernes også denne gangen.\r\nVed hjelp av en inner join smelter vi ordboka sammen med ordene i partiprogrammene:\r\n\r\n\r\ndf = inner_join(sentiment, df_programmer, by = c(\"tekst\" = \"term\"))\r\n\r\n#en utfordring her er at vi blander verdien på en variabel og antallet observasjoner\r\n#bør ekspanderes\r\ndf_utvida = uncount(df, antall)\r\n\r\n\r\n\r\n[1] 14434\r\n[1] 644\r\n\r\nAv de 3 211 ordene i AFINN-ordboka, er 644 ord i bruk i partiprogrammene. Sagt på en anna måte - av de 14 434 ordene i programmene, er det 644 ord som finnes igjen i AFINN. Gir de koda ordene et representativt utvalg? Tja, vanskelig å si - mange av ordene som ofte brukes kan antas å være ganske nøytrale. Men det kan også være at politisk sjargong er mer spesialisert, og har andre positive og negative ord enn det generelle språket. Det kan også være at det er har andre nyanser?\r\n##Hva er de mest stemningsladde ordene i partiprogrammene?\r\n\r\n\r\ntemp = count(df, tekst, sort = TRUE, wt = antall) %>%\r\n  left_join(., sentiment) %>% #hekter også på ordene igjen\r\n  top_n(., 10, n)\r\nknitr::kable(temp)\r\n\r\ntekst\r\nn\r\nverdi\r\nsikre\r\n503\r\n2\r\nbedre\r\n347\r\n2\r\nstyrke\r\n323\r\n2\r\ngod\r\n289\r\n3\r\nrette\r\n273\r\n2\r\nønsker\r\n254\r\n1\r\nviktig\r\n243\r\n2\r\nøke\r\n187\r\n1\r\nstørre\r\n181\r\n3\r\ngodt\r\n161\r\n3\r\n\r\nDe ti mest brukte ordene er positive. De mest brukte positive ordene er “sikre”, “bedre” og “styrke”, alle med en verdi på +2, mens god er koda som +3 (vurderinga som ligger bak at god er sterkere positivt enn bedre skal jeg ikke gå inn i).\r\n##Hva er den gjennomsnittlige stemninga i partiprogrammene?\r\nHvis vi så beregner gjennomsnittlig stemning i de ulike partienes programmer, og plotter denne, får vi den følgende figuren:\r\n\r\n\r\n\r\nHøyre er det gjennomsnittlig mest positive partiet, med +1,3 stemning. Forskjellen ned til KrF og SP er bitteliten. Rødt er det mest negative, på +0,6, men også de er positivt innstilt - sammen med SV (+0,8) og FrP (+0,9).\r\nSpennet fra Høyre ned til Rødt er på 0,7 stemning, altså under en hel stemningsverdi på kodeskalaen. Det er ikke mye - og med disse gjennomsnittene forsvinner mye av variasjonen. Hvordan ser spredninga ut for de enkelte partiene?\r\n\r\n\r\n#skal telle opp antall ord assosisert med hver enkelt følelses-verdi\r\ntemp = group_by(df_utvida, parti, verdi) %>%\r\n  summarise(., antall = n()) %>%\r\n  mutate(., andel = antall / sum(antall))\r\n\r\nggplot(data = temp) +\r\n  geom_col(aes(x = verdi, y = andel)) +\r\n  facet_wrap(~parti) +\r\n  scale_x_continuous(breaks = seq(from = -5, to = 5, by = 1))\r\n\r\n\r\n\r\nAlle partiene bruker positive ord +2 mest, fulgt av +1. Rødt, SV og FrP ser ut til å ha noe større andel negative ord i sine program. Det ser vi også i boksplottet under, hvor medianen for disse tre partiene ligger på ord med +1, mens den for de øvrige partiene ligger på +2. De negative følelsene er for uteliggere å regne (dvs. mer enn 1,5 ganger avstanden mellom første og tredje kvartil). De negative følelsene er innafor denne avstanden for Rødt, SV og FrP.\r\nDette gir mening - Rødt, SV og FrP er typisk mer kritisk til det bestående, og ønsker da kanskje relativt sett større endringer i Oslo enn andre partier. Det gir bittelitt mindre mening i et lokalvalg i Oslo, hvor Rødt og SV jo har utgjort en del av det bestående de siste fire årene. Men det samme kunne man jo sagt om FrP, som sitter i Regjering på sjette året. En anna vinkling på dette er at det er større variasjon i følelsene i FrP, SV og Rødt.\r\n\r\n\r\nggplot(data = df_utvida, aes(x = fct_reorder(parti, verdi, .fun = mean), y = verdi)) + \r\n  geom_jitter(colour = \"steelblue\", alpha = 0.1) + \r\n  geom_boxplot(alpha = 0.5) + \r\n  coord_flip() + \r\n  scale_y_continuous(breaks = seq(from = -5, to = 5, by = 1)) + \r\n  labs(x = \"Parti\", y = \"Stemning\")\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2019-09-04-stemningsanalyse-av-partiprogram/stemningsanalyse-av-partiprogram_files/figure-html5/unnamed-chunk-4-1.png",
    "last_modified": "2023-11-19T21:52:28+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-08-31-tidytext-analyse-av-partiprogram/",
    "title": "Hvordan lese ni partiprogram skikkelig fort? Tidytext-analyse av valgprogram",
    "description": "En kikk på valgprogrammene for kommunevalget i Oslo, med tidytext.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2019-08-31",
    "categories": [],
    "contents": "\r\nDet er høst, 2019, og på tide med LOKALVALG! En statsviters våte drøm? Ikke egentlig - plutselig får en spørsmål om Dhonts metode og slikt som en ikke lenger husker. Men det en kan gjøre er å sette seg inn i partiprogram, og diskutere hvem som er best.\r\nDet er ikke så lett. Alle mener selvsagt at de er best, og snakker av en eller anna grunn neste bare om ting en ikke kan være uenig i.\r\nKan tekstanalyse hjelpe oss litt på veien? For å undersøke det gjør jeg tre ting (som tatt ut av https://www.tidytextmining.com/index.html):\r\nHvilke ord bruker partiene i Oslo mest? Røpealarm: det er fine ord om seg selv.\r\nHvilke ord bruker hvert enkelt parti i større grad enn de andre partiene? Røpealarm: De snakker mer om politiske tema som de selv er opptatt av - men det er vanskelig å si hvor mye de er opptatt av det.\r\nHvilke temaer snakker de ulike partiene mest om? Røpealarm: Seg selv - det var ikke mulig å finne substansielle temaer som helse, eldre og barn - partiene er for det meste opptatt av seg selv\r\n\r\n\r\nsuppressPackageStartupMessages(library(tidyverse))\r\nlibrary(tidytext)\r\nlibrary(here)\r\nlibrary(tm)\r\nlibrary(topicmodels)\r\nlibrary(broom)\r\n\r\n#settings\r\ntheme_set(theme_minimal())\r\nset.seed(1106)\r\n\r\n\r\nDatagrunnlaget\r\nAlle partiene har PDF-filer av valgprogrammene sine for Oslo tilgjengelig. PDF-filer lar seg lese inn, men krever litt tygging for å få fjerna punktsetting, nummer og lignende.\r\nHelt til slutt fjerner jeg også stoppord - 176 vanlige ord i det norske språket som jevnt over brukes mye (i, og, jeg, det, …).\r\n\r\n\r\n#med TM\r\n\r\n# lag et korpus fra pdf-filene\r\nconverted <- VCorpus(DirSource(\"valgprogram\"), readerControl = list(reader = readPDF, language = \"nb\")) %>% \r\n  DocumentTermMatrix(., control = list(language = \"nb\", \r\n                                       removePunctuation = TRUE,\r\n                                       removeNumbers = TRUE,\r\n                                       stopwords = stopwords(\"no\") #fjerner stoppord \r\n                                       ))\r\n\r\n#opprydding\r\n#fjerner .pdf-suffixet\r\ndf = tidy(converted) %>%\r\n  mutate(., document = gsub(\".pdf\", \"\", document, fixed = TRUE))\r\n\r\n#setter bedre navn på variablene\r\nnames(df) = c(\"parti\", \"term\", \"antall\")\r\n\r\n\r\nHvem er mest ordrik?\r\nHer sitter vi da med en data.frame hvor hver rad er frekvensen til et ord i et partis partiprogram. Hvor ordrike er partiene i sine valgprogram?\r\n\r\n\r\n#litt enkel grafing \r\ntemp = group_by(df, parti) %>%\r\n  summarise(., antall_termer = n())\r\n\r\nggplot(data = temp, aes(x = fct_reorder(parti, antall_termer), y = antall_termer)) + \r\n  geom_col() + \r\n  coord_flip() + \r\n  labs(title = \"Rødt har flest unike termer i partiprogrammet\", subtitle = \"Partienes valgprogram for Oslo, 2019-2023\", y = \"Antall termer\",x = \"Parti\")\r\n\r\n\r\n\r\nHvilke ord er mest brukt i valgprogrammene?\r\n\r\n\r\ntemp = group_by(df, term) %>%\r\n  summarise(., antall = sum(antall)) %>%\r\n  top_n(., 10, antall)\r\n\r\nggplot(data = temp, aes(x = fct_reorder(term, antall), y = antall)) + \r\n  geom_col() + \r\n  coord_flip() + \r\n  labs(title = \"Oslo det mest brukte ordet i Oslo-valgkampen\", y = \"Antall ganger brukt\",x = \"Ord\")\r\n\r\n\r\n\r\nDe øvrige ordene er heller ikke spesielt overraskende: Gode, trygge, sikre honnørord, som antakeligvis brukes til å beskrive både innsatsen i forrige periode, innsatsen framover, og hvordan kommunen vil bli med akkurat Dette Partiet ved roret. Det eneste subsansielle som kommer fram her er barn - noe som ikke er rart, en sentral del av kommunepolitikk handler nettopp om barna.\r\nHva er de viktigste ordene for de ulike partiene?\r\nEn ganske usofistikert måte å måle dette på er ved å ganske enkelt telle opp alle ordene, og så se hvilke ord hvert enkelt parti bruker mest.\r\n\r\n\r\ntemp = group_by(df, parti) %>%\r\n  top_n(10, wt = antall) %>%\r\n  arrange(., antall)\r\n\r\nggplot(data = temp, aes(x = reorder_within(term, antall, parti), y = antall, fill = parti)) + \r\n  geom_col(show.legend = FALSE) + \r\n  facet_wrap(~parti, scales = \"free\", ncol = 2) + \r\n  scale_x_reordered() + \r\n  coord_flip() + \r\n  labs(title = \"Oslo og eget parti langt det mest vanlige å omtale\", subtitle = \"Ti mest brukte ord i  valgprogrammet for 2019-2023\", x = \"Parti\", y = \"Antall ganger ordet er nevnt\")\r\n\r\n\r\n\r\nOrdene skiller seg ikke veldig fra hverandre. Alle snakker mest om Oslo.\r\nAp snakker om seg selv. FrP snakker om kommune-kommune-kommune.\r\nHøyre vil ha flere gode og enda bedre barn.\r\nDet vil også KrF, men de vil ha flere sikre løsninger for disse barna.\r\nMDG vil sikre en grønn by.\r\nRødt er opptatt av hva kommunale ansatte bør gjøre.\r\nSp er opptatt av seg og sitt eget bystyreprogram.\r\nSV vil …sikre kommune gjennom ny kommune?\r\nVenstre slår seg også løs med sikring av noe bedre.\r\nHva skriver partiene om, som de andre ikke nevner?\r\nIkke så stort å lære av dette, egentlig. En potensielt nyttigere tanke er å finne fram til unike ord for hvert parti, som i mindre grad brukes av de andre partiene. Dette er såkalte tf_idf-ord, hvor ord som brukes mye på tvers av dokumenter (her, partiprogram) får lavere vekt, mens ord som brukes lite på tvers får høyere vekt.\r\n\r\n\r\nprogram_ord = bind_tf_idf(df, term, parti, antall)\r\n\r\ntemp = group_by(program_ord, parti) %>%\r\n  top_n(10, wt = tf_idf)\r\n\r\nggplot(data = temp, aes(x = reorder_within(term, tf_idf, parti), y = tf_idf, fill = parti)) + \r\n  geom_col(show.legend = FALSE) + \r\n  facet_wrap(~parti, scales = \"free\", ncol = 2) + \r\n  scale_x_reordered() + \r\n  coord_flip() + \r\n  labs(title = )\r\n\r\n\r\n\r\n(Merk her at top_n()-funksjonen tar med flere ord hvis rangeringa er uavgjort - så arbeiderpartiet får flere ord)\r\nIkke overraskende snakker fortsatt alle partiene mest om seg.\r\nAp snakker mer om fengsel, lønnstilskudd, språkkunnskaper og anstendighet enn de andre.\r\nFrP vil helt klart konkurranseutsette, og er opptatt av rusken, gravplasser, utviklingshemmede og hva folk kler seg i.\r\nHøyre snakker om introduksjonsprogrammet, yrkesfag, barnehage og oppvekst.\r\nKrF er opptatt av seniorer og formodentlige både kristne og humanistiske verdier.\r\nMDG snakker om bærekraft, forbruk og dyrevelferd.\r\nRødt er overaskende opptatt av foto, kvinner og millioner - kanskje noe mindre informativt enn de andre. Sp er veldig opptatt av seg selv - og sosialfaget.\r\nSV er mer enn de andre opptatt av samer, turveier, kvinner , ulikhet og rasisme.\r\nVenstre - de vil ha småhus, sexarbeidere, rusbrukere og skolebibliotek.\r\nDenne indikatoren plukka opp på en god måte hva de ulike partiene er opptatt av, og skriver mer om enn andre partier. Men gir det en pekepinn på hva en skal stemme? Nja. En bedre indikator hadde vært om en kunne identifisert mer substansielle temaer på tvers av partiprogrammene, som f.eks. skole, slik at en kunne sett hvor mye hvert enkelt partiprogram bidro til dette temaet.\r\nHvilke temaer tar programmene opp?\r\nOg det kan vi - kanskje. Med LDA - Latent Dirichlet Allocation - kan en estimere hvordan ett dokument består av flere tema, og ett tema består av flere ord på tvers av dokumenter. Så dermed kunne en - kanskje - se om f.eks. partiprogrammene tematiserer skole i ulik grad.\r\nAlgoritmen tar en DocumentTermMatrix, så vi finner igjen denne fra lenger oppe.\r\n\r\n\r\nmodel_1 = LDA(converted, k = 9)\r\n\r\ntema = tidy(model_1, matrix = \"beta\")\r\n\r\ntema_topp = group_by(tema, topic) %>%\r\n  top_n(10, beta) %>%\r\n  ungroup() %>%\r\n  arrange(topic, -beta)\r\n\r\nggplot(data = tema_topp, aes(reorder_within(term, beta, topic) , beta, fill = factor(topic))) + \r\n  geom_col(show.legend = FALSE) + \r\n  facet_wrap(~topic, scales = \"free\") +\r\n  coord_flip() + \r\n  scale_x_reordered()\r\n\r\n\r\n\r\nViser seg at denne algoritmen identifiserer partiene, heller enn temaene innad i partiprogrammene. Dette gjelder uansett hvilken k vi setter på LDA-funksjonen: Det mest gjenkjennelige i dokumenthaugen er skillene mellom partiprogrammene.\r\nHvis vi snur på flisa, og ser på sannsynlighetene for at en spesifikk tema hører til et spesifikt dokuments, ser vi dette veldig tydelig:\r\n\r\n\r\ntema_dokument = tidy(model_1, matrix = \"gamma\")\r\n\r\nggplot(data = tema_dokument, aes(factor(topic), gamma)) +\r\n  geom_boxplot() +\r\n  facet_wrap(~document)\r\n\r\n\r\n\r\nBildet er riktignok ikke helt 100 % krystallklart: Høyres partiprogram har biter som også er identifisert i KrFs partiprogram\r\nOppsummert\r\nNår ulike algoritmer raskt lar seg kjøre, og outputen enkelt lar seg plotte, så er det lett å glemme det viktigste i en slik analyse: Selve analysen. Hva er det vi har sett her?\r\nDe mest brukte ordene skiller seg ikke veldig fra hverandre, men alle partiene er selvsagt mest opptatt av seg selv. Det gjør også at når vi prøver å finne tverrgående tema, så feiler det - vi finner kun igjen partiprogrammene (med en interessant overlapp mellom H og KrF). Det kan ganske enkelt skyldes at datagrunnlaget er for lite - men det kan også tenkes at selv om de alle er like i de mest brukte ordene, så har de ulike nok ordvalg til at de framstår som distinkte.\r\nAlle partiene har også mer unike saker, som de andre i mindre grad snakker om. Det er imidlertid uklart fra denne gjennomgangen hvor stor plass f.eks. samisk politikk tar for Oslo SV - men antakeligvis er bærekraftsmålene en viktig komponent hos MDG.\r\n\r\n\r\n\r\n",
    "preview": "posts/2019-08-31-tidytext-analyse-av-partiprogram/tidytext-analyse-av-partiprogram_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2023-11-19T21:48:19+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-08-02-visualisering-og-sammenlikning-av-fordelinger-i-ggplot2/",
    "title": "Visualisering og sammenlikning av fordelinger i ggplot2",
    "description": "Hvordan visualisere fordelinger på tvers av kategorier, med eksempler fra deltakelse i skolefritidsordninga i norske kommuner",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2019-08-02",
    "categories": [],
    "contents": "\r\nDet har vært en del oppstuss rundt skolefritidsordninga - SFO, eller AKS her i Oslo - de siste dagene. NTNU Samfunnsforskning har levert en evalueringsrapport som i følge NRK peker på enorme forskjer i pris og tilbud. Det er særlig en NTB-melding som har blitt trykt opp rundt omkring, i følge med en datavisualisering fra nyhetsgrafikk.no. Den skal være limt inn under.\r\nUtklipp fra Dagsavisen 2. august 2019Grafikken har masse informasjon, men er allikevel ikke spesielt informativ. Hvorfor ikke? Etter min mening prøver den å dekke over for mye på en gang. Tittelen antyder at den handler om at flest bybarn bruker SFO. Men figurene viser oss andel barn som bruker SFO etter fylke - og ikke byer vs. ikke-byer. Videre trekker den inn gjennomsnittlig månedspris på fylkesnivå, og de ti dyreste og billigste SFO-kommunene - og hvor disse ligger i landet. Altså heller ikke relatert til overskriften.\r\nHva ville vært en bedre måte å vise dette på? Ved å angripe det som tittelen sier at grafikken skal si noe om - sammenhengen mellom å bo i by, og å bruke SFO.\r\nUnder ser vi kjapt på noen enkle måter å visualisere fordelinger på, ved hjelp av R og GGplot2-biblioteket.\r\nDatagrunnlaget\r\nSFO-deltakelse hentes fra SSBs statistikkbank (KOSTRA), tabell 11975. Den gir oss andel av barn fra og med 6 år til og med 9 år som i 2018 brukte kommunal eller privat SFO i en kommune. Dataene hentes fra APIet hos SSB.\r\nHva vil det si at noen bor i en by? I Norge er det ingen offisiell definisjon av en by - det eneste er en gammel veiledende definisjon fra 1997, som tilsier at en kommune med 5000 innbyggere og “sentrale tjenester” kan kalle seg by. Et mål på hva som er en by finner vi derfor i SSBs sentralitetsindeks. Denne indeksen sier noe om hvor mange arbeidsplasser og servicetjenester folk i kommunen kan nå med bil på 90 minutter. Dette er målet vårt på hvor urbant du bor.\r\n\r\n\r\n#SFO\r\nsfo_data = ApiData(\"https://data.ssb.no/api/v0/no/table/11975\",\r\n                   KOKkommuneregion0000 = TRUE,\r\n                   ContentsCode = \"KOSandsfo69kp0000\",\r\n                   Tid = \"2018\"\r\n                   )\r\n\r\ndf = sfo_data[[2]] %>%\r\n  select(., -ContentsCode, -Tid, -NAstatus) %>% #fjerner variabler med kun 1 verdi (konstanter)\r\n  filter(., nchar(KOKkommuneregion0000) == 4) #filtrer ut alle regioner som ikke har 4 karakterer\r\n\r\nnames(df) = c(\"knr_2018\",\"value\")\r\n\r\n#sentralitet\r\nsentralitet = read.csv2(\"sentralitet_2018.csv\", stringsAsFactors = FALSE, colClasses = c(\"character\", \"integer\", \"integer\"))\r\n\r\nsentralitet$sklasse_2018 = factor(sentralitet$sklasse_2018, labels = c(\"Mest sentral\", \"2\", \"3\", \"4\", \"5\", \"Minst sentral\"))\r\n\r\ndf = left_join(df, sentralitet) %>%\r\n    filter(., is.na(value) == FALSE, is.na(sklasse_2018) == FALSE)\r\n\r\n\r\nEn enkel fordeling\r\nFordelinger er veldig viktig, og å kikke på dem kan gi mye innsikt. En fordeling gir deg et bilde på om det er feil eller mangler i dataene, om modellering bør ta høyde til spesifikke ting, og til slutt - fordelinger viser et mye bedre bilde enn enkle punkt-oppsummeringer, som gjennomsnitt og standardavvik.\r\nDet er i hovedsak to teknikker som er mye brukt for å vise fordelinger: histogram og “kernel density estimates”. Histogrammet er bra for enkle fordelinger. De er intuitive for leseren, og lette å tolke. Men nedsida er at bøtte-klassifiserng har mye å si for hvordan det blir seende ut, og små datamengder kan fort bli seende rart ut. Folk som registrer data har også gjerne preferanser for noen dataverdier.\r\nHar du mer enn 150 observasjoner? Bruk bins=100. For mindre n, eksperimenter rundt.\r\nHar du data med naturlige brytninger? Utnytt dem\r\nBruk binwidth, gjerne sammen med center som forteller hva som er midtpunktet for en bøtte.\r\n\r\n\r\nggplot(data = df, aes(value)) + \r\n  geom_histogram(binwidth = 5, center = 2.5) + \r\n  labs(y = \"Antall kommuner\", x = \"Andel barn i SFO\", title = \"De fleste kommuner har rundt 40 - 60 % deltakelse i SFO\")\r\n\r\n\r\n\r\nDet ser altså ut til å være en stor haug med kommuner i midten, og så en del kommuner ute på sidene - ganske så normalfordelt, egentlig.\r\nSammenlikne fordelinger\r\nHvis en skal sammenlikne om to populasjoner eller måloppnåelser er like, må en sammenlikne fordelinger. Histogram med fasetter er ikke plass-effektive, og får mye akser og linjer fort. Det gjelder særlig med mange grupper for sammenlikning.\r\nEn bruker derfor i stedet et boksplot. Hvis en har mye data, er beeswarm bedre. Hvis en har enda mer data, er violin-plot bedre. Hvis det en sammenlikner over er en ordinal variabel, kan ridgeline-plot være best.\r\nI tilfellet med SFO-dataene er ikke gruppene egentlig så mange, slik at histogrammer kanskje kan være egnet - evt. slektningen “freqpoly”. Men som vi kjapt ser, så er det neimen ikke lett å bli spesielt klok av dette. De mest sentrale kommunene ser ut til å ha størst deltakelse i SFO, men det er også på alle måter færrest av disse. Vi trenger et mer relativt mål.\r\n\r\n\r\nggplot(data = df, aes(value, colour = sklasse_2018)) + \r\n  geom_freqpoly(binwidth = 5, center = 2.5) + \r\n  labs(y = \"Antall kommuner\", x = \"Andel barn i SFO\", colour = \"Sentralitet\", title = \"Andelen barn i SFO varierer med en kommunes sentralitet\")\r\n\r\n\r\n\r\nEn mer kompakt måte å vise dette på er da med et boksplott. Relativt gjenkjenbart (selv om en ofte må markere hva som vises - median, grense for første og tredje kvartil - dvs. at 50 % av dataene er innafor boksen), og gir kompakt informasjon. Nedsida er at informasjonen er for kompakt, og viser ikke egentlig fordelinga. En måte å få mer av fordelinga med på, er ved å bruke geom_jitter(). Denne plotter hver enkelt observasjon.\r\n\r\n\r\nggplot(data = df, aes(x = sklasse_2018, y = value)) + \r\n  geom_jitter(colour = \"steelblue\", alpha = 0.3) + \r\n  geom_boxplot(alpha = 0) + \r\n  labs(x = \"Sentralitet\", y = \"Andel barn i SFO\", title = \"De mest sentrale kommunene har høyere deltakelse i SFO\")\r\n\r\n\r\n\r\nDenne visualiseringa får også helt tydelig fram at vel er det slik at de mer sentrale kommunene har høyere SFO-deltakelse, men spredninga er også langt større blant de mindre sentrale kommunene.\r\nBeeswarm og violin er ikke spesielt aktuelt for oss - men ridgeline kan være det. Ridgeline passer der en har en ordinal variabel, altså har informasjon om rekkefølge. Farge på biler har ikke en slik sortering - men f.eks. måneder i et år har det, eller sentralitet på en kommune.\r\nDette er KDE-plot som plottes nærmere enn andre plots. Det gir også svakhetene - de kan overplottes, og kernel-valg er vanskelig når det er mange fordelinger.\r\n\r\n\r\nggplot(data = df, aes(x = value, y = sklasse_2018)) + \r\n  geom_density_ridges(alpha = 0.7) + \r\n  scale_x_continuous(limits = c(0, 100), expand = c(0,0)) + \r\n  theme(axis.ticks.y = element_blank()) + \r\n  labs(x = \"Andel i SFO\", y = \"Sentralitet\")\r\n\r\n\r\n\r\nEr det en sammenheng mellom sentralitet og SFO-deltakelse?\r\nSentralitet er også målt som en kontinuerlig variabel hos SSB. Dette gir oss muligheten til å også bruke et scatterplot, og estimere en trendlinje.\r\n\r\n\r\nggplot(data = df, aes(x = sindeks_2018, y = value)) + \r\n  geom_jitter(alpha = 0.3) + \r\n  geom_smooth()\r\n\r\n\r\n\r\nHva er anbefalinga her?\r\nSå hva hadde vært en bedre måte å vise at flere bybarn bruker SFO? Anbefalingen her må være å bruke boksplot-tilnærmingen. Det krever nok god annotering, men det får de allerede til med kartet.\r\n\r\n\r\nggplot(data = df, aes(x = sklasse_2018, y = value)) + \r\n  geom_jitter(colour = \"steelblue\", alpha = 0.3) + \r\n  geom_boxplot(alpha = 0) + \r\n  labs(x = \"Sentralitet\", y = \"Andel barn i SFO\", title = \"Flest bybarn bruker SFO\") + \r\n  annotate(\"text\", x = 1.5, y = 80, label = \"3. kvartil\") + \r\n  annotate(\"text\", x = 1.5, y = 70, label = \"Median\") + \r\n  annotate(\"text\", x = 1.5, y = 65, label = \"1. kvartil\")\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2019-08-02-visualisering-og-sammenlikning-av-fordelinger-i-ggplot2/visualisering-og-sammenlikning-av-fordelinger-i-ggplot2_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2023-11-19T21:45:11+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-04-23-visualisering-og-sammenlikning-av-antall-i-ggplot2/",
    "title": "visualisering og sammenlikning av antall i ggplot2",
    "description": "Hvordan visualisere antall og sammenlikne kategorier med ggplot2 i R, ved hjelp av søylediagram og punktdiagram",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2019-04-23",
    "categories": [],
    "contents": "\r\nVi har tidligere sett på hvordan andeler bør visualiseres. Denne gangen skal vi se på noe enda mer grunnleggende - antall. Veldig ofte er vi interessert i et enkelt tall eller en observasjon, for eksempel et gjennomsnitt eller en maksverdi. Vi ønsker også å sammenlikne denne verdien på tvers av ulike kategorier, som kjønn, typer biler eller geografisk enhet.\r\nDet er i hovedsak to standard måter å visualisere denne typen data på: stolpediagram (eller søylediagram), og punktdiagram.\r\n\r\n\r\n\r\n###Eksempeldata fra SSBs åpne API.\r\nOgså denne gangen bruker vi eksempeldata fra SSB. Ut ifra publiseringsoversikten ser jeg at det nylig er lagt ut kulturstatistikk, også dette fra KOSTRA. Besøk på folkebibliotek i landets kommuner fra 2015 til 2018 kan kanskje være interessant.\r\n\r\n\r\nalle_data = ApiData(\"https://data.ssb.no/api/v0/no/table/13135\",\r\n             KOKkommuneregion0000 = TRUE,\r\n             ContentsCode = \"KOSbesokbiblinnb0000\",\r\n             Tid = TRUE\r\n)\r\n\r\n#ApiData() returnerer både koder og menneskelesbar tekst, jeg går for tekst denne gangen\r\ndf <- alle_data[[1]] %>%\r\n  select(.,-statistikkvariabel) #filtrerer ut unødvendig info\r\n\r\n\r\nDet viser seg at 2018-tallene er tomme, så vi må begrense oss til 2015-2017.\r\nStolpediagram / søylediagram\r\nDisse figurene er superenkle. For mange er dette standard-diagrammet en tenker på, når en tenker på en graf. De er lettvinte å lage, og ofte lette å forstå - for svært mange. Men: hvis kakediagram er mer nyttig enn ryktet tilsier, så er søyler mindre nyttige en ryktet. Mer om det om litt.\r\nGgplot2 har to geoms for søylediagram: geom_bar og geom_col. geom_col er for bruk når du har tallet som skal mappes, mens geom_bar inkluderer en beregning.\r\nMed geom_col kan vi se nærmere på de ti stedene med de høyeste besøkstallene (per innbygger) i 2017.\r\n\r\n\r\ntemp = filter(df, `år`==\"2017\") %>%\r\n  arrange(., desc(value)) %>%\r\n  slice(., 1:10) %>%\r\n  mutate(., region = as.factor(region), region = fct_reorder(region, value))\r\n\r\nggplot(data = temp, aes(x = region, y = value))+\r\n  geom_col() +\r\n  coord_flip() + \r\n  labs(title =\"Lesehestene i Stjørdal besøkte folkebiblioteket mest\", subtitle =\"I gjennomsnitt 24 ganger i 2017\", x = \"Antall besøk per innbygger\", y = \"Kommune\")\r\n\r\n\r\n\r\nStjørdal kommune har altså flest besøk i folkebiblioteket per innbygger, med 24 besøk i 2017.\r\nSøylediagram må alltid starte på 0. Dette er en av få absolutte regler i visualisering av data. Det skyldes at det vi gjør når vi leser et søylediagram, er å se på lengden av diagrammet. Hvis vi skal sammenlikne flere søyler, sammenlikner vi lengder. Hvis vi da starter på noe annet enn 0, får vi feil lengde. R håndterer dette automatisk for oss.\r\nSiden diagrammet får litt overplotting, må vi også rotere aksene for å lese alle kommunenavnene.\r\nDataene bør alltid være fornuftig sortert, slik at de er lette for leseren å forstå. Siden dette er en topp-ti-liste, kan vi sortere dem fra stor til liten. Anbefalingen fra Grolemund og Wickhams R for Data Science er å ta kompliserte omorganiseringer ut av ggplot-funksjonen og inn i en egen mutate-funksjon, for å gjøre koden lettere å lese-\r\nGeom_bar er en funksjon som gjør litt beregninger og opptellinger selv. Standardinnstillingen er å telle opp antallet observasjoner for hver x-posisjon - i tilfellet over er det region. Den tar også et vekt-argument, som bestemmer hvor mye hver observasjon skal telle med. Dermed kan vi kjapt se hvem som har størst summert gjennomsnittlig besøk blant de 10 første kommunene (over de fire siste årene)\r\n\r\n\r\n#geom_bar\r\ntemp = mutate(df, region = as.factor(region)) %>%\r\n  slice(1:40)\r\n\r\nggplot(data = temp, aes(x = region, weight = value))+\r\n  geom_bar()\r\n\r\n\r\n\r\nHva er problemene med søylediagram? De bør først og fremst brukes på ting som gir en meningsfull kumulering, altså slik at de kan stables (som penger): folk oppfatter gjerne ting under toppen av søyla som inkludert i søyla, og ting over søyla som ikke inkludert i søyla. Så hvis en f.eks. skal angi at noe har en presis verdi, og ikke en annen verdi, så er søylediagram uegna. Eksempler kan være persentiler, temperaturer, ikke-lineære verdier (log).\r\nPunkt-diagram\r\nEksempelet over, med flere stablede gjennomsnitt i et søylediagram, er også uegna, ettersom gjennomsnitt i tre ulike år ikke gir mening å kumulere. Løsninga på dette kan være å plotte dem hver for seg - men også et punktdiagram kan hjelpe. Et punkt-diagram erstatter søylen med et punkt på verdien. Det er plasseffektivt, lett å lese og enkelt.\r\n\r\n\r\n#geom_bar\r\ntemp = mutate(df, region = as.factor(region)) %>%\r\n  slice(1:40) %>%\r\n  mutate(., region = fct_reorder(region, value))\r\n\r\nggplot(data = temp, aes(x = region, y = value))+\r\n  geom_point() + \r\n  coord_flip() +\r\n  labs(title = \"Besøk til folkebiblioteket varierer mer mellom kommuner enn over år\", x = \"Kommune\", y = \"Antall besøk per innbygger\")\r\n\r\n\r\n\r\nHer kommer vi imidlertid også inn på behov for å se på fordelinger og endringer over tid. I det helt grunnleggende eksempelet har vi bare noen tall vi ønsker å kikke på.\r\n\r\n\r\n#trekker et tilfeldig utvalg av enheter\r\ntemp = filter(df, `år` == \"2017\") %>%\r\n  sample_n(., 15) %>%\r\n  mutate(., region = as.factor(region), region = fct_reorder(region, value))\r\n\r\n#punktdiagram\r\nggplot(data = temp) + \r\n  geom_point(aes(x = region, y = value)) + \r\n  coord_flip() + \r\n  labs(title = \"Gjennomsnittlige besøk per innbygger i 2017\", subtitle = \"Tilfeldig utvalgte kommuner\", x = \"Kommune\", y = \"Antall besøk per innbygger\")\r\n\r\n\r\n\r\nAndre tall som lettere lar seg vise med et punktdiagram er logaritmer, eller prosentvise endringer. Et eksempel på en slik størrelse er. “log fold change”. Fold change er forholdet mellom startverdi og sluttverdi, som en kan ta log2-av. Tallet en får da vil da vise hvor mye større/mindre sluttverdien er enn startverdien: 1 betyr dobbelt så stor, 2 fire ganger så stort, -1 betyr dobbelt så liten.\r\n0 er skille mellom økning og nedgang. Når dataene har et så tydelig brudd-punkt, bør det også framgå av visualiseringa. En kan også vurdere å fjerne flere av støttelinjene , som de horisontale.\r\n\r\n\r\n#beregner logFoldChange fra 2015 til 2017\r\n#her er jeg implisitt avhengig av sorteringa av dataene som kommer inn. Dårlig praksis.\r\ntemp = filter(df, `år` == \"2017\"|`år` == \"2015\") %>%\r\n  slice(., 1:30) %>%\r\n  spread(., `år`, value, sep = \"_\") %>%\r\n  mutate(., logFoldChange = log2(`år_2017`/`år_2015`)) %>%\r\n  mutate(., region = as.factor(region), region = fct_reorder(region, logFoldChange))\r\n\r\n#punktdiagram\r\nggplot(data = temp, aes(x = logFoldChange, y = region)) +\r\n  geom_point(size = 2) + \r\n  geom_vline(xintercept=0) +\r\n  labs(title = \"Hvaler og Råde har størst økning i gjennomsnittlig biblo-besøk\", subtitle = \"Fra 2015 til 2017\", y = \"Kommune\") +\r\n  theme(\r\n  panel.grid.major.y = element_blank()\r\n  )\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2019-04-23-visualisering-og-sammenlikning-av-antall-i-ggplot2/visualisering-og-sammenlikning-av-antall-i-ggplot2_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2023-11-19T21:35:30+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-04-05-norsk-data-science/",
    "title": "Data science på norsk",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2019-04-05",
    "categories": [],
    "contents": "\r\n“Data science” eller datavitenskap er den nye vinen. Eller, det skulle man i hvert fall tro når til og med staten arrangerer fagforum for “kunstig intelligens og data science”. Men hva er det? Hva er det på norsk? Og er det viktig?\r\nHva er datavitenskap?\r\nFor det aller første, så er det åpenbart et engelsk begrep som klinger dårlig i norske ører. Jeg har imidlertid ikke funnet noen god norsk oversettelse så langt. Avanserte analyser høres et hakk bedre ut, men mulig det ikke gir helt de riktige konnotasjonene enda.\r\nFramveksten av datavitenskap (i Norge) henger tett sammen med framveksten av kunstig intelligens.\r\n\r\n\r\n#sett inn figuren fra disse dataene\r\n#https://trends.google.com/trends/explore?date=all&geo=NO&q=data%20science,Kunstig%20intelligens\r\ndf = read.csv(\"google_searches_ds_ai.csv\", skip = 2, stringsAsFactors = FALSE, fileEncoding = \"UTF-8\")\r\n\r\nnames(df) = c(\"dato\", \"datascience\", \"kunstig intelligens\")\r\ndf = gather(df, searchterm, verdi, datascience:`kunstig intelligens`)\r\ndf$dato = as.Date(paste0(df$dato,\"-\",\"01\"), \"%Y-%m-%d\") #aner ikke hvorfor jeg må legge til en dag, men det fungerer\r\n\r\nqplot(data = df, x = dato, y = verdi, colour = searchterm, group = searchterm, geom = \"line\")+\r\n  labs(colour = \"søkeord\", title =\"Google-søk etter datavitenskap og AI følger hverandre tett\")\r\n\r\n\r\n\r\nEn måte å framstille dette på ble laget allerede i 2010 av Drew Conway, i det etterhvert MYE delte data science vendiagrammet:\r\ndatascience venn diagramDet er altså tre områder som må kombineres i datavitenskap: teknisk kunnskap, statistikk og domeneekspertise. Conway selv har seinere sagt at han ikke tror på enhjørningen - den perfekte utøveren som er ekspert på alle tre. Snarere handler det om å sette sammen et team som er gode på alle områdene. Men den enkelte bør forstå viktigheten av de andre områdene. I hodet mitt er følgende inndeling nyttig:\r\nanalyser med avanserte metoder. Men også standard-analyser kan bruke avanserte metoder.\r\nutvikling av digitale tjenester som bruker kvantitative metoder for å klassifisere eller predikere, og som kjører i “produksjon”.\r\nLittebitt hype…?\r\nGartner har utvikla en “hype cycle”, som (i følge dem selv) skal fortelle noe om fasene en teknologi o.l. går igjennom: innovasjon, for høye forventninger, desillusjon, opplysning og produktivt platå. For data science ser det slik ut:\r\nGartner hype cycle - from trigger through peak expectations, trough of disillusionment, onto the plateau of realismHvor er vi nå? Antakeligvis på hype-stedet fortsatt, i hvert fall i amerikansk forstand. Men hva med Norge? I 2017 starta UMB på Ås som første norske universitet en master i datavitenskap. Ser du på et google-søk også her, ser det ut til å være godt diskutert i diverse medier og bransjeblader de siste årene.\r\nTrender i utlysninger?\r\nMen ta helst ikke mitt ord for det - se på noen data. NAV har publisert historiske stillingsutlysninger, med både vasket stillingstittel, og de 4000 første tegnene av stillingsbeskrivelsen. Strengt tatt er disse også tilgjengelig gjennom et API, men det har jeg sålangt ikke helt funnet ut av (dokumentasjonen sender meg hit.\r\noppdatert 2021: dette datasettet ligger ikke lenger på denne adressa.\r\n\r\n\r\n# henter data fra https://data.nav.no/dataset/utlysningstekster-ledige-stillinger-historikk/resource/882e3e0f-cd3c-4d3a-8072-be7ba7b3d272\r\n\r\n#df = read.csv2(\"https://data.nav.no/dataset/408fc52c-b50e-4ee7-a620-305eaa5d56e7/resource/882e3e0f-cd3c-4d3a-8072-be7ba7b3d272/download/stillingstekster-2018.csv\", stringsAsFactors = FALSE, header = TRUE, fileEncoding = \"UTF-8\")\r\n\r\n#temp = filter(df, grepl(\"data science\", Stillingsbeskrivelse.vasket))\r\n#str(temp)\r\n\r\n\r\n142 stillinger av 212 011? Ikke veldig hype - men heller ikke veldig grundig søkt i teksten.\r\n\r\n\r\n\r\n",
    "preview": "posts/2019-04-05-norsk-data-science/norsk-data-science_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2023-11-19T21:23:01+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-03-31-prognosekonkurranse-eliteserien-2019/",
    "title": "Eliteserien 2019 - hvordan blir tabellen til slutt?",
    "description": "Noen enkle eksplorerende analyser av ekspertmeninger for en konkurranse om å gjette plasseringer i eliteserien 2019.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2019-03-31",
    "categories": [],
    "contents": "\r\nHvert år arrangerer noen på kontoret en Eliteserie-tippeligakonkurranse. Jeg veit lite om fotball-lagene, og har aldri tippet noe særlig - men pleier å gjøre det greit, basert på andres harde arbeid: eksperter og odds.\r\nHer bruker jeg tidyverse, knitr og here-pakka, og en egenprodusert tabell over ulike tips til tabellplasseringer. Her har jeg også lagt på et superenkelt gjennomsnitt av lagene, for å ha noe å sortere dem etter.\r\n\r\nLag\r\nNettavisen\r\nOddschecker\r\nDagsavisen\r\nDagbladet\r\nAftenposten\r\nResultat\r\ngjennomsnitt\r\nMolde\r\n2\r\n2\r\n1\r\n1\r\n1.2\r\n1\r\n1.44\r\nRosenborg\r\n1\r\n1\r\n2\r\n3\r\n1.8\r\n3\r\n1.76\r\nBrann\r\n3\r\n3\r\n5\r\n2\r\n3.2\r\n9\r\n3.24\r\nSarpsborg 08\r\n4\r\n4\r\n3\r\n5\r\n6.2\r\n12\r\n4.44\r\nVålerenga\r\n5\r\n5\r\n4\r\n4\r\n8.0\r\n10\r\n5.20\r\nKristiansund BK\r\n6\r\n9\r\n7\r\n9\r\n8.0\r\n6\r\n7.80\r\nHaugesund\r\n7\r\n7\r\n10\r\n8\r\n8.0\r\n7\r\n8.00\r\nOdd\r\n8\r\n10\r\n9\r\n6\r\n8.0\r\n4\r\n8.20\r\nLillestrøm\r\n10\r\n11\r\n6\r\n7\r\n8.0\r\n14\r\n8.40\r\nStrømsgodset\r\n9\r\n6\r\n15\r\n12\r\n9.4\r\n11\r\n10.28\r\nBodø/Glimt\r\n15\r\n12\r\n8\r\n10\r\n8.0\r\n2\r\n10.60\r\nTromsø\r\n11\r\n8\r\n13\r\n15\r\n9.4\r\n15\r\n11.28\r\nStabæk\r\n13\r\n14\r\n11\r\n14\r\n11.8\r\n8\r\n12.76\r\nRanheim\r\n12\r\n15\r\n16\r\n11\r\n11.4\r\n16\r\n13.08\r\nViking\r\n14\r\n13\r\n12\r\n16\r\n14.4\r\n5\r\n13.88\r\nMjøndalen\r\n16\r\n16\r\n14\r\n13\r\n13.6\r\n13\r\n14.52\r\n\r\nKilder:\r\nNordicBet\r\n- Nettavisen\r\n- Tidens Krav\r\n- Oddschecker\r\n- Dagsavisen\r\n- Dagbladet\r\n- Aftenposten.\r\nAftenposten-plasseringa er litt annerledes enn de øvrige, ettersom de har spurt fem eksperter om topp tre og bunn tre. Jeg har bare tatt gjennomsnittene av dette.\r\nI en ideell verden skulle jeg også gjerne hatt med lagenes budsjetter. Det har jeg imidlertid ikke klart å skrape sammen, så det får være en god ide til seinere.\r\nEn måte å vise plasseringene på, er med en fargelagt tabell. Her ser vi enklere enn med de rene tallene at det er nokenlunde stor enighet om de øverste fire-fem lagene, og de fire-fem nederste. Hvilke lag som blir plassert hvor blant de seks i midten varierer imidlertid mer.\r\n\r\n\r\n#eksperiment med en heatmap-table\r\ntemp = gather(df,kilde,plassering,Nettavisen:gjennomsnitt)\r\n\r\nggplot(data = temp, aes(x=as.factor(kilde), y = fct_reorder(as.factor(Lag), plassering, .fun = mean, .desc = TRUE)))+\r\n  geom_tile(aes(fill = plassering))+\r\n  labs(x = \"Kilde\", y = \"Lag\", title = \"Molde og Rosenborg i topp, Mjøndalen og Viking i bunn\")+\r\n  scale_fill_gradient2(low = \"steelblue\", mid = \"grey\", high = \"orange\", midpoint = 8)\r\n\r\n\r\n\r\nHer har jeg altså 16 lag med fem tips per lag. Varmekartet gir et raskt overblikk, menen ganske diffus oversikt over de faktiske spredningene for de enkelte lagene.\r\n\r\n\r\nggplot(data = filter(temp, kilde != \"gjennomsnitt\"), aes(x = fct_reorder(as.factor(Lag), plassering, .fun = mean, .desc = TRUE), y = plassering)) + \r\n  #her bruker vi et boksplot for å vise variasjonen i plasseringer for hvert enkelt lag, men gjør det gjennomsiktig\r\n  geom_boxplot(alpha=0) +\r\n  #det er heller ikke flere punkter for hvert enkelt lag enn at en kan vise alle.\r\n  geom_jitter(color=\"steelblue\",alpha=0.3) +\r\n  labs(x = \"Lag\", y = \"Plassering\", title = \"Stor variasjon i tips for lag midt på tabellen\", subtitle = \"Større enighet om topp og bunn\") + \r\n  coord_flip()\r\n\r\n\r\n\r\nHer ser vi tydeligere at konsensusen er størst om de øverste lagene. De lavere lagene på den nedre halvdelen av tabellen har større spredning i tabellposisjoner. Det ser en av spredningen på punktene, og størrelsen på boksene. Særlig Strømsgodset splitter folk.\r\nBoksplottene viser medianen som midtpunkt. Her får en fram at Ranheim havner på kvalifiseringsplass om en legger gjennomsnitt til grunn, fordi en av ekspertene har svært lave forventninger til laget. Medianen legger dem imidlertid på fjerde siste plass, og lar Stabøk gå ned i stedet. Er det mer fornuftig å la ekstre stemmer telle likt, eller skal en heller legge vekt på konsensuspunktet?\r\n…\r\nJeg har ikke den fjerneste anelse. Da velger jeg det enkleste, og går for gjennomsnittet som mitt innspill til årets tippekonkurranse.\r\n\r\n\r\n\r\n",
    "preview": "posts/2019-03-31-prognosekonkurranse-eliteserien-2019/prognosekonkurranse-eliteserien-2019_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2023-11-19T21:19:46+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-03-24-eksempler-p-bruk-av-imdis-api/",
    "title": "Eksempler på bruk av IMDis API",
    "description": "Dette var en innføring i bruk av IMDis udokumenterte API. Siden det er uklart om de fortsatt støtter slik udokumentert fremferd, er koden tatt vekk.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2019-03-24",
    "categories": [],
    "contents": "\r\nIMDis tall og statistikk-nettsider henter dataene sine om innvandring og integrering i kommuner, fylker og Norge fra et API.\r\nAPIet er dessverre ikke dokumentert, men lar seg enkelt utforske ved hjelp av en nettleser-konsoll, f.eks. i Chrome. Her kommer et kort forsøk på litt forklaring. Datasettet bruker NLOD-lisensen. (Det gjorde i hvert fall det i 2019, men sjekk gjerne med IMDis nettsider om det har skjedd endringer).\r\nInnhold i datasettet\r\nDatasettet har informasjon om innvandrere og integrering på en rekke områder i norske kommuner, næringsregioner, fylker, hele landet og bydeler i Oslo, og er tilgjengelig med NLOD-lisens (se nederst for lisens-betingelser). Noe kommer fra IMDi, men mesteparten kommer fra Statistisk sentralbyrå (SSB).\r\nIMDi tilgjengeliggjør dataene fra nettsidene i et krysstabellformat som er uhensiktsmessig for analyseformål, og dataene tilgjengeliggjøres derfor her (som et privat prosjekt) i et flatt format.\r\nEn advarsel: Datasettene er kodet, og kodeboka er foreløpig ikke en del av dette repoet. Beskrivelser av data skal egentlig være tilgjengelig fra et API fra IMDi.no (“http://imdi.no/api/indikatorcarddescriptions” og “http://imdi.no/api/indikatordimensions”), men det ser p.t. ikke ut til å være tilfelle.\r\nResten av innholdet fjernet.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-19T21:07:00+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-03-17-visualisering-av-andeler-i-ggplot2/",
    "title": "visualisering av andeler med ggplot2",
    "description": "Presentasjon av ggplot2-kode for å visualisere andeler som kakediagram, vaffeldiagram og stabla søylediagram",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2019-03-17",
    "categories": [],
    "contents": "\r\nEn vanlig feil i datavisualiseringer er å bruke teknikker ment for andelsdata, på data som ikke er andeler. Visualiseringer som er egna for andeler er blant annet:\r\nkakediagram/paidiagram: brukes når du vil ha en kompakt framvisning av andeler for inntil 3 kategorier på en variabel.\r\nvaffeldiagram: brukes hvis du vil ha framvisning av andeler for flere enn 3 kategorier på en variabel\r\nstablede søylediagram: brukes hvis du vil ha en framvisning av andeler for inntil 3 kategorier for flere grupper.\r\nSå hva gjør du med andeler hvis du har flere enn 3 kategorier som du vil se for flere ulike grupper eller over tid? Da må du bare prøve deg fram.\r\n\r\n\r\n\r\n###Eksempeldata fra SSBs åpne API.\r\nEksempeldataene henter jeg fra ssb.no, hvor jeg ser at fylkeskommunale regnskapstall er tilgjengelig. Byråkrathurra! Jeg har ikke stor peiling på fylkeskommunale regnskap, men ser at en kan få ut brutto driftsutgifter fordelt på generelle tjenesteområder, for de ulike regionene. I disse regionreform-tider er vel fylkeskommunal pengebruk et hett tema? Kanskje ikke - jeg vil tippe det er mye vei, transport, videregående skole og kanskje littebitt tannlege her.\r\n\r\n\r\n#henter data med PxWebApiData::ApiData\r\nalle_data = ApiData(\"https://data.ssb.no/api/v0/no/table/12163\",\r\n             KOKfylkesregion0000 = TRUE,\r\n             KOKfunksjon0000 = c(\"FGF1a\", \"FGF1b\", \"FGF1c\", \"FGF2\", \"FGF3\", \"FGF4\", \"FGF5\", \"FGF6a\", \"FGF7\", \"FGF8\"), \r\n             KOKart0000 = \"AGD10\",\r\n             ContentsCode = \"KOSandel3501\",\r\n             Tid = \"2018\"\r\n)\r\n\r\n#ApiData() returnerer både koder og menneskelesbar tekst, jeg går for tekst denne gangen\r\ndf <- alle_data[[1]] %>%\r\n  select(.,-art,-statistikkvariabel,-`år`) #filtrerer ut unødvendig info\r\n\r\n\r\n##Kakediagram (paidiagram / sektordiagram)\r\nDet første en lærer når en begynner å kikke mer på datavisualisering er at kakediagram er onde. Imidlertid har nyere (2016-ish) forskning vist at de ikke er så dårlige som ryktet skal ha det til. De blir gjerne beskyldt for å kode data som vinkler, noe folk ikke er gode på å se. Forskninga til Kosara sitert i forrige lenke viser at det enten er området eller en eller annen lengde som leses, kanskje en kombinasjon - og at de gjør det bedre enn andre alternativ.\r\n\r\n\r\n#I tråd med pai-hatet, mangler det en egen geom_pie i ggplot. \r\n#For å få det til må du derfor summere opp ting til totale antall, \r\n#plotte dette som et søylediagram med x=1, \r\n#og så justere coord_polar til y. \r\n\r\ntemp <- filter(df,region==\"Landet uten Oslo\")\r\n\r\nggplot(data = temp, aes(x = 1, y = value, fill = funksjon)) +\r\n  geom_col()+\r\n  coord_polar(theta=\"y\")+\r\n  theme_void()+\r\n  ggtitle(\"Fylkeskommunal pengebruk etter område\", subtitle = \"Alle unntatt Oslo\")\r\n\r\n\r\n\r\nDet virker rimelig å si at om du har mer enn noen få biter (tre ser ut til å være et tips), så blir figuren vanskelig å lese. Over ser vi tydelig at videregående opplæring og samferdsel er de største postene, antakeligvis fulgt av eiendomsforvaltning. Men så? Siden det er vanskelig å lese dem presist, egner de seg ikke for svært (men ikke helt) like andeler.\r\nFordelen er at de er kompakte og intuitive, når de brukes riktig:\r\n\r\n\r\n\r\n##Vaffeldiagram\r\nEt vaffeldiagram (waffel chart) kan være mer presist enn et kakediagram, og koder helt klart data som område, ikke vinkler eller vinkler i kombinasjon med noe annet.\r\nFiguren tåler ikke urimelige mengder klasser. Den tar også litt mer plass enn paien, men det er jo fordi en viser mer informasjon.\r\nEksempelet her har 10x10 ruter. Det trenger andelene direkte, så om du ikke har de, må du regne dem ut - eller som i mitt tilfelle, om du har avrudningsfeil, må du komme deg rundt det på no vis.\r\n\r\n\r\n#litt databearbeiding først - filtrering, sortering og avrunding\r\ntemp <- filter(df,region==\"Landet uten Oslo\")%>%\r\n  arrange(.,desc(value))%>%\r\n  mutate(.,andel = round(value,0))\r\n\r\n#waffle() tar en \"named vector\"\r\nandel_utgifter = temp$andel\r\nnames(andel_utgifter) = temp$funksjon\r\n\r\n#så selve plottinga\r\nwaffle(andel_utgifter, \r\n        colors=qualitative_hcl(10,\"Dark 3\"), \r\n        xlab=\"1 rute = 1 prosent\", \r\n        title= \"Fylkeskommunale utgifter etter område\", \r\n        legend_pos=\"right\")\r\n\r\n\r\n\r\nPå grunn av fargevalget er ikke denne mye lettere å lese. Men med litt tid på seg til å velge ut 10 forskjellige farger (eller noe mer sammenslåing av kategorier), kunne det blitt lettere å se at\r\n44 prosent av utgiftene for fylkeskommuner er i snitt til videregående,\r\nlike over 30 prosent går til samferdsel,\r\nderetter kommer eiendomsforvaltning med 6 prosent,\r\ntannhelse og administrasjon ligger på 4 prosent,\r\nnæringsforvaltning og div andre kommer på 2 prosent,\r\nmer administrative utgifter ligger på 1 prosent.\r\nStablet søylediagram\r\nMed kakediagram kommer en langt med å se på andeler på en variabel. Men hva hvis en vil sammenlikne andelene mellom ulike grupper? Du kunne prøvd deg med flere paidiagram eller vaffeldiagram etter hverandre - men de er bygd for intern sammenlikning, ikke sammenlikning på tvers, og tar en del plass.\r\nStablede søylediagram egner seg her. De kan gi mer kompakt informasjon av andeler innenfor ulike grupper mellom ulike enheter (som f.eks. andelen med sykdom x i land A og B) enn det kakediagram og vaffeldiagram kan.\r\nMed tittelen “Stacked bars are the worst!” mer enn antyder Kosara hva han synes om slike diagrammer. Forskningen han siterer ser ut til å handle om bruk av stablede søyler for verdier som ikke er prosenter, men det betyr ikke at de er veldige gode bare fordi dette er prosenter.\r\nDet er altså vanskelig å vurdere flere ulike grupper mot hverandre innad i samme enhet (som f.eks. andelen med sykdom x, y og z i land A). Bruk dem ikke alene for en gruppe, bruk ikke mange ulike (men nesten like) kategorier innad i hver stabla søyle. Og siste tips: Pass på hvilke kategorier som får verdifull plass nederst og øverst, hvor det er mulig å lese ut størrelsen. Det kan gjøres ved å endre rekkefølgen på kategorier som faktorer.\r\n\r\n\r\n#litt databearbeiding først\r\n#her er vi interessert i alle fylkeskommunene og gjennomsnittet for landet uten Oslo,\r\n#vi vil også ha maks tre kategorier, \r\n#og sortert slik (via factor-levels) at videregående kommer nederst\r\n#regionene skal være sortert etter størrelsen på budsjettet til vgs\r\n#litt usikker på hvordan fct_reorder2 får til det, men det virker\r\n\r\ntemp <- filter(df, grepl(\"fylkeskommune\",region)|region==\"Landet uten Oslo\") %>%\r\n  mutate(.,\r\n         funksjon_summert = ifelse(funksjon %in% c(\"Videregående opplæring samlet\", \"Samferdsel, fylkeskommune\"), funksjon, \"Andre\"),\r\n         funksjon_summert = factor(funksjon_summert,levels=c(\"Andre\",\"Samferdsel, fylkeskommune\",\"Videregående opplæring samlet\")),\r\n         region = str_replace(region,fixed(\"fylkeskommune\"),replacement=\" \")\r\n         )%>%\r\n  group_by(.,region,funksjon_summert) %>%\r\n  summarise(.,andel = sum(value)) \r\n\r\n# %>% ungroup() %>%\r\n#   mutate(., region = fct_reorder2(region, as.numeric(funksjon_summert), andel))\r\n\r\nggplot(data=temp)+\r\n  geom_col(aes(x=region,y=andel,fill=funksjon_summert),position=\"fill\") +\r\n  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + \r\n  labs(fill=\"Funksjon\")\r\n\r\n\r\n\r\nOslo er et særtilfelle, som gjør figurverdien misvisende - andelene utgifter i fylket summerer til 11 prosent, i motsetning til de fleste andre. Men position=“fill” gjør at alle settes til å fylle opp til 100 % i figuren.\r\nHva lærer vi av dette? Kanskje ikke så mye. Noen fylker ligger over landssnittet på 44 % av utgiftene til videregående, og noen ligger ganske langt under - og da er det hovedsaklig samferdsel som tar plassen som største utgiftspost. At det dermed er flate Østlands- og sørlandsfylker som bruker en større del på videregående, og vestlands- og Nord-Norge som bruker mer på samferdsel virker intuitivt rimelig.\r\n\r\n\r\n\r\n",
    "preview": "posts/2019-03-17-visualisering-av-andeler-i-ggplot2/visualisering-av-andeler-i-ggplot2_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2023-11-19T21:01:31+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-03-16-introduksjon-til-materiale-om-datavisualsering/",
    "title": "Hvordan lære datavisualisering?",
    "description": "Noen pekere til hva som kan være kvalitetskriterier for vurdering av læremateriell om datavisualisering.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2019-03-16",
    "categories": [],
    "contents": "\r\nInteressert i å lære grunnleggende data-visualisering, enten i R eller i et anna verktøy? Ser du etter bøker eller nettkurs? Min erfaring er at det følgende er viktige kriterier for om noe skal være bra:\r\nDet må være kunnskapsbasert. Selv om det er helt voldsomt mye gratis tilgjengelig et google-søk unna, betyr det også at det kan ta tid å luke ut det gode fra det vonde, skille snørr og kanel, og så videre. Når du skal velge et kurs, pass på at kurset har referanser til ny forskningslitteratur og en begrunna “beste praksis”.\r\nDet må være oppdatert. Etter hvert begynner en del tutorials å bli utdaterte. Særlig ggplot2 og tidyverse har utvikla seg med årene, og tidlige eksempler bruker gjerne bare base-funksjoner (uten at jeg skal starte den diskusjonen).\r\nDet kan gjerne være redskaps-agnostisk.\r\nOppgavefokusert, ikke teknikk-fokusert- Det bør være fokusert på oppgavene du skal gjøre, og ikke teknikken. At du kan tegne linjediagram er flott, men i en praktisk setting sitter du med data som har visse egenskaper - og ønsker å se på disse egenskapene.\r\nOppdatering april 2019: Bruk tida di et annet sted enn på DataCamp.\r\nSelskapet har problemer med seksuell trakasering, og rutinere for å håndtere det. R Weekly har noen lenker her og her om saken. Det viser seg at DataCamp her prøver å løse et problem med en svært problematisk blogg, mens de burde endra policy. Julia Silge og RStudio er blant de som har reagert - for ikke å glemme instruktøren for kurset jeg lenker til over, Nick Strayer.\r\nStrayer har har via Twitter oppfordra folk til å gå et annet sted. Han anbefaler Claus Wilkes bok Fundamentals of Data Vizualization, som er åpent tilgjengelig på internett (via bookdown).\r\nJeg har ikke sett på denne boka, men den ser ut til å oppfylle kravene mine for et godt visualiseringskurs:\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-19T20:53:23+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-03-05-grunnleggende-overlevelsesanalyse/",
    "title": "Grunnleggende overlevelsesanalyse",
    "description": "Helt grunnleggende teknikker for det som er kjent som survival-analyse, forløpsanalyse eller event history -analyse.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2019-03-05",
    "categories": [],
    "contents": "\r\nOverlevelsesanalyse, eller survival, eller event history analysis er en analyse av tid-til-hendelse (time-to-event). Med denne metoden kan en estimere sannsynligheten for at en hendelse vil inntreffe på tidspunkt T. Det er ikke bare overlevelse eller død dette egner seg for, men de fleste ulike typer hendelse. Det klassiske ikke-sykdomseksempelet ser ut til å være tidspunkt for når en maskin bryter sammen (eller dør, om du vil).\r\nDen følgende teksten er inspirert av “Steps to perform survival analysis in R og MainDonald og Braun (2003) “Data analysis and graphics using R”. Den ble skrevet litt før jeg deltok på et lengre kurs, så det er litt grunnleggende.\r\nKort om overlevelsesanalyse\r\nOverlevelsesfunksjonen til en variabel X er definert som sannsynligheten for at variabelen er større enn x. X er gjerne tid, slik at overlevelsesfunksjonen gir sannsynligheten for at en person eller et objekt vil “overleve” lenger enn et gitt tidspunkt, i betydningen ikke få en eller annen status/hendelse, som tar enheten ut av observasjonsrekken.\r\nEn kunne sett for seg å løse dette med klassisk regresjon. Men Hastie (2013) beskriver survival analysis som et spesialtilfelle av regresjon for avhengige variabler som kun delvis er observert for noen individer - dvs. data som er “censored”. F.eks. kan en se for seg en studie som har fulgt individer fra dag 0 til dag 200. Individ A fikk f.eks. oppvåkning på dag 72. Individ B hadde enda ikke fått noen oppvåkning på dag 200. Denne observasjonen er da “right censored” - vi kjenner ikke forløpet til høyre (på en tidsakse fra venstre mot høyre) for denne enheten, men ønsker fortsatt å bruke informasjonen fra individet i studien. I et datasett for klassisk regresjon ville disse observasjonene vært missing - vi vet jo ikke hvor lenge de faktisk har overlevd.\r\nEn del av de samme antakelsene og utfordringene møter denne analyseformen, som klassisk regresjon: antakelser om uavhengige individer, og at censoring er ikke-informativt: det er ingen forskjeller i sannsynlighet for utfallet mellom personer som censoreres og ikke-censoreres\r\nDet er noen ulike teknikker som er relevante:\r\nKaplan-Meier-kurve for å estimere overlevelsesfunksjonen\r\nCox proportional hazard model for å estimere overlevelse med kontinuerlige variabler\r\nestimering av survival-funksjon med trær eller forest\r\nlog-rank-test\r\nVi bruker pbc-datasettet fra survival-pakken som eksempeldata.\r\n\r\n\r\n#survival-pakken er grunnleggende, og kommer med R\r\nlibrary(survival)\r\nsuppressPackageStartupMessages(library(tidyverse))\r\n\r\n#eksempel-datasettet Primary Biliary Cirrhosis (pbc)\r\n?pbc\r\npbc = pbc\r\nstr(pbc)\r\n\r\n'data.frame':   418 obs. of  20 variables:\r\n $ id      : int  1 2 3 4 5 6 7 8 9 10 ...\r\n $ time    : int  400 4500 1012 1925 1504 2503 1832 2466 2400 51 ...\r\n $ status  : int  2 0 2 2 1 2 0 2 2 2 ...\r\n $ trt     : int  1 1 1 1 2 2 2 2 1 2 ...\r\n $ age     : num  58.8 56.4 70.1 54.7 38.1 ...\r\n $ sex     : Factor w/ 2 levels \"m\",\"f\": 2 2 1 2 2 2 2 2 2 2 ...\r\n $ ascites : int  1 0 0 0 0 0 0 0 0 1 ...\r\n $ hepato  : int  1 1 0 1 1 1 1 0 0 0 ...\r\n $ spiders : int  1 1 0 1 1 0 0 0 1 1 ...\r\n $ edema   : num  1 0 0.5 0.5 0 0 0 0 0 1 ...\r\n $ bili    : num  14.5 1.1 1.4 1.8 3.4 0.8 1 0.3 3.2 12.6 ...\r\n $ chol    : int  261 302 176 244 279 248 322 280 562 200 ...\r\n $ albumin : num  2.6 4.14 3.48 2.54 3.53 3.98 4.09 4 3.08 2.74 ...\r\n $ copper  : int  156 54 210 64 143 50 52 52 79 140 ...\r\n $ alk.phos: num  1718 7395 516 6122 671 ...\r\n $ ast     : num  137.9 113.5 96.1 60.6 113.2 ...\r\n $ trig    : int  172 88 55 92 72 63 213 189 88 143 ...\r\n $ platelet: int  190 221 151 183 136 NA 204 373 251 302 ...\r\n $ protime : num  12.2 10.6 12 10.3 10.9 11 9.7 11 11 11.5 ...\r\n $ stage   : int  4 3 4 4 3 3 3 3 2 4 ...\r\n\r\nPBC-datasettet har 418 observasjoner av 20 variabler. 312 personer deltok i en RCT, mens data ble også samlet om 106 personer til (6 personer falt fra).\r\nstatus: censored (0), transplant (1), dead (2)\r\ntime: dager mellom registrering og endelig status\r\n\r\n\r\nqplot(time,data=pbc)\r\n\r\n\r\nqplot(as.factor(status),data=pbc)\r\n\r\n\r\nqplot(as.factor(status),time,data=pbc,geom=\"boxplot\",group=status)\r\n\r\n\r\n\r\nKaplan-Meier\r\nStarter med Surv()-funksjonen, som lager et survival-objekt som kan brukes som avhengig variabel i en modell. survfit()-funksjonen kan så brukes til å finne Kaplan-Meier-estimatoren og plotte en survival-kurve. (språkbruk?)\r\n\r\n\r\n#en kikk på Surv-objektet\r\npbc_survival = Surv(pbc$time,pbc$status==2)\r\nstr(pbc_survival)\r\n\r\n 'Surv' num [1:418, 1:2]  400  4500+ 1012  1925  1504+ 2503  1832+ 2466  2400    51  ...\r\n - attr(*, \"dimnames\")=List of 2\r\n  ..$ : NULL\r\n  ..$ : chr [1:2] \"time\" \"status\"\r\n - attr(*, \"type\")= chr \"right\"\r\n\r\n#så survfit\r\nsurvival_func=survfit(Surv(time,status==2)~1,data=pbc)\r\nsurvival_func\r\n\r\nCall: survfit(formula = Surv(time, status == 2) ~ 1, data = pbc)\r\n\r\n       n events median 0.95LCL 0.95UCL\r\n[1,] 418    161   3395    3090    3853\r\n\r\nHer får vi ut n, antall positive statuser (død - så språket mister litt mening her etter hvert, når modelleringsspråk kolliderer med vanlige betydninger), median tid-til-event (3 395 dager til død), og 95 % konfidensintervaller rundt medianen. Vi kan plotte funksjonen med base plot.\r\n\r\n\r\nplot(survival_func)\r\n#dessverre ingen enkel mulighet for å plott survfit-objektet direkte. Prøver survminer-pakken.\r\nsurvminer::ggsurvplot(survival_func)\r\n\r\n\r\n#dette viser seg å være temmelig unødig, det kan likegreit fikses med broom og ggplot2\r\n\r\nggplot(data = broom::tidy(survival_func), aes(x = time, y = estimate))+\r\n  geom_line() +\r\n  geom_ribbon(aes(ymin=conf.low,ymax=conf.high),alpha=0.2)+\r\n  ggtitle(\"Kaplan-Meier survival curve\")\r\n\r\n\r\n\r\nY-aksen viser sannsynlighet for overlevelse (ikke oppleve status==2), mens x-aksen viser tid i dager. Sannsynligheten for å overleve går ned med tid (og sannsynligheten for å dø går opp). F.eks. er sannsynligheten for å overleve mer enn 1000 dager ca. 80 %.\r\nDenne bygger på antakelsen om at individene er uavhengige, og er en estimering av den underliggende overlevelsesfunksjonen, som teoretisk sett er glatt.\r\nCox proportional hazard model\r\nForskjellen mellom survfit()/Kaplan-Meier og Cox Proportional Hazard Model er…\r\nCox-modellen aksepterer ikke missing-verdier.\r\n\r\n\r\n#kan estimere en cox-model med kun intercept også\r\ncox_model = coxph(Surv(time,status==2)~1,data=pbc)\r\nsummary(cox_model)\r\n\r\nCall:  coxph(formula = Surv(time, status == 2) ~ 1, data = pbc)\r\n\r\nNull model\r\n  log likelihood= -873.4721 \r\n  n= 418 \r\n\r\n#for å lage en survival kurve fra en cox-model må den mates inn i survfit()\r\ncox_curve_0 = survfit(cox_model)\r\ncox_curve_0\r\n\r\nCall: survfit(formula = cox_model)\r\n\r\n       n events median 0.95LCL 0.95UCL\r\n[1,] 418    161   3395    3090    3853\r\n\r\nplot(cox_curve_0)\r\n\r\n\r\n\r\nMen cox-modellen kan også brukes til å estimere en modell. Her er en enkel kjøkkenvask-modell (alle variabler som uavhengige variabler) for pbc-datasettet.\r\n\r\n\r\ncox_model = coxph(Surv(time,status==2)~.,data=pbc)\r\nsummary(cox_model)\r\n\r\nCall:\r\ncoxph(formula = Surv(time, status == 2) ~ ., data = pbc)\r\n\r\n  n= 276, number of events= 111 \r\n   (142 observations deleted due to missingness)\r\n\r\n               coef  exp(coef)   se(coef)      z Pr(>|z|)   \r\nid       -2.729e-03  9.973e-01  1.462e-03 -1.866  0.06203 . \r\ntrt      -1.116e-01  8.944e-01  2.156e-01 -0.518  0.60476   \r\nage       3.191e-02  1.032e+00  1.200e-02  2.659  0.00784 **\r\nsexf     -3.822e-01  6.824e-01  3.074e-01 -1.243  0.21378   \r\nascites   6.321e-02  1.065e+00  3.874e-01  0.163  0.87038   \r\nhepato    6.257e-02  1.065e+00  2.521e-01  0.248  0.80397   \r\nspiders   7.594e-02  1.079e+00  2.448e-01  0.310  0.75635   \r\nedema     8.860e-01  2.425e+00  4.078e-01  2.173  0.02980 * \r\nbili      8.038e-02  1.084e+00  2.539e-02  3.166  0.00155 **\r\nchol      5.151e-04  1.001e+00  4.409e-04  1.168  0.24272   \r\nalbumin  -8.511e-01  4.270e-01  3.114e-01 -2.733  0.00627 **\r\ncopper    2.612e-03  1.003e+00  1.148e-03  2.275  0.02290 * \r\nalk.phos -2.623e-05  1.000e+00  4.206e-05 -0.624  0.53288   \r\nast       4.239e-03  1.004e+00  1.941e-03  2.184  0.02894 * \r\ntrig     -1.228e-03  9.988e-01  1.334e-03 -0.920  0.35741   \r\nplatelet  7.272e-04  1.001e+00  1.177e-03  0.618  0.53660   \r\nprotime   1.895e-01  1.209e+00  1.128e-01  1.680  0.09289 . \r\nstage     4.468e-01  1.563e+00  1.784e-01  2.504  0.01226 * \r\n---\r\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r\n\r\n         exp(coef) exp(-coef) lower .95 upper .95\r\nid          0.9973     1.0027    0.9944     1.000\r\ntrt         0.8944     1.1181    0.5862     1.365\r\nage         1.0324     0.9686    1.0084     1.057\r\nsexf        0.6824     1.4655    0.3736     1.246\r\nascites     1.0653     0.9387    0.4985     2.276\r\nhepato      1.0646     0.9393    0.6495     1.745\r\nspiders     1.0789     0.9269    0.6678     1.743\r\nedema       2.4253     0.4123    1.0907     5.393\r\nbili        1.0837     0.9228    1.0311     1.139\r\nchol        1.0005     0.9995    0.9997     1.001\r\nalbumin     0.4270     2.3422    0.2319     0.786\r\ncopper      1.0026     0.9974    1.0004     1.005\r\nalk.phos    1.0000     1.0000    0.9999     1.000\r\nast         1.0042     0.9958    1.0004     1.008\r\ntrig        0.9988     1.0012    0.9962     1.001\r\nplatelet    1.0007     0.9993    0.9984     1.003\r\nprotime     1.2086     0.8274    0.9690     1.508\r\nstage       1.5634     0.6397    1.1020     2.218\r\n\r\nConcordance= 0.849  (se = 0.018 )\r\nLikelihood ratio test= 171.3  on 18 df,   p=<2e-16\r\nWald test            = 172.5  on 18 df,   p=<2e-16\r\nScore (logrank) test = 286.1  on 18 df,   p=<2e-16\r\n\r\ncox_curve = survfit(cox_model)\r\nplot(cox_curve)\r\n\r\n\r\n\r\nHvordan skal survival-plottet her forstås? Det er fortsatt avtakende sannsynlighet for overlevelse med tid, men med større konfidensintervaller mot slutten (naturlig, ettersom nesten halvparten av observasjonene faller bort som missing). Men for hvilke verdier av de uavhengige variablene? De faktiske verdiene?\r\nSurvival in the forest\r\nLitt usikker på hva som vil være fordeler og ulemper med å benytte trær og random forest-estimering her, så lar det ligge til jeg har forstått det grunnleggende ellers. Et grunnleggende skille vil jo være at cox-regresjon antar en lineær modell, mens trær ikke gjør det.\r\nSammenligning av modeller\r\n\r\n\r\n#kunne vært en ide å bruke broom her for å rydde litt...?\r\n#merk at det som i survfit-objektet er surv, er estimate i broom-dfen\r\ntest = data.frame(cox_curve$surv,broom::tidy(cox_curve)$estimate)\r\nhead(test)\r\n\r\n  cox_curve.surv broom..tidy.cox_curve..estimate\r\n1      0.9990059                       0.9990059\r\n2      0.9978760                       0.9978760\r\n3      0.9966940                       0.9966940\r\n4      0.9955020                       0.9955020\r\n5      0.9942870                       0.9942870\r\n6      0.9930705                       0.9930705\r\n\r\n#setter de sammen\r\nmodeller = bind_rows(cox_0 = broom::tidy(cox_curve_0),cox_alle = broom::tidy(cox_curve),km = broom::tidy(survival_func),.id=\"modell\")\r\n\r\nggplot(data = modeller, aes(x = time, y = estimate, color = modell))+\r\n  geom_line() +\r\n  geom_ribbon(aes(ymin=conf.low,ymax=conf.high),alpha=0.2)+\r\n  ggtitle(\"Sammenlikning av Survival Curves\")\r\n\r\n\r\n\r\nCox-modellen med alle variablene har en høyere sannsynlighet for overlevelse i starten, men den faller brattere, og har større konfidensintervaller. Null-modellen med cox er så godt som lik Kaplan-Meier-kurven.\r\n\r\n\r\n\r\n",
    "preview": "posts/2019-03-05-grunnleggende-overlevelsesanalyse/grunnleggende-overlevelsesanalyse_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2023-11-19T20:48:07+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-03-01-halvmigrering-til-huga/",
    "title": "Halvmigrering til Huga",
    "description": "Migrering av poster fra wordpress til Blogdown.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2019-03-01",
    "categories": [],
    "contents": "\r\nEtter å ha latt bloggen min Kontext ligge i regneregne fem og et halvt år, våknet jeg opp en morgen og tenkte: på tide å skrive noe på internett!\r\nNår jeg kikka på GitHub-repoene mine, innså jeg at flere av dem begynte å likne på blogg-artikler om ymse temaer. I morgen-ørska på bussen snubla jeg så over en artikkel om å flytte bloggen din til Blogdown. Siden jeg allerede bruker R som go-to-verktøy for ymse ting, virket dette rimelig.\r\nSkulle jeg da migrere alle de gamle postene fra wordpress-bloggen? En liten kikk i blogdown-dokumentasjonen tilsa nei. Jeg kopierte derfor heller over de tekstene jeg var spesielt fornøgd med, heller enn å finne igjen gamle innloggingsdetaljer og kaste meg over en aldri så liten terskel i Python-basert XML-rensing.\r\nSiden denne bloggen p.t. redigeres i RStudio med blogdown, pushes til GitHub, hvor den så auto-synces med Netlify, er den basert på RMarkdown. Det er et flott tekstverktøy som tillater innebygde R-skrevne analyser. Så derfor heter bloggen noe med analyser.\r\nTittelen, sier du? Hvor kommer suppa inn? Vel, egentlig var jeg også på utkikk etter et sted å legge alle de ørten matoppskriftene jeg har samla opp. Det ser enn så lenge ikke ut til at dette Hugo-temaet åpner for så mye fancy i den retningen. Vi får se.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-19T20:43:27+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2013-09-03-fordeling-av-mandater-ved-stortingsvalg/",
    "title": "Hvordan fordeles mandater ved stortingsvalg?",
    "description": "En liten gjennomgang av mandatfordelinger i anledning valget.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2013-09-03",
    "categories": [],
    "contents": "\r\nDemokrati er som vi alle veit vanskelig på flere plan – ikke minst når en snakker om praktisk gjennomføring. For hvordan fungerer egentlig Stortingsvalget? Med kun seks små dager igjen til valget, kan det være greit å ta noen skritt tilbake og huske på hvordan et valg faktisk ser ut.\r\nFor det første: Alle som stemmer, stemmer i fylket hvor de er folkeregistrerte. Osloborgere velger en liste fra et parti som stiller til valg i Oslo, trøndere velger på lister som stilles i Sør- eller Nord-Trøndelag.Du stemmer altså ikke på landsbasis, men på fylkesbenken din.\r\nFor det andre: Mandatene fordeles med en matematisk metode. Når stemmene til de ulike partiene i et fylke er talt opp, fordeles disse ved hjelp av den såkalte St. Laguës modifiserte metode. Hvert enkelt partis totale antall stemmer deles på tallene 1.4, 3, 5, 7, 9, osv (kalt delingstall). Mandatene fra et fylke går så til partiene med de høyeste tallene. Et eksempel, basert på stemmetall fra Oslo i 2009:\r\nFor det tredje, kandidater kan strykes og flyttes på lista. For at dette skal ha en effekt, må halvparten av partiets velgere i fylket ha gjort samme endring med samme kandidat. Det skal MYE til for at dette skjer.\r\nFor det fjerde, det finnes ingen absolutt sperregrense ved valg i Norge – det vi kaller sperregrensa angir hvilke partier som kan kjempe om utjevningsmandater. Utjevningsmandater fordeles mellom partier med over 4 % oppslutning på landsbasis. 19 av de totalt 169 stortingsmandatene er utjevningsmandater.\r\nUtjevningsmandatene fordeles ved at alle 169 mandatene (fratrukket mandater til partier under sperregrensa og mandater til partier som ikke ville fått seter ved en nasjonal gjennomgang) fordeles med samme metode som på fylkesnivå. Utjevningsmandatene fordeles så for å dekke opp differansen mellom gjennomgangen på fylkesnivå og gjennomgangen på nasjonalt nivå.\r\nFor det femte, det kan være greit å vite at antallet representater fra hvert fylke er satt på forhånd – og er svært ulikt. I følge Grunnloven (en endring innført i 2003) beregnes antallet representanter utifra areal og folketall. Dette har gitt følgende fordeling:\r\nNerde-note: Delingstallet er viktig. Dette er utledet fra formelen (2*antall tildelte mandater+1). Det vil altså si at når et parti får tildelt et mandat, kalkuleres delingstallet på nytt. I den umodifiserte versjonen er det første delingstallet 1 (ikke 1,4), noe som favoriserer mindre partier – hvis vi beregner mandatfordelinga for Oslo med 1 som første delingstall, ser vi at Høyre får en representant mindre og at Rødt får inn en kandidat.\r\nDette kan sammenliknes med D’Hondts metode, hvor delingstallene beregnes med formelen 1+mandater, dvs. 1,2,3,4,5,6, osv. Også denne favoriserer større partier, men som vi ser hadde det ikke gitt utslag på antallet mandater til de ulike partiene fra Oslo i 2009 – men rekkefølgen av mandattildelingen er svært annerledes, og Ap er veldig nær ved å kapre det 16. mandatet fra SV.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-19T18:35:44+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2013-08-20-rammer-eller-stordriftsfordeler-for-jordbruket/",
    "title": "Rammevilkår viktigere enn størrelse",
    "description": "Dette innlegget sto på trykk i Nationen fredag 9. august, og er basert på en ny rapport jeg har skrevet for AgriAnalyse på oppdrag fra Geno, Nortura og Tine.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2013-08-20",
    "categories": [],
    "contents": "\r\nDebatten om størrelsesutvikling på norske gårdsbruk har gått i sommer. 48 kyr eller 60 kyr per bruk, tallene fra ulike utredninger kastes rundt og ikke minst Høyre har vært i senter. Svein Flåtten i Høyre står for et foreløpig siste bidrag når han (i Aftenposten 30. juli) uttaler at «når arealet er gitt og matproduksjonen må opp, må hvert bruk bli noe større».\r\nDette er i og for seg logisk, men eksempler fra våre naboland viser at det ikke er størrelsen alene som er viktig om en skal øke matproduksjonen. Det spiller også en rolle hvor mye større hvert bruk blir, hvordan denne veksten finansieres, hvordan produksjonen organiseres og ikke minst hvilken lønnsomhet bonden sitter igjen med. Dette handler om den enkelte bondens tilpasning til rammevilkårene i næringa. Tilpasningen har igjen konsekvenser for hvordan landbruket utvikler seg.\r\nSvenske mjølkebruk – effektive og store…\r\nFor å belyse dette nærmere ser AgriAnalyse i en ny rapport på utviklingstrender i storfeholdet i Norge og Sverige. I begge land har en kombinert produksjon av mjølk og kjøtt basert på grovfôrressurser historisk vært viktig, blant annet fordi det har gitt effektiv ressursutnyttelse og bedre økonomi.\r\nI løpet av de siste 20 årene har mjølkeprodusentene i Sverige blitt mange færre, mye større og mer spesialiserte. Mens det i 1990 var 25 921 melkebruk i Sverige, var antallet sunket med 80 % til 4 968 i 2012. Det svenske gjennomsnittsbruket har gått fra 22 mjølkekyr i 1990, til 70 mjølkekyr i 2012. Hver svenske ku ga i 2011 fra seg 9 210 liter melk – en ytelse blant de høyeste i verden. Tilsvarende tall for utvikling i Norge er 12 mjølkekyr i 1990 og 24 mjølkekyr i 2012, og en ytelse per ku på 7 132 liter i 2011.\r\nTil tross for denne effektiviseringa og størrelsesøkninga har Sverige siden 2004 sett et fall i produksjonen av mjølk, etter å ha ligget rett under den nasjonale EU-kvoten på 3,3 millioner tonn fra EU-medlemskapet ble inngått i 1995. I dag er produksjonen 2,9 millioner tonn.\r\n…men fortsatt ikke konkurransedyktige\r\nSentralt for denne utviklingen er det fallende forbruket av drikkemelk. Hvis avsetningsnivået skal opprettholdes, må avsetningen skje i andre kanaler som ost eller yoghurt. På disse markedene er konkurransen høy, og da særlig i Sverige som er medlem av det indre markedet i EU. Siden 1990 har markedsandelen for svensk ost og syrnede produkter falt med 20 prosentpoeng. Høyere konkurranse gir lavere priser, som sammen med høyere kostnader har gitt svenske mjølkebønder dårligere økonomi.\r\nKonsekvensen er tydelig: Bøndene vil ikke produsere til de prisene som tilbys, og nedleggelsene fortsetter i høyt tempo. Svensk TV kunne i mai melde at hvis utviklingen fortsatte, ville den siste melkebonde slutte i 2050.\r\nMindre mjølk = mindre kjøtt\r\nReduksjonen i antallet mjølkekyr har gitt fall i kjøttproduksjonen siden 2000 i Sverige og 2008 i Norge, gjennom færre kyr til slakt og gjennom færre kalver. Sammen med en kraftig økning i forbruket per person og befolkningsøkningen har dette gitt fallende dekning av det nasjonale markedet for storfekjøtt. Svensk storfekjøtt dekker nå 55 % av det nasjonale forbruket. Økningen i antallet ammekyr har ikke vært i nærheten av å kompensere for fallet i melkekyr.\r\nHvilken politikk velger vi?\r\nEr det mulig å kombinere færre, større og mer spesialiserte gårdsbruk med økt matproduksjon til en voksende befolkning? Dette spørs på rammevilkårene for matproduksjonen. Vi kan framheve tre elementer fra den svenske erfaringen som det er viktig å forholde seg til.\r\nFor det første ser vi at en stor del av problemet svenskene har opplevd kan knyttes til økte problemer med avsetning i det nasjonale markedet, spesielt på ost og syrnede produkter. Svenske produsenter kan av ulike årsaker ikke konkurrere med kostnadsnivået hos andre produsenter i EU. Utviklinga i Norge er ikke ulik, men Norge har mer beskyttelse enn Sverige gjennom sitt nasjonale tollvern. Et effektivt tollvern på primærprodukter er svært viktig for kjøtt- og mjølkebransjen, som debattert i ostetollsaken.\r\nFor det andre ser vi at den fallende kombinerte storfekjøttproduksjonen til nå ikke har blitt møtt med økt ammekuproduksjon. Det skal en stor vekst i antallet ammekyr til for å erstatte et fall i mjølkeproduksjonen, noe som har vist seg å være krevende i Sverige. Heller ikke Norge har til nå klart dette, og som Ekspertgruppa for storfekjøttproduksjon tidligere i år satte fokus på er det en voldsom økning som må til for å nå målet.\r\nFor det tredje hjelper det ikke med vekst i størrelse og mer spesialisert produksjon, hvis ikke nok bønder ser det lønnsomt å drive produksjon. Sverige viser oss at større enheter og økt spesialisering ikke alene holder produksjonen oppe, noe Norge har som målsetning å gjøre. Lønnsomheten for den enkelte bonde er avgjørende. Det bør alle partier som ønsker å styrke primærproduksjonen, næringsmiddelindustrien og sikre norsk matforsyning ta med seg inn i valgkampen.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-19T18:33:19+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2013-08-07-handelsavtale-mellom-eu-og-usa/",
    "title": "Om en mulig handelsavtale mellom EU og USA",
    "description": "Kort og faktatungt notat om TTIP-forhandlingene mellom EU og USA.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2013-08-07",
    "categories": [],
    "contents": "\r\nVerdens største handelspartnere, EU og USA, begynte mandag 8. juli 2013 formelt første runde i forhandlingene om en frihandelsavtale, Transatlantic Trade and Investment Partnership (TTIP). Runden fant sted i Washington DC, og skulle gå igjennom alle områder som kan komme til å bli omfattet av avtalen.\r\nHer følger litt info om forhandlingene, og noen kjappe betraktninger rundt mulige konsekvenser. Dette bygger på et orienteringsnotat jeg skrev for noen uker siden, så det er ganske faktatungt.\r\nDette er avtale som har vært snakket om en stund, i følge EU-observerer har handelsbyråkrater i EU ønsket seg dette de siste 20 årene. Den kommer etter at en High-Level Working Group (HLWG) fra Transatlantic Economic Council anbefalte en slik avtale, etter å ha sett på muligheten for å øke handel og investeringer fra 2011 til 2013. Grunndokumentet fra denne gruppa ligger til grunn for forhandlingene. Neste runde finner sted 7. oktober i Brüssel.\r\nEUObserverer sier at begge sider ønsker en avtale før slutten av 2014 (datoer å holde øye med er nyvalget av president for kommisjonen september 2014 og midterm-valg av kongress november 2014). Dette omtales av observatører, ministre og forhandlingsledere som å være veldig ambisiøst. Til sammenligning har forhandlinger om en frihandelsavtale mellom Canada og EU foregått siden 2010.\r\nNUPI-direktør Sverdrup går i Dagens Næringsliv 24. juni hardt ut og kaller avtalen «et transatlantisk EØS», og referer også til betegnelser som «et økonomisk NATO» og «mother of all FTAs». Forventningene til omfanget er altså store. Det kan være verdt å merke seg at TTIP kommer samtidig med at USA forhandler om en Trans-Pacific Partnership in Asia med bl.a. Japan, (ikke Kina). Obama må være ute etter å skrive seg inn i historiebøkene før 2016.\r\nMandat og omfang\r\nHandelsministrene i EU godkjente forhandlingsmandatet 14. juni. En lekket versjon av mandatet fastslår at målet med avtalen er å oppnå «gjensidig liberalisering av handel med varer og tjenester, så vel som handelsrelaterte regler, med et høyt ambisjonsnivå over eksisterende forpliktelser i WTO». Offentlig tilgjengelig info bekrefter dette, EU har mandat til å framforhandle en avtale som omhandler 1) markedsadgang, 2) konvergens av regler og 3) handelsregler for «delte globale utfordringer». Mandatet inkluderer dermed toll, opphavsregler, tjenester, investeringer, offentlige innkjøp, tekniske handelshindringer, sanitære forhold, IP, og geografisk opphavsbetegnelser på alle områder. (For ytterligere info har Kommisjonen publisert en rekke posisjonsdokumenter med tekniske posisjoner).\r\nPå den amerikanske sida melder EUObserver at en avtale til nå har støtte i Kongressen. Til nå er det lite tilgjengelig informasjon om mandatet, informasjonen som ligger ute framhever overfladisk studert det samme som infoen fra EU og HLWG.\r\nDe involverte partene og analytikere sier gjerne at det generelle tollnivået mellom EU og USA allerede er svært lavt (i følge Kommisjonen/WTO i snitt ca. 5,2 % i EU og 3.5 % i USA). De største gevinstene antas derfor å måtte innebære en konvergens i reguleringer. Dette kan innebære harmonisering av regler, eller gjensidig godkjennelse av regler.\r\nEUObserver forventer at finanstjenester, mat og landbruk kan bli blant de vanskeligste områdene. I tillegg forventer de mer overordna at konvergens av reguleringer vil bli et vanskelig tema. Transporttjenester, offentlig innkjøp og standarder i farmasiindustiren har også vært kontroversielle i forhandlinger mellom EU og USA tidligere.\r\nGodkjenning av en endelig avtale\r\nEn avtale må godkjennes av Kongressen før den kan ratifiseres – og Kongressen har også rett til å vedta endringer, noe som gjør handelsavtaler vanskelig. Obama kan få tillatelse til å «Fast track»/»trade promotion authority», som innebærer at Kongressen kun kan si ja eller nei, og har ytret håp om å få til dette. Verdt å merke at representantenes hus og 1/3 av Senatet skal på valg november 2014.\r\nMandatet er tildelt Kommisjonen (DG Trade, DGT) fra Rådet. Et forhandlingsresultat må godkjennes av Rådet og Parlamentet, før det blir bindende. Kommunikasjon mellom DGT, EC og EP under forhandlingene blir dermed sentralt. En skal ikke undervurdere skillelinjer mellom de 28 EU-landene. Før det første forhandlingsmandatet ble godkjent, var Frankrike ute og krevde at audiovisuelle tjenester skal være utenfor forhandlingsmandatet, «l’exeption culturelle». EUObserverer mener dette kan være symbolsk motstand, basert på en dypere skepsis mot frihandelsavtaler.\r\nLandbruk en del av avtalen?\r\nEU og USA er verdens største importører og eksportører av landbruksvarer. Handel med jordbruksprodukter forventes å bli et at de vanskeligste forhandlingsområdene i TTIP, men lite er kjent om konkrete posisjoner enda. Diskusjonene om ikke-tollbaserte handelshindre forventes å bli problematiske (kapittelet om Sanitære og phytosanitære spørsmål, SPS, ser ut til å være sentralt). Disse omfatter bl. a. nasjonale lover og regler, krav til dokumentasjon og bruk av standarder. Eksempler på forskjeller som kan være krevende er:\r\nGenetisk modifiserte organismer (GMO)\r\nBruk og anerkjennelse av merkeordningen «beskyttede betegnelser», lovbeskytte IP/produktbetegnelser på næringsmidler\r\nRegelverk knyttet til bruk av veksthormoner i produksjon (Disputt i WTOs tvisteløsningssystem)\r\nVasking av kylling med klor.\r\nI tillegg har vi spørsmål som dyrevelferd, eksportsubsidier.\r\nKonsekvenser av avtalen for omverdenen – økonomi\r\nHåp om økonomisk vekst som konsekvens kan være en viktig drivmotor for disse forhandlingene,. særlig for veksthungrige EU-politikere. Det er flere estimater på hva en slik avtale kan gi av gevinster. Euobserver siterer en utredning fra Kommisjonen, som slår fast at en avtale kan øke Eus eksport til USA med 28 %, og være verdt 119 milliarder euro per år for EU totalt (0.5%-0.4% høyere BNP). USA kan få 80 milliarder euro per år og 2 millioner nye jobber. Hvis avtalen ikke omfatter annet enn toll, anslås det at fordelene vil være betraktelig lavere (tollnivået mellom de to landene er allerede svært lave på en rekke varer).\r\nDet finnes flere økonomiske analyser av konsekvensene av en slik avtale. En studie som har fått spalteplass i Aftenposten og DN via NUPI ble utført av Ifo, og publisert av Bertelsmann-stiftung. Studien gjør estimater (computational general equilibrium) av effekter av fjerning av all toll, og fjerning av ikke-tollbaserte handelshindringer på EU, USA og tredjeland. Konklusjonen her er USA og EU-land vil kunne tjene på avtalen (særlig en dyptgripende avtale), mens land som står utenfor (som Norge), vil kunne tape. Norge vil på lengre sikt kunne miste 11 500 arbeidsplasser hvis liberaliseringen går langt (gitt en rekke forutsetninger, og usikkerhetsmomentene tatt i betraktning er det lite vits å henge seg opp i tallet, og heller fokusere på retningen). Dette er gitt en rekke forutsetninger, blant annet «alt annet likt». En større standardisering mellom EU og USA vil sannsynligvis kunne påvirke Norge gjennom EØS-avtalen.\r\nDenne typen beregninger er også blitt kritisert for å gjøre urealistiske antakelser om dynamiske effekter av handel, og det er gjort få studier tidligere av reduksjoner av ikke-tollbaserte handelshindringer – studien ser ut til å anta at disse blir store, basert på andre avtaler.\r\nEt minst like interessant spørsmål enn hvem som vil tjene på den og hvem som vil tape på den. I en artikkel på Euobserverer kommenterer Ferdi de Ville at Sør-Europa etter innførselen av Euroen har sett økende handelsunderskudd og forholdsvis lav eksportandel av BNP, mens Nord-Europa (og særlig Tyskland) har hatt overskudd på handelsbalansen. Hun kommenterer at det er lite trolig at dette vil endres, selv med økt markedsadgang til USA (i motsetning til Ifo, som finner store fordeler særlig for Sør-Europa).\r\nKeynesiansk sett bygger de positive anslagene på at økt eksport skal gjøre opp for fallet i etterspørsel drevet av kuttpolitikk. Kan både EU og USA frihandle seg til økonomisk vekst gjennom positiv handelsbalanse samtidig? Har intern devaluering i Sør-Europa gått så langt at de er konkurransedyktige på internasjonale (og nasjonale) markeder?\r\nAndre konsekvenser\r\nNasjonale myndigheters suverenitet vil også bli påvirket. Hvor mye avhenger av omfanget i endringer, tilpasninger eller godkjenninger av ulike reguleringer. EU-Mandatet legger opp til en dynamisk avtale, hvor målet er å utvikle øke harmoniseringen av regler gradvis over tid – altså bygge inn en gjensidig forpliktelse til regel-konvergens. Her er det også verdt å se etter hvorvidt en ISDS-mekanisme inkluderes i avtalen (ISDS: Investor-state dispute settlement – private firmaer gis mulighet til å gå til sak mot visse typer inngripen fra nasjonale myndigheter).\r\nOmfattende forhandlinger kan også åpne opp rom for forsøk på endringer av regler i EU, slik f.eks. forventninger om sluttføring av Doha-runden har bidratt til endringer i CAP.\r\nMer geopolitisk/strategisk kan TTIP sees som et forsøk på å demme opp for Kina og Indias innflytelse, sette en ny standard for hva som omfattes i handelsavtaler, samt etablere felles europeiske og amerikanske standarder som gjeldende i internasjonal handel. Hvis da EU og USA forhandler seg sammen om posisjoner, hvor de tidligere hadde ulike syn, kan dette også påvirke forhandlinger i WTO – eller sette nye standarder for internasjonal handel.\r\nKonsekvenser for sosiale standarder? Forskjeller i f.eks. ratifiserte ILO-konvensjoner? EU-dokumentene slår fast at de ikke ønsker å fire på standardene, men hvis forskjeller godkjenner, betyr det at dårligere praksis på f.eks. arbeidsrettigheter godkjennes. I hvilken grad kan slikt gi konkurransefordeler innenfor et åpent marked?\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-19T18:28:54+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2013-05-05-effekt-av-spekulering-i-mat/",
    "title": "Effekt av matfest på børsen",
    "description": "Hvorvidt matvarespekulasjon har en effekt på priser eller ikke er fortsatt en het debatt. Denne analysen ser næmere på hvordan spekulasjon i matvarer kan tenkes å påvirke prisen på matvarer.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2013-05-05",
    "categories": [],
    "contents": "\r\nTeksten er skrevet for Utveier 1/2013. En versjon med fine bilder og figurer ligger på Issuu, og teksten følger under.\r\nDere har stilt spørsmålet “Bidrar investorer til prisøkninger på energi og mat?” Mitt entydige svar er ja. Michael W. Masters, hedgefond-forvalter\r\nDen 20. mai 2008 var Michael W. Masters et av vitnene i en offentlig høring i det amerikanske senatet. Matvareprisene hadde steget mye, og var fortsatt på vei opp. Hedgefond-direktøren tok opp et tema som til da hadde blitt lite drøftet, spekulasjon, en aktivitet han selv hadde vært involvert i.\r\nMasters var ikke alene om å peke på finansmarkedene. Etter at matprisene fra 2007 til i dag både har økt kraftigere og svingt mer enn tidligere, har det pågått en kraftig debatt blant akademikere og aktivister om rollen til matvarespekulasjon. Fører spekulasjonen til kraftig økende priser og uforutsigbare svingninger? Eller må en se etter årsakene til disse fenomenene andre steder, som i befolkningsvekst og klimaendringer?\r\nKorn og mais blir verdipapirer\r\nFor å forstå denne debatten må vi skille mellom realøkonomien i det fysiske markedet, og finansøkonomien på verdipapirmarkedet. På det fysiske markedet, også kalt spotmarkedet, kjøpes og selges det faktiske matvarer: En handler kan kjøpe 100 tonn korn av en kornbonde for å selge det videre.\r\nVerdipapirmarkedet er mer komplisert. Dette markedet fungerer i utgangspunktet som et forsikringssystem basert på kontrakter mellom bonden og kjøpere av landbruksprodukter. Hvis bonden lover å selge 100 tonn hvete for 100 kroner om fire måneder, er bonden garantert denne prisen for avlinga si. Hvis markedsprisen faller under den avtalte prisen har bonden tjent penger. Hvis markedsprisen stiger over den avtalte prisen, har forsikreren tjent penger. Slike kontrakter kan inngås for å sikre en pris og et leveringsvolum, med ulike tidsfrister og ulike vilkår. En kaller gjerne forsikringene for derivater, fordi verdien skal være avledet fra de underliggende fysiske varene.\r\nLand uten tradisjoner for bondeeid industri, samvirkebedrifter, mangler gjerne ordninger hvor industrien er forpliktet til å hente sine medlemmers produkter – bøndenes produkter – til avtalte priser. Da kan derivater være et gode både for bønder og for industri, i det kontraktene sikrer leveringer, sikrer priser og gjør det mulig for bonden å tenke langsiktig.\r\nI utgangspunktet er altså bonden og kommersielle landbruksinteresser involvert i handelen med matvarederivater. Det har også vært noen aktører, spekulanter, på dette markedet, uten direkte interesser for de faktiske tomatene og agurkene. Denne balansen mellom realøkonomien og finansøkonomien har med årene forskjøvet seg til finansøkonomiens fordel. Det er en vanlig oppfatning at antallet spekulanter vokst seg større enn antallet som faktisk trenger forsikring på matvaremarkedene de siste 15 årene. Automatisert høyfrekvenshandel – såkalt robothandel – har gjort at omsetningen har økt kolossalt. I tillegg flyktet mange spekulanter fra risikable verdipapirer i eiendom når finanskrisa starta i USA, og inn i tryggere matvarederivater.\r\nI 2012 ble det i følge Timothy Wise ved Tufts University omsatt for omtrent ni trillioner dollar i råvarederivater, med investerte beløp på derivatmarkedet på om lag 130 milliarder dollar. Wise anslår at 80 – 90 prosent av denne handelen er såkalt «over the counter». Dette innebærer at den foregår mellom en kjøper og selger, uten offentlig innsyn og uten krav til standardiserte kontrakter: Kontrakten trenger ikke lenger å se ut som eksempelet over, men kan være noe helt annet.\r\nFeil priser, svingende priser\r\nSpørsmålet er om spekulasjon i verdipapirer basert på matvarer er med på å påvirke prisene på mat. Hensikten med verdipapirmarkedet på mat er ikke kun å kjøpe og selge forsikring, men også å gi informasjon om prisen til de som kjøper og selger fysiske varer. Hvordan kan kjøpere og selgere vite hva som er god pris for kornet, når avlingene er usikre og konkurransen på markedet uklar? De ser til verdipapirmarkedene, og bruker prisen på verdipapirer som utgangspunkt for å bestemme matprisen.\r\nProblemet er at prisene på det finansielle markedet ikke lenger avgjøres av tilbud og etterspørsel på det fysiske markedet, hevder de som mener at spekulasjonen er skadelig. Det finansielle markedet gjenspeiler altså ikke den riktige matvareprisen. I stedet settes verdipapirprisene på bakgrunn av en rekke andre faktorer, som for eksempel investorenes behov for sikring mot svingninger andre steder, hvorvidt andre spekulanter tror prisene vil stige eller falle og bevegelser i prisene på andre varer. Særlig de storstilte investeringene i såkalte indeksfond blir trukket fram som forstyrrende av spekulasjonskritikerne.\r\nEt indeksfond for råvarer er i utgangspunktet kun et gitt forhold mellom ulike verdipapirer, basert på råvarer, som olje, mineraler og mat. Investerer man ukelønnen sin i en råvareindeks, fordeles pengene mellom varene etter det på forhånd bestemte forholdet. Fondet tjener penger hvis varene inkludert i indeksen øker totalt, og taper penger hvis prisene på varene faller totalt. Hvis prisene på de større varegruppene i indeksen, som olje og metall, går opp, går indeksen opp. Siden indeksfondet må holde det gitte forholdet mellom de ulike verdipapirene, vil dette også føre til oppkjøp av matvareverdipapirer. Dermed kan prisene på verdipapirene på olje og metaller bli styrende for prisene på verdipapirene for mat. Går indeksen opp, kan flere aktører med mer kapital strømme til fondet, noe som forsterker etterspørselen etter verdipapirene. I følge utviklingsnettverket World Development Movement satt indeksfond i 2011 på over halvparten av alle verdier på verdipapirmarkedet.\r\nKonsekvensen er at etterspørselen etter verdipapirer basert på mat svinger basert på investeringer i indeksfond, og følger prisene på produkter som olje og metall. Den økte kapitalmengden skaper også større svingninger i prisene på verdipapirene basert på mat. Økte og endrede priser på verdipapirmarkedet forplanter seg så til de fysiske markedene. Særlig FNs spesialrapportør for matvaresikkerhet, Olivier de Schutter, har tydelig advart mot en slik effekt.\r\nSmitte til mat\r\nNår prisene på verdipapirene ikke lenger informerer om tilbud og etterspørsel på jordbruksvarer, men om prisbevegelser i andre råvarer og om spekulantenes framtidstro, vil prissetting basert på verdipapirpriser bli feil. Selv om hovedtrenden fortsatt er basert på hendelser som tørke og etterspørselsøkning, kan spekulasjonen dermed være være med på å forklare hvorfor svingningene i prisene har vært så store og hurtige siden 2007.\r\nNår prisen på verdipapirmarkedet øker, vil en selger av fysiske varer ønske å ta ut denne framtidige prisen på sine reelle varer. Aktørene på de fysiske markedene vil ha de samme prisene som på finansmarkedet! Selgeren venter derfor med å selge varene sine, noe som gir færre varer på markedet, og dermed høyere priser. Kjøperen av varene vil derimot sikre seg mot framtidige prisøkninger, og etterspørselen etter verdipapirer vil stige. Hva skjer så? Med større etterspørsel enn tilbud stiger prisene på det fysiske markedet. Papirene vil igjen øke i verdi, og prosessen starter dermed på nytt.\r\nMotargumentene\r\nEr du overbevist av forklaringen på økte matvarepriser? Det er ikke helt sikkert at du burde være det, for her finnes en rekke motargumenter:\r\nStjerneøkonom Paul Krugman er blant de som avviser at prisene på verdipapirer smitter over på matprisene. I utgangspunktet skal ikke prisene på verdipapirene kunne påvirke prisene på de underliggende produktene, mener han. Det blir som om et utfall av hesteveddeløp i dag skulle bli påvirket av de som har satset på travløpet om fire uker. Prisen på tomater settes på det fysiske markedet for tomater, ikke verdipapirmarkedet. Dermed reduseres spørsmålet om spekulasjon til et spørsmål om hvorvidt noen har holdt tilbake store kvanta landbruksprodukter fra markedet for å drive prisene opp. Dette ser det ikke ut til å være gode bevis for.\r\nKritikernes motsvar her er at fordi tomatmarkedet (blant andre) er uoversiktelig, med lite informasjon om prisene, så vil prisene på verdipapirer påvirke hva som sees som en god pris. Selv om grunnleggende trender driver prisen, vil spekulasjonen forsterke uheldige trender og øke prisene enda mer.\r\nMen prisen på finansmarkedet er en god tilnærming til den virkelige prisen, er innvendingen fra finansforsvaret. Jo flere aktører på et marked, jo mer informasjon bringes til torgs, og desto riktigere blir sluttprisen. Hvis du satser på å spekulere på stigende priser på verdipapirene, hevder disse, vil du raskt bli loppet for penger av spekulanter som kjenner den egentlige prisen på mat bedre. Mot dette kommer påstander fra blant andre World Development Movement (WDM) om bobletankegang, flokkoppførsel og indeksfondenes manglende tanker om underliggende forhold i tomatmarkedet. Spekulantene følger ikke informasjon i markededene, de følger hverandre, sier WDM.\r\nBanker med samvittighet?\r\nFinansmarkeder er komplekse, og det er vanskelig å sette seg inn i hva som skjer der – noe som stadig trekkes fram som en av årsakene til finanskrisen. Selv topptrente regulatorer visste ikke når de skulle trykke på den store røde reguleringsknappen. Imidlertid kan det være en indikasjon at størrelser som FNs mat- og landbruksorganisasjon, FAO, uttaler at dette har hatt en effekt. Det største finanskonsernet i Norden, Nordea, har trukket spareprodukt hvor de tilbød privatkunder blant annet investering i matvareindekser. Også Finans Norge sa i debatt med Attac at disse produktene ikke egner seg for privatkunder. De står ikke alene: Commerzbank har fjernet landbruksprodukter fra et av sine indeksfond, østerrikske Volksbank likeså, og nylig ga giganten Barcalys beskjed om at de ikke lenger ønsket å handle i jordbruksråvarer med hedgefond.\r\nFøre-var-prinsipp\r\nNår spekulasjon som teori entret scenen i 2008, hadde mange andre faktorer blitt vurdert, uten at de virket som uttømmende forklaringer på de store prisøkningene. Når en hensyntar spekulasjon kommer en noe nærmere en god forklaring, særlig på de store svingningene, men som vi har sett har også denne forklaringen sine svakheter. Som andre innlegg i denne utgaven av Utveier viser til, er det mange andre faktorer som kan påvirke prisen på mat. Kun å fokusere på spekulasjon blir ikke riktig. Men som argumentene viser kan det være viktig, og det er en debatt for viktig til å overlates finansøkonomene.\r\nEnn så lenge virker det sikreste å gjøre som Financial Times forslår: Så lenge ingen kan forsikre oss om at matvarespekulasjon ikke påvirker prisene, er de potensielle konsekvensene av uregulert spekulasjon sult. Dette er en utvikling vi kan gjøre noe med. I stedet for å bidra til hungersnød, burde de enorme summene spekulantene forvalter gå til investeringer i global matproduksjon.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-19T18:23:09+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2013-02-27-kunnskap-om-banken-din/",
    "title": "Veit du hva banken din gjør?",
    "description": "Uttalelse og lesebrev fra Attac Norges landsmøte i 2013.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2013-02-27",
    "categories": [],
    "contents": "\r\nAttac har i lengre tid arbeidet med bankenes rolle i finanskrisa, og blant annet fått utredet en rapport om bankenes tilknytning til skatteparadis og uetiske investeringer (se Attac.no-oppslaget her). Jeg skrev utkast til en uttalelse som, med noen endringer, ble vedtatt på Attac Norges landsmøte 27. februar, og som senere har blitt sent ut som leserbrev.\r\nEuropa er rammet av en gjeldskrise med massearbeidsledighet, kutt i offentlig velferd og angrep på sosiale rettigheter som resultat. Gjeldskrisa ble utløst da de europeiske bankenes skadelige spekulasjon og tvilsomme utlånspraksis slo tilbake på bankene. De kom da løpende til staten for å bli reddet fra de frie markedskreftene og konkurs.\r\nAttac Norge mener at bankene har et ansvar overfor samfunnet som helhet til å fordele ressursene slik at de på best mulig måte støtter opp under hensyn til sosiale rettigheter, miljø og menneskerettigheter. Vi har dokumentert at de største norske bankene ikke tar sitt samfunnsansvar på alvor. I en gjennomgang av utlån og investeringer fra DNB, Nordea, Danske Bank og Handelsbanken fant vi at alle bankene har tilknytning til flere skatteparadis, finansierer våpenproduksjon og miljøverstinger. Noen hadde også tilknytning til matvarespekulasjon og selskaper involvert i korrupsjon.\r\nMed kontorer og filialer i skatteparadiser som Luxembourg, Sveits, Cayman Islands og City of London mener vi at det ikke er tvil om at norske banker støtter et system som bidrar til hemmelighold, tilrettelegger for skatteunndragelser, og hemmer utvikling i Sør. Ti ganger verdien av verdens bistandsmidler forsvinner fra fattige land på grunn av dette systemet. Verdier tilsvarende 35 oljefond er gjemt bort i slike jurisdiksjoner, midler som trengs sårt i disse vanskelige økonomiske tider. Dette systemet kan ikke norske banker være med på å opprettholde.\r\nVi er imidlertid ikke maktesløse, og Attac Norge vil derfor oppfordre:\r\nDeg til å spørre banken din om hva den gjør med pengene dine, hvorfor den er aktiv i skatteparadis, og hvem den låner ut penger til. Er du ikke fornøyd med svarene, bytt bank.\r\nBanker og finansforetak til å støtte opp under sosiale rettigheter, miljø og menneskerettigheter, gå ut av skatteparadis, og følge samme regler for samfunnsansvar for utlån som for investeringer.\r\nNorske myndigheter til å kreve at bankene offentliggjør mottakerne av større utlån, og kreve land-for-land-rapportering av norsk finansnæring.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-19T01:09:15+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2013-02-07-slipp-bonden-fri/",
    "title": "Slipp bonden fri!",
    "description": "Bør vi lære av Danmark i landbrukspolitikken? Innlegget er skrevet sammen med Christian Anton Smedshaug, og sto blant annet på trykk i Klassekampen 7. februar 2013.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2013-02-07",
    "categories": [],
    "contents": "\r\n«Slipp bonden fri» er blitt et begrep for en deregulert landbrukspolitikk der eiendomsregelverk fjernes og begrensninger på størrelse oppheves. Slik skal enhetene bli større, og de offentlige utgifter mindre. Argumentet er at de gjenværende bønder endelig vil få lønn for strevet, mens de overflødige må legge ned og ta seg jobber i andre deler av økonomien. Men er erfaringen den at deregulering gir bonden bedre lønnsomhet og samfunnet mindre kostnader?\r\nInnenfor rammene av den felleseuropeiske landbrukspolitikken har danskene med årene liberalisert sitt eiendomsregelverk og opphevet direkte begrensninger på størrelse. Dette har bidratt til en kraftig strukturutvikling: Fra 1982 har antallet bruk blitt mer enn halvert til dagens rundt 40.000. Gjennomsnittlig driftsstørrelser i samme periode har økt fra 27 melkekyr, 62 purker og 180 dekar korn til henholdsvis 139 melkekyr, 902 purker og 510 dekar kornareal. Disse tallene skjuler en stor spredning, siden over halvparten av gårdsbrukene drives på deltid, og produksjonen er konsentrert på de største gårdene: Den største tidelen dyrker derfor over 40 prosent av kornet og dretter opp mer enn 40 prosent av slaktegrisene. I 2011 leverte de omtrent tre ganger så mye melk, høstet åtte ganger så mye korn og drettet opp tjue ganger så mange svin som norske bønder.\r\nDanskene har et av Europas mest endringsvillige jordbruk med dyktige bønder og sterk produksjonskultur. Om noe land skulle lykkes med å sette bonden fri fra størrelsesbegrensninger, så er det Danmark, med gode naturgitte forutsetninger for landbruksproduksjon.\r\nTil tross for store enheter og stor produksjon har ikke lønnsomheten fulgt med. Fra 2007 til 2010 gikk det danske landbruket som helhet med underskudd hvert år, noe som vil si at danske bønder i snitt ikke kunne ta ut lønn for eget arbeid disse fire årene. Resultatene var ikke mye bedre i 2011 og 2012. Selv med gjennomsnittlig EU-støtte på 7,5 milliarder kroner i siden 2007, har vederlag til eget arbeid og egen kapital i snitt for disse seks årene vært på minus 923 millioner. Et av Europas mest deregulerte jordbruk taper penger i markedet, og må ha støtte, men selv da kommer de ikke i pluss.\r\nDette problemet har vært kjent lenge i Danmark, og for å bedre lønnsomheten har danske bønder søkt å ta ut stordriftsfordeler, og politikerne har fjernet begrensningene på størrelse. Tallmaterialet tyder på at større gårder i snitt har noe bedre netto driftsresultat enn mindre. Men denne tendensen er ikke større enn at mindre bruk kan like god lønnsomhet som større. Sagt med andre ord, størrelse er ingen garanti for suksess, men kan også gi store tap og store svingninger i resultatene fra år til år, særlig i situasjoner med nedgangskonjunktur.\r\nHvordan kan de danske bøndene holde det gående? Her som mange steder ellers i samfunnet er det gjeld som har erstattet lønnsomheten. I 2011 var den totale gjelda på 343 milliarder danske kroner, med et gjennomsnitt for gårder drevet på heltid på 21,7 millioner kroner. Dette utgjorde fire og en halv gang av total inntekt fra produksjonen i 2011, altså at hele produksjonsinntekta fra fire og et halvt år måtte dekke hele gjelda. Renteutgiftene utgjorde 15 prosent av produksjonsinntektene. Til sammenligning utgjorde driftsrelatert gjeld 1,8 ganger årlige produksjonsinntekter i Norge og renteutgiftene fem prosent.\r\nDen danske erfaringen lærer oss at investeringer i større produksjon må gjøres på bakgrunn av reelle stordriftsfordeler og en maktbalanse i markedet som kan gi økte inntektsmuligheter for bonden. Danske bønder har i perioden med sterk vekst i størrelse fått lavere lønnsomhet og måttet basere driften på økende gjeld og store underskudd på drifta. Det har ikke vært til gavn verken for bonden eller samfunnet.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-19T01:07:17+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2013-01-14-biofuel-or-food/",
    "title": "Biobränsle eller mat - ett dilemma att lösa",
    "description": "Leserinnlegg i svensk avis om konflikten mellom biodrivstoff og mat",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2013-01-14",
    "categories": [],
    "contents": "\r\nBehovet av ekonomisk tillväxt, minskning av utsläppen växthusgaser och säker energiförsörjning gör att stora västerländska företag i dag fokuserar på förnybar energi. Det ger upphov till ett dilemma mellan bränsle och livsmedel.\r\nUSA täcker för närvarande 55 procent av sitt råoljebehov genom import. Ökad användning av biobränslen är en av åtgärderna på vägen till att bli oberoende av oljeimport på lång sikt. För att uppnå detta mål kommer man att använda samma mark där det för närvarande produceras livsmedel, för att producera biobränslen. Myndigheterna i USA menar man kan skörda mat två gånger, och låta den tredje grödan användas till produktion av biodiesel och bioetanol. Detta anses vara möjligt eftersom energigrödor inte behöver innehålla vitaminer, mineraler och proteiner utan bara energi. För att realisera detta mål stödjer USA produktion av bioenergi, bland annat genom Farm Bill, USA:s lantbruksbudget.\r\nEU stöder i likhet med USA sin produktion av bioenergi, men unionen har reducerat sina ambitioner för att produktion av energi inte ska genomföras på bekostnad av produktion av mat. Problemet är att första generations bioenergi produceras av livsmedel eller i områden som kan användas för livsmedel. Under 2011 blev 15 procent av världens majsproduktion använt till bränsle, vilket kan ge stigande matpriser.\r\nUtvecklingen av andra generationens biobränslen (2G-bränsle) baserade på trä och träavfall och andra bioresurser som inte kan ätas, kan vara en långsiktig lösning. Produktionen och konsumtionen av 2G-bränsle har inte haft en så bra utveckling som förväntat, och det finns fortfarande ett behov av offentligt stöd till forskning och utveckling.\r\nHär har Sverige och Norge som länder med stora skog sresurser en viktig roll att spela. Vi har goda erfarenheter av samarbetet med gröna certifikat. Norge har som en av världens största exportörer av olja och gas både resurser och\r\nett moraliskt ansvar för att minska utsläppen. I Sverige finns lång erfarenhet av åtgärder och användning av biobränslen, särskilt etanol.\r\nObligatorisk blandning av 2G-bränsle och riktat forskningsstöd för etanol som produceras av cellulosa är två möjliga åtgärder.\r\nDen norska staten har fyrdubblat stödet till spjutspetsteknik inom förnybar energi genom en statligt finansierad energifond. Fonden är på 35 miljarder norska kronor och ska öka till 50 miljarder före 2016. Borregård i Norge tillverkar miljövänlig bioetanol baserad på grantimmer. Tyvärr är dessa initiativ för små. Men tillsammans med Sverige kan vi uppnå målen. Därför skulle en gemensam svensk-norsk forskningsinsats kunna göra Sverige-Norge världsledande på produktion och användning av 2G-bränsle.\r\n(Dette innlegget ble skrevet sammen med Margaret Eide Hillestad, og sto på trykk i ATL ca. 14. januar 2013)\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-19T01:05:05+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2012-09-23-kunnskapsbasert-policy/",
    "title": "Theories of Change og hva som gir policy-impact for forskning ",
    "description": "Anbefaling av Duncan Green og Matt Wood",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2012-09-23",
    "categories": [],
    "contents": "\r\nDuncan Green, seniorrådgiver hos Oxfam, skriver på «From poverty to power» om «Theories of Change» og hvordan forskere kan bruke teori for å øke effektiviteten til mottakere av forskningsstøtte. Med andre ord, et teoretisk blikk på hvordan forholdet mellom forskere og beslutningstakere ser ut, og hvordan organisasjoner som gir støtte til forskning og tiltak i NGOer kan bidra til å «optimaliseres» NGOers forskning. «Theories of Change» ser ut til å referere til dette rammeverket for å skape endring.\r\nI tråd med dette rammeverket foreslår Green at 1) forskere ikke har insentiver til å legge tydelig fram sine antakelser om politisk endring, noe de burde gjøre 2) at forskere/NGOer må bedre forstå hvordan beslutningstakere tar til seg og bruker informasjon, 3) at endring er avhengig av «mulighetsvinduer», og dermed må NGOer kunne reagere kjapt, 4) at mål og midler må defineres tydelig. Å «endre diskursen» er ikke et mål for et prosjekt.\r\nEn annen som tar for seg lignende utfordringer er Matt Wood, som på LSE-bloggen tar for seg hvilke krav byråkratiet stiller til statsvitere og andre for at deres forskning skal være relevant. Bevisene er anekdotiske, men virker rimelige og velkjente: Byråkrater ønsker seg mer forskning som kan brukes i praksis, og ønsker seg også bedre metodisk kunnskap. Dette er vanskelig, i det universitetsforskning tar lang tid, mens beslutningstakere trenger hurtig input. Dette gir rom for tenketanker og andre institutter som spesialiserer seg på å levere hurtig. Videre er kvantitative bevis det mest ønskelige – men hva da med kvalitativ forskning?\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-19T01:03:16+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2012-08-05-masteroppgaven-del-2/",
    "title": "Velferdsdualisme i nyhetene",
    "description": "Bør en innføre begrensninger i rettigheter til ytelser basert på landbakgrunn?",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2012-08-05",
    "categories": [],
    "contents": "\r\nEn god (og grunnleggende) huskeregel når en gjør større prosjekter er å ta en lengre pause mot slutten. Etter et par ukers tid med andre oppgaver kan en da se om den røde tråden gir like mye mening som en trodde. Dette tipset er aldri lett å følge, og en kan trenge lange tidsperioder før «oppgave-blindheten» forsvinner.\r\nSom jeg forsøkte å beskrive i denne posten er masteroppgaven min et forsøk på et stort prosjekt, som integrerer en analyse av konsekvensene av innvandring for ulike faktorer (økonomi, valgadferd) og en analyse av hvordan disse endringene påvirker politiske beslutningstakere. Å konsentrere på en av delene hadde gjort det lettere å få fram den røde tråden, og hadde nok gjort at omfanget hadde blitt mer håndterlig (ikke full monografilengde).Hvis jeg hadde fulgt mitt eget tips, kunne jeg kanskje ha oppnådd dette. På den andre siden hadde det gjort prosjektet noe kjedeligere, og det ene kan ikke sees på hvis en ikke ser på det andre. Sensuren jeg fikk var også svært god, med få innvendinger.\r\nDermed er det artig å se at nå som agurktiden langsomt er på veg ut, dukker spørsmålet om eksport av kontantstøtte igjen opp. Dagsavisen/NTB kan fortelle at Torbjørn Røe Isaksen (H) og Høyre ønsker å se på tiltak for å redusere eksport av velferdsordninger innenfor rammene av EØS-avtalen. Et mulig tiltak er boplikt. Hvis han ser på danske erfaringer i oppgava mi (som kan lastes ned herifra), heller enn å kun lese Brochmann-utvalgets NOU vil han se at det finnes muligheter.\r\nJeg vil selvsagt ikke stemme på dette forslaget, som jeg har skrevet om før: Et botidskrav vil være et steg bort fra universelle ytelser, og vil innebære behov for mer kontroll og håndheving. For noen småbarnsforeldre med kort botid er barnetrygd en viktig ytelse. Og disse problemene er, i den store sammenhengen, svært små, ikke minst hvis en i tillegg skulle begynne å se på skatteinntektene fra arbeiderne som arbeider i Norge. Betaler man inn, kan man få ut. Innsparing får en ta andre steder.\r\nSå lenge «eksport-problemet» presenteres som et økonomisk problem ser jeg få grunner til at dette vil bli innført. Symbolpolitikken i det kan derimot være sterkere, hvis argumentasjonen flyttes over til «grensene for velferd går ved nasjonens grenser».\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-19T01:00:39+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2012-06-03-masteroppgaven-del-1/",
    "title": "Masteroppgaven del 1",
    "description": "Fører innvandring til velferdsdualisme? Del 1 av masteroppgava mi.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2012-06-03",
    "categories": [],
    "contents": "\r\nFor noen uker siden fullførte jeg en mastergrad i statsvitenskap, etter noen hundre timer ved datamaskina. Oppgaven, «Fører innvandring til velferdsdualisme? En studie av innvandringens effekter på barnetrygd og kontantstøtte i Skandinavia», vil bli tilgjengelig på Universitet i Oslos digitale portal DUO etter sensur.\r\nSelv om Wordle-skyen er fin, gir den ikke et helt godt inntrykk av hva det dreier seg om. Siden å forklare dette vil være viktig for meg de neste månedene, kommer det her et kort sammendrag av hva jeg har drevet med de siste månedene. Å skulle klemme alt datamaterialet og alle betraktningene etter et halvt års arbeid inn i en enkel bloggpost er vanskelig, og dette blir derfor en serie med innlegg.\r\nFørst må det takkes – de fleste faktisk involvert ble behørig takket i forordet til oppgava. Men takk også til RescueTime for å ha holdt oversikt over hva jeg drev med, og minne meg på at 2 timer daglig på facebook ikke er spesielt produktivt. Dessverre manglet gratisversjonen av programmet muligheten til å eksportere dataene på en meningsfull måte. En skryteframstilling av de to siste månedenes 320 timer i OpenOffice, Endnote og på wwww.stortinget.no hadde gjort seg. På den andre sida betyr det at de timene på facebook, spotify, og twitter heller ikke kommer fram. Tekniske hindringer ligger heldigvis fortsatt i veien for total selvfremstilling.\r\nOppgaven ser på hvorvidt innvandring og det som kanskje kan kalles egenskaper ved innvandrerbefolkningen kan forklare utviklingen av forskjeller mellom «policydesignet» på barnetrygd og kontantstøtte i Norge, Sverige og Danmark fra ca. 1996 til 2011. Utgangspunktet er at noen teoretikere (og øvrige samfunnsdebattanter) mener at økt innvandring til generøse velferdsstater vil føre til omfattende endringer av disse velferdsstatene, enten i form av kutt av velferdsordninger, eller ved at det utvikles en form for velferdsdualisme: Velferd kun til de med riktig nasjonalitet og/eller etnisitet.\r\nTidligere forskning har en rekke forslag til hvorfor dette skjer, og jeg har forsøkt å se nærmere på noen av disse forklaringene, oppsummert i et snasent forenklet årsaksdiagram.\r\nDiagrammet viser en noe komplisert versjon av hva som kan skje ved innvandring til en skandinav velferdsstat: Majoritetsbefolkningen kan, av ulike grunner, mislike innvandrerbefolkningen, og stemme på partier som ønsker å redusere velferd til innvandrere eller velferd generelt. Partiene spiller mest sannsynlig en viktig rolle her, i det tidligere forskning gjerne viser hvordan særlig høyrepartier utnytter og lager spenninger mellom ulike grupper for å kunne gjennomføre reformer.\r\nIkke alle er enige i dette dystre bildet: Integrering av ulike innvandrergrupper kan hindre spenninger mellom grupper, velferdsordninger er populære hos mange, og de skandinaviske landene har alle, kanskje med unntak av Sverige, gjennomført innstramminger i innvandringspolitikken (altså kontrollen med hvem som har tilgang til landet). I tillegg er det å snakke om minoritet vs. majoritet en grov overforenkling.\r\nFor å undersøke om innvandring har hatt noe å si, har jeg derfor sett på beslutninger om generøsiteten og krav som stilles til mottaker i barnetrygd og kontantstøtte i Norge, Sverige og Danmark fra 1996 til 2011. Kort oppsummert dreier dette seg om at mens den norske barnetrygden har så godt som ingen (nye) krav til mottaker, men en fallende realverdi siden 1996, og den svenske ingen krav, og en delvis opprettholdt realverdi (ihvertfall hvis en tar hensyn til økninger i tilskudd til familier med flere barn), har danskene innført krav til botid, men i liten grad rørt generøsiteten. For der nordmenn og svensker justerer sine ytelser i statsbudsjettet hvert år, har danskene helt siden 1987 latt «børnechecken» indekseres automatisk.\r\nAt alle landene også hadde kontantstøtteordninger var egentlig noe overraskende, siden kontantstøtten gjerne blir oppfattet som noe særnorskt. Både Sverige og Danmark gir tilskudd på kommunalt plan til familier som ikke ønsker å benytte offentlig barnehagetilbud. Her er det ikke gjort mange endringer siden ytelsene ble innført, men det er interessante forskjeller i hvilke krav som stilles til mottakerne: En av de to danske tilskuddene stiller strenge krav til botid, og det svenske «kommunale vårdnadsbidraget» stiller en rekke krav til at mottakeren ikke kan benytte seg av ytelsene.\r\nVed å samle inn en haug av sammenlignbare data har jeg forsøkt å gjøre koblinger mellom disse ulike beslutningene og variabler som forskjeller i arbeidsmarkedsdeltakelse mellom innvandrerbefolknignen og majoritetsbefolkningen, forskjeller i landbakgrunn, og forskjeller i arbeidsløshet. Selv om landene er like, og dermed forholdsvis lette å sammenligne, er ikke dette en helt sikker analysemetode. Derfor har jeg også gjort 14 eliteintervjuer med politikere og byråkrater i alle tre land, samt detaljerte dokumentstudier, som jeg bruker til fire mindre studier av beslutninger.\r\nJeg konkluderer med at egenskaper ved innvandrerbefolkningen i liten grad ser ut til å kunne forklare forskjellene i design mellom land. Det er en viss mulighet for at den relativt lavere deltakelsen på arbeidsmarkedet hos utenlandsfødte kvinner kan ha hatt noe å si for innførselen av opptjeningskrav ved to nyere\r\nkontantstøtteordninger, men forskjellen mellom kvinner og menns arbeidsmarkedsdeltakelse virker like relevant. Å kun se på regjeringspartienes plassering på en høyre/venstre-dimensjon virker også i liten grad forklarende.\r\nHva kan forklare forskjellene? Når det gjelder utviklingen peker både sammenligningen og en case-studie av det danske botidskravet i barnetrygden på regimet for trygdekoordinering i EU som en viktig faktor. Dette er regler bestemt av EU for hvordan sosiale rettigheter skal koordineres når arbeidskraft i Europa har rett til å bevege seg fritt. Dette regimet har per definisjon den største og tydeligste effekten, siden det utvider gyldighetområdet for de nasjonale ytelsene, til dels betraktelig, og endrer definisjonen av kravene til mottaker samt muligheten for å stille slike krav.\r\nRegimet kan i seg selv ikke forklare de ulike tilpasningene til dette regimer, noe det er noen tilfeller av. Jeg mener at forskjellige beslutninger ikke kan forklares med omfanget av eksporten, manifestasjonen av regimets økonomiske konsekvenser. Informasjon jeg henter inn tyder på at det er mer fruktbart å se spørsmålet prinsipielt i lys av hvem som skal få velferd, enn som økonomiske bekymringer.\r\nFører så innvandring til velferdsdualisme? Dataene jeg har studert tyder ikke på det, i hvert fall ikke direkte. Det lille steget mot velferdsdualisme som kan observeres innen barnetrygden bør heller sees som en respons på at EUs regler utvider målgruppen for ytelsen utover det som var tiltenkt, noe nasjonale politiske aktører har forsøkt å stoppe i Danmark. Det kan derfor være vel så viktig å se på hvordan politiske beslutningstakere vurderer EU-regler og hvem som fortjener en ytelse, som egenskaper ved minoriteten. Dermed er det egenskaper ved politikerne og majoriteten som har valgt dem som bør stå i fokus, ikke minoritetene. Det er tross alt majoriteten som kan gjøre beslutninger om endringer.\r\nI et bredere perspektiv er det interessant å notere seg at den danske sosialhjelpen (fram til regjeringsskiftet høsten 2011) hadde blitt lagt om, tydelig for å ramme innvandrere. Det er også interessant at Axel West Pedersen i en ny kronikk peker på at også reformen av den norske uføretrygden ser ut til å innebære en viss form for dualisme.\r\n«Passiv velferdsdualisme» kan også være problematisk – det faktum at svært mange av de sentrale ytelsene i de skandinaviske velferdsstaten er tilrettelagt folk som lever livet sitt i ett land, gjennom f.eks. krav til deltakelse på det nasjonale arbeidsmarkedet. At ytelser som barnetrygden blir knyttet til bostatus kan i en slik sammenheng være uheldig.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-19T00:58:30+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2011-11-06-robin-hood-finansminister-johnsen/",
    "title": "Vær en Robin Hood, finansminister Johnsen!",
    "description": "Brev til finansministeren om viktigheten av finansskatt.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2011-11-06",
    "categories": [],
    "contents": "\r\nKjære finansminister Sigbjørn Johnsen.\r\nFinansskatt er idag ansett som et sentralt virkemiddel for å redusere mengden skadelig spekulasjon, samtidig som den vil skape skatteinntekter. Det internasjonale pengefondet IMF har sagt at det er gjennomførbart. EU-parlamentet og EUkommisjonen vil ha skatten. Tyskland, Frankrike, Brasil, India, Kina og Sør-Afrika er med på laget. Da bør Europas mest radikale regjering, med Johnsen i spissen, kjenne sin besøkelsestid og gå inn for verdens mest populære skatt idag.\r\nDenne uka er presidenter, statsministere og andre toppolitikere fra verdens 19 største økonomier og EU samlet på G20-møte i Cannes. Krisesituasjonen i den internasjonale økonomien står i sentrum. En av sakene som kommer til å bli tatt opp er skatt på finanstransaksjoner, også kjent som Tobinskatt, Robin Hood-skatt eller finansskatt. Kjært barn har mange navn, som man sier.\r\nOg kjært barn, det er det – også i G20. Tysklands kansler Merkel, Frankrikes president Sarkozy, EU-kommisjonens president Manuel Barrosso og Storbritannias tidligere statsminister Gordon Brown er alle tilhengere, for å nevne noen. Paven, som nok trygt kan sies å være stokk konservativ, sto nylig fram som tilhenger av skatten. Det bør derfor være trygt å si at finansskatt er er verdens mest populære skatt. I Norge har blant annet LO, SV og 28 frivillige organisasjoner gått inn for innføring av skatten.\r\nFra finansminister Sigbjørn Johnsen mangler det imidlertid til nå tydelige utspill. Norge gikk riktignok i fjor inn for en global finansskatt i FN, men holdningen til en løsning med færre land har til nå vært lunken. Det er imidlertid med støtte i økonomisk forskning at den tyske finansministeren nå foreslår at en koalisjon av villige land kan gå foran og innføre skatte. Senere kan en så utvide antallet involverte land, slik en har gjort med f.eks. flyskatten. Her bør altså finansministeren fra Næs stå på trygg nok grunn til å henge seg på.\r\nArgumentasjonen for å innføre den lille skatten er veldig enkel. Det er ikke snakk om en stor skatt, kun 0,05% av verdien på handlede aksjer, valuta, obligasjoner eller derivater. Den vil derfor ikke hindre langsiktige investeringer eller reell handel. Allikevel vil en kunne samle inn store beløp: EUkommisjonen snakker om 57 milliarder euro i året. Mange av G20-tilhengerne ser nok fram til å bruke disse pengene på å rette opp skadeskutte budsjettbalanser og i den pågående gjeldskrisen i Europa. Her har imidlertid Robin Hood-aksjonen, kjent over hele Europa, argumentert for at skatteinntektene bør fordeles mellom flere gode formål: En del bør gå til opprettholdelse og styrking av velferdspolitiske tiltak i landene som samler inn skatten. Den andre delen bør gå som friske midler til utviklingsformål.\r\nDette er virkelig ikke annet enn rettferdig: Bankene og finansindustrien utløste i 2007 enorme redningspakker – vi snakker 4600 milliarder euro i EU – etter å ha skutt seg selv i begge føttene med kompliserte finansprodukter. Slik saftig støtte for å drive med skadelig virksomhet er det få næringer som kan smykke seg med. Det gikk også hardt utover land i sør. Mange av de mindre utviklede landene har også i de senere år blitt offer for finanssektorens spekulasjon i matvarepriser, med katastrofale følger.\r\nDet viktigste argumentet er imidlertid at en finanskatt vil være sand i maskineriet på finansnæringa. Daglig handles det for omtrent 3000 milliarder dollar på verdensbasis. Av dette utgjør handel med reelle varer og tjenester under 3%. Resten er finansnæringa, og en forvokst andel av det står kortsiktig spekulasjon for. Ved å legge en liten skatt på alle finanstransaksjoner vil en kunne dempe muligheten for gevinst på skadelig spekulasjon. Dermed vil vi kunne hindre ting som ødeleggende svingninger i valutakurser, galopperende renter på statsgjeld og eksploderende matvarepriser, for ikke å snakke om at vi vil kunne forhindre finanskriser.\r\nKjære Johnsen. Finanskatt er ikke en vidundermedisin. Det løser ikke alle problemer i verden. Men det er et sted å starte.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-19T00:54:52+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2011-09-16-kritisk-borgerjournalistikk/",
    "title": "Kritisk borgerjournalistikk",
    "description": "Om viktigheten av kritisk journalistikk og den femte statsmakt.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2011-09-16",
    "categories": [],
    "contents": "\r\nInternettet er stort, svært, gigantisk. Noen bør sortere ut et par ting som kan være verdt å lese. Denne uken har jeg valgt ut noen kilder om journalisme.\r\nI et demokrati har Journalisten den svært viktige oppgaven det er å holde oversikt med hvem som får hvilke ressurser, når og hvordan, samt hvorfor dette skjer – for så å informere et størst mulig publikum om det etterpå. Etter å ha jobbet med PR for studentfestivalen ISFiT – verdensstørstestudentfestivalmedtematiskfokus, værsågod – og blant annet fått pressemeldinger direkte skrevet av på dagbladet.no og lest opp på NRK Midt-Norges nyhetssending, så ville jeg vært litt treig hvis jeg ikke ble litt skeptisk til hvordan mediene arbeider. Som Niels Christian Geelmuyden liker å si: ««VIL DERE VITE hva en nyhet er for noe», spurte en kjent amerikansk journalist en gang i tiden. «En nyhet er noe som et eller flere mennesker svært nødig vil at andre skal få kjennskap til.» «Vil dere vite hva resten er», spurte han og viftet med en avis. «Resten er reklame.» (I Aftenposten 2011, om WikiLeaks).\r\nDette har også Ignacio Ramonet tematisert i uttrykket «den femte statsmakt», som kanskje ble brukt for første gang i et tysk foredrag mai 2005: Den fjerde statsmakt, mediene, har mislykkes i sin rolle som maktkritikere, gravere og sannhetsvoktere, og har blitt sammenblandet med mektige politiske og økonomiske aktører – staten og kapitalen og mediene sitter i samme båt, om du vil.\r\nEn svært dyktig journalist som har brukt å si høylydt hva han mener om dette er Robert Fisk (av Vice Magazine betegnet som «A Journalistic God«. Fylt med rettferdig vrede har han langet ut fra Beirut, blant annet mot hvordan utenriksdekning i vestlige (i hovedsak engelske og amerikanske) medier overtar statlige synspunkt og statlig språk, og blir dermed et verktøy for reprodusering av England og USAs propanganda rundt Afghanistan, Irak, Palestina, Israle – eller for Tyrkias fornektelse av folkemordet på armenerne. The New York Times kunne vært omdøpt til «Official say» uttalte han under et foredrag en gang.\r\nHerman og Chomskys «Manufacturing Consent» fra 1988 tar for seg hvordan profittorientering, maktkonsentrering, annonsørenes makt, store aktørers informasjonsmakt, protester, interesseorganisasjoner og antikommunisme eller krigen mot terror hindrer mediene i å oppfylle sitt egentlige oppdrag. Joakim Møllersen, styremedlem i Radikalt Økonominettverk, hadde i mars i år en god artikkel om problemstillingen på Dagsavisens «Nye Meninger»-side.\r\nRamonets forslag til en løsning på problemene som han, Herman og Chomsky skisserer er kritisk borgerjournalisme, muliggjort blant annet gjennom informasjonsrevolusjonen og bloggen. Dette ble også plukket opp av Civitas daværende nestleder Finn Bergersen, som riktignok mente uttrykket kom fra CNN (og ikke radikaleren Ramonet): Bergersen snakker blandt annet om hvordan bloggen er iferd med å innta rampelyset som viktig journalistisk verktøy, og anbefaler nordmenn å ta en titt på dette nye fenomenet. Seks år er tydeligvis mange år på internett – men ikke for mange, Bergersens tips om å kikke på Global Voices (en blogg med bloggere som rapporterer om innholdet i blogger i hele verden) er fortsatt et godt tips.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-19T00:48:20+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2011-08-26-generasjon-praktikum/",
    "title": "Generasjon Praktikum",
    "description": "Om generasjonen av tysk ungdom som jobber gratis i praksis.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2011-08-26",
    "categories": [],
    "contents": "\r\nPraktikum (n). Subst., praksis (m), praksisperiode (m), praktikanttjeneste (m) (1). Et praksisopphold mange tyske studenter må gjennom for å få godkjent gradene sine, måtte det være bachelor- eller mastergrad, eller noe mer utdatert som magister eller diplom. Mange som ikke må p.g.a. studiet gjør det allikevel for å få hardt tiltrengt arbeidserfaring i et land hvor arbeidsløsheten de siste tolv månedene har ligget på rundt 7% (og underansettelsen på over 10%) (Kilde: SpiegelOnline)\r\nSå pregende for Tyskland er dette at det inngikk i testen jeg tok for å kunne studere i Tyskland (Test Deutsch als Fremdsprache). Og resultatet? Tusenvis av unge studenter arbeider gratis i hele Tyskland. Det har gitt opphav til et eget begrep: «Generasjon Praktikum». Begrepet, først brukt av ZeitOnline i 2005, viser til hvordan studenter som egentlig er på jakt etter en fast jobb ser seg nødt til å ta den ene ubetalte praksisperioden etter den andre. For hvem vil vel ha en CV full av hull?\r\nI og for seg er ikke en praksisperiode noe negativt – en får yrkeserfaring og en mulighet til å prøve en jobb. Hvilken statsviter har vel ikke drømt om en praksisplass hos SSB, eller kanskje hos en avis, et handelskammer, eller kanskje et mindre kontor? Gjennom å normalisere slike praksisopphold kan det tenkes at selv små bedrifter med små midler kan ta seg råd til å ta ombord en praktikant. Slik vil tilbudet av relevante praksisplasser kunne øke.\r\nMen hvis tilbudet på kvalifisert arbeidskraft fra høyskoler og universiteter øker mer, da kan firmaenes lovnader om nødvendig arbeidserfaring fort gli over til utbytting av billig og kvalifisert arbeidskraft. Hvorfor ansette noen fast, når en nyutdanna person er villig til å gjøre jobben gratis eller for sultelønn? Kvalifisert overskuddsarbeidskraft med utdanning, som mer enn alt annet ønsker seg en jobb – kanskje for å betale tilbake lån opptatt under studiene, kanskje for å få litt status.\r\nBare synd at ikke alle er istand til å ta slike jobber – ikke alle har foreldre som kan finansiere kost og/eller losji, mens den lovende spiren jager arbeidserfaring. Resultatet burde dermed bli økte forskjeller mellom barn av rike foreldre og fattigere foreldre. Ifølge representanter for et streikeforsøk i 2009 gjelder dette særlig høyskolestudenter (SpiegelOnline).\r\nArgumentene for og imot er greie nok – men hvordan ser situasjonen ut? Den tyske diskusjonen var fram til 2007 basert på anekdoter eller ikke-representative tall. En undersøkelse fra Hochschuls-Informations-System fant at kjedepraksisopphold ikke var et vanlig fenomen, at det var mer utbredt blandt humanister, samfunns- og medievitere enn blant teknisk-naturvitenskapelige fag, og at en mer fruktbar problemstilling ville være å se på kortfristig og underbetalt ansettelse.\r\nEn liknende undersøkelse ble i 2011 gjennomført i Østerrike, og resultatet var liknende: Kjedepraksis og langtidsarbeidsløshet etter endt studium er uvanlig. En organisasjon som kaller seg «Generation Praktikum» gikk ut mot undersøkelsen. De påpekte at det takk og pris ikke var slik, men at undersøkelsens ønske om å avmytifisere Generasjon Praktikum-begrepet ikke holdt mål: Den fokuserte ikke på studentenes betingelse rett etter endt studium, men først på de som hadde vært ute på arbeidsmarkedet i 2-6 år, mente organisasjonen. De hevdet at nylig utstuderte arbeidstakere måtte tåle lav lønn og dårligere arbeidsbetingelser, og at dette gjaldt noen (i undersøkelsen ikke undersøkte) yrkesgrupper som kunstnere mer enn f.eks. ingeniører (kilde: Generation Praktikum).\r\nI Italia er visstnok situasjonen verre, fordi arkitekter, revisorer, advokater o.l. må avlegge lange praksisopphold for å få lisensene sine), men her fant jeg ingen konkrete tall (kilde: Wikipedia). I England gikk «Institute for Public Policy Resarch» ut i The Telegraph og pekte på at ubetalte og kost-og-losji-baserte «internships» med en varighet over seks måneder og/eller arbeidsoppgaver som kan defineres som «normale», normalt sett ville være ulovlig – minstelønnregler må respekteres, også her. Dette betyr langt ifra at det er unormalt – The Guardian hadde i slutten av juli 2011 en sak om hvordan kjendiser auksjonerte bort praksisopphold til høystbydende, og noen av uttalelsene i denne artikkelen tyder på at selv om store selskaper som ansetter akademikere betaler praktikantene sine, gjør små og mellomstore bedrifter det ikke. Flere artikler hos The Guardian.\r\nTall for Norge hadde også vært kjekt – et kjapt google-søk gir bare et upresist anslag: I Norge er «internships» som regel moderat lønnet, ifølge Aftenposten. Det får være en idé til framtidig blogging.\r\nHva jeg synes? Richard Cobbett, freelancende journalist og tidligere redaktør, kan siteres på at «If it’s worth printing, it’s worth paying». Det er en mening jeg deler – hvis utført arbeid er verdt å bruke, så er det verdt å betale for (Kilde: Funambulism).\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-19T00:40:41+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2011-10-03-wto-fra-alfa-til-omega/",
    "title": "WTO fra alfa til omega",
    "description": "Grunnleggende artikkel om WTO fra Attacs medlemsblad Taklinger.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2007-10-03",
    "categories": [],
    "contents": "\r\nWTO – Hva nytt kan man si?\r\nnovember 1999. Regnet høljer ned i Seattle. I gatene utenfor noen møtelokaler er 100 000 demonstranter samlet for å protestere mot urettferdighet. Kamprop, faner og protestmarsj. Til tross for tåregass, gummikuler og politivold er protestene så høylydte at ministerkonferansen i Verdens Handelsorganisasjon bryter sammen, ute av stand til å sette i gang en ny forhandlingsrunde.\r\nAttac og WTO er begge barn av den økonomiske globaliseringen, men er langtifra glade i hverandre. Setter en seg ned og leser en artikkel om WTO med Attac-vinkling kan en fort få inntrykk av at det er djevelen som blir omtalt i særdeles lite smigrende ordlag. Det kan derfor være på tide å ta et skritt tilbake, og se på hva Verdens Handelsorganisasjon egentlig er.\r\nWTO fra A til Å\r\nWTO (uttales dåbbeltveteo), Verdens Handelsorganisasjon, ble oppretta i januar 1995 som en avløsning av GATT. GATT var den internasjonal hovedavtalen om handel og toll som ble innført i 1948. Sammen med en rekke andre tiltak skulle GATT sørge for at de internasjonale økonomiske kreftene skapte vekst, enighet og fred, ikke kollaps, uenighet, og krig.\r\nHvorvidt perioden fra 1940 til 1990 var preget av enighet og fred kan selvsagt diskuteres, men vekst og endring var så absolutt tilstede. Teknologiske framskritt gjorde verden mindre, handelen økte, og ønsket om økt handel økte enda mer. Med økt handel ble land mer gjensidige avhengig av hverandre. Denne prosessen er den økonomisk globaliseringa.\r\nI forsøket på å håndtere den økonomiske globaliseringa utviklet GATT, opprinnelig kun et avtaleverk, seg etterhvert til en semi-institusjon. Denne semi-institusjonen var imidlertid hverken sterk eller omfattende nok til å håndtere det stadig økende ønsket om internasjonal handel. Et vilkår for at internasjonal handel skal fungere, er nemlig trygghet og stabilitet i det internasjonale markedet. Internasjonal handel vil dermed være tjent med internasjonale institusjoner, som kan forhandle fram avtaler, håndheve regler og fungere som legitime møteplasser. Både stater, transnasjonale selskap og økonomer innså dermed at det trengtes et nytt mutilateralt avtaleverk for frihandel som var bedre tilpasset den økte økonomiske globaliseringa. Dermed ble WTO opprettet.\r\nI dag er så godt som alle verdens handlende land medlem av WTO. Organisasjonen har hovedkvarter og sekretariat i Geneve, med rundt 500 ansatte. Det viktigste organet er ministermøtet som blir avholdt annethvert år. WTOs arbeidsoppgaver er å forvalte og overvåke handelsreglene, løse handelskonflikter og være et forum for videre forhandlinger av handelsregler.\r\nWTOs formål\r\nWTOs mål er ifølge vedtektene deres å øke den økonomiske veksten i alle medlemsland gjennom å redusere toll og andre handelshindringer, liberalisere verdenshandelen og skape et forutsigbart, regelbasert handelssystem basert på ikke-diskriminering. Ikke-diskriminering vil på norsk si likebehandling av nasjonale og utenlandske bedrifter, og at alle land skal ha like vilkår.\r\nDet internasjonale handelsregelverket WTO regulerer er utviklet gjennom åtte forhandlingsrunder. Dette regelverket innbefatter GATT, handel med varer, GATS, handel med tjenester, og TRIPS, intellektuell eiendomsrett, også kjent som patenter. Det er mange som mener at WTO ved sin rolle i det internasjonale økonomiske systemet er en av de absolutt mektigste internasjonale organisasjonene.\r\nWTOs rolle er dermed å sørge for at alle følger, og bli behandlet likt av, reglene i det internasjonale markedet. Uten en slik garantist vil det være svært fristende for ett land å sette i gang proteksjonistiske tiltak, og dermed tjene penger på handel uten å måtte gi fra seg markedsandeler til andre land. I det flere land tyr til en slik proteksjonistisk strategi, vil det internasjonale økonomiske systemet kunne kollapse.\r\nInteresser\r\nEt av det viktigste poengene ved WTO er at det er en plattform hvor medlemslandene kan forhandle fram handelsavtaler. Disse medlemslandene har selvsagt svært sprikende interesser, og vil gjerne eksportere mer av det de kan konkurrere med, men nødig importere mer på de områdene der konkurranseevnen mangler. Et av de virkelige store problemene med WTO er mangelen på sammenfallende interesser.\r\nEn type interesser som kan antas å ha relativt stor gjennomslagskraft er de internasjonale storkonsernene. Store selskaper som Coca Cola, Kraft, og General Motors som har større sluttsummer i regnskapene sine enn flere land. Et eksempel på storselskapenes betydning ser en i TRIPS-reguleringene. TRIPS, eller Handelsrelaterte Aspekter ved Intellektuell Eiendomsrett, er patentlovgivning som er ment å sikre insentiver til utvikling av ny teknologi. Gjennom disse avtalene stiller statene som godkjenner avtalen seg bak kravet fra selskapene om at den som gjør en oppdagelse/oppfinnelse, skal kunne patentere denne, få monopol på ideen og dermed kunne tjene inn igjen det det har kostet å oppdage/oppfinne ideen.\r\nKritikere hevder imidlertid at dette kan sees som monopolisering av kunnskap. Denne monopoliseringen kan imidlertid være skadelig for U-land, siden den minsker muligheten de har til å tilegne seg teknologi. Det at disse rettighetene er så sterke som de faktisk er, kan tyde på at transnasjonale selskaper og storkonsern har en betydelig innflytelse.\r\nGlobal rettferd\r\n80% av verdens befolkning må dele 20% av verdens kake. 20% av verdens befolkning har kontroll over 80% av verdens verdier. Rundt en milliard mennesker lever på under én dollar dagen, gudene vet hvor mange som lever på under to, eller tre. Afrika sør for Sahara opplever fortsatt økonomisk stillstand eller tilbakegang. Halvparten av verdens befolkning har aldri holdt en telefon.\r\nHandel blir av mange sett på som et godt verktøy for å rette på situasjonen. WTO har jo da også som mål å skape økt økonomisk vekst i alle sine medlemsland gjennom å liberalisere verdenshandelen. Som en nøkkelinstitusjon og plattform når det kommer til internasjonal handel, burde dermed WTO i teorien kunne bidra til positiv utvikling for de fattigste landene.\r\nI 2001 ble det i Doha, hovedstaden i Quatar, vedtatt en niende forhandlingsrunde, den såkalte utviklingsrunden. En rapport utgitt av SEATINI, Sør og Østafrikansk Handelsinstitutt, som analyserer hvorvidt Doha-runden er en reell utviklingsrunde konkluderer med et rungende «Nei!» De hevder at siden WTO er bygd på prinsippet om likebehandling og gjensidige ytelser mellom medlemslandene, så kan ikke urettferdigheten rettes opp. Skal u-landenes interesser ivaretas, må disse landene særbehandles. Dette har til nå ikke skjedd.\r\nSpørsmålet blir dermed, slik WTO fungerer i dag, hvilke interesser som får gjennomslag og om disse interessene har interesse av at fattige land skal tjene på frihandelsregimet.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-19T00:52:12+01:00",
    "input_file": {}
  }
]
