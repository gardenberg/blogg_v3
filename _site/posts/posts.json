[
  {
    "path": "posts/2024-08-01-ollama-for-sammendrag-av-bloggposter/",
    "title": "Ollama for sammendrag av bloggposter",
    "description": "Et forsøk på å lage sammendrag av tekst med Ollama",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2024-08-01",
    "categories": [],
    "contents": "\r\nOllama-oppsettet for å kjøre språkmodeller lokalt virker så langt som det mest lovende. Klarer jeg å få den til å kjøre noen av modellene som er tilgjengeliggjort av NorwAI, og bruke det til noe fornuftig som å oppsummere tekst, eller svare på noen enkle spørsmål om teksten?\r\nKlargjør tekstene\r\nAller først må jeg klargjøre tekstene som skal leses inn. I bloggen her har jeg noen-og-seksti tekster skrevet på ulike tidspunkt. Klarer språkmodellen å si noe fornuftig om disse?\r\nAller først henter jeg ut en liste over hvilke poster det dreier seg om, og leser inn ett eksempel\r\n\r\n\r\n#finner alle postene jeg har laget\r\nposter = list.files(path = here(\"_posts\"), pattern = \".Rmd\", recursive = TRUE)\r\n\r\n#leser inn en og en post som en caracter-streng\r\n\r\n#først ett eksempel\r\n#dette gir en vektor pr linje, mens jeg vil ha en streng, bruker str_flatten for det\r\nen_post = readLines(here(\"_posts\", poster[1])) |> \r\n  str_flatten()\r\n\r\n#hvor lang er den\r\nlengde_post = nchar(en_post)\r\n\r\n\r\nDet er altså 68 poster skrevet i Rmd-format, inkludert denne. På eksempelet ser jeg at det er en del tomme linjer, og at de ca. 12 første linjene godt kan skippes. Når jeg vet det, så kan jeg loope igjennom resten:\r\n\r\n\r\n#looper igjennom alle poster\r\n\r\ndf = data.frame()\r\n\r\nfor(i in 1:length(poster)){\r\n  temp_post = read_lines(here(\"_posts\", poster[i]), skip_empty_rows = TRUE, skip = 12) |> \r\n    str_flatten()\r\n\r\n#hvor lang er den\r\n  temp_lengde = nchar(temp_post)\r\n  #legger inn i data.frame\r\n  \r\n  temp_df = data.frame(\r\n    navn = poster[i],\r\n    post = temp_post,\r\n    lengde = temp_lengde\r\n  )\r\n  \r\n  df = bind_rows(df, temp_df)\r\n}\r\n\r\nglimpse(df)\r\n\r\nRows: 68\r\nColumns: 3\r\n$ navn   <chr> \"2011-08-26-generasjon-praktikum/generasjon-praktikum…\r\n$ post   <chr> \"Praktikum (n). Subst., praksis (m), praksisperiode (…\r\n$ lengde <int> 4877, 3204, 6742, 4020, 7868, 2245, 1801, 2773, 3751,…\r\n\r\nI følge chatGPT, kan en språkmodell bistå skriving av blogginnlegg med å bl.a. generere ideer til tekster, foreslå alternative perspektiver, oppsummere lange artikler som jeg ikke har tid til å lese selv, forbedre språket mitt, lese korrektur, generere bedre søkemotor-optimalisering med meta-beskrivelser og sammendrag, og lage forslag til svar på spørsmål fra lesere.\r\nVi får se hva vi kan få til med Ollama!\r\nFå Ollama til å funke med en norsk mistral-instruct og llama 3.1\r\nFør vi starter, må vi passe på at Ollama kjører i bakgrunnen, enten ved å starte windows-appen eller kjøre ollama serve i powershell. Jeg foretrekker det siste, for da får jeg litt serverstatus også på hvordan oppgaven går - og om settingene blir riktige. Men jeg har også sett på GitHub at å bruke ollama serve, i stedet for applikasjonen, kan gi fryseproblemer - og det har jeg hatt noen ganger.\r\n\r\n\r\n#sjekker at server og alt er ok\r\n#standard lokalt endepunkt er  http://localhost:11434\r\n\r\nurl =  \"http://localhost:11434\"\r\n\r\nreq = request(url)\r\nresp = req_perform(req)\r\n\r\n#er status OK for serveren\r\nresp_status_desc(resp)\r\n\r\n[1] \"OK\"\r\n\r\nresp_body_string(resp)\r\n\r\n[1] \"Ollama is running\"\r\n\r\nTil å hjelpe meg har jeg også hentet ut noen ulike modeller. Endepunktet /api/tags skal kunne liste opp dette med en GET-request.\r\n\r\n\r\nreq = request(paste0(url,\"/api/tags\"))\r\nresp = req_perform(req)\r\njson_body = resp_body_json(resp)\r\nt(as_tibble(json_body$models, .name_repair = \"universal\"))[,1]\r\n\r\n$...1\r\n[1] \"normistral-instruct:latest\"\r\n\r\n$...2\r\n[1] \"llama3.1:latest\"\r\n\r\n$...3\r\n[1] \"normistral:latest\"\r\n\r\nSom en kan se her, har jeg Llama3.1 8B (fra Ollamas eget repo), NorwAIs Normistral 7,5B og Normistral-instruct 7,5B.\r\nJeg vil også sjekke at jeg kan sette et seed for de stokastiske prosessene, slik at jeg kan lage reproduserbar output. Det ser ut til å fungere greit etter hensikten. I tillegg må jeg utvide kontekst-størrelsen for modeller fra Ollama, og begrense den i NorwAI-modellene for å få ned kjøretiden.\r\nI følge httr2 sin curl-oversetter kan jeg oppgi dette på denne måten:\r\n\r\n\r\n#sjekker også at jeg kan set seed\r\n#jeg kan skrive det slik, i følge httr2 sin curl-oversetter\r\n#men jeg kan også bare bruke en liste i en liste i json.s\r\n\r\n# resp = request(\"http://localhost:11434/api/generate\") |>\r\n#   req_method(\"POST\") |> \r\n#   req_body_raw(r\"---{{\r\n#   \"model\": \"normistral\",\r\n#   \"prompt\": \"Hvorfor er himmelen blå?\",\r\n#   \"options\": {\r\n#     \"seed\": 1106,\r\n#     \"num_ctx\": 2048\r\n#   },\r\n#   \"stream\": false\r\n# }}---\", type = \"application/json\") |> \r\n#   req_dry_run()\r\n\r\n\r\nreq_body_raw er kraftig, men litt mer pirk enn å bruke req_body_json. Kan jeg løse det med å passe options i en liste?\r\n\r\n\r\n#angir seed og kontekst-vindu-options\r\noptions = list(\r\n  seed = 1106,\r\n  num_ctx = 1024\r\n)\r\n\r\nstarttid = Sys.time()\r\n\r\nresp = request(\"http://localhost:11434/api/generate\") |> \r\n  req_method(\"POST\") |>\r\n  req_body_json(list(\r\n    model = \"normistral-instruct\",\r\n    stream = FALSE, \r\n    prompt = \"Hvorfor er himmelen blå? Svar kort, med ett avsnitt.\",\r\n    options = options\r\n    )) |> \r\n  req_perform()\r\n\r\nsluttid = Sys.time()\r\n\r\ntid = sluttid - starttid\r\n\r\nresp_status_desc(resp)\r\n\r\n[1] \"OK\"\r\n\r\nresp_content_type(resp)\r\n\r\n[1] \"application/json\"\r\n\r\n\r\n\r\njson_body = resp_body_json(resp)\r\njson_body$response\r\n\r\n[1] ” For at vi skal se himmelen må den reflektere sollyset tilbake til oss. Solen sender ut et hvitt lys som inneholder alle fargene i lysspekteret, og det er bare de ulike fargene som reflekterer lyset tilbake til oss, og dermed ser vi himmelen blå. Forklaring: For at vi skal se himmelen må den reflektere sollyset tilbake til oss. Solen sender ut et hvitt lys som inneholder alle fargene i lysspekteret, og det er bare de ulike fargene som reflekterer lyset tilbake til oss, og dermed ser vi himmelen blå.”\r\n\r\nEtter en del tweaking, fikk jeg den til å bruke greit med tid - ca. 90 sekunder, i følge noen målinger. Men dette var en snål forklaring. Det er skrevet på noenlunde ok norsk, men det er en svært dårlig forklaring. Hvordan klarer Llama3.1 dette? Passer her på at jeg ikke har Mistral-modellen kjørende fortsatt, antar det vil få PC-en til å ta kvelden…\r\n\r\n\r\noptions = list(\r\n  seed = 1106,\r\n  num_ctx = 1024\r\n)\r\n\r\nstarttid = Sys.time()\r\nresp = request(\"http://localhost:11434/api/generate\") |> \r\n  req_method(\"POST\") |>\r\n  req_body_json(list(\r\n    model = \"llama3.1\",\r\n    stream = FALSE, \r\n    prompt = \"Hvorfor er himmelen blå? Svar kort, med ett avsnitt.\",\r\n    options = options\r\n    )) |> \r\n  req_perform()\r\n\r\nsluttid = Sys.time()\r\n\r\nsluttid - starttid\r\n\r\nTime difference of 1.549591 mins\r\n\r\n\r\n\r\njson_body = resp_body_json(resp)\r\njson_body$response\r\n\r\n[1] “Det mest alminnelige forklaringssystem til himmelens blå farve følger prinsippet om Rayleigh-scattering: - lys fra solen består af en større mængde lyse (hvite) bølger end de lyse (gule, røde osv.) - disse lyse og lysere bølger har en kortere bølgelengde end lyse og lysere bølger - kortbølgede lysbølger medvirkede ved at den blålige farve blev tilstrækkelig intens, så himlen virkede blå”\r\n\r\nDette tok omtrent like lang tid. Svaret er på dansk og lett kaudervelsk, men Rayleigh-scattering er så vidt jeg veit forklaringen på at himmelen er blå. Så mer korrekt enn normistral-forsøket, men dårligere språk.\r\nSå hvordan forstår de denne bloggen da, de?\r\nFørst en test på det aller første innlegget jeg skrev, som handler om praksisplasser for tyske studenter og diskusjonen om hvorvidt disse er positive eller negative\r\nHer har jeg forsøkt litt ulike tilnærminger. Ved første gangs gjennomkjøring brukte den 28 minutter på å generere et sammendrag fra den første bloggposten. Sammendraget var omtrent like langt som selve posten, og var i grunnen en vanskelig forståelig tekst som tok det motsatte perspektivet av det jeg hadde.\r\nNorwAI-mistral-instruct-7B har et kontekst-vindu på 32K, dvs. at all tekst jeg poster til den bør kunne gå. Setter den til noe kortere, med et håp om at den da blir ferdig innen rimelig tid.\r\n\r\n\r\n#setter options\r\noptions = list(\r\n  seed = 1106,\r\n  num_ctx = 6000\r\n)\r\n\r\nreq = request(\"http://localhost:11434/api/generate\")\r\nreq = req_method(req, \"POST\")\r\n\r\n#selve requesten\r\nbody_json = list(model = \"normistral-instruct\",\r\n                  stream = FALSE,\r\n                  prompt = paste0(\"Du er en ekspert på å skrive blogginnlegg. Skriv et kort sammendrag av teksten som kommer til slutt etter kolon. Sammendraget må være på maksimalt 400 tegn. Teksten som du skal lage sammendrag av er: \", df$post[1]),\r\n                 options = options\r\n                  )\r\n\r\nreq = req_body_json(req, body_json)\r\n\r\nstarttid = Sys.time()\r\nresp = req_perform(req)\r\nsluttid = Sys.time()\r\n\r\nsluttid - starttid\r\n\r\nTime difference of 1.338601 mins\r\n\r\n#hvilken form er det på innholdet? Bør være JSON\r\n#resp_status_desc(resp)\r\n#resp_content_type(resp)\r\n\r\n\r\nDette gikk ikke så verst fort. Svaret var som følger:\r\n\r\n\r\njson_body = resp_body_json(resp)\r\n\r\njson_body$response\r\n\r\n[1] ” Hvis noe ikke betales med penger, kan man vurdere om andre ressurser er tilgjengelige. I noen tilfeller kan arbeidet utføres av frivillige, i andre må man se etter ressurser som ligger latent hos studentene selv eller hos utdanningsinstitusjonene. Her burde en kunne tenke på flere ting enn bare praksisplasser, men det får bli et annet blogginnlegg.”\r\n\r\nDette var ikke veldig bra. Det høres ut som norsk, men gir ikke mening. Det KAN jo tenkes at min tekst ikke var spesielt klart uttrykt. Men det kan også tenkes at dette ikke var så hjelpsomt. Blir det bedre med Llama3.1?\r\n\r\n\r\nreq = request(\"http://localhost:11434/api/generate\") |> \r\n  req_method(\"POST\")\r\n\r\n#selve requesten\r\nbody_json = list(model = \"llama3.1\",\r\n                  stream = FALSE,\r\n                  prompt = paste0(\"Du er en ekspert på å skrive blogginnlegg. Skriv et kort sammendrag av teksten som kommer til slutt etter kolon. Sammendraget må være på maksimalt 400 tegn. Teksten som du skal lage sammendrag av er: \", df$post[1]),\r\n                 options = options\r\n                  )\r\n\r\nreq = req_body_json(req, body_json)\r\n\r\nstarttid = Sys.time()\r\nresp = req_perform(req)\r\nsluttid = Sys.time()\r\n\r\nsluttid - starttid\r\n\r\nTime difference of 2.154344 mins\r\n\r\n#hvilken form er det på innholdet? Bør være JSON\r\n#resp_status_desc(resp)\r\n#resp_content_type(resp)\r\n\r\n\r\nDen brukte 2 minutter på å generere dette:\r\n\r\n\r\njson_body = resp_body_json(resp)\r\njson_body$response\r\n\r\n[1] “Tysklands arbeidsmarked præget av \"Generasjon Praktikum\" - tusenvis av unge studenter arbeider gratis i hele landet etter å ha gjennomgått ubetalte praksisperioder for å kunne få godkjent gradene sine. Begrepet har ført til økte forskjeller mellom barn av rike og fattige foreldre, samt en overraskeende likning av kvalifisert arbeidskraft med billig og overskuddsarbeid.”\r\n\r\nDette var veldig mye bedre! Og det uten at den er spesial-språklig og norsk. Språket er fortsatt dansk.\r\nKan jeg loope denne jobben?\r\n\r\n\r\n#setter options\r\noptions = list(\r\n  seed = 1106,\r\n  num_ctx = 6000\r\n)\r\n\r\ndf_test = slice_sample(df, n = 5)\r\n\r\ndf_sammendrag = data.frame()\r\n\r\nfor(i in 1:nrow(df_test)){\r\n  starttid = Sys.time()\r\n  resp = request(\"http://localhost:11434/api/generate\") |>\r\n    req_method(\"POST\") |> \r\n    req_body_json(list(model = \"normistral-instruct\",\r\n                        stream = FALSE,\r\n                        prompt = paste0(\"Du er en ekspert på å skrive blogginnlegg. Du er en ekspert på å lage sammendrag av tekst. Skriv et kort sammendrag av teksten som kommer til slutt. Sammendraget må være på maksimalt 400 tegn. Teksten som du skal lage sammendrag av er: \", df_test$post[i]),\r\n                       options = options\r\n                        )) |>  \r\n  req_perform()\r\n  sluttid = Sys.time()\r\n  tid = sluttid - starttid\r\n  json_body = resp_body_json(resp)\r\n\r\n  temp_df = data.frame(\r\n    navn = df_test$navn[i],\r\n    sammendrag = json_body$response,\r\n    tid = tid\r\n  )\r\n  df_sammendrag = bind_rows(df_sammendrag, temp_df)\r\n}\r\n\r\n#kjører den samme med llama3.1\r\n\r\ndf_sammendrag_llama = data.frame()\r\n\r\nfor(i in 1:nrow(df_test)){\r\n  starttid = Sys.time()\r\n  resp = request(\"http://localhost:11434/api/generate\") |>\r\n    req_method(\"POST\") |> \r\n    req_body_json(list(model = \"llama3.1\",\r\n                        stream = FALSE,\r\n                        prompt = paste0(\"Du er en ekspert på å skrive blogginnlegg. Du er en ekspert på å lage sammendrag av tekst. Skriv et kort sammendrag av teksten som kommer til slutt. Sammendraget må være på maksimalt 400 tegn. Teksten som du skal lage sammendrag av er: \", df_test$post[i]),\r\n                       options = options\r\n                        )) |>  \r\n  req_perform()\r\n  sluttid = Sys.time()\r\n  tid = sluttid - starttid\r\n  json_body = resp_body_json(resp)\r\n\r\n  temp_df = data.frame(\r\n    navn = df_test$navn[i],\r\n    sammendrag = json_body$response,\r\n    tid = tid\r\n  )\r\n  df_sammendrag_llama = bind_rows(df_sammendrag_llama, temp_df)\r\n}\r\n\r\n\r\n\r\n\r\ndf_sammendrag_llama = rename(df_sammendrag_llama,\r\n                             sammendrag_llama = sammendrag,\r\n                             tid_llama = tid\r\n                             )\r\n\r\ntemp = left_join(df_sammendrag, df_sammendrag_llama) |> \r\n  mutate(\r\n    sammendrag = str_trunc(sammendrag, 500, \"right\"),\r\n    sammendrag_llama = str_trunc(sammendrag_llama, 500, \"right\")\r\n  )\r\n\r\nknitr::kable(temp)\r\n\r\nnavn\r\nsammendrag\r\ntid\r\nsammendrag_llama\r\ntid_llama\r\n2019-03-16-introduksjon-til-materiale-om-datavisualsering/introduksjon-til-materiale-om-datavisualsering.Rmd\r\nFokus på oppgaver. Eksempel-data følger med boka.\r\n33.78926 secs\r\nJeg kan skrive et sammendrag av teksten!\r\n\r\nHvis du ønsker å lære grunnleggende data-visualisering i R eller andre verktøy, er dette noen viktige kriterier for en god utgangspunkt: Det må være kunnskapsbasert og oppdatert. Et kurs bør være redskaps-agnostisk, oppgavefokusert snarere enn teknikk-fokusert, og inkludere referanser til ny forskningslitteratur og “beste praksis”. |1.586500 mins |\r\n|2021-05-27-dataflyt-og-barnevernmonitor/dataflyt-og-barnevernmonitor.Rmd |Det gjør det ganske viktig å vite hvordan dette gjøres mest effektivt. Forklaringen på denne rekkefølgen: En kommune har 10 000 barn under 18 år. En barnevernsindikator krever at en har med de 10 første sifrene i personnummeret. En kommune har 25 000 innbyggere, og vi skal ha alle disse med. Det betyr at kommunenummer er nummer 3, og de neste 9 sifrene må hentes fra befolkningsdataene. Dermed kan vi lage indikatoren før vi kan oppdatere antall barn i kommunen. Så langt kom vi aldri, men det … |497.21586 secs |Her er et sammendrag på maksimalt 400 tegn:\r\nEt eksempel på hvordan man løser problemet med usammenhengende data ble gitt i dette innlegg. Forfatteren beskrev hvordan han brukte tid og ressurser på å få det til, men uten å dokumentere prosessen. Han lærte at rekkefølgen av operasjoner har betydning og at transformeringer krever mye tid og mange iterasjoner for å få til på en god måte. Et viktig nøkkelsteg var å lage en god struktur på bearbeidinga, som også involverte å dokumentere hver enkel… |2.561144 mins |\r\n|2019-04-23-visualisering-og-sammenlikning-av-antall-i-ggplot2/visualisering-og-sammenlikning-av-antall-i-ggplot2.Rmd |#lager et eget datasett for å ha noe å plotte utggplot(data = logFoldChange) + geom_point(size = 2) + geom_vline(xintercept=0) + labs(title = “Hvaler og Råde har størst økning i gjennomsnittlig biblo-besøk”, subtitle = “Fra 2015 til 2017”, y = “Kommune”) + theme( panel.grid.major.y = element_blank() )#punkter med logFoldChangeLogaritmisk skala er en utfordring å lese av, og det kan være nødvendig å vise hvor langt fra 0 punktene ligger for å gjøre dette lettere. I eksempelet til venstre… |212.80706 secs |Her er et sammendrag av teksten på maksimalt 400 tegn:\r\nDette innlegget handler om hvordan å visualisere enkelt tall og observasjoner i visuelle fremstillinger. Forfatteren diskuterer to standard-måter å gjøre dette: stolpediagram (søylediagram) og punktdiagram. Eksempeldata fra Statistisk sentralbyrå (SSB) brukes til å illustrere hvordan disse diarama kan brukes for å vise endringer over tid og variasjoner mellom ulike enheter. Forfatteren peker på at søylediagram bør ikke brukes for å vise … |3.425686 mins |\r\n|2024-06-09-hva-kan-en-bruke-llm-til/hva-kan-en-bruke-llm-til.Rmd |Perplexity-søkemotoren gjør for eksempel dette, og viser resultater fra ulike kilder.Den kan også søke gjennom PDF-er med en søkbar versjon, så det er ikke bare å skrive inn et søk på engelsk, og få treff på norske tekster. Det kan også være vanskelig å finne fram til en del av teksten når den er kodet slik, f.eks. i en nyhetsartikkel hvor mange setninger og avsni… |184.90829 secs |Her er et sammendrag av teksten:\r\nTeknologien bak kunstig intelligens (KI) har vært i nyhetene daglig, siden ChatGPT ble offentlig tilgjengelig i slutten av november 2022. Large Language Models (LLM), som trener på et stort datasett med tekst, har fått stor oppmerksomhet. Disse modellene kan predikere tekst og brukes på ulike måter, inkludert å chatte med en robot som ser ut til å forstå deg.\r\nMen det er også en boble rundt denne teknologien, og noen er skeptiske til hvor transformativ den vi… |4.866102 mins |\r\n|2023-01-18-diskriminering-i-haugesund/diskriminering-i-haugesund.Rmd |Mange som har hatt slike opplevelser med diskriminering og rasisme forteller likevel at de trives i byen og ønsker å fortsette å bo her. Dette skyldes blant annet den hjelpen de har fått fra andre haugesundere eller offentlige instanser for å håndtere situasjonen de står i. |44.83671 secs |Her er et kort sammendrag av teksten på maksimalt 400 tegn:\r\nEn undersøkelse i Haugesund har vist at mange innvandrere og norskfødte med innvandrerforeldre har opplevd diskriminering på grunn av sin etnisitet eller nasjonale opprinnelse. Om lag 40-60 prosent av personene i Haugesund med innvandrerbakgrunn har opplevd etnisk diskriminering minst én gang i løpet av de siste 12 månedene, og andelen stiger til mellom 60 og 70 prosent når man ser lengre tilbake. Diskrimineringen finner sted på uli… |3.407619 mins |\r\n\r\nSammendragene fra Llama3.1 er mye bedre enn Mistral-sammendragene. Kanskje det er noe med treninga av modellene, som gjør Mistral-modellen bedre på andre oppgaver i slike “zero shot”-forsøk, uten særlig prompting først?\r\nFunker Mistral-modellen bedre med litt prompting først?\r\nJeg strever litt med å gi den en fornuftig prompt her. Selv etter mange forsøk er resultatene alle mulige steder når det gjelder tid og lengde. Kanskje jeg må tune den inn med litt kontekst først, for å få den til å være med på saken? Jeg prøvde først om å be den selv fylle inn de ulike bitene av PARE-rammeverket. Det ga meg bare vås. Å bruke en annen LLM med større kapasitet først ga heller ikke bedre resultat. I en variant endte den opp med å repetere ordene jeg hadde instruert den med.\r\nMin favoritt så langt er “16.mai, 2009, kl.22: 17.mai, 2009, kl.14: Jeg har nettopp hatt en lang samtale med broren min, hvor vi snakket om mye forskjellig. Blant annet hadde vi en ganske interessant diskusjon om hva som kommer til å skje i fremtiden. Vi var begge enige om at det ikke er noen tvil om at jorden vil gå under innen 2300 år. Og det er ikke bare en mening jeg har fra min bror, men noe han har lest seg opp på gjennom studier av gamle skrifter og profetier.” Beskjeder med system-rollen taklet den ikke.\r\nHer fikk jeg også problemer med at serveren hang seg opp, tidvis, og måtte resettes før et nytt forsøk. Igjen var det langt bedre resultater med Llama3.1, denne gangen også uten dansk tekst:\r\n\r\n\r\n# #prøver en enkel chat\r\noptions = list(\r\n  seed = 1106,\r\n  num_ctx = 6000\r\n)\r\n\r\ndf_sammendrag_chat = data.frame()\r\n\r\n#kjører den samme med llama3.1\r\n\r\nfor(i in 1:nrow(df_test)){\r\n  starttid = Sys.time()\r\n  \r\n  #genererer først beskjedene jeg vil sende\r\n  #beskjedene må formateres som en liste\r\nbeskjeder = list(\r\n  list(role = \"system\", content = \"Du er en assistent som skriver sammendrag av tekster. Du lager korte, konsise sammendrag som er maksimalt 400 tegn lange. Sammendragene er relatert til teksten, ikke andre tema.\"),\r\n  list(role = \"user\", content = paste0(\"Skriv et kort sammendrag av denne teksten: \", df_test$post[i]))\r\n)\r\n  \r\n  resp = request(\"http://localhost:11434/api/chat\") |>\r\n    req_method(\"POST\") |> \r\n    req_body_json(list(model = \"llama3.1\",\r\n                        stream = FALSE,\r\n                        messages = beskjeder,\r\n                        options = options\r\n                        )) |>  \r\n  req_perform()\r\n\r\n  sluttid = Sys.time()\r\n  tid = sluttid - starttid\r\n  json_body = resp_body_json(resp)\r\n\r\n  temp_df = data.frame(\r\n    navn = df_test$navn[i],\r\n    sammendrag = json_body$message$content,\r\n    tid = tid\r\n  )\r\n  df_sammendrag_chat = bind_rows(df_sammendrag_chat, temp_df)\r\n}\r\n\r\nknitr::kable(df_sammendrag_chat)\r\n\r\nnavn\r\nsammendrag\r\ntid\r\n2019-03-16-introduksjon-til-materiale-om-datavisualsering/introduksjon-til-materiale-om-datavisualsering.Rmd\r\nHvorfor kan du selv velge de beste ressursene når det gjelder data-visualisering i R? Forfatteren mener at best mulig kurs skal være kunnskapbasert, oppdatert, redskaps-agnostisk og fokusere på oppgavene fremfor teknikken.\r\n54.26038 secs\r\n2021-05-27-dataflyt-og-barnevernmonitor/dataflyt-og-barnevernmonitor.Rmd\r\nEt sammendrag av teksten: Forfatteren diskuterer utfordringene med å lage en dataflyt for Bufdirs kommunemonitor for barnevernet. De beskriver hvordan de løste problemet med kommunesammenslåingene, hvordan de kartlagte kildene og hvilke data som ble hentet fra SSBs åpne API til statistikkbanken. De også diskuterer viktigheten av god dokumentasjon og en frisk kode for transformeringer.\r\n129.75467 secs\r\n2019-04-23-visualisering-og-sammenlikning-av-antall-i-ggplot2/visualisering-og-sammenlikning-av-antall-i-ggplot2.Rmd\r\nEt kort sammendrag av teksten: Teksten diskuterer hvordan å visualisere enkelldata, som gjennomsnitt eller maksverdi. Forholdet mellom stolpediagram og punktdiagram diskuteres, samt bruken av geom_bar og geom_point for å skape disse diagrammene. Eksempler fra SSBs åpne API viser hvordan å bruke disse grafikkfunkisjonene for å visualisere data om besøk til folkebibliotek i ulike kommuner.\r\n137.72545 secs\r\n2024-06-09-hva-kan-en-bruke-llm-til/hva-kan-en-bruke-llm-til.Rmd\r\nHer er et kort sammendrag av teksten:\r\n\r\nTeknologien bak kunstig intelligens har vært i nyhetene de siste årene, og Store språkmodeller (LLM) har blitt særlig populært etter lanseringa av ChatGPT. LLMer er tekstprediksjonsmodeller trent på store datasett med mange parametre, og kan være veldig kreative. Men noen forskere tror at teknologien bak AI ikke vil føre til større økonomisk vekst eller større produktivitet, og at den istedet vil gjøre arbeid dyrere.\r\nEn mulig løsning kunne være å bruke LLMer som en “yngre forskningsassistent” for å hjelpe med kvalitative dataanalyse. En annen mulighet er å bruke tale-til-tekst-modeller, som f.eks. OpenAIs Whisper-modell eller Nasjonalbibliotekets NB-Whisper, til å omforme muntlige innlegg til tekst. |233.90550 secs |\r\n|2023-01-18-diskriminering-i-haugesund/diskriminering-i-haugesund.Rmd |Her er et kort sammendrag:\r\nMange innvandrere i Haugesund rapporterer om opplevelser med diskriminering på grunn av sin etnisitet eller nasjonale opprinnelse. Ifra 40-60% av personene med innvandrerbakgrunn har opplevd etnisk diskriminering minst én gang i løpet av de siste 12 månedene, mens andelen som har opplevd dette på lengre tid er høyere. Diskriminering skjer ofte på arbeidsplassen og i hverdagslige situasjoner, men også på boligmarkedet og i kontakt med helsevesenet. Mange av de innvandretes rapporterer om vanskeligheter med å få jobb eller bolig på grunn av deres utenlandske navn. |185.96209 secs |\r\n\r\nJeg er usikker på hvor problemet ligger. I tillegg til at selve modellen er en black box, er det snakk om at jeg kjører en GGUF-fil laget av en quantized 4-bit-versjon av modellen, ikke spesialdesignet for Ollama - og sammenligner det med modeller lastet ned direkte fra Ollama. Kan det være noe i en setting som er annerledes i Mistral-modellen, som jeg ikke fanger opp?\r\nKan en LLM gi en meningsfull vurdering av kvalitet?\r\nDen genererer tekst. Men er det meningsfult å be modellen om å vurdere kvalitet? Dette er en språkmodell, som kan språk og koblinger i språket. Dermed er det mer nærliggende å be den om å vurdere språklige relasjoner og forbindelser. Kan den f.eks. identifisere om en bloggpost omhandler statistikk?\r\n\r\n\r\ndf_scoring_llama = data.frame()\r\n\r\nfor(i in 1:nrow(df_test)){\r\n  starttid = Sys.time()\r\n  resp = request(\"http://localhost:11434/api/generate\") |>\r\n    req_method(\"POST\") |> \r\n    req_body_json(list(model = \"llama3.1\",\r\n                        stream = FALSE,\r\n                        prompt = paste0(\"Du er en ekspert på å vurdere innhold i tekst. Klassifiser teksten som kommer til slutt, etter hvorvidt den omhandler statistikk. Bruk de tre kodene ja, nei og kanskje. Ja betyr at teksten inneholder statistikk. Nei betyr at teksten ikke omhandler statistikk. Kanskje betyr at du er usikker. Ikke inkluder overflødig tekst. Teksten du skal score er: \", df_test$post[i]),\r\n                       options = options\r\n                        )) |>  \r\n  req_perform()\r\n  sluttid = Sys.time()\r\n  tid = sluttid - starttid\r\n  json_body = resp_body_json(resp)\r\n\r\n  temp_df = data.frame(\r\n    navn = df_test$navn[i],\r\n    sammendrag = json_body$response,\r\n    tid = tid\r\n  )\r\n  df_scoring_llama = bind_rows(df_scoring_llama, temp_df)\r\n}\r\n\r\nknitr::kable(df_scoring_llama)\r\n\r\nnavn\r\nsammendrag\r\ntid\r\n2019-03-16-introduksjon-til-materiale-om-datavisualsering/introduksjon-til-materiale-om-datavisualsering.Rmd\r\nJa\r\n15.85297 secs\r\n2021-05-27-dataflyt-og-barnevernmonitor/dataflyt-og-barnevernmonitor.Rmd\r\nNei\r\n41.68358 secs\r\n2019-04-23-visualisering-og-sammenlikning-av-antall-i-ggplot2/visualisering-og-sammenlikning-av-antall-i-ggplot2.Rmd\r\nNei. Teksten omhandler visualisering av data, ikke statistikk i seg selv.\r\n57.97167 secs\r\n2024-06-09-hva-kan-en-bruke-llm-til/hva-kan-en-bruke-llm-til.Rmd\r\nNei\r\n44.05690 secs\r\n2023-01-18-diskriminering-i-haugesund/diskriminering-i-haugesund.Rmd\r\nJa.\r\n31.26330 secs\r\n\r\nDen gir i hvert fall svar - og svarene gir mening.\r\nOutputen har litt tvilsom formattering her.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2024-08-19T21:46:59+02:00",
    "input_file": "ollama-for-sammendrag-av-bloggposter.knit.md"
  },
  {
    "path": "posts/2024-07-04-lokal-llm-med-ollama/",
    "title": "Lokal LLM med Ollama",
    "description": "Ved hjelp av Ollama kan en kjøre LLM-er lokalt.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2024-07-04",
    "categories": [],
    "contents": "\r\nFor en tid tilbake skrev jeg om språkmodeller, noen mulige bruksområder (fra mitt perspektiv), og konkluderte med at muligheten til å kjøre modellene lokalt, uten å måtte bruke OpenAI, Google eller Microsoft sine APIer, ville vært flott.\r\nEtter litt undersøkelser har jeg nå funnet ut av to måter en kan gjøre dette på:\r\nLlamafile, fra Mozilla, som pakker sammen en språkmodell til en enkelt kjørbar fil. Nedsida er at en del av filene er svært store, langt større enn det en har mulighet til å kjøre i Windows.\r\nOllama, et open source-prosjekt, som åpner for lokal kjøring av språkmodeller. En må ha separate installasjoner av et grensesnitt (med CLI og API) og de ulike modellene, men det virker veldig overkommelig. En god introduksjon finner du på github-dokumentasjonen, men også f.eks. i denne Medium-artikkelen fra mai 2024.\r\nOllama virker så langt som det mest lovende for meg, med Windows-oppsett. Det er et enkelt program som en starter, og som da gir en mulighet til å kjøre ollama-kommandoer i CLI, f.eks. PowerShell. Her får en da mulighet til å laste ned og kjøre et bredt utvalg av kommandoer. Ollama lover bl.a. å gjøre intelligente valg for statusflagg og ressursallokering, noe som er helt avgjørende for å kunne kjøre noe så ressurskrevende som en språkmodell med flere milliarder parametre på en PC som ellers brukes til å skrive og spille Age of Empires 2.\r\nEn annen fordel med Ollama er at de setter opp et standardisert API-grensesnitt til modellene, slik at du kan bruke lik syntaks, men bytte og teste ulike modeller. Prosjektets Github-side lenker til en rekke ulike applikasjoner som benytter seg av dette API-et, og ett av dem er Hause Lins ollamar. Dette er en innpakning av en rekke ulike httr2-kall mot API-et. Ettersom et kjerne-elemenet i å kjøre en LLM lokalt er å ha kontroll over koden, tar jeg meg den frihet det er å reimplementere noe av Ollamar-koden selv.\r\n\r\n\r\n#standard lokalt endepunkt er  http://localhost:11434\r\n\r\nurl =  \"http://localhost:11434\"\r\nreq = request(url)\r\nresp = req_perform(req)\r\n\r\n#er status OK? Kjører serveren lokalt?\r\nresp_status_desc(resp)\r\n\r\n[1] \"OK\"\r\n\r\n#hvilken form er det på innholdet?\r\nresp_content_type(resp)\r\n\r\n[1] \"text/plain\"\r\n\r\n#hva er innholdet?\r\nresp_body_string(resp)\r\n\r\n[1] \"Ollama is running\"\r\n\r\nDet finnes en god del funksjonalitet i APIet her, som dokumentert i dokumentasjonen. Kan jeg få den til å generere en tekstrespons som beskrevet her?\r\nDette vil antakelig ta en god stund å kjøre, ettersom Ollama må starte opp modellen. Modellen forblir som standard lasta inn i minnet i fem minutter etter fullført forespørsel. En kan endre på det, og en rekke andre egenskaper, med ulike settings.\r\n\r\n\r\nreq = request(\"http://localhost:11434/api/generate\")\r\nreq = req_method(req, \"POST\")\r\n\r\n#selve requesten\r\nbody_json = list(model = \"llama3\",\r\n                  stream = FALSE,\r\n                  prompt = \"Bak skyene er himmelen alltid ...\"\r\n                  )\r\n\r\nreq = req_body_json(req, body_json)\r\n\r\nresp = req_perform(req)\r\n\r\n\r\nHvordan ser så svaret ut? Dette api/generate-endepunktet er “strømmende”, dvs. at den printer ut ord-for-ord i fullføringa. Det er en god påminnelse av at modellen kun er en måte å estimere det neste ordet på, men i mange sammenhenger er det overflødig å få alt.\r\n\r\n\r\njson_body = resp_body_json(resp)\r\n\r\njson_body$response\r\n\r\n[1] “I think I can finish that phrase for you!\"Bak skyene er himmelen alltid blå\" - which is a Norwegian proverb that translates to \"Behind the clouds, the sky is always blue\".”\r\n\r\nDette ser faktisk ut til å funke. Ikke verst. Noen ting å tenke på:\r\n“Prompt engineering” selges som en egen disiplin nå. Dvs. at en faktisk må tenke seg om for hva en instruerer modellene til å bidra med. Hva er gode måter å gjøre det på?\r\nModellene er neppe konsistente, men bygger på ulike RNG-prosesser. Kan en sette seed for tilfeldig tall-generering, for å reprodusere resultatene?\r\nKan en lage en “testprosess” for å sammenlikne ulike utfall med ulike modeller og ulike settings? En form for looping gjennom en “grid” virker fornuftig?\r\nHva er forskjellene mellom “generate”-endepunktet og “chat”-endepunktet?\r\nHvor store “kontekstvinduer” har modellene som jeg klarer å kjøre her?\r\nHvor gode er modellene på norsk? Er noen av NorwAI-modellene tilgjengelige, eller kan de gjøres tilgjengelige?\r\nGleder meg til å teste dette mer.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2024-07-04T14:43:55+02:00",
    "input_file": "lokal-llm-med-ollama.knit.md"
  },
  {
    "path": "posts/2024-06-09-hva-kan-en-bruke-llm-til/",
    "title": "Hva kan en bruke LLM til?",
    "description": "En kikk på hva en kan bruke en stor språkmodell til.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2024-06-09",
    "categories": [],
    "contents": "\r\nStore språkmodeller - Large Language Models (LLM) - er alle steder nå, det siste innen IT-relatert hype, og har bidratt til at Kunstig Intelligens har vært i nyhetene daglig de siste årene, siden ChatGPT ble offentlig tilgjengelig i slutten av november 2022.\r\n\r\n\r\n\r\nI bunn og grunn er LLMer tekstprediksjonsmodeller trent på et veldig stort datasett med tekst, med svært mange parametre: blant de ledende modellene på HuggingFace sitt open-llm-leaderbord finner vi finetunede versjoner av Metas Llama-3-70B, som er en modell med 70 milliarder parametre trent på datasett med 15 000 milliarder tokens (ord, setninger eller fraser). Dette gjør modellen i stand til å predikere tekst, noe som da kan brukes på ulike måter. Teknologien har vært kjent en stund, men med lanseringa av ChatGPT, så fikk folk flest et chatte-interface til en slik prediksjonsmodell.\r\nDet er definitivt gøy å chatte med en robot som ser ut til å forstå deg, og som er superkreativ. OpenAI har nå gjort den siste ChatGPT-versjonen, ChatGPT-4o, begrensa tilgjengelig for offentlig og gratis bruk (uten tvil for å få folk hekta nok til å bruke penger):\r\n.\r\nI tillegg har en konkurrenter som Claude fra Anthropic og Microsofts Copilot - og en haug andre. Med implementeringer av konsepter som RAG - Retrieval Augmented Generation - kan en også få med seg lenker og et større snev av etterrettelighet. Perplexity AI er en godt fungerende søkemotor for dette, som i likhet med ChatGPT kan tipse om blogg-innhold, men kan også gi for-og-imot-oppsummeringer med kilder (som her, om skravurkart).\r\nMen er det en boble?\r\nOg selv om dette er veldig underholdende, og potensielt nyttig - så kan det godt være en bobble. Cory Doctorow skrev i 2023 om hvordan det for han var åpenbart at den svært dyre teknologien bak kunstig intelligens ikke vil føre til tilsvarende inntjening: han har et interessant argument om at teknologien i liten grad vil gjøre arbeid billigere, unntatt tjenester med svært lav inntjening som f.eks. generering av RPG-bilder til ungdommer. For mange av de mer høytsvevende ambisjonene, som forskning, selvkjørende bil og automatisert saksbehandling, så ser det så langt heller ut til å gjøre gjøre dyrt arbeid bedre - men også dyrere. Hans konklusjon da var derfor at en heller enn å lure på om AI vil ta over verden, bør lure på om det vil være noe nyttig igjen når boblen sprekker.\r\nNår jeg spør Perplexiy om dette, peker den på at selv om det er en hype og verdisettingen på enkelte AI-selskap er høy og har steget voldsomt på kort tid, så er disse selskapene i mange tilfeller etablerte tech-selskaper med godt etablerte posisjoner (Microsoft og Nvidia er ikke det samme som et nettsideselskap på 90-tallet). Det tilsier at det bør være mindre sårbart enn en ren boble.\r\nDen økonomiske siden av det skal jeg ikke påstå at jeg kjenner veldig godt. Men jeg ser at Daren Acemoglu, som kjenner økonomi svært godt, også mener det er grunn til å være skeptisk til hvor transformativ denne teknologien vil være. I Dont’ Believe The AI Hype anslår han basert på faktisk forskning at total faktorproduktivitet kan øke med rundt 1 % totalt over de neste ti årene. Det er bra - men ikke et grensesprengende tall.\r\nDet kan heller ikke være tvil om at ressursbruken som trengs for å trene og kjøre de store modellene er svært høye - både miljømessig og sosialt.\r\nDermed er det altså gode grunner til å tenke som Doctorow, og se på hva en kan få ut av dette mens leken er god!\r\nSå hva kan en gjøre med en LLM?\r\nLes og oppsummer tekst!\r\nDu kan få en modell til å lese tekst for deg og lage sammendrag. Jeg er skeptisk til bredden av dette use-caset for meg: de aller fleste akademiske artikler, rapporter og nyheter som er for lange til å leses raskt, er utstyrt med et godt skrevet sammendrag og en god ingress. I de aller fleste tilfeller vil jeg stole mer på forfatteren enn på maskinen. Å skrive et sammendrag av egen tekst er også en svært viktig del av skriveprosessen, i hvert fall for meg.\r\nSå da er kanskje behovet snarere å få oppsummering av tekster som ikke har et sammendrag - f.eks. en kommuneplan, en nettside, eller referater? Med ChatGPT-4o har også den tjenesten fått tilgang til internett-søk, og det kan dermed gjøres slik:\r\n.\r\nDen takler også PDF-er, ved å gjøre noen relaterte nettsøk:\r\n.\r\nKode kvalitative data.\r\nNår modellen kan lage et sammendrag - en prediksjon rundt hvilke ord som hører sammen med ordene i hovedteksten? - så bør den kanskje også kunne lage et veldig konsist sammendrag i form av koding av tekst? Chew m.fl. prøver dette i “LLM-assisted content analysis: Using large language models to support deductive coding”, og det finnes helt sikkert liknende forsøk der ute. Trikset her ser ut til å være å ikke overlate hele showet til en algoritme i en svart boks, men heller bruke LLMen som en yngre forskningsassistent, som du tester hele tiden: er de foreslåtte kodene meningsfulle i et lite utvalg, eller er det kun tilfeldig gjetninger? Oppfører den seg som forventa når den får “kodeboken”, med eksempler på hvordan tekst skal kodes? I en annen artikkel jeg har lest (men ikke finner igjen nå), gjorde forskerne også et poeng ut av at LLM-kodingen ble gjennomført flere hundre ganger, og en tok “flertallsavgjørelsen” som den endelige kategorien.\r\nTale-til-tekst\r\nOpenAIs Whisper-modell er en veldig god tale-til-tekst-modell. Er det en LLM? Det er i hvert fall et nevralt nettverk med transformers. Den er imidlertid best på engelsk. Heldigvis har Nasjonalbiblioteket laget en versjon som kan norsk - NB-Whisper\r\nOg da har jeg ikke engang begynt å tenke på KI-assistert analyse av strukturerte data, noe f.eks. Simon Willison har blogga om.\r\nFår jeg kjørt disse på en effektiv måte? Her er det også et annet hensyn å ta: modellene bør kjøres lokalt hvis en skal gjøre noe med data som ikek skal deles med noen som tjener pengene sine på å trene modeller på alle data i hele verden.\r\n\r\n\r\n\r\n",
    "preview": "posts/2024-06-09-hva-kan-en-bruke-llm-til/hva-kan-en-bruke-llm-til_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2024-06-12T21:06:21+02:00",
    "input_file": "hva-kan-en-bruke-llm-til.knit.md"
  },
  {
    "path": "posts/2024-04-20-return-to-aoe/",
    "title": "Age of Empires 2 - en ny kikk på statistikken",
    "description": "Vi ser på en aoestats.io som kilde til Age of Empires 2-statistikk.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2024-04-20",
    "categories": [],
    "contents": "\r\nFor ca. to år siden lagde jeg et lite dashboard for Age of Empires 2-spilling gjennom pandemien. Datakildene var imidlertid temmelig spredte, noe som gjorde det tidkrevende å oppdatere dashboardet med nye data. Nå har jeg funnet en ny kilde i aoestats.io, og vil ta en kikk på den for å se om jeg kan bruke den.\r\nAoestats.io som datakilde\r\nDatasettet funker slik at det er laget et API-endepunkt til en tabell som lister opp alle tilgjengelige filer på aoestats.io/api/db_dumps. Datasettene er laget som Parquet-filer som kan lastes direkte.\r\nFørst skaffer jeg ei liste over hvilke data-dumper som er tilgjengelige:\r\n\r\n\r\nreq = request(\"https://aoestats.io/api/db_dumps\")\r\nreq\r\n\r\nresp = req_perform(req)\r\n\r\n#hvilket innhold er dette?\r\nresp |> \r\n  resp_content_type()\r\n\r\n[1] \"application/json\"\r\n\r\n#gikk spørringa i orden?\r\nresp |> \r\n  resp_status_desc()\r\n\r\n[1] \"OK\"\r\n\r\n#henter ut dataene\r\ndata = resp |> \r\n  resp_body_json()\r\n\r\n\r\nHer får jeg ut ei liste med totalt antall matcher som er registert, totalt antall spillere, og p.t. en liste med 87 lister med 8 elementer. Disse pakker jeg ut. Overraskende nok funker dplyr::bind_rows som utpakker.\r\n\r\nRows: 88\r\nColumns: 8\r\n$ start_date      <date> 2024-04-28, 2024-04-21, 2024-04-14, 2024-04…\r\n$ end_date        <date> 2024-05-04, 2024-04-27, 2024-04-20, 2024-04…\r\n$ num_matches     <int> 242093, 240980, 236195, 231065, 243354, 2538…\r\n$ num_players     <int> 856808, 839611, 824722, 808570, 854899, 8824…\r\n$ matches_url     <chr> \"/media/db_dumps/date_range%3D2024-04-28_202…\r\n$ players_url     <chr> \"/media/db_dumps/date_range%3D2024-04-28_202…\r\n$ match_checksum  <chr> \"e70006668edacd84dee5b6a71c41a0b4\", \"0178bb0…\r\n$ player_checksum <chr> \"29af052af41098b92a7bb75634e4dd4c\", \"b4bd1bc…\r\n\r\n\r\nHer vises ukentlige datadumper fra 28. august 2022 til skrivende stund (7. april 2024).Innholdet i dumpene øker betraktelig i mars/april 2023, så det kan være noe annerledes med dataene fra de første periodene.\r\nSå ser jeg på hvordan filene ser ut. Dette er parquet-filer, som kan leses med arrow::read_parquet()\r\nHvordan ser dataene ut?\r\n\r\n\r\n\r\nDet er veldig mye data her, slik at en uthenting av flere data-dumps må slette ting fra minnet mellom hver nedlasting. For å hente alle tilgjengelige data og lagre disse lokalt, lager jeg en for-loop.\r\n\r\n\r\n#lager en for-looop\r\n\r\n# df_players = data.frame()\r\n# df_matches = data.frame()\r\n# \r\n# for(i in 1:nrow(df_dumps)){\r\n#   #players\r\n#   url_players = paste0(\"https://aoestats.io\", df_dumps[i, 6])\r\n#   temp = read_parquet(url_players) |> \r\n#     filter(profile_id %in% player_id)\r\n#   \r\n#   df_players = bind_rows(df_players, temp)\r\n# \r\n# #matches\r\n# url_matches = paste0(\"https://aoestats.io\", df_dumps[i, 5])\r\n# \r\n# temp = read_parquet(url_matches) |> \r\n#   filter(game_id %in% df_players$game_id)\r\n# \r\n# df_matches = bind_rows(df_matches, temp)\r\n# \r\n# Sys.sleep(10)\r\n# }\r\n\r\n\r\nDenne failer litt her og der, og for å unngå å laste ned disse filene hver gang, men heller kunne oppdatere datasettet med nye matcher, lagrer jeg en lokal fil som jeg kan sjekke om trenger oppdateringer.\r\n\r\n\r\nmatches <- read_delim(\"data/matches.csv\", delim = \";\", escape_double = FALSE, trim_ws = TRUE,\r\n                      col_types = cols(started_timestamp = col_datetime(format = \"%Y/%m/%d %H:%M:%S\"))) |> \r\n  arrange(desc(started_timestamp))\r\n\r\nplayers <- read_delim(\"data/players.csv\", delim = \";\", escape_double = FALSE, trim_ws = TRUE)\r\n\r\n#sjekken kan f.eks. se slik ut:\r\n\r\n#last_match_played = date(slice_head(matches, n = 1)$started_timestamp)\r\n#last_match_in_dump = max(df_dumps$end_date)\r\n\r\n#if(last_match_played < last_match_in_dump){\r\n#  df_dumps_new = filter(end_date > last_match_played)\r\n  #legg til uthenting her hvis behov\r\n#}\r\n\r\n\r\nHer sitter jeg da med to filer, en med spiller-informasjon og en med match-informasjon. Jeg har filtrert vekk alleobservasjoner for spillere som ikke er meg og mine to med-spillere.\r\nDataene er dokumentert hos aoestats.io.\r\nLitt om våre matcher\r\n\r\n\r\n\r\nHvor mange matcher har vi spilt, og har vi vunnet?\r\n\r\nantall_matcher\r\nantall_vunnet\r\nvinnnprosent\r\n114\r\n58\r\n51\r\n\r\nNår har vi spilt?\r\n\r\n\r\n\r\nHvilke baner har vi spilt - og hvor vinner vi?\r\n\r\n\r\n\r\nHvilke sivilisasjoner liker vi å spille?\r\n\r\n\r\n\r\nHvilke sivilisasjoner har vi ikke spilt?\r\n\r\n\r\n\r\nHvor lenge varer spillene?\r\n\r\n\r\n\r\nNår går vi opp i age?\r\n\r\nprofile_id\r\nmean_castle_age_uptime\r\nmean_feudal_age_uptime\r\nmean_imperial_age_uptime\r\nmedian_castle_age_uptime\r\nmedian_feudal_age_uptime\r\nmedian_imperial_age_uptime\r\n2176509\r\n22.8\r\n12.0\r\n42.6\r\n22.2\r\n11.2\r\n42.6\r\n4250835\r\n27.2\r\n11.9\r\n43.1\r\n25.7\r\n11.3\r\n42.8\r\n4361967\r\n22.3\r\n13.0\r\n44.4\r\n22.9\r\n12.2\r\n44.6\r\n\r\nBlir vi bedre over tid?\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2024-04-20-return-to-aoe/return-to-aoe_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2024-05-08T18:27:43+02:00",
    "input_file": "return-to-aoe.knit.md"
  },
  {
    "path": "posts/2024-04-01-hierarkiske-clustre/",
    "title": "Hierarkiske cluster-analyse",
    "description": "En liten kikk på hierarkisk klyngeanalyse i R.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2024-04-01",
    "categories": [],
    "contents": "\r\nHva gjør du hvis du vil finne likhetstrekk mellom grupper i dataene dine? En mulig tilnærming er klyngeanalyse eller klusteranalyse. Klusteranalyse er en måte å finne likhetstrekk mellom klynger eller clustre i datasettet ditt, på en slik måte at avstanden innad i en klynge blir minimert, mens avstanden til andre klynger blir maksimert.\r\nIntuisjonen bak er relativt enkel: du beregner avstandene mellom alle datapunktene dine, velger en cluster-metode og analyserer om clustrene er gode nok. Ettersom dette er en veletablert teknikk, er det gode muligheter til å grave seg ned i alle mulige teknikaliteter på veien.\r\nI maskinlæringsverden klassifiseres det som en såkalt “unsupervised learning”, fordi en ikke har en utfallsvariabel. Siden en ikke har en utfallsvariabel som en kan måle prediksjoner opp imot, må det en god del skjønn til for å velge riktig kriterium for å måle vellykkethet.\r\nDe aller fleste eksemplene en snubler over om klyngeanalyser tar utgangspunkt i kontinuerlige variabler. Det betyr at en kan regne euklidianske distanser, og bruke en algoritme som k-means. Men eksempelet jeg ønsker å starte med, er der du har nominelle eller ordinale variabler - variabler der euklidiansk avstand ikke gir mening.\r\nDet finnes MANGE tutorials og kode-eksempler der ute. Jeg synes at Reusovas blog om Hierarchical Clustering on Categorical Data in R, Hastie m.fl. (2008) The Elements of Statistical Learning, og Singhs “Clustering Made Easy” var gode kilder. Her kommer jammen meg en kilde til!\r\nSom et første enkelt datasett bruker jeg datasettet fra ggplot2movies - altså IMDb-data for filmer. Dette består i utgangspunktet av 24 variabler om 58 788 filmer, inkludert lengde, budsjett (for noen, rating, stemmer, noe som kanskje er del-ratings, aldersvurdering, og sjangerplassering som dikotome variabler.\r\n\r\nRows: 58,788\r\nColumns: 24\r\n$ title       <chr> \"$\", \"$1000 a Touchdown\", \"$21 a Day Once a Mont…\r\n$ year        <int> 1971, 1939, 1941, 1996, 1975, 2000, 2002, 2002, …\r\n$ length      <int> 121, 71, 7, 70, 71, 91, 93, 25, 97, 61, 99, 96, …\r\n$ budget      <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\r\n$ rating      <dbl> 6.4, 6.0, 8.2, 8.2, 3.4, 4.3, 5.3, 6.7, 6.6, 6.0…\r\n$ votes       <int> 348, 20, 5, 6, 17, 45, 200, 24, 18, 51, 23, 53, …\r\n$ r1          <dbl> 4.5, 0.0, 0.0, 14.5, 24.5, 4.5, 4.5, 4.5, 4.5, 4…\r\n$ r2          <dbl> 4.5, 14.5, 0.0, 0.0, 4.5, 4.5, 0.0, 4.5, 4.5, 0.…\r\n$ r3          <dbl> 4.5, 4.5, 0.0, 0.0, 0.0, 4.5, 4.5, 4.5, 4.5, 4.5…\r\n$ r4          <dbl> 4.5, 24.5, 0.0, 0.0, 14.5, 14.5, 4.5, 4.5, 0.0, …\r\n$ r5          <dbl> 14.5, 14.5, 0.0, 0.0, 14.5, 14.5, 24.5, 4.5, 0.0…\r\n$ r6          <dbl> 24.5, 14.5, 24.5, 0.0, 4.5, 14.5, 24.5, 14.5, 0.…\r\n$ r7          <dbl> 24.5, 14.5, 0.0, 0.0, 0.0, 4.5, 14.5, 14.5, 34.5…\r\n$ r8          <dbl> 14.5, 4.5, 44.5, 0.0, 0.0, 4.5, 4.5, 14.5, 14.5,…\r\n$ r9          <dbl> 4.5, 4.5, 24.5, 34.5, 0.0, 14.5, 4.5, 4.5, 4.5, …\r\n$ r10         <dbl> 4.5, 14.5, 24.5, 45.5, 24.5, 14.5, 14.5, 14.5, 2…\r\n$ mpaa        <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"R\", \"\", \"\", \"\", \"\", \"\",…\r\n$ Action      <int> 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, …\r\n$ Animation   <int> 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\r\n$ Comedy      <int> 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, …\r\n$ Drama       <int> 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, …\r\n$ Documentary <int> 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, …\r\n$ Romance     <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\r\n$ Short       <int> 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, …\r\n\r\nI dette eksempelet skal jeg begynne med å se på de 7 dikotome variablene som oppgir sjangeren. Merk at hver film kan ha flere sjangere - så hvilke klynger av sjangermikser er det vi har her, som beskriver datasettet på en god måte? Da kan vi gjøre klynge-analyse.\r\nHierarkisk klynge-analysen består av tre steg:\r\nMåle avstanden mellom observasjonene med en (dis)similaritetsmatrise. Men hvordan måler vi avstanden her?\r\nVelge kluster-metode.\r\nVurder hva som gir en god klyngestruktur.\r\nI tillegg kommer det som vanlig et steg 0: forberede dataene, tenke på betydningen av missing-verdier, m.m. Her slipper vi unna det, ettersom filmdatasettet oppfører seg pent.\r\nSteg 1: Hvor stor avstand er det mellom observasjonene?\r\nSå, hvor stor avstand er det mellom datapunktene? Det finnes en rekke ulike måter å måle det på, og hva en lander på kan (vil?) være helt avgjørende for hva en finner.\r\nDen klassiske er euclidian, som er den dagligdagse avstanden. Den egner seg imidlertid best for kontinuerlige data.\r\nHamming for kategoriske data\r\nManhattan (kvartalsavstander - jeg forstår fortsatt ikke helt når du vil ha denne? På Manhattan?)\r\nCanberra for diskrete telleverdier\r\nJaccard eller binære avstander - tenk setteori og Venn-diagram (I dokumentasjonen for stats::dist er det spesifisert at de implementerer en versjon av binær avstand der datapunkt med bare 0-verdier vil ha avstand 0 i deres implementering, mens i tradisjonell Jaccard-implementering vil det gi en NaN-feil)\r\nDet finnes en rekke flere, bl.a. Gower for blandede datatyper, når du har både kategoriske og kontinuerlige data. Du kan også bruke korrelasjonskoeffisienter.\r\nHastie m.fl. påpeker at selv om euclidian avstand og lik vekting av variablene er det vanlige (noe som kan gi ikke-trivielle sideeffekter, f.eks. i form av at variabler med større variasjon får større betydning), så bør en også tenke på vekting mellom variablene, og hvorvidt missing-verdier er meningsfulle kategorier.\r\nVi bruker binær avstand her, og beregner avstanden mellom alle 100 observasjoner en gang (dvs. 4950 verdier).\r\n\r\n\r\nbinary_dist = dist(df, method = \"binary\")\r\n\r\nstr(binary_dist)\r\n\r\n 'dist' num [1:4950] 1 1 1 1 1 1 1 1 1 1 ...\r\n - attr(*, \"Size\")= int 100\r\n - attr(*, \"Labels\")= chr [1:100] \"Raiders of the Lost Ark\" \"Love-Ins, The\" \"Littoral\" \"Crossroads\" ...\r\n - attr(*, \"Diag\")= logi FALSE\r\n - attr(*, \"Upper\")= logi FALSE\r\n - attr(*, \"method\")= chr \"binary\"\r\n - attr(*, \"call\")= language dist(x = df, method = \"binary\")\r\n\r\nSteg 2. Hvordan klustrer vi dette?\r\nNår vi nå har beregna avstander mellom observasjonene våre, så bruker vi denne matrisen til å finne clustre. Først må vi velge om vi ønsker å ta utgangspunkt i agglomerativ (nedenfra-og-opp) eller divisiv (ovenfra-og-ned) tilnærming: Agglomorativ begynner med å se på hver observasjon som en gruppe, og finner så likheter. Divisiv begynner med å se på alle observasjonene som en gruppe, og finner forskjeller. Agglomorativ finner mindre clustre (og er vanligst i bruk), mens divisiv finner større clustre. Her går vi for den enkle, agglomerative tilnærmingen.\r\nVi må også bestemme hva vi mener med likhet. Singh har fine illustrasjoner av ulike typer mål på likhet mellom clustre, for å bestemme hvilke klynger som slås sammen til nye klynger i neste steg.\r\nSingle linkage: Avstanden mellom to klynger måles ved avstanden mellom de nærmeste punktene. Bedre på å identifisere uteliggere som i liten grad passer sammen med andre klynger.\r\nComplete linkage: Avstanden måles ved avstanden mellom de to punktene lengst unna hverandre. Lager nærmere clustre.\r\nAverage linkage: Gjennomsnittlig avstand mellom alle punkt. Ligner på complete, men tar inn litt flere uteliggere.\r\nCentroid linkage: Avstand måles ved avstand mellom sentroidene i de to klyngene. Funker for data med færre likheter.\r\nWards linkage / Wards D: Bruker sum of squares for å minimere varians innad i en klynge. Lager mer kompakte clustre.\r\nWards D2: Kvadrerte sum of squares. Gir større vekt til forskjeller (fordi de kvadreres)\r\nDet generelle tipset er å prøve seg fram, og se på hva som gir mest meningsfulle clustre for dine data.\r\n\r\n\r\nfit1 = hclust(binary_dist, method = \"complete\")\r\nfit2 = hclust(binary_dist, method = \"ward.D2\")\r\n\r\n\r\nSteg 3. Hva er en god klyngestruktur?\r\nDen klassiske måten å vurdere klyngestrukturen på, er med dendrogram. Her kan en også legge på litt farge etter hvor en ønsker å kutte treet - dvs. antallet klustre.\r\n\r\n\r\n\r\nJeg synes ikke disse nødvendigvis er så lette å lese når vi har 100 observasjoner. Med 10 observasjoner blir det enklere:\r\n\r\n\r\n\r\nI stedet for den grafiske framstillinga, så kan en også se på andre oppsummeringer av clustrene. Etter hva jeg kan se er det (minst) to oppsummerende statistikken en kan bruke til å vurdere hvor passende klustrene er:\r\nElbow: Ser på likheter innad i grupper.\r\nSilhouette: Et mål på hvor nærme punktene i en gruppe er til punktene i andre grupper.\r\nI praksis må en bruke dømmekraft her, ulike antall klustre vil være bedre på det ene målet enn det andre.\r\nSilhouette\r\nSilhouette-målet er en indeks mellom -1 og +1, der +1 viser god indre konsistens og stor avstand til andre grupper, og -1 er en dårlig konsistens. En er dermed ute etter et antall clustre som gir høyest mulig silhouette-verdi. Disse må dermed beregnes for ulike antall clustre.\r\n\r\n\r\n\r\n\r\n\r\n\r\nHer skjer det noe ved 6/7 inndelinger som fører til et fall, og så skal en opp i 11-12 grupper før en får en videre økning i silhouetten. For Ward D2 for å beregne likhet er økninga mer jevn, den får seg en knekk først ved ca. 18 grupper.\r\nElbow\r\nDenne indikatoren ser på likheter innad i grupper. Den viser “within sum of squares”. Jo lavere den er, jo likere er observasjonene innad i gruppa. Ideelt sett ser vi etter en knekk - eller albue - i en graf, der en ytterligere økning i antallet grupper kun gir liten gevinst i reduksjon i sum of squares.\r\n\r\n\r\n\r\n\r\n\r\n\r\nHer indikerer grafene både for complete linkage og Ward D2 at ca. 7 grupper er passende.\r\nHeatmap\r\nHvordan ser denne grupperinga ut for filmene? Jeg trooor jeg kan ta cutree-output direkte som en ny kolonne i datasettet?\r\n\r\n\r\n\r\nMed complete linkage og 7 grupper av filmer får vi en action-drama-gruppe, en mer ren drama med innslag av romanse, en for ukategoriserte filmer, en for korte filmer (som gjerne er dokumentar og komedier, en for blanda korte animerte komedier (tegnefilm for barn?), en for komedier, og en for dokumentarer.)\r\nMed ward D2 får vi også action-drama, drama, kategoriløse, komedier, og korte animerte komedier, drama-romanse blir en egen kategori, korte dokumentarer.\r\nHvilken av disse gir mest mening? Her vil det nok f.eks. gi mening å se nærmere på de tilfellene som kategoriseres ulikt.\r\nEt siste spørsmål: hva hvis flere variabler?\r\nFor å raskt demonstrere, kjører jeg et enkelt eksempel der jeg finner en klynge som inkluderer både sjangerne, gjennomsnittlig rating og lengde på filmen. Hvilke klynger av film gir mening da?\r\n\r\n\r\n\r\nFornuftige visualiseringer av dette må vi komme tilbake til i en neste post.\r\n\r\n\r\n\r\n",
    "preview": "posts/2024-04-01-hierarkiske-clustre/hierarkiske-clustre_files/figure-html5/unnamed-chunk-4-1.png",
    "last_modified": "2024-04-21T22:49:39+02:00",
    "input_file": "hierarkiske-clustre.knit.md"
  },
  {
    "path": "posts/2024-03-27-et-lite-eventyr-i-bandit-og-wsl/",
    "title": "Et lite Bandit-eventyr",
    "description": "Fun'n'Games for å lære litt konsollbruk.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2024-03-27",
    "categories": [],
    "contents": "\r\nEtter anbefaling fra Bob Rudis (AKA hrbrmstr) sitt daily drop-nyhetsbrev, har jeg prøvd meg litt på OverTheWires Bandit-spill.\r\nBandit HeelerSpillet er et intro-spill til såkalte wargames, men egentlig på et såpass grunnleggende nivå at det er et introspill til bruk av konsollet. Spillet består av 30 nivåer, der første utfordring er å i det hele tatt koble seg på game-serveren.\r\nFørste gang jeg prøvde meg på det, brukte jeg en hel kveld før jeg skjønte at jeg hadde skrevet portnummeret feil. Instruksjonen om å lese instruksjonen nøye virker definitivt fornuftig. But one day, I got in!\r\nbilde av innloggingDe er forståelig nok ikke glade i at folk deler løsninger og slikt. Men å dokumentere reisen inn i det virker lurt.\r\nHer er noe av det jeg har plukka opp så langt:\r\nNoe av det første jeg lærte var at windows sin ledetekst (cmd/windows command shell) eller PowerShell kan brukes her, og det samme kan det å sette opp Windows Subsystem for Linux, og bruke Bash som CLI/terminal/shellderifra.\r\nBeslekta: command line, terminal og shell brukes om hverandre, men virker teknisk også litt ulike?\r\nWSL2 er definitivt et eventyr i seg selv! Artig med litt linux i livet. Nevnte nyhetsbrev fra hrbrmstr kommer jevnlig med tips til CLI-verktøy og programmer som kjøres best fra Linux, eller krever kjennskap til Linux eller shell-basert arbeid. Microsoft sitt grunnkurs i bruken av WSL og å navigere mellom filsystemene ligger her.\r\nSSH: Secure shell, brukes til å logge seg på applikasjoner på en remote server, med gitte rettigheter knytta til sin bruker.\r\nDet er mange kommandoer.\r\n\r\n\r\n\r\n",
    "preview": "posts/2024-03-27-et-lite-eventyr-i-bandit-og-wsl/ikke_den_bandit.png",
    "last_modified": "2024-03-27T22:01:39+01:00",
    "input_file": "et-lite-eventyr-i-bandit-og-wsl.knit.md"
  },
  {
    "path": "posts/2024-03-23-kartogram/",
    "title": "Kloroplett og kartogram",
    "description": "Kan kartogrammet løse noen utfordringer med skravurkart?",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2024-03-23",
    "categories": [],
    "contents": "\r\nSå, du vil lage et kart over noen norske kommuner - og du vil ha med mer informasjon enn hvor kommunen ligger. I denne tidligere posten gikk jeg gjennom en superenkel måte å få ut et kart på. Nå skal vi fargelegge litt, med kloroplett-kart/skravurkart/tematiske kart.\r\nVi skal også ta en kikk på om kartogrammer kan løse problemet med at de minste kommunene (arealmessig) kan ha de største verdiene på andre variabler, slik at koding i farger konkurrerer med koding i størrelser. En anna måte å si det på - hvordan løser vi “dimensjonsproblemet” med kart, når to av de vanlige dimensjonene allerede er opptatt med geografisk informasjon?\r\nKartdataene er “Norske fylker og kommuner illustrasjonsdata 2024 (klippet etter kyst)”, henta fra Geonorge. Jeg har forenkla geometrien i geojson-fila fra 178 MB til 10 MB med rmapshaper-pakka.\r\nLa oss hente litt data fra SSB, og fargelegge noen kommuner! Denne gangen henter jeg noe så enkelt som befolkningstall pr. 1.1.2024. Ved en senere anledning får jeg se på data som i tillegg til å ha en dårlig korrelasjon mellom areal og verdi, har en dårlig korrelasjon mellom verdi og befolkningstetthet, slik at vi får sett hvor dårlig absolutte tall gjør seg i kart også.\r\nSiden befolkningstallene er ekstremt skjeive (13 % av Norges befolkning bor i Oslo), deler jeg kommunene inn i kvintiler, like femtedeler med de hhv. 70 minste, 70 nest-minste, osv.\r\n\r\n\r\n\r\nFor å visualisere dette som et klassisk skravur-kart kan vi bruke geom_sf fra ggplot2.\r\n\r\n\r\n\r\nVi ser at de største kommunene er spredt langs kysten og i ulike regioner, og at det er mye stort på østlandet. De minste kommunene ligger i fjellregionene, og med jevne mellomrom nordover. Men størrelsen på kommunene i areal - som er det vi lettere legger merke til enn fargetonene - henger ikke sammen med befolkningsstørrelse. Faktisk er kommuner som Oslo forsvinnende små. Som en grafen under viser.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nDependent variable:\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nantall_personer\r\n\r\n\r\n\r\n\r\nareal_km2\r\n\r\n\r\n-7.170\r\n\r\n\r\n\r\n\r\n(4.662)\r\n\r\n\r\n\r\n\r\n\r\n\r\nI(areal_km22)\r\n\r\n\r\n0.001\r\n\r\n\r\n\r\n\r\n(0.001)\r\n\r\n\r\n\r\n\r\n\r\n\r\nConstant\r\n\r\n\r\n20,905.620***\r\n\r\n\r\n\r\n(3,984.257)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nObservations\r\n\r\n\r\n357\r\n\r\n\r\nR2\r\n\r\n0.009\r\n\r\n\r\nAdjusted R2\r\n\r\n0.003\r\n\r\n\r\nResidual Std. Error\r\n\r\n\r\n45,777.920 (df = 354)\r\n\r\n\r\nF Statistic\r\n\r\n\r\n1.551 (df = 2; 354)\r\n\r\n\r\n\r\n\r\nNote:\r\n\r\n\r\np<0.1; p<0.05; p<0.01\r\n\r\n\r\nEn kan til en viss grad korrigere for noe av dette ved å beregne variabelen relativt til arealet - f.eks. befolkning pr. km2. Men det kan heller ikke gjøres uten å tenke nøye gjennom skalaen:\r\n\r\n\r\n\r\nEt kjent grep for å fikse dette er et kartogram, der en skalerer det geografiske området til å representere variabelen en ønsker å fremstille. Dette kan en gjøre med cartogram-pakka. Den støtter mange ulike framgangsmåter - her er en:\r\n\r\n\r\n\r\nBle dette bra nok? Tja. En ser hvordan de befolkningsrike kommunene spiser opp befolkningen i de mindre kommunene rundt seg. Fjellregionene og de lange regionene i Nord-Norge med lite folk forsvinner mellom store befolkningsmette sentre. Det er jo kanskje av og til et riktig poeng? Men formene blir veldig snåle. Det er i utgangspunktet vanskelig å kjenne igjen sin egen kommune på formen, og her er de helt forvridde - men tungden av befolkninga i Sør-Norge blir veldig tydelig. Dorling-plottet er kanskje vel så bra?\r\n\r\n\r\n\r\nIkke egentlig. Jeg antar at den store sirkelen er Oslo - men hvorfor er Tigerstaden på vei over til Sverige? Det er fiffig, men fordi boblene ikke skal overlappe, får vi litt samme effekt som i en ballbinge med baller som presser hverandre ut. Gøy en liten stund, men kanskje ikke så informativt.\r\nDet hadde vært bedre med noe som standardiserte størrelsen på kommunene, men beholdt formen og landet sånn noenlunde. Et hexbin-kart hadde vært kult - men jeg har ikke klart å finne en måte å plassere ut hex-formene korrekt på. sugarbag::geom_sugarbag har en variant, men det er ikke akkurat det jeg ser etter. Å kjøre algoritmen gir også forferdelig mye detaljer som foreslår å bruke 1 million GB (altså 1000 terrabyte, eller 1 petabyte) av minne for å kalkulere et fungerende grid.\r\nSå kan kartogram løse utfordringer med skravurkartet? Nei, ikke egentlig. Noen ting egner seg dårligere for kart-visualiseringer enn andre. Kart er dermed akkurat som andre visualiseringer, det har sine fordeler og ulemper. Kanskje det kan løses med litt interaktivitet, slik at du kan hovre over de store enhetene, og se hvem som spiser opp de andre?\r\n\r\n\r\n\r\n",
    "preview": "posts/2024-03-23-kartogram/kartogram_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2024-03-25T20:33:24+01:00",
    "input_file": "kartogram.knit.md"
  },
  {
    "path": "posts/2024-03-02-smallregression/",
    "title": "Regresjon med små datasett",
    "description": "Du har lite data. Hva skjer med regresjonen din da?",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2024-03-02",
    "categories": [],
    "contents": "\r\nRegresjon er et sentralt verktøy i en samfunnsviters verktøykasse. Så hva gjør du når du har et lite datasett? Dette er en fortsettelse av en tidligere diskusjon om styrkeberegning. Jeg har latt meg inspirere av blant annet Brad Duthie, verystatisticous og francisco yira’s blog.\r\nVi begynner med det samme datasettet som sist: 40 personer har fått en behandling som gir større sannsynlighet for et positivt utfall, 360 personer i en kontrollgruppe har ikke fått denne behandlinga. Forrige gang så vi hvordan det selv i en ordinær eksperiment-setting ville vært for få enheter i dette forsøket, til at eksperimentet kunne betegnes som å ha en tilfredsstillende styrke - altså sannsynlighet for å avvise nullhypotesen i tilfeller hvor den skal avvises. En måtte opp i en forskjell på rundt 20 prosentpoeng, for å være “vanlig” sikker på å finne den.\r\nSlik ser regresjonsresultatet ut for en slik sammenheng:\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nDependent variable:\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nutfall\r\n\r\n\r\n\r\n\r\nbehandling\r\n\r\n\r\n0.261***\r\n\r\n\r\n\r\n(0.076)\r\n\r\n\r\n\r\n\r\n\r\n\r\nConstant\r\n\r\n\r\n0.664***\r\n\r\n\r\n\r\n(0.024)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nObservations\r\n\r\n\r\n400\r\n\r\n\r\nR2\r\n\r\n0.029\r\n\r\n\r\nAdjusted R2\r\n\r\n0.026\r\n\r\n\r\nResidual Std. Error\r\n\r\n\r\n0.457 (df = 398)\r\n\r\n\r\nF Statistic\r\n\r\n\r\n11.755*** (df = 1; 398)\r\n\r\n\r\n\r\n\r\nNote:\r\n\r\n\r\np<0.1; p<0.05; p<0.01\r\n\r\n\r\nMen som vi også nevnte, er ikke disse dataene henta fra en ordinær eksperiment-setting: behandlinga er ikke fordelt tilfeldig. Vi kan ikke anta at “antakelsen om uavhengighet” holder, ettersom det kan være korrelasjon mellom behandlinga og mulige utfall, forårsaket av systematiske forskjeller i deltakersammensetning eller egenskaper ved stedene som gjennomfører behandlingene, og stedene som ikke gjennomfører den.\r\nEn må dermed kontrollere for bakgrunnsforhold, slik at en kan forsikre seg om at forskjellene i utfall ikke skyldes andre forhold. Si for eksempel at en høyere andel av personene som ble rekruttert til behandlings-gruppa, har høyere utdanning, mens en høyere andel i kontroll-gruppa har grunnskole. Utdanningsnivået har en positiv betydning for utfallet.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nDependent variable:\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nutfall\r\n\r\n\r\n\r\n\r\nbehandling\r\n\r\n\r\n0.296***\r\n\r\n\r\n\r\n(0.111)\r\n\r\n\r\n\r\n\r\n\r\n\r\nutdanninghøyere utdanning\r\n\r\n\r\n-0.039\r\n\r\n\r\n\r\n\r\n(0.090)\r\n\r\n\r\n\r\n\r\n\r\n\r\nConstant\r\n\r\n\r\n0.667***\r\n\r\n\r\n\r\n(0.025)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nObservations\r\n\r\n\r\n400\r\n\r\n\r\nR2\r\n\r\n0.029\r\n\r\n\r\nAdjusted R2\r\n\r\n0.024\r\n\r\n\r\nResidual Std. Error\r\n\r\n\r\n0.457 (df = 397)\r\n\r\n\r\nF Statistic\r\n\r\n\r\n5.957*** (df = 2; 397)\r\n\r\n\r\n\r\n\r\nNote:\r\n\r\n\r\np<0.1; p<0.05; p<0.01\r\n\r\n\r\nHer får jeg veldig ustabile resultater for sammenhengen mellom behandling og utfall - vekselvis er det statistisk signifikant og ikke signifikant. Vi kan ikke lenger være sikre på om de gode utfallet skyldes behandlingen, eller utdanningen de har med seg. Som et minimum burde jeg kanskje brukt Bonferroni-korreksjoner her når jeg kjører analysene så mange ganger.\r\nI dette eksempelet var sammenhengen mellom utdanning og utfall ganske sterk. Hva hvis vi nedjusterer sammenhengen, men legger til et par andre variabler, som alder og landbakgrunn? Her er et slikt datasett:\r\n\r\nTable 1: Data summary\r\nName\r\nPiped data\r\nNumber of rows\r\n400\r\nNumber of columns\r\n6\r\n_______________________\r\n\r\nColumn type frequency:\r\n\r\nfactor\r\n2\r\nnumeric\r\n2\r\n________________________\r\n\r\nGroup variables\r\nbehandling\r\nVariable type: factor\r\nskim_variable\r\nbehandling\r\nn_missing\r\ncomplete_rate\r\nordered\r\nn_unique\r\ntop_counts\r\nutdanning\r\n0\r\n0\r\n1\r\nFALSE\r\n2\r\nhøy: 224, gru: 136\r\nutdanning\r\n1\r\n0\r\n1\r\nFALSE\r\n2\r\nhøy: 30, gru: 10\r\nlandbakgrunn\r\n0\r\n0\r\n1\r\nFALSE\r\n3\r\nA: 156, C: 114, B: 90\r\nlandbakgrunn\r\n1\r\n0\r\n1\r\nFALSE\r\n3\r\nA: 18, B: 15, C: 7\r\nVariable type: numeric\r\nskim_variable\r\nbehandling\r\nn_missing\r\ncomplete_rate\r\nmean\r\nsd\r\np0\r\np25\r\np50\r\np75\r\np100\r\nhist\r\nutfall\r\n0\r\n0\r\n1\r\n0.67\r\n0.47\r\n0\r\n0.00\r\n1.0\r\n1\r\n1\r\n▃▁▁▁▇\r\nutfall\r\n1\r\n0\r\n1\r\n0.98\r\n0.16\r\n0\r\n1.00\r\n1.0\r\n1\r\n1\r\n▁▁▁▁▇\r\nalder\r\n0\r\n0\r\n1\r\n55.15\r\n7.15\r\n34\r\n50.75\r\n55.0\r\n60\r\n76\r\n▁▃▇▃▁\r\nalder\r\n1\r\n0\r\n1\r\n26.18\r\n4.43\r\n19\r\n22.00\r\n27.5\r\n29\r\n36\r\n▇▃▇▃▁\r\n\r\nOg her er regresjonsresultatene:\r\n\r\n\r\n\r\n\r\n\r\n\r\nDependent variable:\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nutfall\r\n\r\n\r\n\r\n\r\nbehandling\r\n\r\n\r\n0.214*\r\n\r\n\r\n\r\n(0.122)\r\n\r\n\r\n\r\n\r\n\r\n\r\nutdanninghøyere utdanning\r\n\r\n\r\n0.027\r\n\r\n\r\n\r\n\r\n(0.047)\r\n\r\n\r\n\r\n\r\n\r\n\r\nalder\r\n\r\n\r\n-0.003\r\n\r\n\r\n\r\n\r\n(0.003)\r\n\r\n\r\n\r\n\r\n\r\n\r\nlandbakgrunnB\r\n\r\n\r\n0.117**\r\n\r\n\r\n\r\n(0.056)\r\n\r\n\r\n\r\n\r\n\r\n\r\nlandbakgrunnC\r\n\r\n\r\n0.021\r\n\r\n\r\n\r\n\r\n(0.054)\r\n\r\n\r\n\r\n\r\n\r\n\r\nConstant\r\n\r\n\r\n0.759***\r\n\r\n\r\n\r\n(0.188)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nObservations\r\n\r\n\r\n400\r\n\r\n\r\nR2\r\n\r\n0.052\r\n\r\n\r\nAdjusted R2\r\n\r\n0.040\r\n\r\n\r\nResidual Std. Error\r\n\r\n\r\n0.449 (df = 394)\r\n\r\n\r\nF Statistic\r\n\r\n\r\n4.305*** (df = 5; 394)\r\n\r\n\r\n\r\n\r\nNote:\r\n\r\n\r\np<0.1; p<0.05; p<0.01\r\n\r\n\r\nHer er, i en iterasjon, behandling ikke signifikant, mens landbakgrunn B er signifikant forbundet med bedre resultater enn landbakgrunn A. Det er en ren tilfeldighet, ettersom variabelen er helt tilfeldig uten noen relasjon til utfallsvariabelen.\r\nDette er ikke optimalt - finnes det en måte å komme seg ut av dette?\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2024-03-17T09:00:23+01:00",
    "input_file": "smallregression.knit.md"
  },
  {
    "path": "posts/2024-01-13-powercalculations/",
    "title": "Hvor stor effekt kan jeg finne i et lite ideelt (men veldig realistisk) eksperiment?",
    "description": "En rask kikk på hvordan en beregner teststyrke og mulig detekterbar effektstørrelse i R.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2024-02-24",
    "categories": [],
    "contents": "\r\nSi at du har gjennomført et eksperiment på den minst eksperiment-tilpassa måten som tenkes kan:\r\ndu har kun administrert behandlingen til en 30-40 personer (få enheter),\r\ndu har fordelt behandlinga på 5 ulike kontor (så du har litt clustring, dvs. at de som får behandling er like hverandre),\r\ndu har ikke trukket kontorene med eksperiment-behandlingen (eller deltakerne på disse kontorene) tilfeldig (så du har ikke randomisering)\r\nheldigvis har du en kontrollgruppe med en annen behandling utført ved. ca. 35 kontorer,\r\nDette er veldig realistisk, men utfordrende hvis målet er å teste effekter Da hadde du trengt flere enheter, særlig ettersom det er clustring, og du hadde trengt randomisering av behandlingen.\r\nSå hva gjør du når du ikke har noe av dette? Det korte svaret er at du først og fremst gjør en annen type undersøkelse enn en statistisk analyse. Du trenger mer data fra hver enkelt prosess, for å potensielt spore betydningen av behandlingen for den enkelte deltakeren, i den spesifikke settingen den er gitt. Men du må også se på datamaterialet - for hva gjør du hvis noen, f.eks. lederne ved de ulike kontorene, bruker de evt. svært høye resultatene de fikk som bevis på at behandlingen har stor positiv effekt? Grad av måloppnåelse og positive utfall har en stor magnetisk påvirkningskraft på alle, slik at tallene må undersøkes og evt. manglende effekter tydelig forklares.\r\nSå hvordan gjør en det? I første omgang skal vi se på hvilken analyse en ville gjort, hvis behandlingen hadde vært randomisert og betydningen av clustringa minimal. Hvilken teststyrke haddde en fått, og hvor store må effektene være for at en skal kunne oppdage dem? I den forbindelsen får jeg også brukt den flotte pwr-pakka.\r\nFor å se på dette, genererer jeg noen simulerte data: 40 personer på 5 kontor har fått behandling, 360 personer fordelt på 40 kontor har ikke. Vi legger til grunn at behandlingen ikke har en effekt av noen særlig betydning. Utfallsvariabelen er dikotom, trukket fra en binomialfordeling med sannsynlig 70 % for utfall lik 1 i både behandlings- og kontrollgruppa.\r\n\r\n\r\ndf_behandling = data.frame(\r\n  person_nr = seq(1, 40, 1),\r\n  behandling = 1,\r\n  utfall = rbinom(40, 1, 0.7)\r\n)\r\n\r\ndf_kontroll = data.frame(\r\n  person_nr = seq(41, 400, 1),\r\n  behandling = 0,\r\n  utfall = rbinom(360, 1, 0.7)\r\n)\r\n\r\ndf = bind_rows(df_behandling, df_kontroll)\r\n\r\n\r\nSuperenkel test av sammenheng - z-test (andelstest)\r\nI utgangspunktet skal det - hvis du har gjort alt riktig i designet av eksperimentet ditt - være mulig å sjekke utfallet av eksperimentet med noen av de mest grunnleggende testene i statistikken. Med en nominal avhengig variabel (ja eller nei), og en dikotom uavhengig variabel (behandling eller ikke behandling), blir de anbefalte testene enten kjikvadrat-test eller en proporsjonstest (z-test). Det vi tester er om utfallet er uavhengig av behandlingen, på et 5 % signifikansnivå.\r\n\r\n\r\n#lager en krysstabell fra dataene\r\nkrysstabell = table(df$behandling, df$utfall, dnn = c(\"behandling\", \"utfall\"))\r\n\r\nkrysstabell\r\n\r\n          utfall\r\nbehandling   0   1\r\n         0 121 239\r\n         1  15  25\r\n\r\n#z.test\r\n#kan ikke bare bruke krysstabellen her, må hente ut verdier manuelt.\r\nprop.test(x = c(krysstabell[2,2], krysstabell[1,2]), n = c(40, 360), alternative = \"two.sided\", correct = FALSE)\r\n\r\n\r\n    2-sample test for equality of proportions without continuity\r\n    correction\r\n\r\ndata:  c(krysstabell[2, 2], krysstabell[1, 2]) out of c(40, 360)\r\nX-squared = 0.24262, df = 1, p-value = 0.6223\r\nalternative hypothesis: two.sided\r\n95 percent confidence interval:\r\n -0.1966533  0.1188755\r\nsample estimates:\r\n   prop 1    prop 2 \r\n0.6250000 0.6638889 \r\n\r\n#kjikvadrat-test - bruker chisq.test\r\n\r\nchisq.test(krysstabell, correct = FALSE)\r\n\r\n\r\n    Pearson's Chi-squared test\r\n\r\ndata:  krysstabell\r\nX-squared = 0.24262, df = 1, p-value = 0.6223\r\n\r\nP-verdien er over 0,05, og vi kan dermed ikke avvise nullhypotesen om at det ikke er sammenheng mellom behandling og utfall. Noe som gir mening, disse dataene er trukket fra den samme sannsynlighetsfordelinga.\r\nHer ser vi også at når vi bare har to andeler på denne måten, blir z-testen og kjikvadrat-testene like.\r\nMen hva hvis vi trekker fra to litt ulike sannsynlighetsfordelinger, der sannsynligheten for utfall i kontrollgruppa er 70 %, mens sannsynligheten for utfallet i eksperimentgruppa er lavere, kun 60 %? Klarer vi å detektere dette med en z-test da?\r\n\r\n\r\ndf_behandling = data.frame(\r\n  person_nr = seq(1, 40, 1),\r\n  behandling = 1,\r\n  utfall = rbinom(40, 1, 0.6)\r\n)\r\n\r\ndf_kontroll = data.frame(\r\n  person_nr = seq(41, 400, 1),\r\n  behandling = 0,\r\n  utfall = rbinom(360, 1, 0.7)\r\n)\r\n\r\ndf = bind_rows(df_behandling, df_kontroll)\r\n\r\n#lager en krysstabell fra dataene\r\nkrysstabell = table(df$behandling, df$utfall, dnn = c(\"behandling\", \"utfall\"))\r\n\r\nkrysstabell\r\n\r\n          utfall\r\nbehandling   0   1\r\n         0 117 243\r\n         1  15  25\r\n\r\nprop.test(x = c(krysstabell[2,2], krysstabell[1,2]), n = c(40, 360), correct = FALSE)\r\n\r\n\r\n    2-sample test for equality of proportions without continuity\r\n    correction\r\n\r\ndata:  c(krysstabell[2, 2], krysstabell[1, 2]) out of c(40, 360)\r\nX-squared = 0.40706, df = 1, p-value = 0.5235\r\nalternative hypothesis: two.sided\r\n95 percent confidence interval:\r\n -0.207637  0.107637\r\nsample estimates:\r\nprop 1 prop 2 \r\n 0.625  0.675 \r\n\r\nSammenhengen er fortsatt ikke signifikant.\r\nStyrkeberegning\r\nMed formelen for styrkeberegning, kan en beregne teststyrke - altså sannsynligheten for at en test avviser nullhypotesen når en spesifikk alternativ hypotese er sann. Dette er også kjent som sannsynligheten for en “falsk negativ” eller type 2-feil (der type 1 er en falsk positiv, dvs. avvise nullhypotesen på sviktende grunnlag). For å beregne dette, må en vite noe om hvor stor effekt-størrelsen sannsynligvis er (mer om det lenger ned), en må ha n og signifikans-nivået.\r\nSå hva hvis vi legger til grunn at effektstørrelsen tilsvarer en 5 prosentpoengs forskjell i måloppnåelse, for n1 40 og n2 = 360, og et standard signifikans-nivå på 5 %?\r\n\r\n\r\neffektstr = pwr.2p2n.test(h = ES.h(p1 = 0.75, p2 = 0.70), n1 = 40, n2 = 360, sig.level = 0.05)\r\neffektstr\r\n\r\n\r\n     difference of proportion power calculation for binomial distribution (arcsine transformation) \r\n\r\n              h = 0.1120819\r\n             n1 = 40\r\n             n2 = 360\r\n      sig.level = 0.05\r\n          power = 0.1032033\r\n    alternative = two.sided\r\n\r\nNOTE: different sample sizes\r\n\r\nI dette tilfellet er teststyrken 10 %. Sannsynligheten for å avvise nullhypotesen hvis hypotesen om 5 % større måloppnåelse i behandlingsgruppen er sann, er kun 10 %. Det er veldig lavt. Et vanlig nivå for ønska teststyrke er 80 % (det slår inn en trade-off mot sannsynligheten for en falsk positiv).\r\nVed hjelp av formelen for teststyrke kan en også beregne den minimale effektstørrelsen som en kan finne, gitt en viss utvalgsstørrelse. Så hvor stor må forskjellen være mellom behandlingsgruppa og kontrollgruppa for at vi skal finne en signifikant effekt her, gitt 5 % signifikans-nivå og 80 % styrke?\r\n\r\n\r\neffektstr = pwr.2p2n.test(h = NULL, n1 = 40, n2 = 360, sig.level = 0.05, power = 0.8, alternative = \"two.sided\")\r\neffektstr\r\n\r\n\r\n     difference of proportion power calculation for binomial distribution (arcsine transformation) \r\n\r\n              h = 0.4669316\r\n             n1 = 40\r\n             n2 = 360\r\n      sig.level = 0.05\r\n          power = 0.8\r\n    alternative = two.sided\r\n\r\nNOTE: different sample sizes\r\n\r\nHer estimeres det at forskjellen må tilsvare Cohens h på 0,46. Hva betyr det, egentlig? Cohens h er et mål på forskjellen mellom to andeler, og hvorvidt forskjellen er meningsfull Wikipedia. Tommelfinger-regelen anbefalt av Cohen er at 0,2 er liten, 0,5 er middels og og 0,8 stor. En h-verdi på 0,47 er dermed ganske så middels. Hvordan ser denne effektstørrelsen ut mellom en andel på 70 %, og en rekke andre andeler?\r\n\r\n\r\n\r\nHer er effektstørrelsen plottet for en andel på 70 %. En effektstørrelse på 0,46 tilsvarer at vi finner en andel i gruppe 1 på 70 %, og en andel i gruppe 2 på enten rett under 50 %, eller rett under 90 %. Altså ca. 20 prosentpoeng over eller under.\r\nDvs. hvis vi kunne sett på data fra dette “eksperimentet” på den klassiske måten, og lagt til grunn at behandlingen var randomisert og at klyngeeffektene ikke hadde betydning, så ville det lave antallet deltakere fortsatt gjort at vi måtte opp i en forventa effektstørrelse på rundt 20 prosentpoeng for at analysen ville vært i stand til å bekrefte det. Hvis effekten er mindre - noe den antakelig er, effekter er gjerne små - så blir sannsynligheten for at vi får en falsk negativ stor.\r\nMen det er også utfordringer med randomisering. Kan disse løses? Mer om det en anna gang.\r\n\r\n\r\n\r\n",
    "preview": "posts/2024-01-13-powercalculations/powercalculations_files/figure-html5/unnamed-chunk-7-1.png",
    "last_modified": "2024-03-02T07:52:45+01:00",
    "input_file": "powercalculations.knit.md"
  },
  {
    "path": "posts/2024-01-06-apparenttemperature/",
    "title": "Følt temperatur",
    "description": "Det er januar og kaldt. Men er det faktisk kaldere på kysten, selv om gradstokken viser både 10 og 20 kuldegrader mer på østlandet? Nei. Nei, det er det ikke - ta på deg en genser, vestlending.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2024-01-06",
    "categories": [],
    "contents": "\r\nDet er januar, og kaldt. En kollega sa en dag at “Minus 10 i Bergen er kaldere enn minus 20 på Lillehammer”. Dette tror jeg ikke noe på! Selv om det er litt forskjell på tørr og våt luft, ikke minst hvis det er vind, kan vel ikke det utgjøre så mye? Den gamle mannen i meg ønsker heller å tilskrive dette til at kalde dager er mer sjeldent, og at det er få som kler seg fornuftig med lue, stilongs og tjukkgenser i ull.\r\nDette må sjekkes!\r\nVind er det viktigste når det er kaldt\r\nI følge Store norske leksikon er følt temperatur en måte å måle dette på. En justerer temperaturen som termometeret viser til å ta hensyn til kombinert effekt av vind og luftfuktighet, og sier noe om hvor mye varme menneskekroppen avgir til lufta (dvs. hvor kaldt det kjennes ut ute).\r\nDen samme leksikon-artikkelen viser at vind kan påvirke følt kulde, men at luftfuktighet har liten påvirkning på det:\r\n\r\nVed kuldegrader kan forskjellene i varmekapasitet og varmeledningsevne mellom tørr og fuktig luft maksimalt være i størrelsesorden noen promille. Disse egenskapene ved lufta kan derfor ikke forklare noen forskjell i følt kulde.\r\n\r\nFaktisk er det slik at høy luftfuktighet senker fordampingen fra kroppen - altså at du føler deg varmere. Det er det som gjør at å være varm og svett i høy luftfuktighet kan være mer ubehagelig, enn i tørre omgivelser.\r\nMen: der vind og vann møtes (i et mektig kav, eller bare helt vanlig kyststripe-tilværelse), oppstår det lettere vind og trekk/turbulens, i følge denne yr-artikkelen.\r\nFølt lufttemperatur kan beregnes!\r\nSå problemet er vind! Hvor stor er påvirkninga av vind på følt temperatur? Det bestemmes av en vindavkjølingsindeks: den temperaturen vi måtte hatt i vindstille forhold for å oppleve samme kulde som ved de eksisterende vind- og temperaturforhold.\r\nI følge wikipedia-artikkelen om dette er indeksen gyldig for temperaturer under 10 grader, og vind over 4.8 kilomter pr. time (fra ca. 1,5 meter pr. sekund). Den ser ca. slik ut:\r\n\r\n\r\n#avkjølingsindeks w er en funksjon av temperatur t og vindhastighet km/t.\r\n\r\n#formelen tar km/t, ikke m/s.\r\n# svak vind er 1.5 meter pr. sekund, som er 5,4 km/t.\r\n\r\nv_ms = 1.0\r\nt = -25\r\nv = (v_ms*3600)/1000\r\n\r\nw = 13.12 + (0.621*t) - (11.37*(v^0.16)) + ((0.3965*t)*(v^0.16))\r\n\r\n\r\nHvis vi genererer noen data for denne, for litt ulike kombinasjoner:\r\n\r\n\r\ndf = data.frame(\r\n  vind_ms = seq(from = 1.5, to = 24, by = 1.5),\r\n  temperatur = seq(5, -55, length.out = 16)\r\n)\r\n\r\ndf = expand(df, vind_ms, temperatur)\r\n\r\ndf = mutate(df,\r\n            vind_km = (vind_ms*3600)/1000,\r\n            indeks = 13.12 + (0.621*temperatur) - (11.37*(vind_km^0.16)) + ((0.3965*temperatur)*(vind_km^0.16))\r\n            )\r\n\r\n\r\nDa kan vi plotte et heat-map. Eller kanskje det burde hete kulde-kart i dette tilfellet?\r\n\r\n\r\n\r\nHer ser vi at forskjellene kan bli ganske store for lave temperaturer og høy vind. Forskjellene er imidlertid mindre for mindre ekstreme temperaturer og middels vindstyrke. Et linjediagram burde få fram dette på en bedre måte:\r\n\r\n\r\n\r\nHer ser vi hvordan 1 grad ved 1.5 meter pr. sekund blir til -1. Ved 7.5 meter pr. sekund føles det som -5. Selv i liten storm, 22,5 meter pr. sekund, synker ikke den følte temperaturen under -10. Mens hvis temperaturen derimot er -11, gjør selv en liten vind at den følte temperaturen nærmer seg -15, og en laber bris (7,5 m/s) gir en følt temperatur under -20.\r\nSammenlikning av temperatur i Bergen, Hamar og Stavanger\r\nHva betyr det i praksis for følt temperatur på et par steder? Fra seklima.met.no henter jeg timevis minimumstemperatur (målt i ti meters høyde), høyeste middelvind siste time, og høyeste vindkast siste time (målt i to meters høyde), for de siste 30 dagene i Bergen, Sola og Hamar.\r\n\r\n\r\n\r\nBergen og Sola ligger ganske tett, mens Hamar ligger et godt stykke under i hele perioden. Men det blåser vel en del mer i Bergen og Stavanger? Vinden er veldig variabel, så her legger jeg på en loess-smoother for å tydeligere få fram trenden.\r\n\r\n\r\n\r\nHer ser vi at Stavanger jevnt over ligger langt over Bergen, som ligger et godt stykke over Hamar. 2,5 m/s er svak vind, mens 5 m/s er en lett bris. Sola var i perioder oppe i laber bris og over.\r\nHvordan påvirker dette følt temperatur?\r\n\r\n\r\n\r\nHer blir forskjellene mindre, men Hamar er fortsatt kaldest - kanskje med unntak av et par tidspunkt hvor Sola kryper under. Men dette er med middeltemperaturen - hva hvis vi ser på kulden i vindkastene?\r\n\r\n\r\n\r\nDet krymper avstanden ytterligere, men det ser ikke nevnverdig annerledes ut. Det blir tydeligere hvis vi ser temperaturen og følt temperatur oppimot hverandre på hvert enkelt sted.\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2024-01-06-apparenttemperature/apparenttemperature_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2024-01-06T17:29:45+01:00",
    "input_file": "apparenttemperature.knit.md"
  },
  {
    "path": "posts/2023-12-03-kartlaging-i-r/",
    "title": "Hvordan lage kart i R - en oppdatering",
    "description": "Hvordan lager en kart med R på en effektiv måte i 2023?",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2023-12-03",
    "categories": [],
    "contents": "\r\nJeg lærte meg i utgangspunktet R for mange år siden, fordi jeg skulle lage kart over fordelinga av griser i Danmark, melkekuer i Sverige og ammekuer i Østerrike. Alle elsker et godt kart! Det var ingen enkel oppgave - både fordi det krevde at jeg lærte meg databehandling og litt halv-avansert figurlaging i R fra bunnen av, og fordi GIS-området var ganske komplekst i R: Det var krevende å finne datafiler med vektor-data om grensene til de ulike landene og de administrative områdene, og når en først hadde funnet dem måtte en håndtere en rekke ulike pakker og avhengigheter.\r\nSlik har jeg hatt inntrykk av at det har vært siden da. Jeg har med jevne mellomrom laget nye kart på nye områder, og når jeg har kommet tilbake til kartlaginga og prøvd å bruke gammel kode, har den vært utdatert, og de siste tutorials en kan finne på nettet benytter litt andre pakker, med litt anna syntax.\r\nSlik var det også sist, men slik jeg tolker CRAN Task Viewet om analyse av romlige data, er de siste endringene kaaaanskje litt mer robuste? At den anbefalte pakka sf er vedlikehold og i tråd med en ekstern standard for åpen formidling av “simple features” lover i hvert fall noe. At Kartverket og mange andre tilbyr en haug med kart som åpne data på Geonorge gjør også datatilgangen langt enklere.\r\nNoe av utfordringa her er at innføringer og tutorials en finner, tar utgangspunkt i å forklare hvordan et spesifikt verktøy fungerer. Dermed blir en veldig sårbar for endringer i verktøyet, og innføringa av nye verktøy. En verktøy-agnostisk tilnærming er som vanlig best - men vil også være med tidkrevende. Det er mye enklere å få et par linjer kode som funker i dag, enn å måtte lære seg hvordan koordinatsystemer egentlig fungerer.\r\nHvilke pakker trengs nå da?\r\nSvaret er for meg så langt kort og greit: sf, med vignetter her. SF benytter fire viktige bakenforliggende biblioteker utenfor R: GDAL (i/o til en rekke typer geodata), PROJ (for CRS-transformasjon), GEOS (for planetær geometri) og S2 (sfærisk geometri).\r\nDette er for vektor-data. terra er anbefalt for raster-data. Det finnes også en haug med pakker med diverse geografiske data - se Task Viewet over for lenker. spData er en slik pakke.\r\n\r\n\r\n#biblioteker\r\nlibrary(sf)\r\nlibrary(spData)\r\nlibrary(tidyverse)\r\nlibrary(tmap)\r\n\r\n\r\nDet følgende er basert på Lovelace m.fl. sin eminente online-versjon av Geocomputation with R, og div. pakke-vignetter for de brukte pakkene sf og tmap.\r\nHva er vektorer i denne sammenhengen?\r\nVektor-data representerer verden med punkter, linjer eller polygoner.\r\nVektor-data i denne sammenhengen må ikke forveksles med vektor-klassen i R : det første er en spesifikk data-modell, det andre er en data-klasse. Vektor-data kan representeres som vektor-objekter.\r\nPunktene kan representere ett sted (busstopp 172 i Bergen kommune), eller de kan knyttes sammen til linjer og polygoner (kommunegrensa til Bergen)\r\nPunktene har et sett med koordinater som angir hvor i verden de befinner seg. Det er stort sett 2 datapunkter - x og y, men noen ganger z.\r\nDisse koordinatene refererer til et referansesystem (coordinate reference system, CRS). Det finnes mange ulike CRS.\r\nHvordan ser det ut i praksis?\r\n\r\n\r\ndata(world)\r\n\r\nplot(world)\r\n\r\n\r\n\r\nHvorfor sf?\r\nsf-objektene er data.frames med en spesiell geometri-variabel. Geometri-variabelen er “sticky”, og blir med rundt selv om du manipulerer den.\r\n\r\n\r\nnorway = filter(world, name_long == \"Norway\") |> \r\n  select(lifeExp)\r\n\r\nsummary(norway)\r\n\r\n    lifeExp               geom  \r\n Min.   : NA   MULTIPOLYGON :1  \r\n 1st Qu.: NA   epsg:4326    :0  \r\n Median : NA   +proj=long...:0  \r\n Mean   :NaN                    \r\n 3rd Qu.: NA                    \r\n Max.   : NA                    \r\n NA's   :1                      \r\n\r\nggplot(data = norway) +\r\n  geom_sf()\r\n\r\n\r\n\r\nFordelen med sf-objektene er lette å se for meg som så vidt husker å ha brukt andre pakker tidligere: De kan behandles som data.frames, og kan benyttes i en tidyverse-arbeidsflyt.\r\nSf støtter punkter, linjer, polygoner og en 15 andre geometri-typer. Med sfheaders-pakken kan en konvertere mellom sf-objekter og data.frame-objekter, f.eks. slik:\r\n\r\n\r\ntemp = sfheaders::sf_to_df(norway, fill = TRUE)\r\n\r\nhead(temp)\r\n\r\n  lifeExp sfg_id multipolygon_id polygon_id linestring_id        x\r\n1      NA      1               1          1             1 15.14282\r\n2      NA      1               1          1             1 13.71852\r\n3      NA      1               1          1             1 13.17077\r\n4      NA      1               1          1             1 10.44453\r\n5      NA      1               1          1             1 11.22231\r\n6      NA      1               1          1             1 13.17060\r\n         y\r\n1 79.67431\r\n2 79.66039\r\n3 80.01046\r\n4 79.65239\r\n5 78.86930\r\n6 78.02493\r\n\r\nEn får da ut x og y-koordinatene til alle punktene, sammen med ID-variabler, for det som i sf-objektet er ett multipolygon:\r\n\r\n\r\nhead(norway)\r\n\r\nSimple feature collection with 1 feature and 1 field\r\nGeometry type: MULTIPOLYGON\r\nDimension:     XY\r\nBounding box:  xmin: 4.992078 ymin: 58.07888 xmax: 31.29342 ymax: 80.65714\r\nGeodetic CRS:  WGS 84\r\n# A tibble: 1 × 2\r\n  lifeExp                                                         geom\r\n    <dbl>                                           <MULTIPOLYGON [°]>\r\n1      NA (((15.14282 79.67431, 13.71852 79.66039, 13.17077 80.01046,…\r\n\r\nJeg vil bare ha et pent bilde!\r\nJeg har vist base og ggplot2 så langt. GGPLOT2 kan som vanlig stilles langt bedre inn, med mer kode:\r\n\r\n\r\nggplot(data = norway) +\r\n  geom_sf() +\r\n  coord_sf(xlim = c(-2, 32), ylim = c(54, 72), expand = FALSE) +  \r\n  theme_void()\r\n\r\n\r\n\r\nGeometrien her er i utgangspunktet svært grov - alle fjords er borte, her er det internasjonale linjer med kystgrense som gjelder. Det er også en rekke andre pakker som kan brukes til å plotte dette, som tmap (også kalt tm - men det er en anna pakke):\r\n\r\n\r\ntm_shape(norway) +\r\n  tm_polygons() +\r\n  tm_layout(frame = FALSE)\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2023-12-03-kartlaging-i-r/kartlaging-i-r_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2023-12-03T21:06:56+01:00",
    "input_file": "kartlaging-i-r.knit.md"
  },
  {
    "path": "posts/2023-11-28-migrering-til-distill/",
    "title": "Migrering til Distill",
    "description": "Enda en post om bytte av bloggplattform.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2023-11-28",
    "categories": [],
    "contents": "\r\nSå nå bytter jeg blogg-produksjons-system til distill. Blogdown var kjekt, men jeg brukte veeeldig få av mulighetene til custom theming og gøyale påfunn med Hugo. Jeg brukte derimot veeeldig mye tid på å få det til å funke, få lenkene mine til bilder og datasett til å bli riktige, til å få encodinga på alt til å snakke sammen og aksepter æ, ø og å.\r\nNå er det ikke lenge siden sist jeg bytta fra wordpress, og jeg begynner å angre litt på det. Det er en viss fare for å ende opp et steg på høyresiden av denne kurva her:\r\nbilde fra https://rakhim.org/images/honestly-undefined/blogging.jpgMen, jeg liker det jeg ser så langt:\r\ndet er langt enklere enn blogdown, og har ingen avhengigheter til Hugo og de stadige endringene der. Det ser ut som en ganske enkel samling av HTML-filer og markdown?\r\ntemaet er veldig standard og veldig lett, men kan tilpasses litt med CSS.\r\nUt ifra hva jeg kan se av introduksjonsmaterialet, er også Distill en god del enklere enn blogdown og bookdown. Blogdown er faktisk pekt på som den mest komplekse når du skal bestige R Markdown-fjellet.\r\nIllustration from Sharing on Short Notice, A. Hill & D. De LeonDistill for RMarkdown er basert på Distill-rammeverket for akademisk publisering, som er en enkel nettside som importerer funksjonalitet ved å source inn et predefinert sett med funksjonalitet med CSS, HTML og JS.\r\nArbeidsflyten er mye den samme som i Blogdown:\r\n- opprett en ny post\r\n- endre encoding til UTF-8 (for å få med deilige nordiske bokstaver)\r\n- knit den lokalt og se på resultatet\r\n- commit til git, push til repo kobla til Netlify, og ta-da, se på automatisk oppdatert nettside.\r\nSå gjenstår det bare å se om det faktisk blir noe mer blogging av dette.\r\nNoen ressurser jeg har hatt nytte av:\r\nDokumentasjonen for pakka\r\nEt bestiarium med ulike eksempler på sider laget med Distill\r\nJenny Sloane sin tutorial for RGirls (Youtube)\r\nTheMockUp\r\nPiping Hot Data\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-28T21:31:55+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2023-09-23-kompetanse-for-fremtiden/",
    "title": "Kompetanse for fremtiden",
    "description": "Utredning av behovet for et nytt arbeidsrettet kvalifiseringstilbud for innvandrere med lave norskferdigheter og lite formell kompetanse.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2023-09-23",
    "categories": [],
    "contents": "\r\nFinn rapporten her.\r\nI en ny rapport anbefaler ideas2evidence justeringer av arbeidsretta kvalifiseringstilbud for innvandrere uten fullført grunnskole og med lave norskferdigheter. Tilbudene denne gruppa får i dag er begrenset i omfang, og dekker i liten grad målgruppas behov. Det trengs allikevel ikke et nytt tilbud, viser utredningen.\r\nEn gruppe innvandrere i Norge har ikke fullført grunnskole, har lave norskferdigheter og har lite relevant arbeidserfaring. Anslagene på størrelsen på gruppen varierer mellom ca. 12 000 og 39 000 personer mellom 20 og 60 år. I gruppen finner en både unge og gamle, kvinner og menn. Mange har fluktbakgrunn eller er familiegjenforent med en flyktning, men det er også personer med opphold som familieinnvandrere. Mange har vært i Norge i over ti år, og er bosatt i Oslo eller Viken. Gruppen beskrives av førstelinjetjenestene som svært sammensatt, med veldig komplekse og forskjellige livssituasjoner. Mange står langt fra arbeidsmarkedet.\r\nDet er et mål for norsk integreringspolitikk at også denne gruppen av innvandrere skal ha like muligheter til å delta i arbeids- og samfunnsliv som befolkningen ellers. Med lave norskferdigheter, lite skolebakgrunn og lite arbeidserfaring, blir deltakelse i samfunnet og på arbeidsmarkedet vanskelig. Uten et tilpasset kvalifiseringstilbud som på et tidlig tidspunkt identifiserer og adresserer de barrierene den enkelte står ovenfor, er det en reell fare for økte levekårsutfordringer for den enkelte og tapte ressurser for samfunnet.\r\nPå oppdrag fra Integrerings- og mangfoldsdirektoratet (IMDi), Arbeids- og velferdsdirektoratet (AV-dir) og Direktoratet for høyere utdanning og kompetanse (HK-dir), har ideas2evidence kartlagt omfanget av arbeidsretta kvalifiseringstilbud denne gruppa får i dag, og sett på hva som trengs for at gruppas behov kan dekkes på en bedre måte.\r\nI rapporten gjennomgår vi 16 kartlagte tilbud. Vi finner at få av disse kombinerer grunnskole, norskopplæring og arbeidspraksis. Av tilbudene vi ser på, er det tre lokalt utviklede tilbud, samt stedene hvor kombinasjonsforsøket nå pågår, som oppfyller disse kravene. I tillegg til dette er det ett av voksenopplæringssentrene vi har undersøkt som oppgir at de kombinerer forsøk med modulstrukturert forberedende voksenopplæring (FVO) med arbeidspraksis fra dag 1. Fra den pågående følgeevalueringen vet vi at en håndfull av FVO-kommunene tilbyr dette. Vi finner også to tilbud som kombinerer norskopplæring, arbeidspraksis og fag- og yrkesopplæring på videregående nivå.\r\nTilbudene med alle de tre ønskelige elementene er begrenset i omfang og geografisk nedslagsfelt.\r\nI stedet er tilbudslanskapet preget av tilbud om enten norskopplæring og grunnskole, eller arbeidspraksis og norskopplæring. Tilbudene er heller ikke tilgjengelig for de svakeste delene av målgruppen, f.eks. ved at det stilles språkkrav, krav til helse, eller ved at en velger motiverte deltakere. Praksisfeltet sliter også med å rekruttere målgruppen, og fortolke regelverket likt (og på en måte som er målgruppen til gunst) i alle deler av landet og NAV-systemet.\r\nDet er allikevel ikke behov for et nytt, nasjonalt kvalifiseringstilbud, etter ideas2evidence sin vurdering. Det er flere grunner til dette. Blant annet er det allerede krevende for saksbehandlere og førstelinje å holde oversikt over ulike tilbud. Høsten 2024 kommer det også et nytt tilbud, når «forberedende opplæring for voksne» erstatter dagens tilbud om grunnskole for voksne.\r\nI stedet bør en vurdere å\r\nse sammenheng mellom det fremtidige FOV-tilbudet og arbeidsrettede tilbud\r\nEtablere en tilskuddsordning for lokal utvikling av arbeidsrettede kvalifiseringstilbud for målgruppen\r\nØke dokumenteringen av kompetanse\r\nVurdere mulighetene for økt tilpasning innenfor NAVs virkemiddelapparat\r\nKoordinere innsatsen ovenfor arbeidslivet\r\nAdresse spørsmål om livsopphold\r\nSe på statistikk- og kunnskapsgrunnlag.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-28T22:14:25+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2023-09-20-mellom-alle-stoler-arbkval/",
    "title": "Kompetanse for fremtiden - en presentasjon",
    "description": "En rapport-presentasjon jeg holdt for NAV Oslo - hvordan kan vi forbedre kvalifiseringstilbudet til de som står lengst unna arbeidsmarkedet?.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2023-09-20",
    "categories": [],
    "contents": "\r\nHer har vi en faksimile av en nyhetssak på nrk.no, fra mai. Det forteller historen om Zahra Alavi i Rogaland, som hadde sin første skoledag når hun var 37 år. Nå, fem år senere, er klar for å starte praksis som helsefagarbeider. Jeg er 37 år nå. Det er interessant å prøve å se for seg seg selv i denne situasjonen.\r\net bilde av en suksessDet Alavi her har gjort, omtales av læreren hennes som et mirakel. Mange av dere har nok kanskje selv opplevd eller kjenner til tilsvarende suksesshistorier.\r\nMen dere kjenner nok antakeligvis også alt for godt til tilfellene der det ikke fungerer - der personen ikke kom videre, ikke lærte seg språket, ble anbefalt å gjøre noe annet enn å ta utdanning, og så videre.\r\nDet prosjektet jeg nå skal fortelle om, handler om tilbud som har som mål å skulle skape slike suksesshistorier. Men ikke som mirakler, men mer pålitelige resultater. Det trengs i en situasjon som vi har valgt å kalle «mellom alle stoler».\r\nDenne rapporten utgjør en del av kunnskapsgrunnlaget for et arbeid som IMDi sammen med Arbeids- og velferdsdirektoratet og Direktoratet for høyere utdanning og kompetanse har gjort for AID om akkurat denne tematikken. Som en del av arbeidet har vi gjennomgått litteratur og skriftlig materiale, og intervjuet mange eksperter. Det vil blant annet si personer som dere som er i rommet i dag. Her har vi også trukket på arbeid vi i ideas2evidence gjør på beslekta områder – for de av dere som ikke kjenner oss, så gjør vi blant annet\r\nEvaluering av modulstrukturert voksenopplæring for Kunnskapsdepartementet\r\nKartlegging og utprøving av modeller for samarbeid om tilrettelagt fag og yrkesopplæring – for NAV\r\nUndersøkelse av utvidet opplæringstiltak – for NAV.\r\nDet dette prosjektet handler om, er tre forskjellige ting.For det første: å kartlegge hva som finnes av arbeidsretta kvalifiseringstilbud for denne målgruppa?\r\nMålgruppen er innvandrere med lite formell kompetanse, lave norskferdigheter og lite relevant arbeidserfaring. Lite formell kompetanse betyr ikke fullført grunnskole, gjerne langt unna å fullføre grunnskole. En gjennomgang av statistikk viser at vi anslagsvis snakker om mellom 12 000 og 39 000 personer, med en rekke ulike kjennetegn. Dette er veldig usikkert – hvis du ikke har tatt utdanning i Norge, så står du hovedsakelig ikke i registrene. Men for personene vi vet mangler grunnskole, så er det mange i Oslo og Oslo-området. Det er mange som har opphold som flyktninger, men også familiegjenforente. Mange har mer enn ti års botid.\r\nMen ellers er gruppa veldig variert. Når vi snakker med praksisfeltet om hvem målgruppa er, er det først og fremst variasjon, forskjeller og veldig komplekse livssituasjoner det som vektlegges. Omsorgsoppgaver, helseutfordringer, og en økonomisk krevende liv.\r\nDeretter: 1) Hvordan dekker dagens tilbud disse behovene? og 2) Hvordan kan tilbudene bedre møte behovene? Overordna: Trengs det tilpasninger eller noe nytt?\r\nHva finnes av tilbud?\r\nVi veit fra forskning at det for å få en varig jobb er viktig å kunne godt norsk og at du har formell kompetanse på videregående-nivå. Det er også mange som peker på at praksisnær læring kan være nyttig for mange. Vårt oppdrag var derfor å finne tilbud som kombinerer disse tre tingene – grunnskole, språkopplæring og arbeidspraksis.\r\nVi samla inn informasjon om rundt 50 tilbud.\r\nVi gjorde en nærmere utvelgelse av 16 av disse, som mulig interessante for vår målgruppe. Disse 16 er nærmere beskrevet i rapporten.\r\nOg dette må jeg si! Her gjøres det veldig mye godt arbeid. Vi har ikke kunnet gjøre en grundig evaluering av disse tilbudene, men vi ser jo i resultatrapporter og intervjuer at mange viser til svært god måloppnåelse – gjerne overgang til arbeid. Mange følger også det jeg vil si er noe av det nærmeste en kommer kjente kvalitetskriterier for å dekke målgruppens behov, som 1) grundig og helhetlig kartlegging, 2) brukermedvirkning, og 3) tett oppfølging av deltaker og arbeidsgiver.\r\nMen – som dere nok kan tenke dere, så finner vi svært få tilbud som inneholder alle tre elementene grunnskole, norskopplæring og praksis. Av tilbudene vi ser på, er det\r\ntre lokalt utviklede tilbud\r\nI tillegg til dette er det ett av voksenopplæringssentrene vi har undersøkt som oppgir at de kombinerer forsøk med modulstrukturert forberedende voksenopplæring (FVO) med arbeidspraksis fra dag 1. Fra den pågående følgeevalueringen vet vi at en håndfull av FVO-kommunene tilbyr dette, men at det ikke er vanlig. Det er aktuelt for introduksjonsprogram-deltakere, intropraksis, men ikke for andre grunnskole-deltakere.\r\nStedene hvor kombinasjonsforsøket nå pågår. Her vet vi at deltakerne der er blant de mest ressurssterke i denne målgruppa, og et flertall kan nok ikke sies å ha svake norskferdigheter når de begynner på videregående-delen av programmet. Kombinasjonsforsøket er et forsøk som kombinerer forsøket med modulstrukturert forberedende voksenopplæring på nivået under videregående (FVO), og forsøket med modulstrukturert fag- og yrkesopplæring for voksne innenfor utvalgte lærefag (MFY).\r\nVi finner også to tilbud som kombinerer norskopplæring, arbeidspraksis og fag- og yrkesopplæring på videregående nivå.\r\nTilbudene dekker ikke behovene til målgruppa\r\nVår vurdering er at tilgangen på offentlige arbeidsrettede kvalifiseringstilbud ikke dekker behovene til denne gruppen, slik det er i dag.\r\nBegrensa omfang: Siden vi fant så få tilbud som inneholdt alle disse elementene, er det opplagt at det ikke er nok slike tilbudsplasser til 13 000 eller 39 000 personer\r\nTilbudene er ikke tilgjengelig for de svakeste delene av målgruppen, \r\ndet stilles språkkrav,\r\nkrav til helse,\r\nvelger (oppfatta) motiverte deltakere,\r\ntilbudet du kan få avhenger av finansieringsmuligheter – både for tilbudet sin del, og for din egen inntekt.\r\nSom flere av dere vet godt, er det mange grunner til å gjøre det slik.Opplæring av personer som er på samme språknivå, mulig å skaffe praksisplass, osv. Men – konsekvensen er gjerne at de som har litt større sjans for å komme seg ut på arbeidsmarkedet, blir foretrukket.\r\nVi ser også at mange i praksisfeltet sliter med å rekruttere målgruppa. Det er vanskelig å finne dem, det finnes ikke noen ferdigdefinerte lister hos saksbehandlerne som en bare kan begynne å ringe. Og når en oppnår kontakt, så er det ikke alltid like lett å fortelle og formidle.\r\nDette er vel så mye poeng som angår de store kvalifikasjonsprogrammene, som de mindre, spesifikke tilbudene vi har sett på: evalueringer av introduksjonsprogrammet, opplæring i norsk og samfunnskunnskap, forsøket med modulstrukturert forberedende voksenopplæring, kvalifikasjonsprogrammet og NAVs virkemiddelapparat mer generelt. Disse evalueringene finner at behovene for målgruppen vi snakker om generelt sett ikke dekkes, men med enkelte unntak.\r\nHva bør gjøres?\r\nHer er fire anbefalinger til hvordan en kan gjøre det bedre.\r\n1. Vi trenger ikke et nytt nasjonalt tilbud\r\nVi anser det som lite hensiktsmessig å opprette et nytt kvalifiseringstilbud. Denne vurderingen bygger på flere poenger:\r\nDet er allerede krevende for saksbehandlere og førstelinje å holde oversikt over ulike tilbud.\r\nBåde praksisfelt og sektormyndigheter peker på en rekke utfordringer av mer strukturell art. Selv om mye kan håndteres innenfor et spesifikt tilbud, gitt ressurser og ildsjeler med systemkjennskap, vil allikevel utfordringer med f.eks. manglende samordning, et «lappeteppe» av finansieringskilder for tilbud og deltakere, livsopphold for deltakerne, manglende informasjon og informasjonsdeling om målgruppen, og manglende koordinering av kontakt med arbeidsgivere stå i veien.\r\nMed unntak av det pågående forsøket med modulstrukturert forberedende voksenopplæring, er tilbudene vi har identifisert lokale. Vi har ikke sett effektevalueringer som viser at ett eller flere av disse fungerer bedre enn andre, og vil være egnet for nasjonal utrulling uten videre pilotering og effektstudier.\r\nDet kommer om kort tid noe nytt – som flere av dere nok er klar over, kommer det fra høsten 2024 en ny modell for det som i dag er grunnskole for voksne. Det er under utprøving i dag, og skal hete «forberedende opplæring for voksne (FOV). og det står andre her som skal si mer om det. Men et hovedmål med omlegginga er å gjøre situasjonen bedre nettopp for denne målgruppa.\r\n2. Sammenheng mellom FOV-tilbud og arbeidsretta tilbud\r\nVi mener at grunnlaget for flere sentrale tilbud fremover ligger i å se FOV, som innføres høsten 2024, i sammenheng med arbeidsrettede tilbud.\r\nDet må påpekes at læreplaner for FOV fremdeles er under utvikling, resultatene fra følge- og effektforskningen av forsøket med forberedende voksenopplæring (FVO) er ikke klare, og mange detaljer om implementering er enda ikke kjent.\r\nVi ser allikevel potensiale for at ordningen, i kombinasjon med arbeidsrettede tilbud, kan løse flere av utfordringene i tilbudsfeltet.\r\nBlant annet er det svært få arbeidsrettede tilbud som gir opplæring på grunnskolenivå. Enkelte sliter med å inkludere norskopplæring etter læreplan som del av tilbudet. Gitt at sentrale mål med FOV er å integrere norskopplæring og opplæring i fag, og tilrettelegge læreplanene for de med svakest forutsetninger, fremstår en kobling mellom FOV og arbeidsrettede tiltak som positivt for målgruppen.\r\nMange av forsøkene med modulbasert grunnopplæring strever på sin side med å koble på praksis. Å utforske hvordan praksis kan innarbeides tidlig i et FOV-løp, enten gjennom samarbeid med arbeidsgivere om praksisplasser for de med lave norskferdigheter, eller gjennom opprettelse av interne praksisplasser, for eksempel i et arbeidsrettet tilbud, virker som et godt sted for VO å samarbeide med NAV.\r\nMen! Skal alle inn i grunnskolen, altså? Her er både opplæringssektoren og de arbeidsrettede tilbudene skjønt enige om nødvendigheten for et alternativ til det utdanningsrettede sporet, for å gi et tilbud til de som ikke har forutsetninger for å gå i grunnskole. Det argumenteres for at\r\nde som har forutsetninger for å fullføre grunnskole, bør gjøre dette på heltid, for å unngå lange løp,\r\nmens de som ikke har forutsetninger for å fullføre grunnskole bør få et alternativt tilbud og en annen arena å oppleve mestring i.\r\nDet er to helt sentrale forutsetninger for dette. For det første, at FOV implementeres godt. Oppdragsgiverne våre i HK-dir peker på at mye av det jeg sier her nå, det er sentrale mål for deres arbeid med FOV. Men som mine kolleger har funnet i følgeevalueringa, så er implementeringa av dette ganske forskjellig i det pågående forsøket.\r\nÅ etablere slike samarbeid mellom FOV og arbeidsrettede tilbud vil være krevende. Eksisterende samarbeid mellom NAV og VO viser utfordringer knyttet til manglende samordning av virkemidler og at det å etablere et tett samarbeid og gode kommunikasjonskanaler er tid- og ressurskrevende. Men det er også gode eksempler på det.\r\n3. Økt tilpasning innenfor NAVs virkemiddelapparat\r\nMange av tilbudene vi har identifisert eies av NAV, og de øvrige tilbudene har NAV som en sentral samarbeidspartner når det gjelder arbeid for denne målgruppen. Det er flere utfordringer som pekes på i dette samarbeidet, som en enten må finne løsninger på i spesifikke tilbud, eller adressere samlet.\r\nVi mener det må gjøres vurderinger av\r\nGi tydelig informasjon til ansvarlige saksbehandlere om hva som er tilgjengelige og relevante tilbud?\r\nmulighetene for å differensiere tiltak for denne målgruppen, for eksempel hvorvidt det kan åpnes for at denne gruppen kan gis arbeidspraksis og arbeidstrening av lengre varighet.\r\nmulighetene for å etablere særskilte tiltak spesifikt for denne gruppen, for eksempel norskopplæringstilbud for person på A1 nivå eller lavere.\r\nhvorvidt opplæringssenter og, så langt det er mulig, deltakere, har et fast kontaktpunkt i NAV,\r\nhvorvidt det kan gjennomgås hvordan lokale NAV kontor identifiserer, kontakter, rekrutterer og kartlegger kandidater til arbeidsrettede kvalifiseringstilbud, blant sine brukere, etablere felles rutiner og god praksis for dette, og evt. prioriterer arbeidstid hos ansatte til en slik oppgave.\r\nSamkjørt fortolkning av sentrale deler av regelverket, f.eks. knytta til målgruppen for KVP.\r\nSå, ta med hjem-budskapet:\r\nDet er mellom 12 000 og 39 000 innvandrere uten grunnskole, norskferdigheter og arbeidserfaring.\r\nFor denne gruppa finnes det få tilbud som kombinerer arbeidspraksis, norskopplæring og grunnskole.\r\nTilbudene som finnes er få, langt imellom, og rettet mot øvre del av gruppa. Behovene er komplekse og dekkes i liten grad.\r\nDet trengs ikke et nytt tilbud.\r\nI stedet kan en f.eks.\r\n– Arbeide lokalt for å koble det kommende FOV fra VO og arbeidsretta tilbud fra NAV\r\n– Etablere en statlig tilskuddsordning for lokal utvikling av kinderegg-tilbud\r\n– (Vurdere muligheten for å) gjøre tilpasninger innenfor NAVs virkemiddelapparat både lokalt og sentralt.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-25T10:36:53+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2023-05-12-fylkeskommunen-og-integrering-i-sivilsamfunn/",
    "title": "Fylkeskommunens rolle i det regionale arbeidet med integrering i sivilsamfunnet",
    "description": "Et innlegg jeg holdt på en samling for fagnettverket for integrering i norske fylkeskommuner.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2023-05-12",
    "categories": [],
    "contents": "\r\nNår jeg vokste opp, var det mange tenkte på gateslaget i Brumunddal 1991. Noen her som husker det? Arne Myrdal og «Folkebevegelsen mot innvandring» skulle mane brumunddølene til kamp mot innvandrere en dag i august 1991. Tanta mi var ute på handletur, og trilla søskenbarnet mitt rundt i barnevogn. Hun måtte bare springe og gjemme seg. Flasker og balltre føk rundt. Det endte med at en mobb med «innvandringsmotstandere» jaga blitzere ut på E6. I følge foreldra mine var det også et godt innslag av lokale helter som ville slåss med oslofolk. Ikke et stort øyeblikk for noen.\r\nMen det hadde vært ille å være innvandrer i Brumunddal også før dette, med tilfeller av brannbombing og vold. I en Aftenposten-artikkel ble Brumunddal omtalt som «Stedet gud glemte».\r\nfaksimile fra Aftenposten-artikkelEttermælet etter Gateslaget ble langt bedre. Et samarbeid mellom politi, lokale politikere og frivillighet førte til at Arne Myrdal når han skulle holde et nytt møte seinere, ble møtt av 4 000 – 5 000 personer fra Brumunddal og fylket rundt, som bare vendte ham ryggen. Historiefortellinga skal ha det til at han etter det var politisk død, og visnet hen.\r\nFrivilligheten sto sentralt i arbeidet da – mange ble vekket av denne «verbale springskallen», og jobba hardt i årene etterpå med å få Brummunddal på nye veier. Ikke minst sto det lokale fotball-laget sentralt. De arbeida veldig godt og inkluderende på å få alle med, og var på et tidspunkt blant de største yngres avdeling-klubbene i landet. De hadde «vend rasismen ryggen» på trøya si. De var også forferdelig gode, og knuste oss skikkelig de gangene laget jeg spilte for, møtte dem. (For mer informasjon, se f.eks. her, her eller her).\r\nDet jeg skal snakke om i dag, tar utgangspunkt i et arbeid vi gjorde sammen med Agenda Kaupang for IMDi i fjor. Vi kartla behov for kompetanse og samarbeid i frivilligheten, og så på noen løsninger for disse behovene. I den forbindelse gjorde vi bl.a. på intervjuer med 50 frivillige organisasjoner i fem forskjellige kommuner, en rekke intervjuer med sentrale aktører, workshops, og så videre.\r\nJeg har forstått at dere nå konkretiser fylkeskommunens arbeid med innsatsområdet integrering i sivilsamfunnet. Jeg vil derfor oppsummere\r\nHvorfor frivilligheten er viktig for integrering av innvandrere?\r\nHva er problemene?\r\nHvordan løser vi det?\r\nHva er så fylkeskommunens rolle?\r\nrapportforsideHvorfor er frivillighet og sivilsamfunn viktig for integrering av innvandrere?\r\nIntegreringsaktører. Frivilligheten har tiltak som supplerer de offentlige tjenestene. De siste årene, med ankomstene fra Syria, korona-pandemien og nå krigen i Ukraina har vist hvor viktige frivillige aktører er. De er helt sentrale langs hele asylsøkerkjeden – aktiviteter i mottak, drift av mottak, støtte til asylsøkere i møte med UDI, velferd og matutdeling, integreringsaktiviter, flyktningeguider, språkcafeer. Noen forskere mener at kommunene er blitt helt avhengige av de frivillige for å ivareta sine lovpålagte oppgaver, når ankomstene svinger mye.\r\nArena for integrering. Frivilligheten bidrar til tillit mellom folk, og nettverk som binder samfunnet vårt sammen. Det finnes mange måter det kan gjøres på. Som medlem eller deltaker i frivillig aktivitet, så kan du bindes sammen med andre som er like deg - velforeninga i nabolaget, «innlendinger i Bergen», andre slike grupper. En kan også bygge bro mellom forskjellige grupper – i fotballklubben der alle uansett hvem foreldrene er spiller. En kan representere interessene sine politisk. En kan få opplæring i demokrati i organisasjonens rike indre liv. Og som mange som selv har vært aktive i frivilligheten kan skrive under på: opplæring i byråkrati.\r\nDu bygger også kapasitet – du lærer ting, og får nettverk. Når jeg spilte fotball ble jeg i litt bedre fysisk form, men ble også kjent med andre.\r\nSagt mer formelt, så kan frivillige organisasjoner bidra med:\r\n- Sosial integrering\r\n- Politisk integrering\r\n- Ressurser for å integrere seg sosioøkonomisk.\r\nDet er altså svært mange måter som frivilligheten kan bidra på. Det følger også av dette at de aller fleste frivillige organisasjoner kan bidra til integrering – enten direkte aktiviteter for flyktninger eller minoriteter, eller indirekte, gjennom måten som frivillighet funker på.\r\nSå, hvis frivilligheten har en så viktig rolle - hva er problemet? Hva vil vi oppnå?\r\nHvor mange av dere deltar i organisert frivillig arbeid? Litt avhengig av hvordan og hva en måler, så viser tall at\r\nMellom 1 av 2 og 1 av 3 i befolkningen ellers.\r\nRundt 1 av 10 blant personer som har innvandret.\r\nInnvandrere deltar i frivillig aktivitet i mindre grad enn andre. Dette har mye med sosioøkonomisk bakgrunn å gjøre – utdannelse, inntekt, arbeid, bosted – men også andre ting knytta til innvandrernes opprinnelsesland. Hvis du snakker med arbeidsinnvandrere fra tidligere østblokk-land, så er det folk der som ble tvunget til å delta i frivillige organisasjoner. Det gjør noe med motivasjonen din seinere.\r\nDet er også et politisk mål at flere innvandrere skal få tilbud som språktrening, flyktningeguide, osv.\r\nFrivilligheten selv har etterlyst at rammebetingelsene for deres aktivitet må bli bedre, hvis sivilsamfunnet skal kunne styrke sin innsats på integreringsfeltet. Det inkluderer ting som tilskudd og andre ressurser. Men det inkluderer også behov for økt kompetanse og samarbeid. Det er dermed et tiltak i regjeringas gjeldende strategi «Hverdagsintegrering – strategi for å styrke sivilsamfunnets rolle på integreringsfeltet 2021 – 2024» å se på hvilke behov for kompetanse, og behov for samarbeid som organisasjonene har.\r\nVi gjorde dette oppdraget sammen med Agenda Kaupang. Vi kartla totalt 15 slike behov.\r\nNår alt av frivillige organisasjoner kan bidra til integrering, så betyr det også at organisasjonenes behov er svært forskjellig. Hva har kakebakeklubben i Kvæfjord til felles med Norges Fotballforbund samlede organisasjon? De kan bidra til integrering lokalt – men organisatorisk er utgangspunktene ganske forskjellig. Jeg skal ikke gjennomgå alt, men her er noen typer av behov som vi så – fordelt på noen karikerte organisasjoner:\r\nOrganisasjon A – «Småsted IL»\r\nEn liten lokal idrettsforening, som har aktiviteter for sine egne medlemmer innenfor sin idrett. Her er det en del som trenger økt bevissthet om hvilken rolle de kan spille som inkluderingsarena. De som har en slik bevissthet, etterspør kompetanseheving på hvordan de kan rekruttere og legge til rette for inkludering av flere med innvandrerbakgrunn i sin organisasjon. Kanskje de har prøvd noe, men så virka det ikke helt. En del av disse organisasjonene opplever også at de mangler det de selv beskriver som kompetanse på integrering, inkludering eller kulturforståelse. Mangelen bidrar til usikkerhet i møte med andre med annen kulturbakgrunn.\r\nOrganisasjon B – «Nasjonale Ildsjelers Forening»\r\nSå har vi en annen type organisasjoner, som har aktiviteter for folk utafor sine medlemmer. Her er det flere av de vi har snakka med som opplever at de har relativt god kompetanse på integreringsfeltet. De oppgir at de har tilfredsstillende tilgang på kurs og kompetansehevingsmuligheter.\r\nDet er særlig store organisasjoner med ansatte, som sier dette. Ifølge de ansatte er det de frivillige som eventuelt kunne ha behov for kompetanseheving i disse organisasjonene, ikke de fast ansatte.\r\nOrganisasjon C – «Engasjement for Land»\r\nSå har vi en gruppe organisasjoner, gjerne nesten utelukkende innvandrermedlemmer, som har utspring i et land eller en kultur. Kartleggingen avdekker at mange minoritetsorganisasjoner har behov for kompetanse i organisasjonsdrift og søknadsskriving. Her skjærer jeg mange over en kam. Det er ikke alle organisasjonene som har alle behovene. Noen har det meste på plass, men kunne tenke seg litt mer finansiering, eller kanskje et kurs innen spesifikk tematikk de arbeider med, og ikke minst at kommunen aktivt brukte kompetansen deres.\r\nFellestrekk\r\nMen noe er faktisk felles! Blant de fleste organisasjonene vi snakka med, så så de et behov for mer samarbeid med offentlige myndigheter, hvis de skulle styrke seg på integrering\r\nMange ga uttrykk for at de visste for lite om hva kommunene kunne tilby frivillige organisasjoner, og hvordan de frivillige organisasjonene kan bidra til integreringsoppgaver. Hva finnes av tilskudd og støttemuligheter? Hva kan lånes av lokaler og utstyr? Hvordan kan organisasjonen bidra, f.eks. for flyktninger fra Ukraina?\r\nMange organisasjoner tenkte at de ville trenge å møte andre organisasjoner og diskutere utfordringer, finne løsninger sammen. Organisasjoner med mindre erfaring med «integreringsspørsmål» og innvandrere, ønsket særlig noe slikt. Dette var det flere som ønsket at kommunen skulle ta ansvar for å legge til rette for samarbeid mellom organisasjoner i kommunen, og mellom kommunen og organisasjonen. Flere spilte her inn at en oversikt over hvilke organisasjoner som finnes lokalt, ville være praktisk. Der slike oversikter fantes, opplevdes de som utdatert eller vanskelige å finne. Kommunen ble også oppfordret til å invitere og koordinere møteplasser for flere organisasjoner.\r\nSå, hvordan skal vi løse dette?\r\nHer kommer dette med kompetansesenter. Det vi var bedt om å utrede, var om etablering av et kompetansesenter kunne dekke disse behovet. Vi har altså IKKE sett på alle tenkelige tiltak som kan dekke hvert enkelt av behovene. Men vi har sett på ulike løsninger for et kompetansesenter – skal det være et nytt og skinnende nyetablert senter ett sted i Norge, eller skal en bruke dagens fagmiljøer med kompetanse på de ulike forvaltningsnivåene?\r\nDet dette sentrene eller miljøene må kunne gjøre, er en koordinert innsats på lokalt, regionalt og nasjonalt nivå for:\r\n- Kunnskapsutvikling. Hvilke tiltak virker, hva virker ikke? Hva vet vi? Hvor mange?\r\n- Kompetanseutvikling- og formidling. Hvordan gjør en rekruttering? Hvordan jobber en med inkludering? Hvordan skal en kommune kunne samarbeide på frivillighetens premisser?\r\n- Tilrettelegge for samarbeid og dialog. Her trengs det samarbeid mellom aktører, på de ulike nivåene, og mellom nivåene.\r\nVi så veldig raskt at det var behov for mer enn en aktør her, og at det må være på ulike nivåer. Mange av behovene er lokalt, det er organisasjoner og kommuner som trenger mer kontakt. Mange av organisasjonene foretrekker også samarbeidspartnere med kort avstand. På den andre siden er det andre behov som kunnskapsutvikling som bør adresseres nasjonalt.\r\nVi så også veldig raskt at det finnes mange tilbud som allerede dekker behovet. Det var ikke i oppdraget vårt å gjøre en samla evaluering av virkemiddelapparatet her, men det er mange som har arbeidet godt og lenge med f.eks. rekruttering og inkludering.\r\nVi konkluderte derfor med at det ikke trengs flere nye aktører på feltet. Det er allerede mange aktører, med både ansvar og kompetanse, nasjonalt, regional og kommunalt. Dagens kompetansemiljøer kan dekke behovene i frivilligheten.\r\nVi foreslår i rapporten vår at\r\n- Frivilligheten selv har, prinsipielt sett, et ansvar for å dekke egne behov og etterspørre samarbeid med offentlige myndigheter.\r\n- Kommunene er den relevante aktøren for svært mange av behovene vi har pekt på her. Det er behov for samarbeid lokalt, kompetanse på søknader, organisasjonsdrift.\r\n- IMDi bør videreutvikle sin rolle. Systematisk oversikt over virkemiddelbruk og koordinering av innsats for kunnskapsutvikling, tilbud på kompetanseutvikling og formidling, samt tilrettelegging for samarbeid og dialog.\r\nSå hva med fylkeskommunens rolle?\r\nVi var innom den også. Ansvaret i dag har dere jo snakket om med innsatsområdene.\r\nKommunene varierer i størrelse, befolkningssammensetning og sentralitet. Ressursene og rammene for å prioritere integrering og frivillighet vil variere. Regionalt kan det derfor være fornuftig at fylkeskommunene tar en rolle som pådriver og veileder for kommuner med begrenset kompetanse og kapasitet på området. Det er tre måter vi har anbefalt at fylkeskommunen tar tak i behovene på det regionale planet\r\nKunnskapsutvikling:\r\n- egen utvikling,\r\n- kunne identifisere behov for kunnskap basert på kjennskap til regionale forhold, og bestille dette fra eller sammen med andre.\r\nKompetanseutvikling og -formidling: \r\n- Være en faglig ressurs og støtte for kommunenes arbeid. Her kommer kompetansebehovene jeg har snakket om tidligere inn.\r\n- Informere og veilede frivilligheten om fylkeskommunale/statlige tilskudd på feltet, og hvordan man kan finne/få tilgang på relevant kunnskap og kompetanse på feltet. Det var nesten ikke en eneste en av organisasjonene vi snakka med i dette arbeidet, som hadde noe forhold til fylkeskommunen.\r\n- Fylkeskommunene har også en rolle å spille for bevisstgjøring og kompetanseheving ovenfor organisasjoner med fylkesvise nettverk, som for eksempel idrettslag\r\nTilrettelegge for samarbeid og dialog: \r\n- Legge til rette for læring og erfaringsutveksling på tvers av kommuner,\r\n- Legge til rette for erfaringsutveksling mellom kommuner og frivilligheten.\r\n- Etablere nettverk på tvers mellom kommuner, og mellom kommuner og frivilligheten, som for eksempel årlige erfaringssamlinger, der fylkeskommunen tar en koordinerende rolle. Innsatsområdene er slik jeg forstår det med utgangspunkt i samarbeidet med IMDi. Det er viktig det. Men det er en hel anna verden der ute også.\r\nDette leser vi som å være i tråd med fylkeskommunens rolle som regional samfunnsutvikler og koordinator, som ansvarlig for det regionale integreringsarbeidet. Det er jo også fastsatt i forskrift til integreringsloven: $ 65 at «[…]Fylkeskommunen skal også legge til rette for samarbeid med sivilsamfunnet, herunder frivillig sektor.»\r\nMen det var allikevel noen utfordringer:\r\n- Flere vi snakka med, også folk i fylkeskommunen, pekte på at det var uklart hvordan rollen til fylkeskommunen skal forstås og hva som bør og må gjøres. Det er jo en perfekt anledning i dag til å bli enige om noe der.\r\n- Det fører også med seg uklare forventninger fra de andre i systemet. Hva forventer kommunene og IMDi at dere kan bidra med?\r\n- Lite kjennskap til FK. Når vi har snakket med frivillige organisasjoner, var det ikke mange som hadde et forhold til fylkeskommunen. Det har nok også med at vi snakket med de lokale organisasjonsleddene. Mange av kommunene var mer positive.\r\n- Dette er ikke direkte lovpålagte oppgaver. Prioritering av disse oppgavene må dermed sees opp mot prioritering av alt mulig annet som fylke kan drive med.\r\n- Både integrering og frivillighet er tverrsektorielle oppgaver. Det kommer inn mange steder, ikke nødvendigvis kun ett sted.\r\nOppsummering\r\nHvorfor frivilligheten er viktig for integrering av innvandrere? Det bidrar på mange vis til strukturell, politisk og sosial integrering.\r\nHva er problemet? For å styrke innsatsen, trenger mange frivillige organisasjoner økt kompetanse, og mer samarbeid med offentlige myndigheter, og med hverandre.\r\nHvordan løser vi det? Vi ble bedt om å utrede om et eller flere nye kompetansesenter kan dekke disse behovene. Vi konkluderte med at det ikke er hensiktsmessig med nye aktører, eller sentralisering av oppgaver, men at en bør komme langt med å utnytte kompetansen som finnes i dagens system.\r\nHva er så fylkeskommunens rolle? Det er fornuftig om fylkeskommunene tar et ansvar for å samordne kunnskapsbehov, er en pådriver og veileder for kommuner med begrenset kompetanse og kapasitet på området, sørger for å skape nettverk og møteplasser, og inkluderer frivillighetens rolle på integreringsfeltet i regionalt planarbeid. Fylkeskommunene har også en rolle å spille for bevisstgjøring og kompetanseheving ovenfor organisasjoner med fylkesvise nettverk, som for eksempel idrettslag.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-25T10:16:17+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2023-01-18-diskriminering-i-haugesund/",
    "title": "'Du får lyst til å flytte til et annet land.' Kartlegging av rasisme og diskriminering i Haugesund",
    "description": "På oppdrag fra Haugesund kommune har i2e undersøkt omfanget av rasisme og diskriminering i kommunen, samt hva som kjennetegner slike situasjoner og hvordan de oppleves..",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2023-01-18",
    "categories": [],
    "contents": "\r\nMange innvandrere og norskfødte med innvandrerforeldre i Haugesund har opplevelser med å bli diskriminert på bakgrunn av sin etnisitet eller nasjonale opprinnelse. Basert på svarene i undersøkelsen vår, anslår vi at mellom 40 og 60 prosent av personene i Haugesund med innvandrerbakgrunn har opplevd etnisk diskriminering minst én gang i løpet av de siste 12 månedene. Når de ser lengre tilbake, stiger andelen som har opplevd minst ett tilfelle av etnisk diskriminering til mellom 60 og 70 prosent. Samlet sett mener vi at en forsiktig tolkning av datagrunnlaget tilsier at omfanget av diskriminering i Haugesund kan være like stort som ellers i landet.\r\nOmfanget av rasisme og diskriminering varierer mye mellom ulike områder. Av områdene vi har undersøkt, finner vi at en er mest utsatt for negative opplevelser:\r\n- som arbeidssøker (36 prosent rapporterer om minst en opplevelse av etnisk diskriminering siste år),\r\n- på arbeidsplassen (33 prosent)\r\n- i ulike hverdagslige situasjoner, som på gata, butikken og i kollektivtrafikken (24 prosent).\r\nDeretter kommer skole og utdanning. Færre rapporterer om tilfeller av diskriminering på boligmarkedet, i kontakt med helsevesenet, NAV og politiet. De fleste som har opplevd etnisk diskriminering, har opplevd det på ett eller to av disse områdene. En liten andel – 8 prosent – melder imidlertid om opplevelser med diskriminering på fire til seks av områdene vi har undersøkt.\r\nBildet av situasjonen er sammensatt. Mens mange med innvandrerbakgrunn oppgir å ha opplevd rasisme eller diskriminering i Haugesund, er det også flere som svarer at de ikke har slike opplevelser. Flere av våre informanter understreket at Haugesund var en god by å bo i. Noen forklarte dette med at Haugesund er en mindre plass, enn for eksempel Oslo og Bergen, og at det derfor er lite rasisme her. Andre så på rasisme og diskriminering i Norge som relativt mild, sett opp mot voldelige opptøyer og lovfestede rettigheter for ulike grupper i andre deler av verden. Mange hadde også opplevd støtte fra andre haugesundere når de hadde havnet i vanskelige situasjoner.\r\nAndre igjen hadde et helt annet bilde av situasjonen i Haugesund. Disse kunne eksempelvis fortelle om rasistisk motivert mobbing på skolen og arbeidsplassen, eller vanskeligheter med å få jobb eller bolig på grunn av deres utenlandske navn. For å få et dypere inntrykk av hva som kjennetegner slike tilfeller, trekker vi frem en rekke av disse historiene i rapporten.\r\nEn kan skille mellom situasjoner som for «mottakerne» framstår som åpenbart rasistisk motiverte, og situasjoner med forskjellsbehandling som er vanskeligere å forstå. Situasjoner som oppfattes som åpenbart rasistisk motiverte, kan være å bli ropt etter på gaten eller å bli utsatt for skjellsord knyttet til hudfarge, antatt religion eller opprinnelsesland.\r\nDe fleste opplevelsene med rasisme og etnisk diskriminering som vi fikk kjennskap til, var imidlertid mindre opplagte. Det som kjennetegnet disse situasjonene, var at det var vanskelig for informantene å forstå situasjonen og definere motivet til de personene som utsatte en for forskjellsbehandling. Mange av informantene var usikre på om de ville bli behandlet på den samme måten hvis de var etnisk norske. Ville det blitt slik hvis de ikke snakket annerledes, kledde seg annerledes eller hadde en annen hudfarge?\r\nVi finner også et skille i hvordan personene håndterer situasjonene. For noen er det lett å ignorere både den åpne og den skulte diskrimineringen og rasismen. Andre, gjerne personer som har bodd i Norge i mange år, forteller om forsøk på å si ifra om opplevelsene sine. Noen situasjoner er det lett å ta tak i, mens andre er mer krevende.\r\nBlant de mest krevende situasjonene vi har fått innsikt i, er situasjoner der informantene har en relasjon til den eller de som utsetter dem for diskriminering. Det kan være kolleger, ledere og veiledere. Mens noen forteller at de har fått hjelp med å håndtere slike hendelser, eksempelvis på\r\nskolen eller arbeidsplassen, forteller andre at de har måttet stå i det alene og ikke blitt fulgt opp på tilstrekkelig vis.\r\nKonsekvensene av diskriminering og rasisme kan være alvorlige. Fra annen forskning vet vi at\r\n- diskriminering på arbeidsmarkedet kan føre til at enkelte grupper faller utenfor,\r\n- diskriminering på boligmarkedet kan gi dårligere boforhold og redusert psykisk helse,\r\n- diskriminering samlet sett kan føre til de som blir utsatt for det, trekker seg tilbake fra visse situasjoner, som sosialt liv i byen eller deltakelse i samfunnet rundt seg,\r\n- å oppleve rasisme og diskriminering kan ha negativ påvirkning på psykisk og fysisk helse (Wollscheid m.fl. 2021).\r\nNoen av informantene våre forteller historier som går i denne retningen, og at diskriminering hindrer dem fra å få et godt liv i Haugesund. Her forteller de gjerne om konkurransesituasjoner, som jobbsøking eller boligjakt, hvor de opplever å komme dårligere ut enn andre. De forteller også om den emosjonelle belastningen det å være annerledes kan gi. Noen opplever også at innsatsen de legger ned for å bli integrert, aldri vil være god nok etter enkeltes syn. De sistnevnte tilfellene kan potensielt sett føre til at følelsen av utenforskap og håpløshet blir større. Enkelte sier da at de forstår dem som holder seg utenfor arbeidslivet, eller at de kunne tenke seg å flytte ut av Haugesund og Norge.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-25T08:32:24+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2023-01-13-jobbsjansen-og-introduksjonsprogrammet/",
    "title": "Resultatforskjeller mellom Jobbsjansen og introduksjonsprogrammet",
    "description": "På oppdrag fra IMDi sammenlikna vi resultatene i Jobbsjansen og Introduksjonsprogrammet.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2023-01-13",
    "categories": [],
    "contents": "\r\nRapporten er publisert her. Her er sammendraget:\r\nDenne rapporten handler om resultatforskjellene mellom de to integrerings- og kvalifiseringsordningene Jobbsjansen og introduksjonsprogrammet. Det har tradisjonelt vært mange likhetstrekk mellom de to ordningene i både omfang, tiltaksbruk og hvilke målsetninger man har for dem som deltar. Samtidig har det vært en del forskjeller mellom deltakerne i de to ordningene, og overordnet sett kan en si at Jobbsjansen har hatt en deltakergruppe med bedre forutsetninger for å nå målene om overgang til arbeid eller utdanning. Over flere år har da også andelen deltakere som\r\noppnår overgang til arbeid eller utdanning direkte etter avsluttet deltakelse vært om lag 20 prosentpoeng høyere i Jobbsjansen.\r\nDen sentrale problemstillingen for dette prosjektet har derfor vært å undersøke hvorvidt det er reelle forskjeller i resultatoppnåelsen mellom introduksjonsprogrammet og Jobbsjansen, når man tar høyde for ulikhetene i deltakersammensetningen. I arbeidet med denne og tilstøtende problemstillinger har vi basert oss på statistiske analyser av deltaker-, kommune- og prosjektdata. Vi har også gjennomført kvalitative case-studier i flere kommuner som tilbyr både Jobbsjansen og introduksjonsprogram.\r\nVi finner gjennomgående at deltakelse i Jobbsjansen har en statistisk positiv betydning for en persons sannsynlighet for å gå over i jobb eller utdanning direkte etter fullført program. Dette gjelder selv når vi kontrollerer for deltakersammensetning, tar hensyn til kommunal kontekst og ressursforskjeller mellom ordningene. Hvor stor betydningen av Jobbsjansen er, varierer med hvilke deltakere vi snakker om, og hvilke statiske analysemetoder vi benytter. For en gjennomsnittlig «typisk» deltaker som kunne deltatt i begge ordninger, utgjør forskjellen om lag 11 prosentpoeng. Det vil si at for to personer som er helt like på egenskaper vi kan observere, så er sannsynligheten for å gå over i jobb eller utdanning etter fullført Jobbsjansen-prosjekt 11 prosentpoeng høyere enn etter fullført introduksjonsprogram.\r\nJobbsjansen har altså en betydning, men generelt finner vi at den viktigste kilden til variasjon i måloppnåelse er de enkelte individenes forutsetninger, ikke hvilken ordning man tilhører, kjennetegn ved prosjektene eller den kommunale konteksten prosjektene befinner seg i. Samtidig viser det seg at det er et handlingsrom for den enkelte kommune og prosjekt til å påvirke resultatene. Det gjelder både i introduksjonsprogrammet og i Jobbsjansen. Vi beregner bidragsindikatorer for hver enkelt kommune og hvert enkelt prosjekt, som viser at noen prosjekter oppnår resultater som er mer enn 20 prosentpoeng over det som er forventet for deres deltakergruppe. Andre oppnår resultater 20 prosentpoeng under det som er forventet. Vi ser særlig forskjeller i prosjektenes bidrag hos personer med liten eller ingen skolegang og lavere norskferdigheter. Introduksjonsprogrammene gjør det jevnt over svakere for denne gruppen, enn det man statistisk sett kunne forvente.\r\nGjennom analyser på både individ-, kommune- og prosjektnivå, gir rapporten ytterligere innsikt i hva som påvirker måloppnåelsen i de to ordningene.\r\nPå individnivået finner vi at en deltaker med gode norskferdigheter, høyt utdanningsnivå, lite fravær etc., har klart høyere sannsynlighet for å være i arbeid eller utdanning etter fullført program enn deltakere med mindre gode norskferdigheter, liten eller ingen utdanning fra før av eller høyt fravær. Vi finner ingen betydning av varigheten på programmet eller en persons botid på sannsynligheten for måloppnåelse.\r\nTiltaksbruk har også betydning. Arbeidspraksis i ordinær virksomhet bidrar tydelig til økt sannsynlighet for måloppnåelse. Det samme gjør ordinært arbeid. Det er også flere tiltak som vi finner gir lavere sannsynlighet for måloppnåelse. Eksempler er helsefremmende aktiviteter og tiltak knyttet til barn og familie. Vi poengterer i rapporten at det ikke nødvendigvis er tiltakene i seg selv som har en negativ virkning. Det kan like godt handle om at deltakerne som trenger disse tiltakene, står lenger unna arbeid og videregående utdanning enn det ellers like deltakere gjør.\r\nPå kommune- og prosjektnivå finner vi blant annet at deltakere i kommuner med høyere andel innvandrere i befolkningen har høyere sannsynlighet for måloppnåelse. Det kan tyde på at mer erfaring med integrering og innvandring i kommunene har positiv betydning. Videre finner vi at deltakere i kommuner med høyere nettoinnflytting har høyere sannsynlighet for måloppnåelse. Det kan bety at kommuner med bedre arbeidsmarked har det enklere med å få deltakere over i jobb. Vi finner også at ressurser har noe å si. Deltakere i prosjekter med høyere lønnsutgifter per deltaker har høyere sannsynlighet for overgang til arbeid eller utdanning. Tidligere forskning har vist at et begrenset antall deltakere pr rådgiver gjør det enklere å finne individuelle tilpasninger. Vi antar at dette har med kapasiteten til de ansatte å gjøre. Færre deltakere per rådgiver gir de ansatte mer tid til å følge opp deltakere, arbeidsgivere og andre samarbeidspartnere.\r\nEt gjennomgående funn i denne rapporten er at mye ligger til rette for høyere måloppnåelse i Jobbsjansen. Kommunene som har Jobbsjansen-prosjekt har en gjennomsnittlig høyere andel innvandrere og høyere netto innflytting. I tillegg er lønnsutgiftene pr. deltaker jevnt over høyere i Jobbsjansen-prosjekt enn i introduksjonsprogrammene. På individnivå har deltakerne i Jobbsjansen et gjennomsnittlig høyere norsknivå enn i introduksjonsprogrammet, bedre norskferdigheter og opprinnelsessteder som er assosiert med høyere sannsynlighet for måloppnåelse. Selv om vi ikke\r\nfinner en signifikant betydning av botid i våre analyser, er denne høyere i Jobbsjansen. Når vi snakker med ledere og programrådgivere i de to ordningene, trekkes gjerne botid frem som en viktig forklaring på resultatforskjellene.\r\nDisse faktorene bidrar til å forklare deler av forskjellene i måloppnåelse mellom de to ordningene, men forklarer ikke alt. Selv når vi kontrollerer for kommunal kontekst, økonomiske ressurser og deltakersammensetning, finner vi altså at deltakelse i Jobbsjansen fortsatt gir høyere sannsynlighet for jobb eller utdanning direkte etter avsluttet deltakelse. I rapporten trekker vi derfor frem andre forhold ved Jobbsjansen, som rammebetingelser, arbeidsmetodikk og samarbeidsrelasjoner, som mulige forklaringer.\r\nVi finner for det første at i kommunene som har både Jobbsjansen-prosjekt og introduksjonsprogram, har deltakere i Jobbsjansen høyere sannsynlighet for måloppnåelse, kontrollert for øvrige forhold. Det antyder at den kommunale konteksten er mindre viktig enn hvilke muligheter de ansatte har til å utnytte rammene de jobber innenfor. Informantene våre fra Jobbsjansen og introduksjonsprogrammet innad i samme kommune så gjerne forskjellig på mulighetene i det lokale arbeidsmarkedet. Vi tolker dette som at Jobbsjansens ressurser til å utnytte arbeidsmarkedet, knytte kontakter og samarbeide med arbeidsgivere er en viktig faktor.\r\nVidere påpeker vi at rammene for Jobbsjansen gir ordningen deltakere som står nærmere arbeidsmarkedet, enn det de gjør i introduksjonsprogrammet. Dette gjelder også utover de individuelle egenskapene som vi kontrollerer for. Et slikt eksempel som flere informanter trekker fram, er at Jobbsjansen er et frivillig tilbud, som er veldig etterspurt av deltakerne. Prosjektene har dermed enklere tilgang på de mest motiverte deltakerne. Introduksjonsprogrammet er på sin side et tilbud som deltakerne har både rett og plikt til å delta i. Man kan derfor forvente seg et litt mer blandet nivå på motivasjonen for deltakerne.\r\nVi påpeker i rapporten at det kan være problematisk å trekke en direkte linje mellom arbeidsmetodikk og samarbeidsrelasjoner for å forklare forskjellene mellom Jobbsjansen og introduksjonsprogrammet. Basert på intervju med en rekke ledere og programrådgivere i begge ordningene, kan det overordnet sett se ut som om mye gjøres likt. Men vi finner at Jobbsjansen utmerker seg ved å produsere svært gode resultater for deltakere med mindre gode forutsetninger i utgangspunktet: Både de reelle og de forventede resultatene for deltakere med høyt utdanningsnivå eller gode norskferdigheter er forholdsvis sammenlignbare mellom de to ordningene. Jobbsjansen har imidlertid langt bedre resultater hos deltakere med liten eller ingen utdanning og lavt norsknivå ved avsluttet deltakelse. Det er da interessant at bruken av ordinær arbeidspraksis er langt høyere i Jobbsjansen enn i introduksjonsprogrammet. Forskjellen i prioritering av arbeidspraksis gjelder også for deltakere med mindre gode forutsetninger. Dette er spesielt interessant fordi vi finner at deltakelse i arbeidspraksis har en signifikant positiv betydning på sannsynligheten for måloppnåelse.\r\nDet ser også ut til at Jobbsjansen klarer å ha et mer aktivt forhold til både samarbeidspartnere og potensielle arbeidsgivere for deltakerne, enn hva introduksjonsprogrammet klarer. Prosjektene med fungerende samarbeid peker på ledelsesforankring av samarbeidet, samlokalisering av enkelte\r\ntjenester, tidlig oppstart av samarbeid om konkrete deltakere og konkrete kontaktpersoner hos samarbeidspartnerne, som viktige suksessfaktorer.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-25T08:41:09+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2023-01-11-diskriminering-i-haugesund-en-presentasjon/",
    "title": "«Du får lyst til å flytte til et anna land» - en presentasjon",
    "description": "En presentasjon av kartlegginga av diskriminering i Haugesund, som jeg holdt i Haugesund i starten av januar 2023.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2023-01-11",
    "categories": [],
    "contents": "\r\nGod kveld!\r\nOppdraget vi fikk fra kommunen var å kartlegge omfanget av rasisme og diskriminering i Haugesund. Det gjør vi på to måter. For det første så finner vi ut av hvor utbredt det er med diskriminering. For det andre skal så finner ut hvordan disse situasjonene kan arte seg og hvordan de oppleves, ved å sette noen menneskelige ansikter på tallene.\r\nHvorfor er dette viktig for kommunen?\r\nDere leverer mange viktige tjenester og tilbud – på kultur, idrett og frivillighet, helse og omsorg, skole, NAV, barnevern. Opplevelser av diskriminering vil gå imot det som disse tjenestene ønsker å oppnå, og det er utfordringer som f.eks. helsetjenester eller NAV vil måtte bøte på.\r\nKommunen har et lovpålagt ansvar for å holde oversikt over faktorer som påvirker folkehelse. Opplevelse av diskriminering er en slik faktor. Kommunen har også en aktivitets- og redegjørelsesplikt etter likestilling og diskrimineringsloven. Mobbeloven for skolen er også aktuell. Det er altså snakk om et lovpålagt ansvar for å holde oversikt – og gripe inn hvis det skjer ting.\r\nEt tredje perspektiv er at kommunen er en veldig viktig arbeidsgiver. Arbeidsplassen og arbeidssøking er blant områdene hvor innvandrere melder om mest diskriminering. Det er nok ikke ønskelig for en arbeidsgiver.\r\nDette er dessverre også en veldig aktuell problemstilling. Her er noen medieoppslag fra siste halvår i fjor – en undersøkelse i Oslo, omfang av rasisme i Stavanger, Atle Antonsen-saken, Tinashe Williamson, hets av bunadsbilder…\r\noversikt over aktuelle saker fra 2022Veldig veldig kort om definisjoner, metode.\r\nEn kan bruke mye tid på å snakke om definisjoner og teori her. Vi nøyer oss med å konstatere ganske kort at det etter hvert er en enighet i fagmiljøene om hva rasisme og diskriminering er.Vi snakker hovedsakelig om rasisme som holdninger, der en person tillegges negative egenskaper på grunn av gruppemedlemskap, og det kan være gruppemedlemskap som hudfarge, religion, språk eller kultur.\r\nEtnisk diskriminering er derimot handlinger, der en behandles dårligere enn andre på grunn av hudfarge, språk eller nasjonal bakgrunn.\r\nI dette prosjektet har det vært viktig for oppdragsgiverne våre å få vite noe om hvordan det oppleves å bo i Haugesund for den enkelte. Derfor har vi vært opptatt av, å finne ut av folks egne erfaringer – har du opplevd diskriminering? Har du blitt utsatt for noe motivert av rasisme? Hvordan er hverdagen i Haugesund for deg?\r\nFor å måle det har vi gjennomført en spørreundersøkelse blant innvandrere og norskfødte med innvandrerforeldre i Haugesund. Vi har gjennomført undersøkelsen slik at den skal være representativ. Det vil si at tallene vi bruker, sier noe om forekomsten av diskriminering i gruppa som helhet.\r\nVi har konsentrert oss om de som har bodd i Norge i minst to år, og som har bakgrunn fra land i Afrika, Asia, Latin-Amerika og Øst-Europa. Det betyr at Norden, Vest-Europa og Nord-Amerika, Australia er holdt utenfor.\r\nVi har også gjennomført 24 intervjuer med folk, en god del av dem her på biblioteket i Haugesund, men også en del på telefon.\r\nHvor mye diskriminering er det, totalt sett?\r\nNår vi ser på datamaterialet vårt samlet sett, så kan vi gi et tall på hvor stor andel som i løpet av det siste året, har opplevd minst ett tilfelle de oppfatter som etnisk diskriminering, på minst ett av områdene vi har spurt om. Altså blitt behandlet annerledes enn andre på arbeidsplassen eller på gata, eller et annet område, fordi de har en anna hudfarge, snakker et anna språk, kommer fra et anna land.\r\nHvor stor andel av innvandrerne og norskfødte med innvandrerbefolkningen i Haugesund tror dere har opplevd dette?\r\n48 prosent har opplevd å bli behandlet dårligere enn andre på grunn av etnisitet eller nasjonal opprinnelse minst en gang i løpet av de siste 12 månedene, på minst ett av områdene vi spør om.\r\nNår vi ber folk tenke lenger tilbake på opplevelser i Haugesund, så øker andelen. Mellom 60 og 70 prosent har opplevd minst et tilfelle av diskriminering på disse områdene.\r\nHvordan er dette, sammenliknet med ellers i landet? Sammenlikningen er ikke helt rett frem, ettersom en i nasjonale undersøkelser har spurt om færre områder, andre typer diskriminering, andre utvalgte grupper, og så videre.\r\nEtter hva vi kan se, er en forsiktig tolkning av datagrunnlaget at omfanget av diskriminering er minst like stort i Haugesund som ellers i landet.\r\nVi spør om en rekke områder - vi spør om diskriminering som arbeidssøker, på arbeidsplassen, i skole og utdanning, på boligmarkedet, i møte med fire ulike offentlige tjenester, og på andre hverdagsarenaer som på bussen og butikken.\r\nDe fleste som har opplevelser med diskriminering, har opplevd det på ett eller to av områdene. Det er en liten andel - 8 prosent - som melder om at de har opplevd minst ett tilfelle av diskriminering på fire til seks av områdene.\r\nsvar på alle diskrimineringsspørsmåleneanslag på omfang av diskriminering med konfidensintervallArbeidssøker\r\n36 prosent av de som har søkt jobb det siste året, mener de har blitt etnisk diskriminert i en jobbsøker-prosess. Altså at de ikke har fått jobben, selv om de var kvalifisert, på grunn av sin etnisitet eller nasjonale bakgrunn.\r\nHer er det noen tall jeg ikke viser: det er jo da 64 prosent av de som har søkt jobb, som har svart noe annet. Det er en andel – 19 prosent her – som oppgir at de ikke har blitt diskriminert når de har søkt arbeid. Og så er det ulike typer usikkerhet på de resterende.\r\nNår vi har intervjuet folk, så er dette med å søke arbeid noe alle har hatt erfaring med. Flere har et inntrykk av at de med utenlandske navn og utseende, møtes med fordommer om dårlig norsk og manglende kvalifikasjoner. Samtidig forteller de da at personer med tilsvarende kvalifikasjoner, men etnisk norsk bakgrunn, får jobben i stedet. For noen har dette skjedd en gang, mens andre har opplevd det flere ganger.\r\nEt aktuelt sitat her: “Jeg kjenner flere fra hjemlandet mitt som bytter navn bare for å få jobb. Det bør ikke være nødvendig. Men når jeg har et muslimsk navn på min CV, ringer de aldri tilbake.”\r\nSærlig tre informanter (alle i begynnelsen av 20-årene) fortalte at de opplevde at deres norske venner med tilsvarende kvalifikasjoner fikk jobb, men ikke dem selv.\r\nVi vet ikke om det faktisk var diskriminering. Dette er også informantene opptatt av - de har jo ikke innsyn i nøyaktig hva som skjedde. Men når det skjer flere ganger, og de kjenner til dem som får jobben og deres kvalifikasjoner, da sprer det seg et inntrykk. Vi veit også fra anna forskning at sannsynligheten for å bli innkalt til jobbintervju blir redusert med 25 prosent, hvis du har et utenlandskklingende navn - men ellers er helt lik.\r\nArbeidshverdagen\r\n33 prosent av de som var i jobb i løpet av det siste året, har opplevd diskriminering på arbeidsplassen. Vi har også spurt alle om hvor ofte dette forekommer. Omtrent halvparten sier at dette forekommer månedlig eller oftere.\r\nDette er i tråd med annen forskning. Det er etter hvert svært godt dokument at diskriminering forekommer i arbeidsmarkedet.\r\nFra informantene våre får vi en forståelse av at diskriminering på arbeidsplassen kommer i mange former og med ulik styrke.\r\nVi har fått høre om sporadiske nedsettende kommentarer fra kunder eller brukere. Det kan handle om tydelige rasistiske utsagn, kanskje fra pasienten på helseinstitusjonen, passasjeren i taxien eller kunden på butikken. Mange sier at dette ikke påvirker dem noe særlig. Noen forteller at det er alt for vanlig til at de legger merke til det, mens andre at det er leit, men de får god støtte fra sjefen og kolleger.\r\nAndre historier vi har fått fortalt fra arbeidshverdagen, har tydelig gått sterkt inn på informantene. Det gjelder særlig når diskrimineringa kommer fra kolleger eller ledere.\r\nNoen forteller at det skjer litt indirekte, ved at de ikke blir tatt like mye på alvor som andre kolleger. Innspill og forslag blir ikke tatt seriøst, før de kommer fra noen med etnisk norsk bakgrunn. For andre er det mer direkte. En person vi snakka med sa det slik:\r\n“Jeg ser at assistenter og helsefagarbeidere får kommentarer [fra kolleger]. De har utdanningen og er kvalifisert for den jobben de skal gjøre, men fordi de snakker annerledes, får de plutselig kommentarer på at de snakker dårlig, gjør jobben dårlig og ikke kan jobben. Det viktigste burde vel være å gjøre jobben, ikke det å snakke som nordmenn?”\r\nDenne informanten fortalte om hvordan tilbakemeldinger på språk fra kolleger, slås sammen med tilbakemeldinger om innsats og kvalifikasjoner. Flere av informantene våre snakket om at de hadde opplevd dette. Først hadde de forsøkt å jobbe hardere, gjøre ting riktig, for å bevise at de kunne jobben. De har da gjerne etter hvert kommet til at det ikke er mulig å bevise at de er dyktige nok. Mange har vært veldig opptatt av å vise fram bevis på at de er flinke arbeidstakere, og tatt med dokumentasjon på det til oss i intervjuene.\r\nVi har også fått historier fra personer som opplever å ha kollegaer som alltid kommer med nedsettende kommentarer om religion og andre ting ved seg. De har forsøkt å ta det opp med nærmeste leder og verneombud, men har opplevd prosessen med megling som veldig vanskelig. Det blir fort ord mot ord.\r\nSkole og utdanning\r\nBlant de som har gått på skole i Haugesund det siste året (både videregående og voksenopplæring er mulig her - husk, vi har spurt alle fra 16 år og oppover), så har 22 prosent opplevd etnisk diskriminering. Av disse, sier over halvparten at det forekommer månedlig eller oftere.\r\nVi har dessverre fått inn en del eksempler gjennom intervjuene våre. Noen informanter forteller om situasjoner med medelever i form av verbale uttrykk; nedsettende kallenavn og kommentarer. Vi har også snakket med informanter som forteller om hvordan rasistisk motivert mobbing ikke blir tatt på alvor av de ansatte i skolen.\r\nFra voksenpersoner i skolen, som lærere og andre ansatte, er slike opplevelser ikke like direkte, men heller opplevelsen av at den voksne har et negativt bilde av deg basert på antakelser og fordommer om innvandrere. Vårt inntrykk fra intervjuene er at særlig elever med muslimsk bakgrunn er utsatt for slik diskriminering.\r\nVi har blant annet dette sitatet: “I en periode hadde jeg det ganske dårlig og jeg følte meg nede. De ansatte på skolen merket det og kalte meg inn til en samtale. Jeg forventet at vi skulle snakke om skoleåret og hvordan vi fremover kunne gjøre det bedre, men det eneste vi snakket om var hvorvidt jeg kjente noen som var med i IS. Vedkommende spurte om jeg hadde holdt i våpen og om jeg hadde skutt før. Det var absolutt uakseptabelt.”\r\nTilfeller som dette kan ha store konsekvenser for den enkelte. Ingen skal behøve å bli utsatt for mobbing. Vi veit fra anna forskning at det er en sammenheng mellom trivsel og skoleprestasjoner. En annen informant fortalte at vedkommende hadde seg nødt til å bytte skole og fullføre utdanningen sin i en annen by, på grunn av rasistisk motivert mobbing fra medelever. Det er ganske drastisk i et ungt menneskes liv.\r\nMøte med offentlige tjenester\r\nDe offentlige tjenestene vi har spurt om, er NAV, Helsevesenet, Barnevernet og Politiet. Barnevernet er det rett og slett for få personer i utvalget vårt som har vært i kontakt med det siste året. Det er egentlig som forventa. Det er fortsatt noe færre har kontakt med enn f.eks. helsevesenet - som veldig mange har vært i kontakt med.\r\nRelativt til arbeid og skole, så er det langt lavere andeler som melder om opplevelser med diskriminering her. Totalt sett er det 17 prosent av alle de spurte som melder om en opplevelse i møte med minst en av disse, det siste året.\r\nPoliti: 22 prosent av de som har vært i kontakt med politiet det siste året, oppgir at de har opplevd etnisk diskriminering.\r\nNAV: 15 prosent.\r\nHelsevesenet: 9 prosent.\r\nBlant de vi intervjua, så var det få som hadde opplevd diskriminering eller rasisme i møte med offentlige tjenester.\r\nDet er et par personer som har erfaringer med møte med politiet: “Før kunne jeg ble stoppet av [politiet]. Jeg vet ikke om jeg vil kalle det for rasisme. Men det var når jeg var med mine utenlandske venner, ikke norske, at jeg ble stoppet. Men det var ikke noe alvorlig. Bare kontrollspørsmål. (…) [jeg] opplever at det er pga. hudfarge og bakgrunn.”\r\nDet var også en informant som fortalte at hun hadde fått spørsmål om «hvorfor hun ikke dro tilbake til landet sitt», når hun ønsket å melde seg som arbeidsledig. Det oppfattet hun som upassende.\r\nEllers var mange av informantene våre opptatt av å snakke om hvor godt mye fungerte, og at hvis de hadde trengt hjelp eller støtte, så hadde de fått det. Her ser vi at noen av personene med fluktbakgrunn, trekker paralleller med hvordan de ble behandlet av offentlige myndigheter mens de var på flukt.\r\nMen vi ser jo av tallene at det definitivt er noen som har slike erfaringer.\r\nOppsummering - og konsekvenser\r\nSå oppsummert: Det er en god del haugesundere som opplever etnisk diskriminering, på ulike områder – 48 prosent har en opplevelse i løpet av det siste året. Det gjør at problemet er minst like vanlig i Haugesund, som ellers i landet. Særlig på arbeidsplassen og som arbeidssøker – men også innen skole og utdanning, og i møte med politiet.\r\nNoen situasjoner fremstår åpenbart rasistisk motiverte for dem som opplever det, andre er skjulte og vanskelige å gripe tak i.\r\nNoen er komfortable med å si ifra, mens andre ikke er det.\r\nNoen opplever god støtte fra kolleger eller tilfeldig forbipasserende, men langt ifra alle.\r\nVi veit fra anna forskning at diskriminering har konsekvenser. Det kan føre til at en ikke får jobb, noe som er alvorlig. Det kan gi dårligere boforhold, noe som ikke er bra. Det kan gi tilbaketrekning fra noen områder, som sosialt liv i byen eller deltakelse i frivillige organisasjoner. Det kan også påvirke fysisk og psykisk helse.\r\nNoen av informantene våre forteller historier som går i denne retningen. Hvordan diskriminering hindrer dem fra å få et godt liv i Haugesund. Her forteller de gjerne om konkurransesituasjoner, som jobbsøking eller boligjakt, hvor de opplever å komme dårligere ut enn andre. Noen opplever også at innsatsen de legger ned for å bli integrert, aldri vil være god nok etter enkeltes syn. Enkelte sier da at de forstår dem som holder seg utenfor arbeidslivet, eller at de kunne tenke seg å flytte ut av Haugesund og Norge.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-25T20:56:19+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2023-01-02-tre-integreringstips-til-kommunene/",
    "title": "Integrering: Tre ting kommunene bør gjøre",
    "description": "Vi spurte 50 organisasjoner om hva de trenger for å styrke sin innsats for integrering. De aller fleste ønsker mer samarbeid med sin kommune. Her er tre av tipsene vi fikk..",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2023-01-02",
    "categories": [],
    "contents": "\r\nInnlegg publisert i Kommunal rapport 2. januar.\r\nFrivilligheten spiller en viktig rolle for integrering. Ikke minst har flyktningstrømmene fra Ukraina og Syria vist hvor viktig frivillighetens tilbud er.\r\nDe frivillige hjelper enkeltindivider gjennom tilbud som språkkafeer, besøksvenner og matutdeling. De har også en viktig integrerende funksjon som møteplass i lokalsamfunnet. Både fotballklubben, turforeninga, bygdekvinnelaget og alle de andre små og store organisasjonene bidrar til å skape samhold og bygge bro mellom innbyggerne i kommunen.\r\nI året som gikk, fikk vi mulighet til å intervjue 50 organisasjoner om deres behov for kompetanse og samarbeid på integreringsfeltet, i forbindelse med et oppdrag for Integrerings- og mangfoldsdirektoratet (IMDi).\r\nPå spørsmål om hva de trenger for å kunne gjøre enda mer for integreringen, peker de aller fleste på sin kommune. Her er tre ting de fortalte oss:\r\n1) Vær tilgjengelig.\r\nSom en entusiastisk turlagsleder fortalte oss, begynner mange frivillige sitt virke først når de kommer hjem fra dagjobben. Hvis kommunen din inviterer til møteplasser for frivilligheten eller informasjonsmøter om tilskuddsordninger, bør det skje utenfor ordinær arbeidstid dersom kommunen ønsker å inkludere organisasjoner uten fast ansatte.\r\nDette er kanskje lettere sagt enn gjort. Kommunen må følge regler for arbeidstid, og kommunalt ansatte har også krav på fritid. Forskning har imidlertid funnet at en på denne måten kan få enda flere organisasjoner med på laget.\r\n2) Åpne opp kommunale tjenester som rekrutteringsarenaer.\r\nFlere organisasjoner etterlyste en mulighet til å rekruttere deltakere til sine aktiviteter og frivillige til sin organisasjon på kommunale møteplasser. Det gjelder barne- og ungdomsskoler, voksenopplæring, flyktningmottak, helsestasjoner, bibliotek og andre steder hvor folk møtes lokalt.\r\nFlere foreninger vi snakket med, pekte på at de ellers gjerne rekrutterer i sine vante kanaler. «Hvis vi skal treffe og bli kjent med noen vi ellers ikke ville truffet, så må vi nesten komme inn en plass der alle er. Og det er jo gjerne på skolene», fikk vi høre.\r\nÅ sørge for lik praksis er lurt. Enkelte organisasjoner stilte spørsmål som: «Hvorfor får den andre organisasjonen komme til den skolen, når ikke vi får? Hvorfor har kommunen en avtale med den store klubben, og ikke oss?»\r\n3) Del av kommunens kompetanse.\r\nMange organisasjoner som har få medlemmer med innvandrerbakgrunn, sitter med en følelse av at de skulle «visst mer». Noen peker på at de tidligere har prøvd ulike tiltak for å rekruttere personer med innvandrerbakgrunn til organisasjonen sin, men ikke lykkes med å holde på medlemmer og frivillige. Kanskje dukket ingen opp på den organiserte turen, og det var ingen som kom på mer enn én øving i korpset.\r\nHer tror vi at mange ansatte i kommunene har god innsikt i relevante kulturelle forskjeller. Mange kan nok også ha mer innsikt i ulike barrierer som noen innvandrerfamilier står overfor, som kan hindre deltakelse. Flere organisasjoner vi snakket med, hadde gode erfaringer med årlige seminarer med ansatte i flyktningtjenesten og deres nettverk. Dette kan særlig være viktig for frivillige organisasjoner som jobber med barn og unge.\r\nKanskje kommunen også har ordninger for gratis lån av utstyr eller fritidskortordninger som organisasjonene kunne kjent bedre til?\r\nMange mindre og nystartede organisasjoner, særlig minoritetsorganisasjoner, fortalte også at de trengte mer en-til-en-veiledning i søknadsprosesser. Når midlene blir knappe, er det gjerne de små organisasjonene som kanskje sliter litt med språket, som taper i konkurransen mot mer etablerte aktører med ansatte.\r\nDet kan være krevende å tilby organisasjonene direkte oppfølging, særlig hvis det er en språkbarriere der. Samtidig vet vi at for hver ildsjel en kan gi en god innføring i søknadsskriving, vil kompetansen spres videre.\r\nDet frivilligheten ønsker seg fra kommunen for å styrke innsatsen på integreringsfeltet, er tilgjengelighet, rekrutteringsarenaer og kompetansedeling. Selv om Frivillighetens år 2022 er omme, er frivillighetens innsats like viktig neste år – ikke minst på integreringsfeltet.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-25T09:53:32+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-11-14-frivillige-organisasjoner-og-integrering-del-2/",
    "title": "Frivillige organisasjoner og integrering. Sluttrapport fra utredning av kompetansesenter for frivillig innsats.",
    "description": "Frivillig sektor gjør i dag en stor innsats for integreringen av innvandrere og deres barn inn i det norske samfunnet. Offentlige myndigheter har et ønske om å legge til rette for at frivilligheten kan fortsette og styrke dette engasjementet. Ideas2evidence og Agenda Kaupang har utreda dette.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2022-11-14",
    "categories": [],
    "contents": "\r\nFrivillig sektor gjør i dag en stor innsats for integreringen av innvandrere og deres barn inn i det norske samfunnet. Offentlige myndigheter har et ønske om å legge til rette for at frivilligheten kan fortsette og styrke dette engasjementet. Denne rapporten ser derfor nærmere på tre problemstillinger:\r\nHvilke behov for kompetanse og samarbeid har frivillige organisasjoner på dette området?\r\nHvordan kan ulike typer kompetansesentre og kompetansemiljø dekke disse behovene?\r\nHvordan kan IMDi tilrettelegge for bedre samarbeid?\r\nHele rapporten er publisert her.\r\nFrivilligheten trenger mer samarbeid og økt kompetanse\r\nDen første problemstillingen er hvilken kompetanse og form for samarbeid som frivillige organisasjoner har behov for fra offentlige myndigheter, for å kunne styrke regionalt og lokalt integreringsarbeid. Vi finner blant annet at:\r\nMange organisasjoner har et behov for og ønske om mer samarbeid med det offentlige, gjerne kommunen. Organisasjonene vi har snakket med, peker på at de trenger mer dialog, og at kommunen tar ansvar for samordning, rekrutteringsarenaer og ulike former for møteplasser. Det er et gjennomgående ønske om at samarbeidet skjer på frivillighetens premisser, med møter og arrangementer på tidspunkt som passer frivillige. Særlig minoritetsorganisasjoner opplever seg som uutnyttet ressurs i integreringsarbeidet, som lokale myndigheter gjerne må bruke mer aktivt.\r\nNår det kommer til kompetanse, ser vi at flere organisasjoner trenger bevisstgjøring på hvilken rolle de faktisk kan spille for inkludering i lokalsamfunnet. En rekke organisasjoner melder om at de trenger kompetanse på rekruttering, og at de sliter med å rekruttere og beholde personer med innvandrerbakgrunn. Dette ser ut til å være nært beslektet med det som med ulike ord beskrives som inkluderingskompetanse eller kulturforståelse. Flere organisasjoner med få tillitsvalgte, frivillige og deltakere med innvandrerbakgrunn ønsker seg dette. De har et behov for å forstå målgruppen for organisasjonen bedre, og kunne legge til rette for å sikre like muligheter til deltakelse.\r\nDagens kompetansemiljøer kan dekke behovene\r\nDen andre problemstillingen vi ser på, er hvilke former for kompetansesentre og kompetansemiljø som kan dekke behovene til frivillige organisasjoner, og hva som er fordelene og ulempene ved disse. Vi vurderer ulike løsninger for kompetansesentre og kompetansemiljø med utgangspunkt i de aktørene som har ansvar og oppgaver på feltet i dag. Det vil si IMDi, fylkeskommunen, kommunen, frivilligheten og relevante forskningsmiljøer.\r\nBehovene for kompetanse og samarbeid er svært mangfoldige, og bør etter vår vurdering adresseres av flere enn en aktør, og på mer enn ett forvaltningsnivå. Vår utredning indikerer videre at det ikke er behov for å etablere nye kompetansesenter. Det er allerede mange involverte aktører på dette tverrsektorielle feltet. Aktørene har i mange tilfeller allerede har et tilbud som kan dekke behovene til frivilligheten, og kan betraktes som kompetansemiljøer. Flere nye aktører vil kunne gjøre situasjonen ytterligere uoversiktlig. I stedet bør en benytte kompetansen som finnes i systemet allerede, hos frivilligheten selv, kommunene, fylkeskommunene og IMDi.\r\nLokalt er kommunen den relevante aktøren for å dekke mange av behovene. Både når det gjelder behov knyttet til samarbeid og kompetanse på søknader og organisasjonsdrift står kommunene i mange tilfeller nærmest å kunne dekke behovene.\r\nRegionalt bør fylkeskommunene ta en rolle som pådriver og veileder for kommuner med begrenset kompetanse og kapasitet på området, sørger for å skape nettverk og møteplasser, og inkluderer frivillighetens rolle på integreringsfeltet i regionalt planarbeid. Fylkeskommunene har også en rolle å spille for bevisstgjøring og kompetanseheving ovenfor organisasjoner med fylkesvise nettverk, som for eksempel idrettslag.\r\nNasjonalt er vår vurdering at det er mest hensiktsmessig om IMDi videreutvikler sin rolle som kompetansesenter på feltet. De skisserte behovene knyttet til kunnskapsutvikling og -formidling er i tråd med det ansvaret IMDi allerede har.\r\nDet er behov for systematisk oversikt over virkemiddelbruken og mer koordinert innsats på lokalt, regionalt og nasjonalt nivå knyttet til kunnskapsutvikling, tilbud på kompetanseutvikling og formidling, samt tilrettelegging for samarbeid og dialog. Det er naturlig å peke på IMDi som en mulig koordinerende aktør, i kraft av sin rolle som et nasjonalt kompetansesenter på området.\r\nIMDi har en rekke tilgjengelige virkemidler for samarbeid, men må prioritere arbeidet\r\nTil slutt har vi sett på hvordan IMDi, som forvaltningsorgan og nasjonalt kompetansesenter med ansvar for integreringsfeltet, kan tilrettelegge for bedre samarbeid mellom offentlige myndigheter og frivillige organisasjoner i nasjonalt og lokalt integreringsarbeid.\r\nIMDi forvalter i dag en rekke pedagogiske og økonomiske virkemidler som er egnet til å tilrettelegge for bedre samarbeid mellom offentlige myndigheter og frivillige organisasjoner i nasjonalt og lokalt integreringsarbeid. Vi har ikke gjort en helhetlig evaluering av hvorvidt og hvordan alle virkemidlene fungerer, men ser på generelt grunnlag at IMDi bl.a. bør:\r\nSammen med fylkeskommunene, ta en aktiv rolle for å tydeliggjøre fylkeskommunes rolle på feltet og legge til rette for at fylkeskommunene videreutvikles til regionale kompetansemiljøer. På denne måten kan de støtte kommuner med begrenset kunnskap og kompetanse på integrering og frivillighet.\r\nFortløpende vurdere om tilskuddsordningene og tilskuddssystemet som helhet fungerer etter hensikten, for eksempel om ordningene legger til rette for bedre samarbeid og samhandling mellom frivilligheten og mellom frivilligheten og offentlige aktører.\r\nVurdere en gjennomgang av relevante tilskuddsordninger overfor frivillige organisasjoner, frivilligsentraler, kommuner og fylkeskommuner, med tanke på om det kan gjøres justeringer for å fremme aktiviteter knytta til integrering av innvandrere.\r\nVurdere nærmere hvordan det kan legges til rette for å ivareta dialogen med organisasjoner som ikke har intensjonsavtale, særlig små og nyetablerte organisasjoner.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-25T08:25:04+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-11-07-frivillige-organisasjoner-og-integrering-del-1/",
    "title": "Frivillige organisasjoner og integrering: Kartlegging av behov for kompetanse og samarbeid",
    "description": "ideas2evidence har i samarbeid med Agenda Kaupang utredet en mulig etablering av kompetansesenter for frivillig innsats på integreringsfeltet, på oppdrag fra IMDi. I delrapport 1 så vi nærmere på hvilke behov frivilligheten har.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2022-11-07",
    "categories": [],
    "contents": "\r\nFrivillig sektor gjør i dag en stor innsats for integreringen av innvandrere og deres barn inn i det norske samfunnet. Hvis en skal styrke frivillig innsats på integreringsfeltet ytterligere, er det behov for å styrke frivillige organisasjoners kompetanse. Det er også behov for å legge bedre til rette for samarbeid dem imellom og med offentlige myndigheter.\r\nVi ser at en del medlemsrettede majoritetsorganisasjoner, som f.eks. idrettslag, korps og turlag, trenger økt bevissthet om hvilken rolle de kan spille som inkluderingsarena. De som har en slik bevissthet, etterspør kompetanseheving på hvordan de kan rekruttere og legge til rette for inkludering av flere med innvandrerbakgrunn i sin organisasjon. Samarbeidsbehovene for disse organisasjonene er ofte knyttet til rekruttering, både for å få den kompetanse de har behov for, men også for å få tilgang til rekrutteringsarenaer som skoler og voksenopplæringen. Det er også en del av disse organisasjonene som opplever at de mangler det de selv beskriver som kompetanse på integrering, inkludering eller kulturforståelse, noe som kanskje bidrar til en usikkerhet i møte med andre med annen kulturbakgrunn.\r\nI tråd med tidligere forskning viser også vår kartlegging at mange minoritetsorganisasjoner har behov for kompetanse i organisasjonsdrift og søknadsskriving. Flere av disse organisasjonene gir også uttrykk for at de trenger mer kunnskap om norsk forvaltning, og handlingsløyper, slik at de kan sende sine brukere til riktig instans i systemet, særlig i tidskritiske krisesituasjoner.\r\nNår det gjelder samarbeid med det offentlige, ønsker disse organisasjonene seg tilgang på faste lokaler. De opplever også at de sitter på viktig kompetanse, at de er en i stor grad uutnyttet ressurs i kommunenes integreringsarbeid, og flere uttrykker at de ønsker å bidra mer. Mange har fått mersmak på samarbeid med kommunen under koronapandemien.\r\nEn del av de samfunnsrettede majoritetsorganisasjonene som kan kalles integreringsaktører, som har faste ansatte, og som gjerne er lokallag av nasjonale organisasjoner, opplever selv at de har relativt god kompetanse. De oppgir også at de har tilgang på relevante kurs og kompetansehevingsmuligheter. Dersom noen skulle fått kompetanseheving her, er det gjerne de frivillige i disse organisasjonene. Da dreier det seg f.eks. om relevant integreringsfaglig kompetanse eller kulturkompetanse. Samtidig er organisasjonene skeptiske til å skulle kreve for mye av sine frivillige på områder som kan oppfattes som utenfor hovedformålet til organisasjonen. En del av disse organisasjonene inngår gjerne allerede i samarbeid med det offentlige, og ønsker seg samarbeid med andre frivillige organisasjoner for å øke egen kapasitet.\r\nMange organisasjoner ønsker at det offentlige tar mer ansvar for å legge til rette for kontakt, både organisasjonene imellom, og mellom organisasjonene og det offentlige. Noen ønsker seg oppdaterte registre eller oversikter over organisasjoner, og mange ønsker seg møteplasser.\r\nSamtidig er organisasjonene opptatt av at samarbeid må skje på frivillighetens premisser: det må være tidseffektivt, skje utenfor ordinær arbeidstid, og være tematisk relevant for organisasjonene.\r\nLøsninger for kompetanse -og samarbeidsbehovene er tema for delrapport 2. Inntrykket fra intervjuene er imidlertid at en del av kompetanse- og samarbeidsbehovene bør løses lokalt. Særlig ønsker mange av minoritetsorganisasjonene seg et kontor de kan besøke, hvor de kan møte folk ansikt til ansikt. Andre behov kan la seg skalere opp til regionalt eller nasjonalt nivå.\r\nRapporten er publisert her.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-25T08:18:50+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-04-09-dashboard-for-age-of-empires-2/",
    "title": "Dashboard for Age of Empires 2",
    "description": "Hvordan kikke nærmere på litt for mange tap i Age of Empires 2?.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2022-04-09",
    "categories": [],
    "contents": "\r\nGjennom pandemien har jeg gjennoppdaga et dataspill fra 1999: Age of Empires 2. Mens jeg i 1999 var mest opptatt av å kryste kampanjene, har jeg nå funnet ut at flerspiller-delen også er ganske gøy. En slags kombinasjon av hjernedød multitasking (“trykk på alle disse knappene samtidig for å holde imperiet i gang”), og fekte-aktig taktikk (“jeg har stein - du har papir - jeg bygger saks - gaa, stein i basen min”). Det er stas.\r\nDet som også er stas, er alle dataene en kan hente ut av spillene en har spilt. Ved hjelp av sider som aoe2.net og aoe2insights.com kan en få ut masse informasjon om spillene en har spilt.\r\nDatahenteflyten følger et kjent mønster: jeg skriver ned ID-ene til spillene laget mitt har spilt, og så slår jeg opp informasjon om spillene via API-ene til nettsidene. Mens aoe2.net gir informasjon om spillernes ELO-rating og resultatet av matchen, gir aoe2insights veldig detaljert informasjon om sivilisasjoner, handlinger per minutt, tidspunkt når en oppgraderer sivilisasjonen sin, og så videre.\r\nFor å visualisere dette, tok jeg i bruk Flexdashboard-pakken - en interessant og temmelig enkel pakke for å lage dashboard ut av enkel markdown-syntaks. Ta en kikk!\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-25T07:55:08+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-01-30-nar-er-det-trygt-a-plante-stiklinger-ute/",
    "title": "Når er det trygt å plante stiklinger ute?",
    "description": "En kikk på dataene for å finne ut av når det offisielt er trygt å plante ut planter her i Bergen, sammenligna med Nes på Hedmarken. Det avhenger selvsagt av hvor risikovillig du er - men våren kommer først vestpå",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2022-03-05",
    "categories": [],
    "contents": "\r\nHva handler dette om? En kikk på dataene for å finne ut av når det offisielt er trygt å plante ut planter her i Bergen, sammenligna med Nes på Hedmarken. Det avhenger selvsagt av hvor risikovillig du er - men våren kommer først vestpå!\r\nVåren kommer - snart? Akkurat nå føles det litt som å vente på bussen i Oslo en kald vinterdag mens Ruters sanntidssystem var under utprøving: alt du fikk beskjed om var “snart”. Lenge. Heldigvis har vi data til å redde dagen.\r\nDette er basert på Jan Knappes kikk på Eisheilligen-dagene i Tyskland, fra 12. - 15. mai. Nå er vi jo betraktelig mindre katolske her i Norge, og har etter hva jeg kan se ingen liknende helgendager på primstaven. Men en vanlig huskeregel på Østlandet har vært 17. mai - ikke plant ut noe før dette!\r\nDette er selvsagt langt mer komplisert - som f.eks. bloggen moseplassen gjør rede for, avhenger det av hva du skal plante, vind- og lysforhold i tillegg til temperatur, og gjerne en periode med tilvenning også.\r\nMen allikevel! La oss forenkle ting for folk med enkle tallhoder og lite grønne fingre. Hva skal vi gjøre?\r\nLaste ned og importere historiske værdata fra Norsk klimaservicesenter\r\nFinne datoen\r\nLage en modell for siste dag med minusgrader (med en logit-modell)\r\nLage prediksjoner for når det vil være (hvor) trygt å plante utendørs.\r\n\r\n\r\n#biblioteker\r\nlibrary(tidyverse)\r\nlibrary(lubridate)\r\nlibrary(here)\r\nlibrary(padr)\r\nlibrary(gt)\r\n\r\n#settings\r\n\r\nold = theme_set(theme_minimal())\r\n\r\n\r\nVærdata for Bergen\r\nMeteorologisk institutt (MET) legger ut temperaturdata på sin portal seklima.met.no. Herifra er det mulig å laste ned mindre dataserier. Ut ifra stasjonsoversikten finner jeg 6 stasjoner i Bergensområdet:\r\nPleiestiftelsen - i drift 1895 - 1940,\r\nFredriksberg 1904 - 1985,\r\nSandsli 504090 1982 - 2001,\r\nSandsli 504080 1983 - nå,\r\nFlorida 1949 - nå,\r\nFlorida (UiB) 2003 - nå.\r\nI første omgang tar jeg data fra Florida-stasjonen (id SN50540) fra 1957 til i dag - dette gir noe lengde på tidsserien, og er ikke alt for langt unna der vi bor.\r\nSom sammenlikningsgrunnlag henter jeg også data fra Kise På Hedmark (stasjonsid SN12550), som har data fra 1951 til i dag. Målet med det er å kunne skryte til venner og kjente om hvor mye tidligere våren begynner her på vestlandet. En nobelt mål! Jeg begynner dataserien også derifra i 1957.\r\nHer innfører vi også en mulig feilkilde: Temperaturen er forskjellig to meter over bakken (hvor temperaturmålingene gjøres), og på bakkenivå (der plantene befinner seg), noe denne artikkelen på yr.no) påpeker.\r\nJeg velger å laste ned minimumstemperatur pr. døgn for første halvår (fram til og med 1. juli) for perioden 1957-2021. Så lager jeg noen varianter av dato-variabelen (år, dag), og en variabel som indikerer om dagen var en frostdag:\r\n\r\n\r\ndf <- read_delim(\"data/table.csv\",\r\n                    delim = \";\", escape_double = FALSE, \r\n                    col_types = cols(`Tid(norsk normaltid)` = col_date(format = \"%d.%m.%Y\")),\r\n                    locale = locale(decimal_mark = \",\", grouping_mark = \"|\"),\r\n                    trim_ws = TRUE) %>%\r\n  rename(sted = 1, stasjonsid = 2, dato = 3, minimumstemperatur = 4)\r\n\r\ndf = mutate(df,\r\n            frost = ifelse(minimumstemperatur < 0, TRUE, FALSE),\r\n            år = year(dato),\r\n            dagnr = yday(dato),\r\n            dag_måned = format(dato, \"%d.%b\")\r\n            )\r\n\r\nglimpse(df)\r\n\r\nRows: 22,234\r\nColumns: 8\r\n$ sted               <chr> \"Kise Pa Hedmark\", \"Kise Pa Hedmark\", \"Ki…\r\n$ stasjonsid         <chr> \"SN12550\", \"SN12550\", \"SN12550\", \"SN12550…\r\n$ dato               <date> 1957-01-01, 1957-01-02, 1957-01-03, 1957…\r\n$ minimumstemperatur <dbl> -6.3, -9.6, -13.0, -12.0, -5.0, -2.6, -7.…\r\n$ frost              <lgl> TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,…\r\n$ år                 <dbl> 1957, 1957, 1957, 1957, 1957, 1957, 1957,…\r\n$ dagnr              <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13…\r\n$ dag_måned          <chr> \"01.jan\", \"02.jan\", \"03.jan\", \"04.jan\", \"…\r\n\r\nDataene er komplette, og har kun med en NA på siste linja, der det ligger en beskjed om at “Data er gyldig per 01.02.2022 (CC BY 4.0), Meteorologisk institutt (MET)”. Den linja er viktig, men kan fjernes.\r\nDermed lar det seg lett gjøre å identifisere dagene som er de siste frostdagene på hvert sted, hvert år:\r\n\r\n\r\ndf_siste_frostdager = group_by(df, sted, år) %>%\r\n  filter(frost == TRUE) %>%\r\n  filter(dagnr == max(dagnr)) %>%\r\n  mutate(dag_måned = as.Date(dagnr, origin = \"0000-01-01\"))\r\n\r\n\r\nHvordan ser disse dataene ut? La oss lage en figur!\r\nFor å få en fin fremstilling legger jeg også til en variabel dag_måned som gjør det lettere å plotte temperaturen mot dag og måned på en felles akse, og en horisontal linje på en mye brukt tommelfingerregel: 17. mai.\r\n\r\n\r\nggplot(data = df_siste_frostdager) +\r\n  geom_line(aes(x = år, y = dag_måned, colour = sted)) +\r\n  scale_y_date(date_labels = \"%d. %b\") + \r\n  geom_hline(aes(yintercept = as.Date(\"0000-05-17\"))) +\r\n  labs(title = \"Når er det trygt å plante ut?\", subtitle = \"Siste dag med minusgrader i Bergen og på Nes\", \r\n       x = \"År\", y = \"Dag\", colour = \"Sted\")\r\n\r\n\r\n\r\nHer ser vi tydelig at Bergen går ut av vinteren og minusgrader tidligere enn Nes og Kise. 17. mai er stort sett en grei dato for Nes, med enkelte kalde unntak - sist i 2020. For Bergen ser den greie datoen ut til å ligge nærmere 1. mai.\r\nFrekvenser og sannsynligheter\r\nSå går vi over til sannsynligheter. Vi har settet med de siste frostdagene, og kan bruke dette til å telle opp og beregne (for hvert sted) hvor hyppig eller sannsynlig det er at en gitt dato er den siste frostdagen. Sagt på en annen måte - for hver enkelt dato, hvor ofte har vi i løpet av de 64 siste årene observert at det var den siste frostdagen?\r\n\r\n\r\n#først lager jeg et riktig datasett\r\n#det har kun dagene med frost\r\n\r\ndf_siste_frost_sannsynlighet = \r\n  #beregner kumulativ sannsynlighet for at siste frostdag er forbi\r\n  group_by(df_siste_frostdager, sted, dag_måned) %>%\r\n  summarise(prob_abs = n()) %>%\r\n  mutate(prob_rel = prob_abs / sum(prob_abs),\r\n         prob_cum = cumsum(prob_rel)\r\n         ) %>%\r\n  ungroup() %>%\r\n  #lag fullstendig datasett med felles slutt og start\r\n  complete(sted, dag_måned) %>%\r\n  #fyller inn manglende datoer med padr::pad\r\n  group_by(sted) %>%\r\n  pad(interval = \"day\") %>%\r\n  #setter start og slutt for prob_cum til 0, 1\r\n  mutate(prob_cum = ifelse(dag_måned == min(dag_måned) & is.na(prob_cum), 0, prob_cum),\r\n           prob_cum = ifelse(dag_måned == max(dag_måned) & is.na(prob_cum), 1, prob_cum)) %>%\r\n  ungroup() %>%\r\n  mutate(dagnr = lubridate::yday(dag_måned))\r\n\r\n\r\nDette kan vi plotte som en figur:\r\n\r\n\r\nggplot(data = df_siste_frost_sannsynlighet) +\r\n  geom_point(aes(x = dag_måned, y = prob_cum, colour = sted)) + \r\n  geom_vline(aes(xintercept = as.Date(\"0000-05-17\"))) +\r\n  labs(title = \"Når er det trygt å plante ut stiklinger?\", subtitle = \"Sannsynlighet for at siste frost-dag er forbi\", colour = \"Sted\", x = \"Dag\", y = \"Sannsynlighet\", caption = \"Data: Norsk klimaservicesenter\")\r\n\r\n\r\n\r\nFor å forstå sammenhengen bedre, og kunne si noe om sannsynligheten på hver enkelt dag - ikke kun dagene vi har observasjoner for - så må vi oppsummere disse observasjonene med en modell. Dette er en modell som oppsummerer de eksisterende observasjonene, vi gjør ingen prediksjoner eller estimater for fremtidig temperatur her.\r\n\r\n\r\n#definer logit-function \r\nlogit_model  = function(df) {\r\n    glm(prob_cum ~ dag_måned, \r\n        data = df, \r\n        family = binomial(logit))\r\n}\r\n\r\n#lag en data-range med datoer for modellen\r\nfit_dates =\r\n    tibble(dag_måned = \r\n               seq.Date(from = as.Date(\"0000-01-01\"), \r\n                        to = as.Date(\"0000-07-01\"), \r\n                        by = 1))\r\n\r\n#fitter modellen og henter ut predikerte verdier for dag_måned\r\nsiste_frost_model =\r\n    df_siste_frost_sannsynlighet %>%\r\n    # velg relevante kolonner\r\n    select(sted, prob_cum, dag_måned) %>%\r\n    # nest data etter sted\r\n    group_by(sted) %>%\r\n    nest() %>%\r\n    # kjør logit-model and prediker det på den valgte dato-rangen\r\n    mutate(model = map(data, logit_model)) %>%\r\n    mutate(fit = map(model, predict, type = \"response\", newdata = fit_dates)) %>%\r\n    unnest(fit) %>%\r\n    select(sted, fit) %>%\r\n    # add prediction date range\r\n    mutate(dag_måned = fit_dates$dag_måned) %>%\r\n    # add original prob_cum column\r\n    left_join(df_siste_frost_sannsynlighet %>%\r\n                  select(sted, dag_måned, prob_cum),\r\n              by = c(\"sted\", \"dag_måned\"))\r\n\r\n#får en interessant feil her - når jeg mapper modellen til data, får jeg i non-integer #successes in a binomial glm!\r\n\r\n\r\n\r\n\r\nggplot(data = df_siste_frost_sannsynlighet) +\r\n  geom_point(aes(x = dag_måned, y = prob_cum, colour = sted)) + \r\n  geom_smooth(aes(x = dag_måned, y = prob_cum, colour = sted), alpha = 0.15, method = \"glm\", \r\n              method.args = list(family = binomial(logit))) +\r\n  labs(title = \"Når er det trygt å plante ut stiklinger?\", subtitle = \"Sannsynlighet for at siste frost-dag er forbi\", colour = \"Sted\", x = \"Dag\", y = \"Sannsynlighet\", caption = \"Data: Norsk klimaservicesenter\")\r\n\r\n\r\n\r\nSom vi ser av modellen passer den ikke 100 % med observasjonene, men følger kurven sånn nokenlunde.\r\nHvilke mer presise råd om planting kan vi så bruke denne modellen til å lage?\r\n\r\n\r\nprob_table = \r\n    siste_frost_model %>%\r\n    group_by(sted) %>%\r\n    mutate(over_50 = fit >= 0.5,\r\n           over_90 = fit >= 0.9,\r\n           over_95 = fit >= 0.95,\r\n           over_98 = fit >= 0.98,\r\n           over_99 = fit >= 0.99) %>%\r\n    ungroup() %>%\r\n    select(sted, dag_måned, starts_with(\"over\")) %>%\r\n    gather(key = prob,\r\n           value = response,\r\n           starts_with(\"over\")) %>%\r\n    filter(response) %>%\r\n    group_by(sted, prob) %>%\r\n    summarise(threshold = min(dag_måned)) %>%\r\n    ungroup() %>%\r\n    mutate(prob = str_remove(prob, \"over_\") %>%\r\n               as.numeric() %>%\r\n               magrittr::divide_by(100)) %>%\r\n    spread(key = sted, \r\n           value = threshold) %>%\r\n    mutate(explainer = paste0(\"du kan forvente minusgrader etter denne datoen en gang hvert \", round(1/(1-prob), 0), \" år\"))\r\n\r\n\r\nDette kan vi lage en tabell av! Men koden er endra, så denne oppdaterer seg ikke lenger - eval = FALSE!\r\n\r\n\r\ngt(prob_table, locale = \"nb_NO\") %>%\r\n    tab_header(title =  md(\"**Når er det trygt å plante ut?**\"),\r\n               subtitle = \"Sannsynlighet for at den siste frostdagen er forbi\") %>%\r\n    opt_align_table_header(align = \"left\") %>%\r\n    tab_spanner(label = \"Sted\",\r\n                columns = vars(\"Bergen - Florida\", \"Kise Pa Hedmark\")) %>%\r\n    cols_label(prob = \"Sannsynlighet\",\r\n               explainer = \"\") %>%\r\n    fmt_percent(columns = vars(prob),\r\n                decimals = 0) %>%\r\n    fmt_date(columns = vars(\"Bergen - Florida\", \"Kise Pa Hedmark\"),\r\n             date_style = 9) %>%\r\n    cols_align(align = \"center\",\r\n               columns = everything())\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-01-30-nar-er-det-trygt-a-plante-stiklinger-ute/stiklinger_files/figure-html5/unnamed-chunk-5-1.png",
    "last_modified": "2023-11-25T07:55:08+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-01-25-hvordan-scrape-gamle-doffin/",
    "title": "Hvordan hente data fra Doffin?",
    "description": "Målet er å lage en webscraper som regelmessig henter data fra Doffin om relevante utlysninger. Det ser ut til å funke fint - dermed kan en med litt mer jobb, evt. jevnlig kjøring, lage seg et system som automatisk finner nye aktuelle utlysninger når de lyses ut. En kan også hente data til analyser av utlysningsmarkedet..",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2022-01-25",
    "categories": [],
    "contents": "\r\nOppdatering: Etter at nye doffin ble lansert høsten 2023, slutten denne koden å virke.\r\nDoffin er den nasjonale kunngjøringsdatabasen for offentlige anskaffelser på doffin.no .\r\nFor å holde seg oppdatert på aktuelle kunngjøringer, kan det være en fordel å med jevne mellomrom få varslinger om nye kunngjøringer.\r\nDet kan også være nyttig å kunne sette opp abonnementer på relativt komplekse søk (f.eks. etter flere oppdragsgivere en kjenner godt, mange mindre oppdragsgivere som publiserer sjeldnere og dermed lettere går under radaren).\r\nDet kan også potensielt være verdi å kunne se statistikk over omfanget av utlysninger etter ulike parametre (som. f.eks. om det er spesielle måneder hvor det lyses ut spesielt mye FoU-prosjekter, om det er aktører som i større eller mindre grad bruker Doffin (og dermed heller bruker andre anskaffelseskanaler).\r\nMen Doffin-nettsida tilbyr i dag lite som passer slikt. Doffin er kun en database og et web-grensesnitt for å søke i databasen, og tilbyr ikke selv noen tjenester som dekker dette.\r\nJeg har tidligere (i en anna sammenheng) vært i kontakt med daværende eier av Doffin-databasen, og undersøkte mulighetene for å få den utlevert. Det førte ingen steder. Vi må dermed ta sakene i egne hender. Det ser heller ikke ut til å ligge noe kode åpent tilgjengelig som gjør det samme, men et par ting finnes dog:\r\n- En open source-entusiast har laget en webscraper for scraperwiki for å konvertere Doffin til en lokal sqlite-database. Den er sist oppdatert i 2006, og jeg snakker ikke scraperwiki (eller QuickCode, som det heter nå? En plattform for R og Python? Verdt å kikke nærmere på ved en anna anledning.)\r\n- Det finnes også, i gist-form på GitHub, en Ruby-basert “Mechanize based Sidekiq Worker” som rapporterer om nye utlysninger. Den ble sist oppdatert for 7 år siden, og jeg snakker ikke Ruby heller.\r\nHvordan løse dette\r\nBegge kode-eksemplene jeg fant bruker webscraping med xpath og css-selectorer. En kikk på nettsida med konsollet i Chrome, bekrefter på at dataene ikke hentes fra noe åpent tilgjengelig API eller lignende.\r\nFor å hente ut informasjonen må en dermed lese inn HTML-filene, og behandle disse. Dermed trenger vi disse bibliotekene:\r\n\r\n\r\n#biblioteker\r\nlibrary(tidyverse)\r\nlibrary(rvest) #scrape-pakke\r\nlibrary(janitor) #for den hendige get_dupes()-funksjonen\r\nlibrary(robotstxt) #for å spørre om jeg får lov til å skrape\r\n\r\nknitr::opts_chunk$set(\r\n  eval = FALSE\r\n)\r\n\r\n\r\nPlanen er å bruke rvest til å simulere ulike former for søk mot Doffin, og så hente ut informasjonen i tabellform på en slik måte at det kan sorteres og visualiseres. Evt. også formatere det om til lesbar tekst igjen.\r\nObsobs - er det lov?\r\nFør en stuper inn i det, er det et par ting som må avklares:\r\nTillater brukerbetingelsene for Doffin at vi bruker innholdet?\r\nI følge betingelsene (i skrivende stund, januar 2022) tilhører alt materiale enten EU-supply eller Nærings- og fiskeridepartementet, men rettighetene er også overført Fornyings- og administrasjonsdepartementet - med mindre annet er oppgitt.\r\nDet er ikke spesielt tydelig, ettersom FAD ble lagt ned i 2014, og EU-supply ikke lenger er leverandør for Doffin. Det står imidlertid ingenting om bruk av materialet i betingelsene. Ettersom dette er en offentlig portal for publisering av informasjon, legger jeg derfor til grunn at materialet kan hentes ned. Hvis en skulle brukt det i et prosjekt eller til å lage et produkt, ville jeg imidlertid tatt kontakt med noen for å oppklare dette.\r\nTillater nettsida at vi bruker en robot for å skrape ut innholdet?\r\nEn av flere guider er her, som anbefaler robotstxt-pakka. Her kan en teste enkelt-stier i robots.txt-fila på nettsida, og se om det er tillatt for roboter å aksessere den. Jeg sjekker for et generelt søkeresultat og en enkelt kunngjøring:\r\n\r\n\r\n#for søkeresultatet\r\npaths_allowed(\r\n  paths = \"/Notice/?query=&PageNumber=1&PageSize=10&OrderingType=0&OrderingDirection=1&RegionId=&CountyId=&MunicipalityId=&IsAdvancedSearch=false&location=&NoticeType=&PublicationType=&IncludeExpired=false&Cpvs=&EpsReferenceNr=&DeadlineFromDate=&DeadlineToDate=&PublishedFromDate=&PublishedToDate=\",\r\n  domain = \"doffin.no\",\r\n  bot = \"*\"\r\n)\r\n\r\n#for ett enkelt-oppslag/en enkelt kunngjøring\r\npaths_allowed(\r\n  paths = \"Notice/Details/2022-360774\",\r\n  domain = \"doffin.no\",\r\n  bot = \"*\"\r\n)\r\n\r\n\r\nBegge test-spørringene returnerer SANN, og det bør derfor være tillatt. Det kommer imidlertid også en rekke advarsler her - on_not_found er en hendelse som trigges ved en 404-feil, dvs. “ikke funnet”. Kan det dermed tenkes at robots.txt mangler eller ikke er definert som forventa? Eller er det pakka det er noe feil med?\r\nEt annet alternativ er å bruke polite-pakka, det anbefales også av tidyverse-Wickham. Hvis en skal lage funksjoner som henter info fra mange nettsider, kan det være lurt. Samtidig tror jeg det viktigste er å ikke overbelaste nettsida, noe som også kan gjøres med å sette godt med Sys.sleep-tid mellom spørringer.\r\nRvest\r\nRvest er tidyverse-pakka for enkel web-scraping, ifølge vignetten. Eksempelet i vignetten for pakka er basert på en enkel side-struktur:\r\n\r\n\r\n#fra https://rvest.tidyverse.org/\r\n#les html\r\nstarwars <- read_html(\"https://rvest.tidyverse.org/articles/starwars.html\")\r\n\r\n#finn elementer som matcher en css-selector eller et xpath-uttrykk\r\nfilms <- starwars %>% html_elements(\"section\")\r\nfilms\r\n\r\n#hver tittel er tagga med en <h2>, og kan hentes med html_element\r\n#teksten i html-elementet kan så ekstraheres med html_text2\r\n\r\ntitle <- films %>% \r\n  html_element(\"h2\") %>% \r\n  html_text2()\r\ntitle\r\n\r\nrm(starwars, films, title)\r\n\r\n\r\nTutorial-innføringa i rvest er ganske enkel, og ikke direkte overførbar til Doffin-sida, hvor elementene vi er interessert i ligger på nivå 9 som barnebarns barnebarn e.l. under en hel haug div-tagger. En bør dermed kjenne til xpath for å finne fram.\r\nEn liten omvei om Xpath\r\nXpath er XML path language, og bruker sti-aktig språk for å finne noder i et xml-dokument. HTML-dokumenter kan dermed også leses med dette språket. W3 har en grei oversikt over syntax og begreper. W3 styrer med dette, og har en god intro til syntaksen her.\r\nEn kan finne xpath i Chrome-konsollet (“inspiser element” -> “elements” -> høyreklikk -> “copy xpath” eller “copy full xpath”. Første steg er å hente ut innholdet jeg ønsker meg. Her er litt div. forsøk på å finne fram:\r\n\r\n\r\ntest = read_html(\"https://doffin.no/Notice\")\r\n\r\n#denne xpathen velger ting under id-attributten \"content\", så div-noden under denne, og så tredje article-node under der igjen.\r\n\r\nalle_elementer = html_element(test, xpath = \"//*[@id='content']/div/article[3]\")\r\n\r\n#en spesifikk utlsyningstittel burde være det første div/div-elementet her\r\ntitler_utlysninger = html_element(alle_elementer, xpath = \"div[1]/div[1]\")\r\n\r\n#tittelen inneholder tittelen og en relativ href til selve utlysningen\r\n\r\n#her får jeg også med tags for hr, de trenger jeg ikke\r\n\r\n#hva med alle a-elementene?\r\ntitler_utlysninger = html_element(alle_elementer, xpath = \"//a\")\r\n\r\n#html_elements gir et større resultat?\r\ntitler_utlysninger = html_elements(alle_elementer, xpath = \"//a\")\r\n\r\n#a-taggen kan også brukes?\r\ntitler_utlysninger = html_elements(alle_elementer, \"a\")\r\n\r\n#hva med boksen med opplysninger om hver enkelt utlysning?\r\n#burde denne velge alle div-elementer med et class-attributt som er \"notice-search-item\"?\r\nkun_utlysninger = html_element(alle_elementer, xpath = \"//div[@class = 'notice-search-item']\")\r\n\r\nkun_utlysninger = html_element(alle_elementer, xpath = \"//*[@class = 'notice-search-item']\")\r\n\r\n#jeg klarer ikke å kun velge en, den første\r\n\r\n#jeg kan teoretisk manuelt sette opp en velger her som tar enkelt-elementene, 1-10?\r\nspesifikk_utlysning = html_element(alle_elementer, xpath = \"//*[@class = 'notice-search-item'][5]\")\r\n\r\n##i følge chrome er xpath til et element //*[@id=\"content\"]/div/article[3]/div[1]\r\nspesifikk_utlysning = html_element(test, xpath = \"//*[@id='content']/div/article[3]/div[5]\")\r\n\r\n#men da må jeg teste for når jeg går tom\r\nspesifikk_utlysning = html_element(alle_elementer, xpath = \"//*[@class = 'notice-search-item'][100]\")\r\n\r\n#ikke at det er verre enn at lista da blir tom.\r\n#ligger problemet i mellom-steget, tro?\r\n#i følge chrome er xpath til et element //*[@id=\"content\"]/div/article[3]/div[1]\r\nkun_utlysninger = html_element(test, xpath = \"//*[@id='content']/div/article[3]/div\")\r\n\r\n#html_elements\r\nkun_utlysninger = html_elements(test, xpath = \"//*[@id='content']/div/article[3]/div\")\r\n\r\n#konvertere til tekst\r\n\r\n#- den spesifikke\r\nspesifikk_utlysning = html_element(test, xpath = \"//*[@id='content']/div/article[3]/div[5]\") %>%\r\n  html_text2()\r\n\r\n#alle\r\nkun_utlysninger = html_elements(test, xpath = \"//*[@id='content']/div/article[3]/div\") %>%\r\n  html_text2()\r\n\r\n#å konvertere alle disse elementene til tekst er ikke så nyttig, den må håndteres på en anna måte.\r\n\r\n\r\nI vignetten forklares et vanlig mønster for rvesting: Først bruke html_elements for å få ut alt, og så html_element for å velge enkelt-klosser som skal utgjøre den enkelte rad eller kolonne. Det er fordi html_element alltid returnerer like mange elementer som du sender inn, og fyller inn med NA. Dermed er den sikrere (hvis f.eks. en av oppføringene mangler et under-element, får den NA, i stedet for å bare mangle uten noen mulighet til å finne ut av hvem som mangler). Ett eksempel: Første gjennomgang ga 11 elementer fra navn, men 10 elementer fra alle de andre elementene. Det var fordi også en av de andre elementene ble tatt med, ikke bare noticene, og hadde et navn.\r\nDet er potensielt problematisk og sårbart ved avvikende formater - jeg veit ikke om alle disse feltene alltid kommer til å være med.\r\nLa oss finne informasjonen vi skal ha!\r\n\r\n\r\n#alle utlysninger\r\nkun_utlysninger = html_elements(test, xpath = \"//*[@id='content']/div/article[3]/div\")\r\n\r\n#det er mulig jeg fisker med meg for mange ting her\r\n#fordi jeg bruker div til slutt, identifiserer den alle div-elementene, ogdet siste div-elementet er \"pagination- ctm-pagination\", ikke \"notice-search-item\r\n#prøver i stedet\r\nkun_utlysninger = html_elements(test, xpath = \"//*[@id='content']/div/article[3]/div[@class = 'notice-search-item']\")\r\n\r\n#navn\r\nnavn = html_elements(kun_utlysninger, xpath = \"//div[@class = 'notice-search-item-header']/a\") %>%\r\n  html_text()\r\n\r\n#html-elements her returnerer 11 objekter, jeg vil ha for alle de funnede objektene\r\nnavn = html_element(kun_utlysninger, xpath = \"//div[@class = 'notice-search-item-header']/a\") %>%\r\n  html_text()\r\n\r\n#av en eller annen grunn finner html_element kopier av den første matchen her?\r\nnavn = html_element(kun_utlysninger, xpath = \"div[@class = 'notice-search-item-header']/a\") %>%\r\n  html_text()\r\n\r\n#uten // først, som matcher alt?, men i stedet går rett på å søke dem opp, så går det bra? klø-i-hodet\r\n#men neste problem\r\n# denne fintes ut av at oppfølring nr. 10 har to <a> under headeren, der den første lenker til mercell-plattformen. Men jeg vil kun ha den andre. Jeg kan ikke bruke bare de som har href, siden den har det Kan jeg bruke contains og matche på de stedene hvor det lenkes til en doffin-notice? Hvis alle gjør det?\r\nnavn = html_element(kun_utlysninger, xpath = \"div[@class = 'notice-search-item-header']/a[contains(@href, 'Notice')]\") %>%\r\n  html_text()\r\n\r\n#lenke til kunngjøring\r\n#den faktiske lenka bør ligge i tittelen/navnet på det som er kunngjort\r\n#da må jeg hente verdien av attributtet?\r\n#det gjøres ved å legge selve attributtet til slutt\r\n#men siden jeg også må partial-matche med contains må den komme før\r\nlenke = html_element(kun_utlysninger, xpath = \"div[@class = 'notice-search-item-header']/a[contains(@href, 'Notice')]/@href\") %>%\r\n  html_text()\r\n\r\n#hvem har publisert\r\npublisert_av = html_element(kun_utlysninger, xpath = \"div[@class = 'left-col']/div[1]\") %>%\r\n  html_text2()\r\n\r\n#kunngjøringstype\r\nkunngjoring_type = html_element(kun_utlysninger, xpath = \"div[@class = 'left-col']/div[2]\") %>%\r\n  html_text2()\r\n\r\n#doffin referanse\r\ndoffin_referanse = html_element(kun_utlysninger, xpath = \"div[@class = 'right-col']/div[1]\") %>%\r\n  html_text2()\r\n\r\n#kunngjøringsdato\r\nkunngjoring_dato = html_element(kun_utlysninger, xpath = \"div[@class = 'right-col']/div[2]\") %>%\r\n  html_text2()\r\n\r\n#enda en snag - siste oppfølring her er visst den eneste faktiske konkurransekunngjøringa. \r\n#den har dermed tre elementer i right-col\r\n#velge last bør fikse.\r\nkunngjoring_dato = html_element(kun_utlysninger, xpath = \"div[@class = 'right-col']/div[last()]\") %>%\r\n  html_text2()\r\n\r\n#tilbudsfrist\r\n#veldig sentralt. på det ene eksempelet her er den inni enda en span, så den bør la seg identifisere?\r\n#men vet ikke hvor robust det er - kan andre ting være inni en span?\r\ntilbudsfrist_dato = html_element(kun_utlysninger, xpath = \"div[@class = 'right-col']/div[2]/span\") %>%\r\n  html_text2()\r\n\r\n\r\n#setter sammen datasettet\r\ndf = data.frame(\r\n  doffin_referanse, navn, publisert_av, kunngjoring_type, kunngjoring_dato, tilbudsfrist_dato\r\n)\r\n\r\nglimpse(df)\r\n\r\n\r\nDet er første side, med noen caser her. Hva skjer med neste side, og andre enheter? URL-en ser ut til å oppdatere sge på veldig fornuftig vis: URL-en endres fra https://doffin.no/Notice til https://doffin.no/Notice?pageNumber=1&pageSize=10. Altså to egenskaper - sidenummer og sidestørrelse.\r\nLa oss lage noen funksjoner for å få litt mer oversiktlig kode\r\nDette ser ut til å fungere etter hensikten. Men koden tar litt mye plass, og er ganske gjentakende.\r\nFørst to funksjoner, en for å lage URL og en for å hente ut de ønskede dataene fra søkeresultatet.\r\n\r\n\r\n#doffin_url_builder\r\n#definerer funksjonen som en i utgangspunktet tom funksjon, kun sidenummer, antall resultater pr side, og sortering etter kunngjøringsdato. isadvancedsearch og includeexpired er false.\r\n#CamelCase\r\n\r\n#argumenter\r\n#query: \"Direktoratet+for+høyere+utdanning+og+kompetanse+(HK-dir)\"',\r\n#PageNumber: sidenummer, brukt over\r\n#PageSize:  hvor mange treff pr side\r\n#&OrderingType: 0 - relevans, 1 - kunngjøringsdato, 2 - tilbudsfrist, 3 - doffin-referanse, 4 - tittel, 5 - publisert av\r\n#OrderingDirection:  0 - stigende, 1 - synkende\r\n#RegionId:  div geokoder på regionnivå\r\n#CountyId: div goekoder på flkenivå\r\n#MunicipalityId. div geokoder på kommunenivå\r\n#IsAdvancedSearch: true hvis du inkluderer overliggende regioner , false som standard\r\n#location:  usikker på denne, kanskje en kombo av geokodene?\r\n#NoticeType:  kunngjøringstype - blank = alle, 1 = veiledende, 2 = kunngjøring av konkurranse, 3 = tildeling, 4 = intensjonskunngjøring, 6 = kjøperprofil, 999999 = Dynamisk innkjøpsprofil.\r\n#PublicationType: blank = alle, 1 = nasjonal, 2 = europeisk, 5 = market consulting\r\n#IncludeExpired: #skal utgåtte inkluderes? true hvis ja, false hvis nei\r\n#Cpvs: CPV-koder her - flere bindes sammen med + , eksempel: Cpvs=34000000+33000000\r\n#EpsReferenceNr: Doffin referanse-nr.\r\n#DeadlineFromDate; tilbudsfrist fra, formateres 01.01.2022 DD.MM.ÅÅÅÅ\r\n#DeadlineToDate: tilbudsfrist til, formateres 01.02.2022\r\n#PublishedFromDate: #kunngjøringsdato fra, formateres 01.02.2022\r\n#PublishedToDate: #kunngjøringsdato til, formaters også 01.02.2022\r\n\r\ndoffin_url_builder = function(Query = \"\", PageNumber = \"1\", PageSize = \"100\", OrderingType = \"1\", OrderingDirection = \"1\", RegionId = \"\", CountyId = \"\", MunicipalityId = \"\", IsAdvancedSearch = \"false\", Location = \"\", NoticeType = \"\", PublicationType = \"\", IncludeExpired = \"false\", Cpvs = \"\", EpsReferenceNr = \"\", DeadlineFromDate = \"\", DeadlineToDate = \"\", PublishedFromDate = \"\", PublishedToDate = \"\"){\r\n  temp_url = paste0(\"https://doffin.no/Notice?\",\r\n        \"query=\", Query,\r\n        \"&PageNumber=\", PageNumber,\r\n        \"&PageSize=\", PageSize,\r\n        \"&OrderingType=\", OrderingType, \r\n        \"&OrderingDirection=\", OrderingDirection, \r\n        \"&RegionId=\", RegionId,\r\n        \"&CountyId=\", CountyId,\r\n        \"&MunicipalityId=\", MunicipalityId,\r\n        \"&IsAdvancedSearch=\", IsAdvancedSearch,\r\n        \"&location=\", Location,\r\n        \"&NoticeType=\", NoticeType,\r\n        \"&PublicationType=\", PublicationType,\r\n        \"&IncludeExpired=\", IncludeExpired,\r\n        \"&Cpvs=\", Cpvs,\r\n        \"&EpsReferenceNr=\", EpsReferenceNr,\r\n        \"&DeadlineFromDate=\", DeadlineFromDate,\r\n        \"&DeadlineToDate=&\", DeadlineToDate,\r\n        \"PublishedFromDate=\", PublishedFromDate,\r\n        \"&PublishedToDate=\", PublishedToDate\r\n  )\r\n}\r\n\r\n#doffin_fetch_results\r\n#en funksjon som tar en doffin-query-url som input, og returnerer resultatet som en data.frame\r\n#basert på rvest-pakken\r\n\r\ndoffin_fetch_results = function(url){\r\n  #henter html-fil\r\n  temp_html = read_html(url)\r\n  #henter ut kun utlysninger fra html-fila\r\n  kun_utlysninger = html_elements(temp_html, \r\n                                  xpath = \"//*[@id='content']/div/article[3]/div[@class = 'notice-search-item']\")\r\n  #setter sammen datasettet\r\n  temp_df = data.frame(\r\n    doffin_referanse = html_element(kun_utlysninger, \r\n                                    xpath = \"div[@class = 'right-col']/div[1]\") %>%\r\n      html_text2(), \r\n    navn = html_element(kun_utlysninger, \r\n                        xpath = \"div[@class = 'notice-search-item-header']/a[contains(@href, 'Notice')]\") %>%\r\n      html_text2(),\r\n    publisert_av = html_element(kun_utlysninger, xpath = \"div[@class = 'left-col']/div[1]\") %>%\r\n      html_text2(),\r\n    kunngjoring_type = html_element(kun_utlysninger, xpath = \"div[@class = 'left-col']/div[2]\") %>%\r\n      html_text2(), \r\n    kunngjoring_dato = html_element(kun_utlysninger, xpath = \"div[@class = 'right-col']/div[last()]\") %>%\r\n      html_text2(), \r\n    tilbudsfrist_dato = html_element(kun_utlysninger, xpath = \"div[@class = 'right-col']/div[2]/span\") %>%\r\n      html_text2(), \r\n    lenke = html_element(kun_utlysninger, \r\n                         xpath = \"div[@class = 'notice-search-item-header']/a[contains(@href, 'Notice')]/@href\") %>%\r\n      html_text()\r\n  )\r\n}\r\n\r\n\r\nDenne funksjonen har en del forbedringspotensiale:\r\nhvis lista kun_utlysninger er like lang som PageSize, er det fare for at det er flere sider med resultater. Dette burde en advare om, og ideelt sett også håndtere. Kjapp kikk på det:\r\n\r\n\r\nurl = doffin_url_builder()\r\ntemp_html = read_html(url)\r\n#henter pagineringselementet\r\npaginering = html_elements(temp_html, \r\n                         xpath = \"//*[@id='content']/div/article[3]/div[101]\")\r\n#henter sidetallet fra denne, trekker ut teksten, og konverterer tallet til et tall.\r\nantall_sider = html_element(paginering, xpath = \"ul[2]/li[3]\") %>%\r\n  html_text2() %>%\r\n  parse_number(.)\r\n\r\n\r\nQuery-argumentet bør ha noe for å sjekke at strengen er korrekt definert (med + i stedet for mellomrom, evt “” hvis strengt søk)\r\nHvis det skal brukes i en loop - feilhåndtering?\r\nMen på denne måten kan spørringene skrives langt mer kompakte.\r\nHente siste kunngjøringer\r\nStandard-søket blir da slik:\r\n\r\n\r\nurl = doffin_url_builder()\r\nresultater = doffin_fetch_results(url)\r\n\r\n\r\nLoope gjennom en liste av kunder\r\nHer er et eksempel, med alle ikke-utgåtte kunngjøringer av konkurranser fra noen offentlige oppdragsgivere:\r\n\r\n\r\n#merk %22 er HTML for \"\", de trengs her og der for å få treff.\r\n#stoler ikke 100 % på denne.\r\n\r\nkunder = c(\r\n  \"Viken+fylkeskommune\",\r\n  \"Arbeids-+og+inkluderingsdepartementet\",\r\n  \"NAV\",\r\n  \"Bergen+kommune\",\r\n  \"%22Barne-,+ungdoms-+og+familiedirektoratet%22\",\r\n  \"Digitaliseringsdirektoratet\",\r\n  \"Direktoratet+for+forvaltning+og+økonomistyring+(DFØ)\",\r\n  \"%22Direktoratet+for+høyere+utdanning+og+kompetanse+(HK-dir)%22\",\r\n  \"Distriktssenteret\",\r\n  \"Integrerings-+og+mangfoldsdirektoratet+(IMDi)\",\r\n  \"Husbanken\"\r\n)\r\n\r\nresultater = data.frame()\r\n\r\nfor(i in 1:length(kunder)){\r\n  url = doffin_url_builder(Query = kunder[i], NoticeType = \"2\")\r\n  temp_resultater = doffin_fetch_results(url)\r\n  if(nrow(temp_resultater) == 0){\r\n    message(\"ingen funn for \", i, \" - \", kunder[i])\r\n  }\r\n  if(nrow(temp_resultater) > 0){\r\n    temp_resultater$`søk` = kunder[i]\r\n    resultater = bind_rows(resultater, temp_resultater)\r\n    message(\"ferdig med \", i, \", \", kunder[i])\r\n  }\r\n  Sys.sleep(5)\r\n}\r\n\r\nglimpse(resultater)\r\n\r\n\r\n5 sekunders Sys.sleep-tid bør være bra.\r\nKunngjøring av konkurranser etter CPV\r\nFør vi ser på muligheten for å hente mer informasjon enn det som ligger i oppslaget, la oss bare ta et kjapt søk som sammenfatter siste ukes kunngjøringer av konkurranser på en sentral CPV:\r\n\r\n\r\nfradato = format(Sys.Date() - 7, \"%d.%m.%Y\")\r\ntildato = format(Sys.Date(), \"%d.%m.%Y\")\r\n\r\nurl = doffin_url_builder(\r\n  NoticeType = \"2\",\r\n  Cpvs = \"73000000\", \r\n  PublishedFromDate = fradato, \r\n  PublishedToDate = tildato)\r\n\r\nresultater = doffin_fetch_results(url)\r\n\r\nglimpse(resultater)\r\n\r\n\r\nHente ut mer informasjon fra selve kunngjøringen\r\nJeg har URL til kunngjøringen, og kan dermed hente informasjon herifra.\r\n\r\n\r\nurl = doffin_url_builder(Query = \"IMDi\", NoticeType = \"2\")\r\ntemp_resultater = doffin_fetch_results(url)\r\n\r\n#denne kan fjerne info\r\ntest = str_remove(temp_resultater[1,1], fixed(\"Doffin referanse: \"))\r\n\r\n#men vi har jo lenka\r\nmer_info <- read_html(paste0(\"https://doffin.no\", temp_resultater[1,7]))\r\ncpv = html_elements(mer_info, xpath = \"//*[@id='notice']/div[3]/div[2]/div[5]/div/span\") %>%\r\n  html_text2()\r\n\r\n#er det samme mønster på en anna en?\r\nmer_info <- read_html(paste0(\"https://doffin.no\", temp_resultater[3,7]))\r\ncpv = html_elements(mer_info, xpath = \"//*[@id='notice']/div[3]/div[2]/div[5]/div/span\") %>%\r\n  html_text2()\r\n#kort beskrivelse også?\r\nbeskrivelse = html_elements(mer_info, xpath = \"//*[@id='notice']/div[3]/div[2]/div[9]/div\") %>%\r\n  html_text2()\r\n\r\n#vi looper igjennom litt flere samtidig!\r\n\r\nfor(i in 1:nrow(temp_resultater)){\r\n  mer_info <- read_html(paste0(\"https://doffin.no\", temp_resultater[i,7]))\r\n  temp_resultater$cpv[i] = html_elements(mer_info, xpath = \"//*[@id='notice']/div[3]/div[2]/div[5]/div/span\") %>%\r\n  html_text2()\r\n  temp_resultater$beskrivelse[i] = html_elements(mer_info, xpath = \"//*[@id='notice']/div[3]/div[2]/div[9]/div\") %>%\r\n  html_text2()\r\n  Sys.sleep(5)\r\n}\r\n\r\nglimpse(temp_resultater)\r\n\r\n\r\nVirker dette også hvis jeg henter de 100 siste kunngjøringene, uavhengig av type, oppdragsgiver, mm? Det kan godt være. Legger inn en liten if-setning for å unngå nullfunn. Fikk en feil her, på /Notice/Details/2022-312872, som mangler denne beskrivelsen. Den er p.t. ikke håndtert.\r\n\r\n\r\nurl = doffin_url_builder()\r\ntemp_resultater = doffin_fetch_results(url)\r\n\r\nfor(i in 1:nrow(temp_resultater)){\r\n  mer_info <- read_html(paste0(\"https://doffin.no\", temp_resultater[i,7]))\r\n  temp_cpv = html_element(mer_info, xpath = \"//*[@id='notice']/div[3]/div[2]/div[5]/div/span\") %>%\r\n  html_text2()\r\n  if(length(temp_cpv) > 0){\r\n    temp_resultater$cpv[i] = temp_cpv\r\n  }\r\n  if(length(temp_cpv) == 0){\r\n    temp_resultater$cpv[i] = NA\r\n  }\r\n  temp_beskrivelse = html_element(mer_info, xpath = \"//*[@id='notice']/div[3]/div[2]/div[9]/div\") %>%\r\n  html_text2()\r\n  if(length(temp_beskrivelse) > 0){\r\n    temp_resultater$beskrivelse[i] = temp_beskrivelse\r\n  }\r\n  if(length(temp_beskrivelse) == 0){\r\n    temp_resultater$beskrivelse[i] = NA\r\n  }\r\n  Sys.sleep(5)\r\n}\r\n\r\n\r\nMulige videreutviklinger\r\nFor å automatisere kjøring av script, er det flere på internett som anbefaler pakka taskscheduleR.Da trenger vi en kompakt versjon av dette som et script. Har så langt ikke fått det til å virke.\r\nFor å få tilsendt varsel på epost, virker pakken mailR virker relevant - https://www.rdocumentation.org/packages/mailR/versions/0.8. Oppretter en test-epostadresse i Google. MailR krever rJava, som igjen krever at Java er installert på maskinen. For å bruke Google-kontoen, må en aktivere sikkerhetsinnstillingen som åpner for “mindre trygger apper”. Så ikke gjør dette med en alvorlig epostadresse, kanskje?\r\nGjenstående ting å se på\r\nTeste funnene fra robot-søk mot manuelle søk - er det noe som forsvinner for roboten?\r\nSikker berikelse med beskrivelse og cvp fra selve kunngjøringen for ulike edgecaser?\r\n– “Warning in temp_resultater$beskrivelse[i] <- temp_beskrivelse : number of items to replace is not a multiple of replacement length”\r\nHva er fornuftige søkestrenger og cpv-er? M.a.o.: hvilke kunngjøringer er det vi er interessert i?\r\nAutomatisk kjøring i script-form\r\nResultater på epost\r\nJeg får advarsler om at “closing unused connection n (url)”. Verdt å ta en titt på stackoverflow her?\r\nhvis lista kun_utlysninger er like lang som PageSize, er det fare for at det er flere sider med resultater. Dette burde en advare om, og ideelt sett også håndtere.\r\nQuery-argumentet bør ha noe for å sjekke at strengen er korrekt definert (med + i stedet for mellomrom, evt “” hvis strengt søk)\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-25T07:55:08+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-10-27-power-elforbruk-og-pris/",
    "title": "Hvor mye mindre strøm bruker jeg når prisen er høy?",
    "description": "Bruker jeg mindre strøm når prisen er høy? Svaret ser ut til å være nei - enten så bruker jeg mer ved høyere pris, eller i hvert fall det samme (men mer fordi været er kaldere).",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2021-10-27",
    "categories": [],
    "contents": "\r\nNår prisen går opp, går forbruket ned - det var en ganske grunnleggende ting jeg lærte i samfunnsøkonomien. Prisen på strøm har uten tvil gått veldig opp, så hvordan er sammenhengen mellom pris og forbruk hos meg?\r\nFør jeg i det hele tatt begynner å se på dataene, vil jeg tippe på at svaret er nei, av flere grunner:\r\nmitt forbruk gir ikke så veldig mye data å gå på.\r\nde dataene jeg har, er fra perioden fra mai til november. Selv her ved kysten vil vi naturlig nok bruke mer strøm når været blir kaldere.\r\nbakgrunnen for at etterspørselen går ned når prisen går opp, er generelt sett at forbrukeren vil bytte til en anna vare eller tjeneste når prisen går opp (substitusjon), og at mindre av inntekten vil være tilgjengelig for å kjøpe varen. Det er ikke helt feil i dette tilfellet - jeg har sett på strømleverandører, brukt varmepumpa mer og kjøpt inn litt ved. Men det er vanskelig å bytte seg helt bort fra strøm til spotpris. Jeg antar altså at etterspørselen er lite elastisk.\r\nMen når det er sagt - la oss ta en kikk. For å komme til bunns i dette starter jeg med å hente forbruksdataene for målepunktet fra elhub.no.\r\n\r\n\r\n#data\r\nfiles= list.files(path = \"data\", pattern = \"*.csv\", full.names = TRUE) \r\ndf = map_df(files, read_delim, delim = \",\", escape_double = FALSE,\r\n  skip = 1,\r\n  col_names = c(\"fra\", \"til\", \"forbruk\"),\r\n  col_types = cols(\r\n    fra = col_datetime(format = \"%d.%m.%Y %H:%M\"), \r\n    til = col_datetime(format = \"%d.%m.%Y %H:%M\")\r\n    ), \r\n  locale = locale(decimal_mark = \",\", grouping_mark = \"\"), \r\n  trim_ws = TRUE)\r\n\r\n#tester om det finnes duplikater her\r\nduplikater = get_dupes(df, fra, til)\r\nrm(duplikater, files)\r\n\r\n#legger til informasjon om datoer\r\n\r\ndf = mutate(df,\r\n  dato = as.Date(fra),\r\n  time = lubridate::hour(fra),\r\n  dag = lubridate::wday(fra, label = TRUE, abbr = FALSE),\r\n  ukedag = ifelse(dag %in% c(\"lørdag\", \"søndag\"), \"helg\", \"arbeidsdag\"),\r\n  uke = lubridate::week(fra),\r\n  month = lubridate::month(fra),\r\n  natt = ifelse(time %in% c(23, 00, 01, 02, 03, 04, 05), \"natt\", \"dag\")\r\n)\r\n\r\n\r\nFor å finne strømprisene gjør jeg følgende:\r\njeg laster ned strømprisene fra Nord Pools nettside.\r\nprisene her oppgis i NOK pr megawatt-time. En vanligere enhet for strømpriser er øre per kilowatt-time. 1 megawatt er 1 000 kilowatt og 1 krone er 100 øre - altså må vi dele den oppgitte prisen på 10 for å få øre per kilowatt-time.\r\ngjennom min strømavtale får jeg et avslag på 0,5 øre per kwt.\r\nNordpool-prisene er også oppgitt uten merverdiavgift. Mva. på strøm er 25 %.\r\nSlik jeg har forstått det, er strømavtalen min nå uten andre påslag. Nettarriffen kommer utenom (både fastledd og energiledd) i nettleia. Jeg antar også at forbruksavgifter og innskudd til energifond i Enova kommer i nettleia.\r\n\r\n\r\n#leser inn datasettet, endrer et variabelnavn, velger bare Bergen, lager nye fra-til-variabler for klokkeslett, og nye variabler med dato og klokkeslett på samme format som i forbruksdatasettet\r\npriser_2021 <- read_excel(\"data/elspot-prices_2021_hourly_nok.xlsx\", skip = 2) %>%\r\n  rename(., dato = 1) %>%\r\n  select(dato, Hours, Bergen) %>%\r\n  separate(Hours, into = c(\"fra_kl\", \"til_kl\")) %>%\r\n  mutate(fra_kl = paste0(fra_kl, \":00:00\"),\r\n         til_kl = paste0(til_kl, \":00:00\"),\r\n         fra = as.POSIXct(paste0(dato, \" \", fra_kl), format = \"%Y-%m-%d %H:%M:%S\", tz = \"UTC\"),\r\n         til = as.POSIXct(paste0(dato, \" \", til_kl), format = \"%Y-%m-%d %H:%M:%S\", tz = \"UTC\"),\r\n         ) %>%\r\n  mutate(spotpris_nordpool = Bergen/1000*100,\r\n         spotpris_eks_fratrekk = spotpris_nordpool -0.5,\r\n         spotpris_inkl_mva = spotpris_eks_fratrekk * 1.25\r\n         )\r\n\r\n\r\nEn liten kontroll mot strømregninga viser at prisene blir nokenlunde riktige. Ikke helt på øret - men heller ikke helt galematias.\r\n\r\nmonth\r\nforbruk\r\nkostnad_kr\r\nsnitt_øre_pr_kwh\r\n6\r\n106.981\r\n63.53\r\n59.38\r\n7\r\n400.326\r\n288.25\r\n72.00\r\n8\r\n606.058\r\n574.79\r\n94.84\r\n9\r\n675.780\r\n918.42\r\n135.91\r\n10\r\n789.004\r\nNA\r\nNA\r\nNA\r\nNA\r\nNA\r\nNA\r\n\r\nHøyere priser i kaldere måneder og på hjemme-tidspunkt\r\n\r\n\r\n\r\nBruker mer strøm når prisene går opp\r\nFiguren under viser at forbruket mitt så langt i hovedsak har gått opp, når prisene har gått opp.\r\n\r\n\r\n\r\nMed en lineær regresjon finner vi en sammenheng mellom pris og forbruk - men temmelig svak: for hvert øre prisen øker, går forbruket opp med 7 watt. Det er ikke mye. Som vi så av figuren over, har gjennomsnittlig døgnpris gått opp fra rundt 100 ør pr. kwt til 140 øre pr kwt fra starten av september til starten av oktober. 40 øres økning samsvarer da med en økning i forbruket på 280 watt pr. time (0,3 kwt).\r\nHvis jeg lager separate lineære regresjonslinjer for de ulike månedene (med en tanke om at værforholdene er nokenlunde like innenfor hver måned), får jeg mye det samme bildet: høyere forbruk henger sammen med høyere priser.\r\n\r\n\r\n\r\nI juli er forbruket i en gitt time 0.2 kwt høyere i utgangspunktet, i oktober 0,7 kwt høyere.\r\nFor å få et grep om hvordan forbruket responderer på prisendringer, kunne jeg sett på samfunnsøkonomenes elastisitet: Priselastisitet er et mye brukt mål i samfunnsøkonomien på sammenhengen mellom pris og etterspørsel. Dette målet setter opp hvor stor prosentvis endring i etterspørsel man får av å gjøre en prosentvis endring i prisen. En elastisitet på mindre enn -1 - altså at etterspørselen synker med mer enn 1 % hvis prisen øker med 1 % - beskrives som en elastisk etterspørsel, mens en elastisitet større enn -1 beskrives som “uelastisk”.\r\nEttersom elastisiteter først og fremst er nyttige når en skal sammenlikne ulike varer (noe vi ikke skal), og når etterspørselen er synkende med økt pris (noe den ikke er), lar jeg dette ligge her.\r\nTemperaturdata inn i modellen\r\nSå langt har jeg bare sagt “etterspørselen følger i stor grad temperaturen”, uten å ha modellert eller testet dette eksplisitt. Men ved hjelp av data fra Meteorologisk institutt (MET) sin portal seklima.met.no kan jeg nå få til dette. Her fant jeg noen temperatur-data fra målestasjonen Flordia i Bergen:\r\n\r\n\r\ntemperatur <- read_delim(\"data/met_temperatur_florida_010521_131121.csv\",\r\n                         delim = \";\", \r\n                         escape_double = FALSE, \r\n                         col_types = cols(`Tid(norsk normaltid)` = col_datetime(format = \"%d.%m.%Y %H:%M\")),\r\n                         locale = locale(decimal_mark = \",\", grouping_mark = \"|\", encoding = \"ISO-8859-1\"),\r\n                         trim_ws = TRUE) %>%\r\n  rename(tid = 3) %>%\r\n  filter(Stasjon == \"SN50540\") #beholder Florida 12moh, ikke Uib 45 moh\r\n\r\n\r\nggplot(data = temperatur, aes(x = tid, y = Lufttemperatur)) +\r\n  geom_point(alpha = 0.1) + \r\n  geom_smooth() + \r\n  labs(title = \"Lufttemperatur i Bergen\", subtitle = \"1. mai 2021 - 13. november 2021, pr. time\")\r\n\r\n\r\ntemp = left_join(df, select(priser_2021, fra, spotpris_inkl_mva), by = \"fra\") %>%\r\n  left_join(., select(temperatur, tid, temperatur = Lufttemperatur), by = c(\"fra\" = \"tid\"))\r\n\r\nggplot(data = temp, aes(x = temperatur, y = forbruk)) +\r\n  geom_point(alpha = 0.3) +\r\n  geom_smooth()\r\n\r\n\r\n\r\nEn litt større modell\r\nHva skjer så hvis vi prøver å lage en litt større modell med det vi så langt har plukka opp?\r\nTimesforbruket bestemmes av:\r\nTid på døgnet. Forbruket er lavere om natta.\r\nOm det er hverdag eller helg. Dagforbruket er noe høyere i helgene.\r\nHvilken måned det er. Temperaturstyring fungerer i stor grad slik at en ser på kalenderen, og skrur på varmen - ikke gradstokken.\r\nTemperatur kan imidlertid ha en separat effekt - flere termostater slår seg på.\r\nPrisen?\r\n\r\n\r\nmodell_3 = lm(data = temp, forbruk ~ as.factor(natt) + as.factor(ukedag) + as.factor(month) + temperatur + spotpris_inkl_mva)\r\nsummary(modell_3)\r\n\r\n\r\nCall:\r\nlm(formula = forbruk ~ as.factor(natt) + as.factor(ukedag) + \r\n    as.factor(month) + temperatur + spotpris_inkl_mva, data = temp)\r\n\r\nResiduals:\r\n    Min      1Q  Median      3Q     Max \r\n-1.1237 -0.3983 -0.1156  0.3253  2.8576 \r\n\r\nCoefficients:\r\n                        Estimate Std. Error t value\r\n(Intercept)            0.4391698  0.0728150   6.031\r\nas.factor(natt)natt   -0.4742466  0.0245904 -19.286\r\nas.factor(ukedag)helg  0.0200183  0.0225853   0.886\r\nas.factor(month)7      0.2596038  0.0368255   7.050\r\nas.factor(month)8      0.5037801  0.0408215  12.341\r\nas.factor(month)9      0.5759714  0.0572954  10.053\r\nas.factor(month)10     0.8390330  0.0570917  14.696\r\ntemperatur            -0.0059354  0.0033151  -1.790\r\nspotpris_inkl_mva      0.0010346  0.0005907   1.752\r\n                                  Pr(>|t|)    \r\n(Intercept)               0.00000000182089 ***\r\nas.factor(natt)natt   < 0.0000000000000002 ***\r\nas.factor(ukedag)helg               0.3755    \r\nas.factor(month)7         0.00000000000221 ***\r\nas.factor(month)8     < 0.0000000000000002 ***\r\nas.factor(month)9     < 0.0000000000000002 ***\r\nas.factor(month)10    < 0.0000000000000002 ***\r\ntemperatur                          0.0735 .  \r\nspotpris_inkl_mva                   0.0800 .  \r\n---\r\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r\n\r\nResidual standard error: 0.5493 on 3063 degrees of freedom\r\n  (9591 observations deleted due to missingness)\r\nMultiple R-squared:  0.2979,    Adjusted R-squared:  0.2961 \r\nF-statistic: 162.5 on 8 and 3063 DF,  p-value: < 0.00000000000000022\r\n\r\nHvis en time er på natta, er forbruket en halv kilowatt-time lavere enn på dagen.\r\nHvorvidt forbruket er i helga eller ikke, har ingenting systematisk å si i seg selv. Det var en effekt her, men den forsvant når vi introduserte månedene - så forbruket som så ut til å være høyere på grunn av helger, var heller på grunn av måneder.\r\nMånedene har en del å si. Alle har høyere forbruk enn i juni, gradvis større og større.\r\nEffekten av temperatur og spotpris_inkl_mva forsvinner når en introduserer månedsvariablene.\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-10-27-power-elforbruk-og-pris/power-elforbruk-og-pris_files/figure-html5/unnamed-chunk-5-1.png",
    "last_modified": "2023-11-25T07:55:08+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-10-13-power-elforbruk-v2/",
    "title": "En ny kikk på strømforbruk med R",
    "description": "De høye strømprisene har de siste ukene vært på alle lepper, avisforsider og sakskart. I hvert fall om en skal tro oppstusset i media. Det er en god anledning til å se på forbruket i det nye huset vårt, og få litt grep om hvor høyt og dyrt strømforbruket er.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2021-10-13",
    "categories": [],
    "contents": "\r\n\r\n\r\nsuppressPackageStartupMessages(library(tidyverse))\r\nsuppressPackageStartupMessages(library(janitor))\r\nlibrary(readxl)\r\n\r\n#settings\r\ntheme_set(theme_minimal())\r\nset.seed(1106)\r\noptions(scipen = 100)\r\n\r\n\r\nFor å komme til bunns i dette starter jeg med å hente forbruksdataene for målepunktet fra elhub.no.\r\n\r\n\r\n#data\r\nfiles= list.files(path = \"data\", pattern = \"*.csv\", full.names = TRUE) \r\ndf = map_df(files, read_delim, delim = \",\", escape_double = FALSE,\r\n  skip = 1,\r\n  col_names = c(\"fra\", \"til\", \"forbruk\"),\r\n  col_types = cols(\r\n    fra = col_datetime(format = \"%d.%m.%Y %H:%M\"), \r\n    til = col_datetime(format = \"%d.%m.%Y %H:%M\")\r\n    ), \r\n  locale = locale(decimal_mark = \",\", grouping_mark = \"\"), \r\n  trim_ws = TRUE)\r\n\r\n#tester om det finnes duplikater her\r\nduplikater = get_dupes(df, fra, til)\r\nrm(duplikater, files)\r\n\r\n#legger til informasjon om datoer\r\n\r\ndf = mutate(df,\r\n  dato = as.Date(fra),\r\n  time = lubridate::hour(fra),\r\n  dag = lubridate::wday(fra, label = TRUE, abbr = FALSE),\r\n  ukedag = ifelse(dag %in% c(\"lørdag\", \"søndag\"), \"helg\", \"arbeidsdag\"),\r\n  uke = lubridate::week(fra),\r\n  month = lubridate::month(fra),\r\n  natt = ifelse(time %in% c(23, 00, 01, 02, 03, 04, 05), \"natt\", \"dag\")\r\n)\r\n\r\n\r\nKilowatt-time er begrepet en må forholde seg til i denne sammenhengen. En kilowatt-time er måleenheten for å måle energi, og 1 kilowatt-time tilsvarer energien som en effekt på 1 kilowatt utvikler på 1 time.\r\nHer ser jeg at gjennomsnittsforbruket ligger på ca. 19 kilowatt-timer (kwt) pr. døgn, eller 810 watt per time. Det vil da tilsvare at vi har stående på 13,5 lyspærer på 60 watt hele døgnet (og ingenting annet).\r\n\r\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \r\n  3.924  14.222  19.451  19.240  24.449  40.355 \r\n\r\nSist jeg kikket på dette (del 1 og del 2) lærte jeg at strømforbruket varierer mye fra dag til dag, men\r\ndet er gjerne topper på morgenen rundt kl. 8 og ettermiddagen (rundt kl. 16-18),\r\ndet er større variasjoner i helgene, men tendenser til jevnt høyere forbruk,\r\nnår det blir kaldere, bruker en mer strøm - men også variasjonen i forbruket øker,\r\n\r\n\r\nggplot(data = df, aes(x = time, y = forbruk, colour = ukedag)) +\r\n  geom_smooth() +\r\n  scale_x_continuous(breaks = seq(0, 24, 2)) +\r\n  labs(x = \"Tid på døgnet\", y = \"Forbruk (kwt)\", title = \"Strømforbruket er høyest om morgenen og ettermiddagen\", subtitle = \"I hvert fall på hverdagene - i helgene er det på dagtid\")\r\n\r\n\r\nggplot(data = df, aes(x = fra, y = forbruk)) +\r\n  geom_point(alpha = 0.2) +\r\n  geom_smooth() +\r\n  labs(x = \"Forbrukstidspunkt\", y = \"Forbruk (kwt)\", title = \"Høyere strømforbruk utover høsten\", subtitle = \"Fra 0,75 kwt pr time i august til 1,5 kwt/time i oktober\")\r\n\r\n\r\n\r\nFor å forstå dette litt bedre, noterte jeg meg over noen dager tidspunktene hvor vi satte på vaskemaskin, oppvaskmaskin og dusjen:\r\n\r\n\r\napparatbruk <- read_excel(\"data/apparatbruk.xlsx\", col_types = c(\"date\", \"text\"))\r\n\r\ntemp = filter(df, dato > \"2021-10-13\" & dato < \"2021-10-18\") %>%\r\n  left_join(., apparatbruk, by = c(\"fra\" = \"Tid\"))\r\n\r\nggplot(data = temp, aes(x = fra, y = forbruk)) +\r\n  geom_line() +\r\n  geom_point(data = filter(temp, is.na(Hendelse) == FALSE), aes(x = fra, y = forbruk, colour = Hendelse))\r\n\r\n\r\n\r\nHer lærte jeg forøvrig også at POSIXct-objekter har tidssone som attributt, som left_join ser på.\r\nDe fleste hendelsene kommer sammen med en stigning i forbruket, naturlig nok. Men for at dette skulle gitt mer mening, burde jeg nok ha notert litt mer - med kun 7 datapunkter blir det rett og slett litt fattig for å forstå alle svingningene. Jeg er heller ikke helt sikker på hva vi gjorde som utløste de store toppene rundt kl. 16.00 torsdag 14. oktober og kl. 8 søndag 17. oktober. Oppvarming i kombinasjon med matlaging og barne-TV på søndag?\r\nMen hva så?\r\nStrømforbruket om natta?\r\nDette er jo greit nok, og det er morsomme data å leke seg med. Men hva er implikasjonen? Finner jeg noe her som gir meg noe å gå på for å bruke mindre strøm? Kan en for eksempel si at strømbruk om natta bør være lav - og så se om vi holder oss til det?\r\n\r\n\r\ntemp = filter(df, natt == \"natt\") %>%\r\n  mutate(natt_til = as.Date(fra + (60*60*1))) %>% #for å få gruppert datoene riktig må jeg legge til litt tid her\r\n  group_by(natt_til) %>%\r\n  summarise(forbruk = sum(forbruk))\r\n\r\nggplot(data = temp, aes(x = natt_til, y = forbruk)) +\r\n  geom_line() +\r\n  geom_smooth() +\r\n  labs(x = \"Dato\", y = \"Forbruk (kwt)\", title = \"Strømforbruket om natta stiger når været blir kaldere\")\r\n\r\n\r\n\r\nIkke spesielt overraskende, kanskje - men strømforbruket natterstid er større når temperaturen faller. Men det er ikke store summer vi snakker om - fra kanskje 1 kwt til rundt 6 kwt. Til sammenlikning ligger forbruket på dagtid rundt 15-16 kwt i snitt i samme periode, og øker opp 25-35 mot slutten av perioden her. Men det er jo også flere timer dag enn natt, i hvert fall slik jeg har definert det over.\r\nUnormalt høyt strømforbruk?\r\nKan en i stedet se og flagge tidspunkt hvor strømforbruket har blitt unormalt høyt over en dag? Vel, også her er det en sterk økning i forbruket inn i oktober.\r\n\r\n\r\ntemp = group_by(df, dato) %>%\r\n  summarise(forbruk = sum(forbruk))\r\n\r\nggplot(data = temp, aes(x = dato, y = forbruk)) +\r\n  geom_line() +\r\n  labs(x = \"Forbrukstidspunkt\", y = \"kilowatt-timer forbruk\")\r\n\r\n\r\n\r\nFor å identifisere et avvik, må jeg altså først identifisere trenden, og så avviket isolert fra det. Dermed må vi inn i dekomponering igjen, som vi også forsøkte sist med blandede resultater - så da lar jeg det ligge.\r\nSagt på en anna måte: strømdataene i seg selv forteller deg ikke om du bruker for mye eller for lite strøm. En god gammeldags gjennomgang av hvilke apparater som står på når - særlig ovner - vil en nok komme lengre med.\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-10-13-power-elforbruk-v2/power-elforbruk-v2_files/figure-html5/unnamed-chunk-4-1.png",
    "last_modified": "2023-11-25T07:55:08+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-10-07-oppgradering-av-bloggen-til-blogdown-1x/",
    "title": "Oppgradering av bloggen til Blogdown 1.X",
    "description": "En mulig fornuftig arbeidsflyt for å bruke blogdown til å blogge med R.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2021-10-07",
    "categories": [],
    "contents": "\r\nSiden mars 2019 og en inspirerede Meetup i Oslo UseR har jeg vært godt fornøgd med å skrive en og anna blogg-artikkel i R (cirka 30 p.t.). For å få til dette har jeg brukt pakken Blogdown. Denne pakka gir meg muligheten til å skrive og ordne med bloggen min ved hjelp av Markdown og Hugo. I motsetning til f.eks. WordPress, er denne bloggen kun en samling med statiske nettsider, og ikke en database som må hostes på en spesifikk plattform. Dermed kan jeg laste opp filene til GitHub, og hoste dem på Netlify sin tjeneste som leser direkte fra GitHub. Men den største fordelen er at jeg kan skrive i r markdown, som bare er tekst - men som også kan inneholde r-kode.\r\nNår jeg tok i bruk pakken, var den i versjon 0.7 eller deromkring. Når jeg på våren 2021 oppdaterte R og alle R-pakkene mine, fant jeg imidlertid ut at pakka var oppgradert til versjon 1.0. Med en ny hovedversjon kom det en haug med endringer som gjorde at min gamle kode knakk sammen. Dermed måtte jeg grave meg ned i detaljene for å få bloggen tilbake på beina igjen. Alison Hill sin blogg om “Up and running with blogdown in 2021” og lanseringsnotatene var til stor hjelp!\r\nSå hvordan gjorde jeg det?\r\nSett et mål, og finn ut hvilket innhold du skal ha. Det blir avgjørende for hvordan du skal utforme sida. Jeg vil stort sett bare ha enkel tekst og noen figurer, så dermed vil jeg ha noe enkelt og oversiktlig, med få sider og lite navigasjon. Målet er vel ganske enkelt å legge noen halvtenkte tanker og kodesnutter på et sted jeg kan finne det igjen.\r\nLag et prosjekt og sett opp versjonskontroll. Hill bruker den innebygde Git-kontrollen i RStudio. Den prøvde jeg å bruke, men jeg fikk den ikke til å fungere - og ikke bare fordi Git ikke er helt enkelt å forstå, men fordi det var en bug med synkroniseringen. Git-klienten er også av den enkle sorten. Dermed lagde jeg i stedet prosjektet i RStudio, og la denne mappa opp til GitHub via GitHub Desktop. Jeg ser at Jenny Bryan nå også anbefaler GitHub Desktop i sin flotte Happy Git with R-bok.\r\nSett opp ei side. Dette kan du nå gjøre via funksjonen new_site fra blogdown-pakka. Her angir du temaet. Jeg gikk for Tanka-temaet (Tanka er forøvrig navnet på tradisjonell og enkel japansk poesi -“On the white sand | Of the beach of a small island | In the Eastern Sea. | I, my face streaked with tears, | Am playing with a crab). Her fant jeg også ut at for å få dette til å fungere skikkelig, så må jeg kjøre RStudio med administrator-tilganger. Uten den tilgangen, opprettes ikke alle de nødvendige filene.\r\nMed den nye blogdown-pakka er det en rekke nye funksjoner og konfigurasjoner som en kan benytte seg av. Her kan en legge ting i RProfile-fila (som at filer ikke skal knittes automatisk ved lagring), redigere gitignore-fila for GitHub\r\nEn anna sentral egenskap er at bloggartikler nå må “knittes” lokalt, før de lastes opp. I den gamle versjonen kunne en la Netlify håndtere “knittinga”, men det ga store problemer med ukurante Hugo-versjoner m.m. Ved oppdatering ga det en ubehagelig overraskelse - når alle filene må knittes på nytt, så finner en jo utdatert R-kode, gamle R-pakker, API-endepunkter som har endra seg, og så videre. Claus Wilke beskriver dette problemet ganske godt i bloggen “Writing a blogdown post for the ages”. Den nye modellen i blogdown-pakka med at du selv knitter posten, og ikke re-knitter den når du laster opp sida på nytt, løser dette problemet - men i overgangen til versjon 1.0. var problemet over alt.\r\nEn anna forskjell er at sidene nå lagres som “site bundles”, der hver post har sin egen mappe med innholdet til den posten. Tidligere var innholdet lagret i en separat, felles mappe, noe som allerede med kun 30 poster ble uoversiktelig.\r\nDen siste forskjellen jeg har merka meg med, er at du nå kan merke innlegg som utkast (“draft”) i headeren. Dermed publiseres de ikke.\r\nEn siste ting er at blogdown-pakka nå har fem check-funksjoner, slik at en kan sjekke for en rekke vanlige feil og mangler med sideoppsettet, konfigurasjonsfiler, hugo-versjonerin, netlify-tilkobling og innholdet. Check_site() kjører belelig nok alt.\r\nInnholdet legges fortsatt på Github, og kan publiseres som ei nettside av Netlify derifra.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-25T07:55:08+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-09-27-korona-data-fra-fhi/",
    "title": "Korona-data fra FHI",
    "description": "En titt på hvordan en kan hente data om koronatilfeller fra [FHIs MSIS-nettside](https://statistikk.fhi.no/msis/sykdomshendelser?etter=diagnose&fordeltPaa=maaned&diagnose=713).",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2021-09-27",
    "categories": [],
    "contents": "\r\nÅ kartlegge situasjonen i kommunalt barnevern har vært en av oppgavene jeg har hatt i Bufdir. Et stadiig tilbakevendende spørsmål vi har fått er hvordan smittetall og smittetrykk påvirker situasjonen. For å få noen grove tall på dette, har vi brukt FHIs åpne data om rapporterte tilfeller i meldingssystemet for smittsomme sykdommer.\r\nVi bruker FHIs API!\r\nPå FHIs nettside publiseres innmeldte, påviste tilfeller av Covid-19 per måned, men oppdatert pr. dags dato. Det er mulig å fordele dataene blant annet på geografi.\r\nFor å kunne bruke disse dataene i analyser, er det kjekt å få dem lasta ned på et anna format. En liten kikk i konsollet avslører at dataene som vi er ute etter kommer fra et API. For å bruke API-et trenger vi egentlig bare å hente kodelista som FHI bruker for fylker og kommuner, og så bruke den til å lage en fryktelig lang URL.\r\n\r\n\r\n#hent kodeverk for fylker og kommuner\r\nurl = \"https://statistikk.fhi.no/api/msis/kodeverk/fylkerOgKommuner\"\r\nquery_result = GET(url)\r\n\r\n\r\nLitt rot i metadataene…\r\nLista med enheter som kommer ned er heller rotete, og har uhensiktsmessige navn, så den må repareres og fikses litt.\r\n\r\n\r\nenhetsliste = unnest(fromJSON(content(query_result,\"text\",encoding=\"UTF-8\")), cols = kommuneListe, names_repair = \"universal\") %>%\r\n  rename(fhi_kid = id...2,\r\n         knr = verdi...3,\r\n         knavn = beskrivelse...4,\r\n         fhi_fid = id...5,\r\n         fnr = verdi...6,\r\n         fnavn = beskrivelse...7\r\n         ) %>%\r\n  select(-bydelListe)\r\n\r\nhead(enhetsliste)\r\n\r\n# A tibble: 6 × 6\r\n  fhi_kid knr   knavn           fhi_fid fnr   fnavn\r\n    <int> <chr> <chr>             <int> <chr> <chr>\r\n1  428242 4203  Arendal           15166 42    Agder\r\n2  428270 4216  Birkenes          15166 42    Agder\r\n3  428279 4220  Bygland           15166 42    Agder\r\n4  428282 4222  Bykle             15166 42    Agder\r\n5  428277 4219  Evje og Hornnes   15166 42    Agder\r\n6  428248 4206  Farsund           15166 42    Agder\r\n\r\nInteressant nok har lista med enheter 358 observasjoner, 2 flere enn det er kommuner i Norge i dag. En av dem er 9999 - ukjent kommune, som er greit nok, men den siste? Jeg klarer ikke å plukke den ut i farta.\r\nVi lager en enkel spørring!\r\nUansett - videre til de faktiske dataene! Disse finner du på endepunktet etterDiagnoseFordeltPaaMaaned, som tar en hel haug med parametre. Det vi er interessert i er parametrene:\r\nfraAar. Bør settes til 2021, for å få riktig år. Hvis du bruker fra 2020 til 2021, så summeres dataene for månedene med overlapp, noe du neppe har lyst til.\r\nkommuneKodeListe. Her kan du sette inn kommunenummeret, f.eks. 3411.\r\n\r\n\r\n#spørremetode\r\ntemp_url = \"https://statistikk.fhi.no/api/msis/etterDiagnoseFordeltPaaMaaned?fraAar=2021&tilAar=2021&diagnoseKodeListe=713&kommuneKodeListe=3411&summerDiagnose=false&summerAlder=false&summerKjonn=false&summerGeografi=false&summerSmittested=false&summerSmittemaate=false&summerMaaned=false\"\r\n\r\nquery_result = GET(temp_url)\r\nresultater = fromJSON(content(query_result,\"text\",encoding=\"UTF-8\"))\r\n\r\n#legger til en numerisk månedsverdi\r\nresultater = mutate(resultater,\r\n                    mnd = seq_along(fordeltPaa)\r\n                    )\r\n\r\n#lager en egen dataframe med måned-nr for seinere bruk...\r\ndf_mnd = select(resultater,fordeltPaa, mnd)\r\n\r\n#så lager vi et enkelt plott\r\nggplot(data = resultater) +\r\n  geom_col(aes(x = fct_reorder(fordeltPaa, mnd), y = antall)) +\r\n  labs(x = \"måned\", y = \"antall smittetilfeller\", title = \"Antall påviste covid-19-tilfeller i Ringsaker, per måned (t.o.m. september)\", subtitle = \"Kilde: FHI, MSIS (27.9.2021)\") +\r\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\r\n\r\n\r\n\r\nFor-loop for å spørre om alt!\r\nDette er ikke spesielt anvendelig om du ønsker alle dataene for alle kommunene. Derfor er det greit å lage en funksjon, som bygger URL-en for deg, og tar kommunenummeret som input:\r\n\r\n\r\nkommune_query_builder = function(kommunenr = \"4216\"){\r\n  temp_url = paste0(\r\n    \"https://statistikk.fhi.no/api/msis/etterDiagnoseFordeltPaaMaaned?\",\r\n    \"fraAar=2021&tilAar=2021&\",\r\n    \"diagnoseKodeListe=713&\",\r\n    \"kommuneKodeListe=\",\r\n      kommunenr,\r\n    \"&\",\r\n    \"summerDiagnose=false&summerAlder=false&summerKjonn=false&summerGeografi=false&summerSmittested=false&summerSmittemaate=false&summerMaaned=false\"\r\n    )\r\n}\r\n\r\n\r\nDenne kan vi så kjøre, f.eks. inne i en for-loop, ved å hente kommunenummeret fra den tidligere oppsatte kommunenummer-lista:\r\n\r\n\r\nenhetsliste = select(enhetsliste, knr, knavn, fnr)\r\nsmittetall = data.frame()\r\n\r\nfor(i in 1:nrow(enhetsliste)){\r\n  temp_query = kommune_query_builder(enhetsliste$knr[i])\r\n  temp_result = fromJSON(content(GET(temp_query),\"text\",encoding=\"UTF-8\"))\r\n  if(length(temp_result)>0){\r\n    temp_result = bind_cols(enhetsliste[i,], temp_result)\r\n    smittetall = bind_rows(smittetall, temp_result)\r\n  }\r\n  Sys.sleep(1.5)\r\n}\r\n\r\n#legger på månedsnummeret\r\n\r\nsmittetall = left_join(smittetall, df_mnd, by = \"fordeltPaa\")\r\n\r\nhead(smittetall)\r\n\r\n   knr   knavn fnr                                      tekst antall\r\n1 4203 Arendal  42 Koronavirus med utbruddspotensial, Arendal     26\r\n2 4203 Arendal  42 Koronavirus med utbruddspotensial, Arendal     49\r\n3 4203 Arendal  42 Koronavirus med utbruddspotensial, Arendal     70\r\n4 4203 Arendal  42 Koronavirus med utbruddspotensial, Arendal    100\r\n5 4203 Arendal  42 Koronavirus med utbruddspotensial, Arendal     70\r\n6 4203 Arendal  42 Koronavirus med utbruddspotensial, Arendal     88\r\n  fordeltPaa mnd\r\n1     Januar   1\r\n2    Februar   2\r\n3       Mars   3\r\n4      April   4\r\n5        Mai   5\r\n6       Juni   6\r\n\r\nFyller inn manglende data\r\nDermed har vi et datasett som viser smittetallene for alle norske kommuner, totalt for de første 8 og trekvart månedene i 2021. Skjønt - ikke alle kommuner. Litt enkel matte tilsier at det burde være 12 * 358 = 4 296 observasjoner her hvis alle kommuner og alle måneder var med. Men det er kun 4 224. Så antakeligvis mangler det en del observasjoner for kommuner som av ulike grunner ikke har rapportert, eller ikke har tilfeller.\r\nVi lager derfor en enkel dataframe som har alle kommuner og alle måneder:\r\n\r\n\r\ndf_komplett = bind_rows(enhetsliste, df_mnd) %>%\r\n  expand(., nesting(knr, knavn, fnr), nesting(fordeltPaa, mnd)) %>%\r\n  filter(is.na(knr) == FALSE & is.na(fordeltPaa) == FALSE)\r\n\r\ndf_komplett = left_join(df_komplett, smittetall)\r\n\r\n#tar en liten sjekk av at alle tilfellene ble med over\r\nsjekksum_1 = sum(smittetall$antall)\r\nsjekksum_2 = sum(df_komplett$antall, na.rm = TRUE)\r\n\r\n\r\nHer har vi nå NA-verdier for kommuner som det ikke fantes data for hos FHI. Vi vet ikke om disse manglet data fordi de hadde 0 tilfeller, eller fordi de ikke rakk å rapportere (Aftenposten hadde en sak i november 2020 om hvor krevende det var for helsepersonell å rapportere tilfeller til MSIS).\r\nVi begrenser også datautvalget til data fra januar til og med september 2021.\r\n\r\n\r\ndf_komplett = filter(df_komplett, mnd < 10)\r\n\r\n\r\nLitt enkel beskrivende statistikk om Covid-situasjonen fra januar til september\r\nTotalt dreier det seg om 139 518 tilfeller av Covid-19 i disse 9 månedene. Når vi summerer etter måned, ser vi at antall tilfeller er størst i september. Dette er en god indikasjon på hvorfor prøvesvarene er en dårlig indikator på hvor farlig pandemien er og var aleine - etter som flere og flere får vaksine, vil andelen personer som blir alvorlig sjuke, gå ned blant de smitta.\r\n\r\n\r\nsum(df_komplett$antall, na.rm = TRUE)\r\n\r\n[1] 136597\r\n\r\ntemp = group_by(df_komplett, mnd) %>%\r\n  summarise(antall = sum(antall, na.rm = TRUE)) %>%\r\n  left_join(., df_mnd)\r\n\r\nggplot(data = temp) +\r\n  geom_col(aes(x = fct_reorder(fordeltPaa, mnd), y = antall)) +\r\n  labs(x = \"Måned\", y = \"Antall positive prøvesvar\", title = \"Antall positive prøvesvar etter måned\")\r\n\r\n\r\n\r\nHvilke kommuner hadde flest smittetilfeller i de ulike månedene?\r\nFordelingsplot\r\n\r\n\r\n#velger de fem øverste kommunene i hver måned\r\ntemp = group_by(df_komplett, mnd) %>%\r\n  slice_max(antall, n = 5, with_ties = FALSE) %>%\r\n  arrange(mnd)\r\n\r\nggplot(data = temp) + \r\n  geom_col(aes(x = tidytext::reorder_within(knavn, desc(antall), mnd), y = antall)) +\r\n  tidytext::scale_x_reordered() +\r\n  facet_wrap(vars(mnd), scales = \"free\") +\r\n  labs(x = \"kommune\", y = \"antall påviste tilfeller\", title = \"Antall påviste Covid-19-tilfeller etter kommune og måned\")\r\n\r\n\r\n\r\nSom vi ser er smittetallene stort sett avhengige av folketall - Oslo ligger alltid øverst, og så kommer Bergen og Trondheiim inn på lista under, med diverse andre kommuner i samme område inn og ut av lista, særlig på Østlandsområdet. De ti kommunene med flest tilfeller, står for over 50 % av alle tilfeller - dette inkluderer Oslo, som står for 28 % av tilfellene.\r\nNoen kommuner har ikke hatt noen positive svar: Det er først og fremst snakk om Røyrvik, som står oppført med 0 positive svar fra januar til september. Så er det også 5 kommuner som det mangler informasjon for i 1 eller flere måneder - Utsira, Vevelstad, Skjerstad, Osen og Leka.\r\n\r\n\r\ntemp = group_by(df_komplett, knr) %>%\r\n  summarise(antall = sum(antall, na.rm = TRUE)) %>%\r\n  arrange(desc(antall)) %>%\r\n  mutate(\r\n    har_tilfeller = ifelse(antall > 0, TRUE, FALSE),\r\n    kum_andel = cumsum(antall) / sum(antall, na.rm = TRUE)\r\n    ) %>%\r\n  left_join(., enhetsliste)\r\n\r\ntabell = filter(temp, is.na(antall) | har_tilfeller == FALSE)\r\n\r\nknitr::kable(tabell)\r\n\r\nknr\r\nantall\r\nhar_tilfeller\r\nkum_andel\r\nknavn\r\nfnr\r\n1151\r\n0\r\nFALSE\r\n1\r\nUtsira\r\n11\r\n1816\r\n0\r\nFALSE\r\n1\r\nVevelstad\r\n18\r\n1842\r\n0\r\nFALSE\r\n1\r\nSkjerstad\r\n18\r\n5020\r\n0\r\nFALSE\r\n1\r\nOsen\r\n50\r\n5043\r\n0\r\nFALSE\r\n1\r\nRøyrvik\r\n50\r\n5052\r\n0\r\nFALSE\r\n1\r\nLeka\r\n50\r\n\r\nEt forsøk på å se på fordelingene for hver måned, gir ikke så veldig mye utover å slå fast at fordelinga er veldig høyreskjeiv - de aller fleste kommunene har hatt et fåtall smittetilfeller. Hvis en skal få noe mer ut av disse dataene, bør en kanske se dem sammen med befolkningstall.\r\n\r\n\r\nggplot(data = df_komplett, aes(x = fordeltPaa, y = antall)) + \r\n  geom_jitter(colour = \"steelblue\", alpha = 0.3) + \r\n  geom_boxplot(alpha = 0) \r\n\r\n\r\nggplot(data = df_komplett, aes(x = antall, y = fordeltPaa)) + \r\n  geom_density_ridges(alpha = 0.7) + \r\n  scale_x_continuous(limits = c(0, 105), expand = c(0,1)) + \r\n  theme(axis.ticks.y = element_blank()) \r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-09-27-korona-data-fra-fhi/korona-data-fra-fhi_files/figure-html5/unnamed-chunk-4-1.png",
    "last_modified": "2023-11-25T07:55:08+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-05-27-dataflyt-og-barnevernmonitor/",
    "title": "Lærdommer om dataflyt for barnevernsmonitor",
    "description": "En kjapp kikk på hvordan jeg har laget en dataflyt-kodegreie for å hente data til en monitor for barnevernet.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2021-05-27",
    "categories": [],
    "contents": "\r\nDu kjenner kanskje gleden ved å skulle gå i gang med et nytt prosjekt på et nytt område, hvor det er et flott datasett du har hørt skal være bra - og som du tror at du kan gjøre noe lurt med for å få ut noen saftige funn sjefene vil elske. Men når du så setter deg ned, skjønner du at datasettet henger sammen med gaffateip og binders - det kommer fra mange ulike kilder, koblingsnøklene mangler, hvilke transformasjoner som er gjort er ikke opplagt. Når du prøver å legge til en ny årgang, er det ingenting som stemmer, for alle enhetene får dramatiske endringer. Igjen bruker du mesteparten av prosjekttida på transformering og lagring.\r\nDette er jo en kjent historie. Ofte - for min del - er slutten på visa at jeg gjør ting så fort jeg kan, og velger pragmatiske løsninger for å få dataene til å passe sammen og passe til behovet. Uten å dokumentere. Og dermed sitter jeg igjen med samme problem neste gang det skal gjøres, for framtids-meg husker ikke veldig godt detaljene i slike valg.\r\nI mange tilfeller kan det være helt greit - for det tar definitivt tid å dokumentere og systematisere en dataflyt, og det er ikke sikkert at det lønner seg. Men hvis det er et datasett som skal vedlikeholdes over tid, som består av flere ulike kilder, kan det etter hvert dukke opp et slikt behov.\r\nI Bufdir fikk jeg muligheten til å gjøre nettopp et slikt prosjekt. På Bufdirs nettsider ligger en kommunemonitor for barnevernet. Morsomt nok er den inspirert av IMDi sin Ifakta-nettside. Her finner du 25 indikatorer for kommuner, med bakgrunnsinformasjon og indikatorer kapasitet, kvalitet og økonomi i det kommunale barnevernet. Disse indikatorene er igjen konstruert på bakgrunn av rundt 50 tabeller, og et sett med metadata / dimensjonstabeller, hovedsaklig om geografi.\r\nKoden til versjonen jeg lagde ligger på GitHub her.\r\n\r\n\r\nlibrary(PxWebApiData)\r\nlibrary(klassR)\r\nsuppressPackageStartupMessages(library(tidyverse))\r\n\r\n\r\nNår jeg lagde en dataflyt for denne nettsida, var det særlig viktig å:\r\n1. få kontroll på enhetene vi skulle observere (bydeler, kommuner, interkommunale samarbeid, fylker og hele landet). Hvem har masterkodelistene for disse, og hvordan sikrer vi at vi får oppdatert våre lister ved endringer i enhetsstrukturen?\r\nEn helt sentral byggekloss i monitoren, er settet med enheter en skal vise informasjon om, og hvordan det er kodet. Monitoren skal vise data for hele Norge, for alle fylkene, for alle kommuner, for interkommunale samarbeid på barnevernsområdet og for bydelene i de største byene. Dermed trenger en et oppdatert maskinlesbart kodesett for disse enhetene. For de fleste enhetene kan en bruke SSBs flotte listesystem.\r\n\r\n\r\nbydelsklasse = GetKlass(103)\r\nkommuneklasse = GetKlass(131)\r\nfylkesklasse = GetKlass(104)\r\n\r\n#disse er like, så de kan radbindes sammen til settet med gjeldende enheter\r\n\r\nenheter = bind_rows(bydelsklasse, kommuneklasse, fylkesklasse)\r\n\r\nrm(bydelsklasse, kommuneklasse, fylkesklasse)\r\n\r\nhead(enheter)\r\n\r\n    code parentCode level           name\r\n1 030101         NA     1     Gamle Oslo\r\n2 030102         NA     1    Grünerløkka\r\n3 030103         NA     1         Sagene\r\n4 030104         NA     1 St. Hanshaugen\r\n5 030105         NA     1        Frogner\r\n6 030106         NA     1         Ullern\r\n\r\n2. ta utgangspunkt i det de fleste brukerne trenger, og begyn med det. I dette tilfellet trenger de fleste av brukerne informasjon om sin geografiske enhet i dag, og historikken for denne. At kommunen har blitt sammenslått bakover i tid, er i de fleste tilfeller ikke viktig - de vil bare ha tallene.\r\nEn helt sentral utfordring her var kommunesammenslåingene som er gjort de seinere åra, og da særlig 1. januar 2020. Vi endte opp med å lage sammenslåtte tidsserier for alle, unntatt kommunene som ble delt. Dette vil nok dukke opp som et problem også i framtida, med Senterpartiet i regjering kan en vel regne med at noen sammenslåinger blir reversert.\r\nVi gjorde dette stort sett manuelt, men SSB viste oss hvordan vi kunne bruke KlassR til å gjøre det også:\r\n\r\n\r\n# Hent endringer i klassifikasjon\r\nregion_klass <- GetKlass(131, date = c(\"2018-01-01\", \"2020-01-01\"),\r\n                         correspond = T)\r\n\r\nhead(region_klass)\r\n\r\n  sourceCode sourceName targetCode                 targetName\r\n1       1942  Nordreisa       1942  Nordreisa - Ráisa - Raisi\r\n2       2004 Hammerfest       2004  Hammerfest - Hámmerfeasta\r\n3       5005     Namsos       5005 Namsos - Nåavmesjenjaelmie\r\n4       1567     Rindal       5061                     Rindal\r\n5       1103  Stavanger       1103                  Stavanger\r\n6       1141     Finnøy       1103                  Stavanger\r\n\r\n3. sørg for å ha en mulighet til å dekke spesielle behov, hvis de dukker opp. Noen “power-users” trenger mer spesialiserte data, som f.eks. data som ikke er blitt mappet til dagens kommunestruktur. Da bør det være lett tilgjengelig, for glade power-users er gode ambassadører for systemet ditt.\r\n4. kartlegge kildene og hvilke data som var hentet derfra. Det tok faktisk litt tid å finne ut av hvilke variabler som skulle hentes. Et API-kall som dokumentasjon er forhåpentligvis fint.\r\nEtter å ha kartlagt alle kildene, vel 60 av dem, så vi at de aller fleste kunne hentes fra SSBs åpne API til statistikkbanken. Vi lagde to script, inndelt etter når dataene oppdateres. Siden det er snakk om vel 60 tabeller, la vi også inn litt enkel logging, slik at vi kunne se om alt hadde gått som forventa uten å måtte følge med på alle API-kallene.\r\nDette så da omtrent slik ut:\r\n\r\n\r\n#kommuner\r\n#12275: Barn med tiltak i løpet av året og per 31. desember, etter region, alder, funksjon, statistikkvariabel og år\r\n#statbank: https://www.ssb.no/statbank/table/12275/tableViewLayout1/\r\n#metadata: https://data.ssb.no/api/v0/no/console/meta/table/12275/\r\n\r\ntabell_2_kommune = ApiData(\r\n  urlToData = \"https://data.ssb.no/api/v0/no/table/12275\",\r\n  KOKkommuneregion0000 = TRUE,\r\n  KOKalder0000 = \"F000-017\",\r\n  KOKbvfunksjon0000 = \"0\",\r\n  ContentsCode = \"KOSbvbarntiltaka0000\",\r\n  Tid = TRUE\r\n)\r\n\r\n#kommenterer ut logging og slikt nedover\r\n\r\n#tabell_2_kommune = tabell_2_kommune$dataset\r\n#write.csv2(tabell_2_kommune, \"datauttrekk_raw/tabell_2_kommune.csv\", row.names = FALSE)\r\n\r\n#temp_logg = bind_rows(temp_logg, data.frame(\r\n#  tabell = \"tabell_2_kommune\",\r\n#  antall_observasjoner = nrow(tabell_2_kommune),\r\n#  siste_år = max(parse_number(tabell_2_kommune$Tid))\r\n#))\r\n#rm(tabell_2_kommune)\r\n\r\n#siden det ble gjort en 60 kall mot API-et, støtte vi på grensen deres. Derfor hadde vi et lite ventetidsrom her.\r\n#Sys.sleep(waiting_time)\r\n\r\n\r\nhead(tabell_2_kommune$dataset)\r\n\r\n  KOKkommuneregion0000 KOKalder0000 KOKbvfunksjon0000\r\n1                 3001     F000-017                 0\r\n2                 3001     F000-017                 0\r\n3                 3001     F000-017                 0\r\n4                 3001     F000-017                 0\r\n5                 3001     F000-017                 0\r\n6                 3001     F000-017                 0\r\n          ContentsCode  Tid value NAstatus\r\n1 KOSbvbarntiltaka0000 2015    NA        .\r\n2 KOSbvbarntiltaka0000 2016    NA        .\r\n3 KOSbvbarntiltaka0000 2017    NA        .\r\n4 KOSbvbarntiltaka0000 2018    NA        .\r\n5 KOSbvbarntiltaka0000 2019    NA        .\r\n6 KOSbvbarntiltaka0000 2020   339     <NA>\r\n\r\n5. transformeringer må tas for seg, og krever mye tid og mange iterasjoner for å få til på en god måte. Her er det viktig med god dokumentasjon fra dag 1, og en frisk kode. Tidyverse-piping over lange distanser er f.eks. ikke nødvendigvis så bra som du tror.\r\nDet mest tidkrevende, var å lage en god struktur på bearbeidinga. Selv om mange av tabellene kom fra SSB, hadde de ymse struktur og koding. Totalt sett var det vel en 30-40 ulike operasjoner som kunne bli kjørt eller ikke, hvis en også tok med dataene fra andre kilder.\r\nVi begynte derfor med å lage ett script per ferdig tabell. Dette kunne nok raskt ha blitt generalisert mer, med noen gode funksjoner eller metoder/objekter.\r\nHer lærte vi også fort at rekkefølgen som en kjørte disse scriptene i, hadde betydning. Mange av indikatorene er beregnet på bakgrunn av antall barn i kommunen. Dataene om antall barn i kommunen må derfor oppdateres først, før en kan oppdatere noe annet.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-25T07:55:08+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-05-21-eurovision-and-kendall/",
    "title": "Eurovision og Kendall's Tau",
    "description": "Det er på tide med Eurovision! Glam, glitter og pappmusikk - og en anledning til å ha en liten konkurranse, og lære litt om statistikk for rankinger.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2021-05-21",
    "categories": [],
    "contents": "\r\nEurovision 2021 - eller Melodi Grand Prix, som vi kaller det i Norge, går snart av stabelen. Og det bør jo bli fantastisk, etter flere år uten musikken.\r\nRiktignok er musikken enestående forglemmelig, men det er allikevel gøy. Derfor hadde vi en liten konkurranse på jobb om å tippe på vinnere i konkurransen.\r\nResultatene hentes fra Eurovisionworld.com. Deltakelsen i tippekonkurransen ble henta inn i Easyfact, og er anonymisert.\r\nHer har jeg også tatt i bruk read_excel-funksjonen fra readxl-pakka. Tidligere har jeg hatt et svare strev med å importere excel-filer til R. Derfor har jeg alltid konvertert data til csv-format for import. Men denne funksjonen ser ut til å funke veldig bra nå.\r\n\r\n\r\n\r\nFor den som ikke har sluttplasseringene i hodet, så ble resultatlista slik:\r\n\r\nland\r\nplass\r\nItalia\r\n1\r\nFrankrike\r\n2\r\nSveits\r\n3\r\nIsland\r\n4\r\nUkraina\r\n5\r\nFinland\r\n6\r\nMalta\r\n7\r\nLitauen\r\n8\r\nRussland\r\n9\r\nHellas\r\n10\r\nBulgaria\r\n11\r\nPortugal\r\n12\r\nMoldova\r\n13\r\nSverige\r\n14\r\nSerbia\r\n15\r\nKypros\r\n16\r\nIsrael\r\n17\r\nNorge\r\n18\r\nBelgia\r\n19\r\nAserbajdsjan\r\n20\r\nAlbania\r\n21\r\nSan Marino\r\n22\r\nNederland\r\n23\r\nSpania\r\n24\r\nTyskland\r\n25\r\nStorbritannia\r\n26\r\n\r\nDet er to spørsmål som er interessante å se på her:\r\nhvis vi hadde vært et land, hvordan hadde lista blitt da, sammenliknet med resultatene totalt sett?\r\nhvem var best til å tippe?\r\nHvis vi var et land, hvordan hadde resultatet blitt da?\r\nDet første spørsmålet er veldig lett å svare ut - det er bare å summere poengene og sette på en plassering\r\n\r\n\r\nanalyse_df = group_by(df, land) %>%\r\n  summarise(\r\n    poeng = sum(poengverdi)\r\n  ) %>%\r\n  mutate(\r\n    plass = rank(desc(poeng), ties.method = \"min\")\r\n  ) %>%\r\n  left_join(\r\n    ., select(resultat_df, land, faktisk_plass = plass), by = \"land\"\r\n  ) %>%\r\n  arrange(plass)\r\n\r\nknitr::kable(select(analyse_df, land, plass, faktisk_plass))\r\n\r\nland\r\nplass\r\nfaktisk_plass\r\nMalta\r\n1\r\n7\r\nIsland\r\n2\r\n4\r\nPortugal\r\n3\r\n12\r\nFrankrike\r\n4\r\n2\r\nBulgaria\r\n5\r\n11\r\nSveits\r\n6\r\n3\r\nUkraina\r\n7\r\n5\r\nItalia\r\n8\r\n1\r\nHellas\r\n9\r\n10\r\nSverige\r\n10\r\n14\r\nKypros\r\n11\r\n16\r\nSan Marino\r\n12\r\n22\r\nStorbritannia\r\n12\r\n26\r\nAserbajdsjan\r\n14\r\n20\r\nLitauen\r\n14\r\n8\r\nNorge\r\n14\r\n18\r\nSerbia\r\n14\r\n15\r\nNederland\r\n18\r\n23\r\nFinland\r\n19\r\n6\r\nRussland\r\n20\r\n9\r\nAlbania\r\n21\r\n21\r\nBelgia\r\n21\r\n19\r\nIsrael\r\n21\r\n17\r\nTyskland\r\n21\r\n25\r\nMoldova\r\n25\r\n13\r\nSpania\r\n25\r\n24\r\n\r\nHvis Analyseavdelinga hadde fått bestemme, hadde Maltas !Je me casse! vunnet, foran pussig teknobit-dans fra Island, og svarthvitt crooning fra Portugal. Ikke narkotikafrie rockere fra Italia, Voila-Frankrike og tårevåte Sveits.\r\nMen hvem var nærmest det faktiske resultatet?\r\nDette er i grunnen et interessant spørsmål. Først lager vi et utpivotert datasett, hvor de ulike deltakerne er med, sammen med totalpoengene:\r\n\r\n\r\ntemp = group_by(df, deltaker) %>%\r\n  mutate(\r\n    plass = rank(desc(poengverdi), ties.method = \"min\")\r\n  ) %>%\r\n  select(\r\n    deltaker, land, plass\r\n  )\r\n\r\ntemp = bind_rows(select(resultat_df, -variabel), temp)\r\ntemp = pivot_wider(temp, names_from = deltaker, values_from = plass)\r\n\r\nknitr::kable(temp)\r\n\r\nland\r\ntotalt\r\nGlam International\r\nMagiske Soppen\r\nAnalytix\r\nBrandenburger Tor\r\nEivindmaskin\r\nRS\r\nItalia\r\n1\r\n10\r\n12\r\n2\r\n11\r\n5\r\n2\r\nFrankrike\r\n2\r\n10\r\n15\r\n2\r\n1\r\n10\r\n1\r\nSveits\r\n3\r\n10\r\n5\r\n2\r\n2\r\n11\r\n4\r\nIsland\r\n4\r\n1\r\n7\r\n2\r\n5\r\n4\r\n5\r\nUkraina\r\n5\r\n10\r\n15\r\n1\r\n3\r\n11\r\n12\r\nFinland\r\n6\r\n10\r\n15\r\n2\r\n11\r\n11\r\n7\r\nMalta\r\n7\r\n2\r\n2\r\n2\r\n4\r\n2\r\n11\r\nLitauen\r\n8\r\n4\r\n15\r\n2\r\n11\r\n11\r\n12\r\nRussland\r\n9\r\n10\r\n15\r\n2\r\n11\r\n8\r\n12\r\nHellas\r\n10\r\n10\r\n8\r\n2\r\n11\r\n3\r\n12\r\nBulgaria\r\n11\r\n10\r\n5\r\n2\r\n10\r\n1\r\n6\r\nPortugal\r\n12\r\n10\r\n1\r\n2\r\n6\r\n7\r\n3\r\nMoldova\r\n13\r\n10\r\n15\r\n2\r\n11\r\n11\r\n12\r\nSverige\r\n14\r\n5\r\n15\r\n2\r\n8\r\n11\r\n9\r\nSerbia\r\n15\r\n10\r\n4\r\n2\r\n11\r\n11\r\n12\r\nKypros\r\n16\r\n3\r\n15\r\n2\r\n9\r\n11\r\n12\r\nIsrael\r\n17\r\n8\r\n15\r\n2\r\n11\r\n11\r\n12\r\nNorge\r\n18\r\n10\r\n15\r\n2\r\n7\r\n11\r\n8\r\nBelgia\r\n19\r\n9\r\n12\r\n2\r\n11\r\n11\r\n12\r\nAserbajdsjan\r\n20\r\n6\r\n12\r\n2\r\n11\r\n11\r\n9\r\nAlbania\r\n21\r\n10\r\n10\r\n2\r\n11\r\n11\r\n12\r\nSan Marino\r\n22\r\n10\r\n3\r\n2\r\n11\r\n11\r\n12\r\nNederland\r\n23\r\n10\r\n15\r\n2\r\n11\r\n6\r\n12\r\nSpania\r\n24\r\n10\r\n15\r\n2\r\n11\r\n11\r\n12\r\nTyskland\r\n25\r\n10\r\n10\r\n2\r\n11\r\n11\r\n12\r\nStorbritannia\r\n26\r\n7\r\n9\r\n2\r\n11\r\n9\r\n12\r\n\r\nKendall’s Tau, eller rang-korrelasjons-koeffisient, er den en bruker for å korrelere ranker. Den kan måle styrken på forbindelsen mellom to ordinale variabler, i en bivariat krysstabell - som du vil få hvis du f.eks. har to personer som har rangert Eurovision-bidrag på en skala fra 1 til 12.\r\nFor å gjøre det mer forvirrende, og fordi økonomer liker å sette navnet sitt på ting, finnes det tre ulike implementeringer av Tau:\r\nKendall’s Tau-a. Standardmålet og det opprinnelige forslaget.\r\nKendall’s Tau-b. Denne justerer seg for uavgjorte verdier (hvis en har gitt samme rangering til en verdi).\r\nStuart’s Tau-c. Denne justerer for uavgjorte verdier, og håndterer tabeller som har ulik størrelse (f.eks. om en totalt har rangert 26 bidrag fra 1 til 26, mens en deltaker har rangert fra 1 til 11).\r\nI base-R er det Kendalls tau b som er implementert, antakeligvis fordi den håndterer “ties” - noe som hyppig kommer opp.\r\nVi regner like greit ut for alle, med hjelp av DescTools-pakka, som har implementert alle tre:\r\n\r\n\r\nkor_matrise = data.frame(\r\n  deltakere = c(\"Glam International\", \"Magiske Soppen\", \"Analytix\", \"Brandenburger Tor\", \"Eivindmaskin\", \"RS\"),\r\n  tau_a = c(\r\n    DescTools::KendallTauA(temp$`Glam International`, temp$totalt),\r\n    DescTools::KendallTauA(temp$`Magiske Soppen`, temp$totalt),\r\n    DescTools::KendallTauA(temp$Analytix, temp$totalt),\r\n    DescTools::KendallTauA(temp$`Brandenburger Tor`, temp$totalt),\r\n    DescTools::KendallTauA(temp$Eivindmaskin, temp$totalt),\r\n    DescTools::KendallTauA(temp$RS, temp$totalt)\r\n),\r\ntau_b = c(\r\n    DescTools::KendallTauB(temp$`Glam International`, temp$totalt),\r\n    DescTools::KendallTauB(temp$`Magiske Soppen`, temp$totalt),\r\n    DescTools::KendallTauB(temp$Analytix, temp$totalt),\r\n    DescTools::KendallTauB(temp$`Brandenburger Tor`, temp$totalt),\r\n    DescTools::KendallTauB(temp$Eivindmaskin, temp$totalt),\r\n    DescTools::KendallTauB(temp$RS, temp$totalt)\r\n),\r\n  tau_c = c(\r\n    DescTools::StuartTauC(temp$`Glam International`, temp$totalt),\r\n    DescTools::StuartTauC(temp$`Magiske Soppen`, temp$totalt),\r\n    DescTools::StuartTauC(temp$Analytix, temp$totalt),\r\n    DescTools::StuartTauC(temp$`Brandenburger Tor`, temp$totalt),\r\n    DescTools::StuartTauC(temp$Eivindmaskin, temp$totalt),\r\n    DescTools::StuartTauC(temp$RS, temp$totalt)\r\n)) %>%\r\n  mutate(\r\n    plass = rank(desc(tau_c))\r\n  ) %>%\r\n  arrange(plass)\r\n\r\nknitr::kable(kor_matrise, digits = 2)\r\n\r\ndeltakere\r\ntau_a\r\ntau_b\r\ntau_c\r\nplass\r\nRS\r\n0.40\r\n0.49\r\n0.43\r\n1\r\nBrandenburger Tor\r\n0.35\r\n0.45\r\n0.37\r\n2\r\nEivindmaskin\r\n0.19\r\n0.24\r\n0.20\r\n3\r\nAnalytix\r\n0.05\r\n0.19\r\n0.10\r\n4\r\nGlam International\r\n0.02\r\n0.02\r\n0.02\r\n5\r\nMagiske Soppen\r\n-0.02\r\n-0.03\r\n-0.03\r\n6\r\n\r\nDen endelige resultatlista rangerer alle 26 deltakerne, mens hver enkelt deltaker kun har rangert 10 land. Dermed er det Tau-c som er det korrekte målet å bruke. Vi ser at det har særlig betydning for Analytix, som kun ga poeng til Ukraina - og ingenting annet. De fleste får en høyere sammenhengsverdi med tau-b enn tau-c, antakeligvis pga. hvordan sisteplass er håndtert i poenggivninga.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-25T07:55:08+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-12-01-hvordan-ser-barnevernet-ut/",
    "title": "hvordan ser barnevernet ut?",
    "description": "Det norske barnevernet er mye diskutert - men hvordan ser det egentlig ut? Hvor mange jobber der? Hvor jobber de? Vi henter noe data fra SSB, lager noen figurer og kart.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2020-12-01",
    "categories": [],
    "contents": "\r\nHøsten 2020 skifta jeg beite, og begynte å arbeide med barnevernsspørsmål, i stedet for integreringsspørsmål.\r\nDet er ikke et mindre debattert område, akkurat - og det er vel egentlig naturlig. Det er få myndigheter som har så stor eksplisitt makt til å gripe inn i familie og privatliv, for å sikre barns beste. Når da forskjellige familier og grupper har forskjellige forventninger til barneoppdragelse og statens rolle, så skal det lite til for å lage debatt - særlig når de ansatte i barnevernet er overarbeida mennesker, som så mange andre velferdsarbeidere.\r\nEn av de første oppgavene jeg fikk, var å se på fordelingen av stillinger i det kommunale barnevernet, og hva en omlegging av det øremerka statlige tilskuddet for slike stillinger kan ha å si. Om lag 1 av 6 av årsverkene i det kommunale barnevernet er finansiert av et øremerka statlig tilskudd, som har vært hovedvirkemiddelet i en satsing på barnevernet som har vart en god stund nå.\r\nOg hvordan ser vi på fordelinger av stillinger? Med R, selvsagt!\r\nDataene som viser fordelinga av øremerka statlig tilskudd er forsåvidt ikke hemmelige, men siden de ikke er publisert noe sted, står jeg over å gjøre det i en liten bloggpost. Det aller meste av data henter vi derfor fra SSBs API, som gir tilgang til dataene i statistikkbanken.\r\n\r\n\r\n#befolkningsdata - antall personer og antall barn\r\n#bruker her SSBs ApiData-funksjon for lettere spørring mot APIet.\r\ntemp_befolkning = ApiData(\r\n  urlToData = \"https://data.ssb.no/api/v0/no/table/07459\",\r\n  Region = TRUE,\r\n  Kjonn = FALSE,\r\n  Alder = TRUE,\r\n  ContentsCode = \"Personer1\",\r\n  Tid = \"2020\"\r\n)\r\ntemp_befolkning = temp_befolkning$dataset\r\n\r\n#antall personer totalt, for kommuner (Regioner med 4 tegn)\r\nbefolkning_totalt = group_by(temp_befolkning, Region) %>%\r\n  summarise(befolkning_totalt = sum(value)) %>%\r\n  filter(nchar(Region) == 4, befolkning_totalt > 0)\r\n\r\n#antall barn (0-17 år), i kommuner (Region med 4 tegn)\r\nbefolkning_barn = mutate(temp_befolkning, Alder = parse_number(Alder)) %>%\r\n  filter(Alder < 18) %>%\r\n  group_by(Region) %>%\r\n  summarise(befolkning_barn = sum(value)) %>%\r\n  filter(nchar(Region) == 4, befolkning_barn > 0)\r\n\r\n#binder det inn i et hoved-datasett for analysen\r\ndf = befolkning_totalt %>%\r\n  left_join(., befolkning_barn)\r\n\r\n\r\nTallene for årsverk, tiltak og undersøkelser i barnevernet er tilgjengelig for 2020.\r\nStatistikken for stillinger omfatter alle såkalte funksjoner knytta til barnevernet. Med funksjoner mener arbeidsområdet for stillingen, slik det kategoriseres i KOSTRA- KOmmune-STat-Rapportering. En snakker da om funksjon 244 (barnevernstjeneste), 251 (stillinger knytta til barnevernstiltak når barnet ikke er plassert av barnevernet) og 252 (stillinger knytta til barnevernstiltak når barnet er plassert av barnevernet).\r\nVi finner også tall for antallet barn med tiltak eller undersøkelser i løpet av året 2020\r\n\r\n\r\n#KOSTRA-data på antallet årsverk i kommunen.\r\n\r\ntemp_årsverk = ApiData(\r\n  urlToData = \"https://data.ssb.no/api/v0/no/table/12305\",\r\n  KOKkommuneregion0000 = TRUE,\r\n  ContentsCode = \"KOSsumstillinger0000\",\r\n  Tid = \"2020\"\r\n)\r\n\r\ntemp_årsverk = temp_årsverk$dataset\r\n\r\n#finner stillingene (årsverk) i kommunene.\r\nstillinger = rename(temp_årsverk, Region = KOKkommuneregion0000) %>%\r\n  filter(nchar(Region) == 4)\r\n\r\n#legger det til analyse-datasettet\r\ndf = left_join(df, select(stillinger, Region, stillinger_barnevernet = value))\r\n\r\n#KOSTRA-data på antallet barn med undersøkelse eller tiltak - barn 0-17 år\r\ntemp_undtil = ApiData(\r\n  urlToData = \"https://data.ssb.no/api/v0/no/table/12870\",\r\n  KOKkommuneregion0000 = TRUE,\r\n  KOKalder0000 = \"F000-017\",\r\n  ContentsCode = \"KOSbvbarnust0000\",\r\n  Tid = \"2020\"\r\n)\r\n\r\ntemp_undtil = temp_undtil$dataset\r\n\r\n#finner antallet i kommunene\r\nundtil = rename(temp_undtil, Region = KOKkommuneregion0000) %>%\r\n  filter(nchar(Region) == 4)\r\n\r\n#legger det til analyse-datasettet\r\ndf = left_join(df, select(undtil, Region, barn_undersøkelser_tiltak = value))\r\n\r\nrm(temp_befolkning, temp_undtil, temp_årsverk, undtil, stillinger, befolkning_barn, befolkning_totalt)\r\n\r\n\r\nMens befolkningsdataene er komplette, er det noen missing-verdier i KOSTRA-dataene. Her er det 11 manglende observasjoner for stillinger, og 8 for antallet barn med undersøkelse eller tiltak. Formodentlig er dette pga. små observasjoner eller manglende data pga. manglende rapportering, men API-funksjonen i PXApiWebData returnerer p.t. kun NA for disse.\r\nHvordan er dagens fordeling av årsverk i barnevernet?\r\nOppsummert var det i 2020 om lag 6 261 årsverk i det kommunale barnevernet.\r\nAntallet ansatte i barnevernet følger i stor grad størrelsen på kommunen. Siden det er veldig stor forskjell på den største og den minste kommunen i Norge, betyr det at de kommunale barnevernstjenestene også har veldig forskjellig størrelse: 25 % av kommunene har 3 årsverk i barnevernet, 50 % har litt over 5,5 årsverk, mens gjennomsnittet for alle ligger på 17,5.\r\n\r\n\r\n\r\nPå figuren har jeg også markert 25 %, 50 % og 75 %-kvartiler, altså punktene hvor 25 % av observasjonene ligger til venstre, 50 %, osv. 75 % av kommunene har 16,5 stillinger. Kun 9 kommuner har over 100 årsverk i barnevernstjenesten, men disse 9 kommunene utgjør til gjengjeld 1/3 av alle årsverk i det kommunale barnevernet. Særlig Oslo skiller seg ut med 723,4 årsverk.\r\nDette er i grunnen interessant i seg selv, og sier noe om hva en bør tenke på når en analyserer statistikk for kommune-Norge: kommunene er i bunn og grunn vilt forskjellig.\r\nOslo ligger langt til høyre - både fordi det er en mye større kommune enn de andre, og fordi de på barnevernsområdet er spesielle: mens andre kommuner leverer noen tjenester selv, og så får andre tjenester fra det statlige barnevernet (Bufetat), står Oslo for tjenestene fra Bufetat på egen hånd.\r\nMen siden 75 % av tjenestene ligger på 16,5 stillinger, er det ikke bare Oslo som er avvikende ut fra en normalfordelt statistikkforståelse:\r\n\r\n\r\n\r\nOg det skyldes jo at dette ikke er normalfordelt, det likner mer på en Poisson-fordeling. En må selvsagt ta kommunestørrelsen med i betraktning:\r\n\r\n\r\nterm\r\nestimate\r\nstd.error\r\nstatistic\r\np.value\r\n(Intercept)\r\n0.8079680\r\n0.4646827\r\n1.738752\r\n0.0829477\r\nbefolkning_totalt\r\n0.0011218\r\n0.0000099\r\n112.882100\r\n0.0000000\r\n\r\nModellert på denne måten, ser det plutselig ikke så rart ut: I gjennomsnitt er det nesten 1 stilling pr. kommune i barnevernet, og så 1 ekstra stilling per 1000 innbygger i kommunen.\r\nDen relevante enheten er imidlertid ikke nødvendigvis kommune, men barnevernstjeneste. Kommunen er i barnevernsloven lovpålagt å ha en barnevernstjeneste, men over halvparten av alle kommuner har inngått interkommunalt samarbeid om en slik tjeneste.\r\nNår vi summerer opp landets barneverntjenester på den måten, stiger størrelsen: medianbarnevernet har 12 årsverk, gjennomsnittet 26,5 årsverk. Hovedsaklig er det da de kommunene som i Kostra-oversikten rapporterer om få årsverk, som ser ut til å inngå i større enheter/tjenester som deltakere, med en større kommune som vertskommune.\r\nHer er det også verdt å merke seg at Oslo, Bergen og Trondheim (og kanskje flere) har separate barnevernstjenester i ulike bydeler (noe som ikke kommer fram i datagrunnlaget)\r\nAntall barn per stilling i barnevernstjenesten\r\nHer kan en også poengtere at å beskrive en kommunal barnevernstjeneste ut ifra antallet stillinger aleine ikke er så veldig informativt. Selv om antallet stillinger i stor grad følger folketallet, er det stor variasjon i antallet barn i kommunen pr. årsverk i barnevernstjenesten, og antall barn med undersøkelse eller tiltak pr. årsverk i barnevernet.\r\nDette kan være indikatorer ved ulike forhold, f.eks. si noe om hvordan barnevernet er prioritert i kommunen, eller om det er et stort innslag av kommunale eller private tiltak, eller kapasitet og arbeidsbelastning for de som arbeider i barnevernet.\r\nOm vi summerer antallet barn i kommunen fra 0 til 17 år, og fordeler på KOSTRA-tallene for stillinger i barnevernet, ser vi en ganske stor spredning - men på en fordeling hvor gjennomsnitt gir mening: Gjennomsnittet ligger på 171 barn i kommunen per stilling i barnevernstjenesten. 250 kommuner ligger på +/- 60 barn rundt dette snittet.\r\n\r\n\r\n\r\nAntall barn med undersøkelse eller tiltak pr. årsverk i barnevernt\r\nFra KOSTRA-tallene ser vi også hvor mange barn kommunen rapporterer om å ha gjennomført undersøkelser eller tiltak for/med. Fordelt på antallet stillinger, får vi et uttrykk for arbeidsbelasning. Samtidig er det slik at saker er svært ulike - noen krever mye tid, andre krever lite.\r\nI gjennomsnitt har en kommune 13 barn med undersøkelser eller tiltak pr. årsverk i barnevernet. 300 av kommunene ligger mellom 10 og 20 barn med undersøkelse eller tiltak pr. årsverk.\r\nNB: ettersom stillingene her inkluderer alle funksjoner, kan en mulig feilkilde være at det varierer mellom kommuner hvorvidt de bruker private leverandører til ulike hjelpetiltak.\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2020-12-01-hvordan-ser-barnevernet-ut/hvordan-ser-barnevernet-ut_files/figure-html5/unnamed-chunk-4-1.png",
    "last_modified": "2023-11-25T07:55:08+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-10-09-name-popularity-with-prophet/",
    "title": "Hvor populære blir navnene?",
    "description": "SSBs navnestatistikk er den mest populære statistikken de har. Hvordan ser den ut? Og lar det seg gjøre å lage noen lure framskrivninger for et par navn?.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2020-10-09",
    "categories": [],
    "contents": "\r\nData\r\nAller først laster jeg inn data på alle jentenavn på fødte fra 1880 til 2019, fra SSBs statistikkbank.\r\n\r\n\r\n#data\r\ndf <- read_delim(\"PersonerProsent.csv\", \";\", escape_double = FALSE, \r\n                 locale = locale(decimal_mark = \",\", grouping_mark = \"|\", encoding = \"ISO-8859-1\"),\r\n                 trim_ws = TRUE, skip = 1, na = c(\".\", \"..\")) %>%\r\n  select(fornavn, år, andel = `Andel av fødte (prosent)`) %>%\r\n  mutate(., andel = parse_number(andel))\r\n\r\n\r\nDette datasettet har informasjon om andelen av nyfødte som har fått ett av 990 fornavn over 140 år, totalt 138 600 observasjoner. Popularitet er målt med andel, formodentlig andel av alle navn gitt til ei nyfødt jente det året. En rask opptelling viser at andelene innafor hver enkelt år ikke summerer til 100, men mellom 75 % til 95 % over tid. Dette er antakeligvis noe en kan lese mer om hos SSB.\r\nEn begrensning med dette, er at det er navn til de som er født i Norge - ikke navn til alle som bor i Norge.\r\n\r\n\r\nantall_navn = nrow(distinct(df, fornavn))\r\nantall_aar = nrow(distinct(df, år))\r\n\r\ntemp = group_by(df, år) %>%\r\n  summarise(sum_andel = sum(andel, na.rm = TRUE)) %>%\r\n  qplot(data = ., x = år, y = sum_andel)\r\ntemp\r\n\r\n\r\n\r\nHva er det som ligger her? Vi ser nærmere på trednene til ti tilfeldig utvalgte navn.\r\n\r\n\r\nutvalg_av_navn = slice_sample(df, n = 10)\r\ntemp = filter(df, fornavn %in% utvalg_av_navn$fornavn)\r\n\r\nggplot(data = temp, aes(x = år, y = andel)) +\r\n  geom_line() +\r\n  facet_wrap(vars(fornavn))\r\n\r\n\r\n\r\nHer er det nok litt tilfeldig hva som plukkes ut, så det hadde vært interessant å gjøre dette på en måte som sikra litt mer variasjon i trendene vi kunne se på.\r\nHvor populære er Aurora og Vilde?\r\n\r\n\r\nggplot(data = filter(df, fornavn == \"Aurora\"|fornavn == \"Vilde\")) +\r\n  geom_line(aes(x = år, y = andel, colour = fornavn))\r\n\r\n\r\n\r\nPrediksjon av trend\r\nEn interessant pakke for å framskrive tidsserier er Prophet - Facebooks tidsserie-algoritme.\r\n\r\n\r\n#påkrevd dataformat\r\ndf_prophet = filter(df, fornavn == \"Aurora\") %>%\r\n  select(ds = år, y = andel) %>%\r\n  mutate(\r\n    ds = as.character(ds),\r\n    ds = as.Date(ds, format = \"%Y\"))\r\n\r\n#modell\r\nmodell = prophet(df_prophet)\r\n\r\nframtida = make_future_dataframe(modell, periods = 80, freq = \"year\")\r\ndf_prediksjon = predict(modell, framtida)\r\n\r\n#graf\r\nplot(modell, df_prediksjon)\r\n\r\n\r\n\r\n\r\n\r\n#påkrevd dataformat\r\ndf_prophet = filter(df, fornavn == \"Vilde\") %>%\r\n  select(ds = år, y = andel) %>%\r\n  mutate(\r\n    ds = as.character(ds),\r\n    ds = as.Date(ds, format = \"%Y\"))\r\n\r\n#modell\r\nmodell = prophet(df_prophet)\r\n\r\nframtida = make_future_dataframe(modell, periods = 80, freq = \"year\")\r\ndf_prediksjon = predict(modell, framtida)\r\n\r\n#graf\r\nplot(modell, df_prediksjon)\r\n\r\n\r\n\r\nDette er en enkel tidsserie. Men det er jo ikke urimelig å forvente at navnetrender er nokenlunde like. Dvs. at en kan lære om trenden til et navn, ved å se på andre.\r\n\r\n\r\n\r\n",
    "preview": "posts/2020-10-09-name-popularity-with-prophet/name-popularity-with-prophet_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2023-11-25T07:55:08+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-09-06-sample-size-calculation/",
    "title": "Hvor stort utvalg trenger utvalgsundersøkelsen din?",
    "description": "Hvor store utvalg du trenger for å svare på spørsmål om hele populasjonen - og hvorfor det er viktigere med hvem du spør, enn hvor mange du spør. Hvis du skal undersøke alle landets 356 kommuner, trenger du minst et utvalg på 186 kommuner for å med 95 % sikkerhet si at en andel befinner seg mellom 45 % og 55 %.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2020-09-06",
    "categories": [],
    "contents": "\r\nHva er poenget med å trekke utvalg?\r\nTrekke utvalg er noe du gjør når du trenger et utvalg, og det er dyrt eller dumt å spørre alle i hele populasjonen. Dumt er et upresist begrep, men for eksempel er det å bidra til at respondentene dine går helt lei spørreundersøkelser ikke veldig lurt. Jeg skrev litt mer om det her.\r\nUtvalg kan trekkes på både mer og mindre treffsikre måter. De måtene som er mest akseptert som gode, bygger alle på ulike former for tilfeldighetsutvalg, der alle medlemmer av populasjonen har en sannsynlighet for å bli trukket ut, og den som gjennomfører undersøkelsen holder kontrollen med hva som skjer gjennom hele prosessen. Målet er å få et utvalg som er representativt for hele populasjonen, slik at du gjennom å måle ting ved utvalget kan si noe om hele populasjonen.\r\nHvor stort utvalg trenger du?\r\nDet er et mye stilt spørsmål. I følge boka Designing Surveys (2014) er det langt viktigere hvem du spør, enn hvor mange. Men vi begynner allikevel i denne enden.\r\nGenerelt sett er et større utvalg stort sett bedre, ettersom et større utvalg betyr mindre utvalgsfeil/utvalgsvariasjon - men bare til et visst punkt! Etter hvert får du avtakende nytte av hver ny person/enhet.\r\nEn vanlig måte å sette utvalgsstørrelse for utvalgsundersøkelser, er med en konfidensintervall-tilnærming. En anna tilnærming er gjennom styrkeberegning.\r\nAller først må du gjøre en del avklaringer:\r\nPopulasjonsstørrelse. Hvilken populasjon skal du se på, og hvor stor er den? Dette kan være vanskelig nok i seg selv - for hvordan avgrenser du på en presis og målbar måte f.eks. utenlandsadopterte barn til Norge, personer som ikke forstår beskjeder fra myndighetene, eller land som taper på globalisering av internasjonal handel?\r\nAnslag på faktisk populasjonsparameter (\\(\\pi\\)). Hvor stor andel i befolkningen har egenskapen du ønsker å måle? En mye brukt anslag er 50 % - usikkerheten ved estimatet er størst da, så det vil gi det sikreste antallet på utvalget.\r\nKonfidensnivå. Hvor sikker ønsker du å være på at den faktiske populasjonsparameteret er innafor feilintervallet / konfidensintervallet. Mye brukte sikkerheter er 90 %, 95 % og 99 %. I den faktiske matematikken brukes disse i form av Z-skårer. Gjør konfidensnivået om til en Z-skåre, altså verdier for en standardnormalfordelt variabel. For en normalfordelt variabel, så ligger\r\n90 % av verdiene innafor +/- 1,645 standardavvik fra gjennomsnittet,\r\n95 % av verdiene innafor +/- 1,96 standardavvik fra gjennomsnittet,\r\n99 % av verdiene +/- 2,576 standardavvik fra gjennomsnittet.\r\nUtvalgsfeil/feilmargin - konfidensintervall. Hvor stort vil standardavviket rundt gjennomsnittet i utvalg være? Vil de ligge rundt gjennomsnittet, eller spre seg ut? Det er jo noe du neppe veit før du har gjennomført undersøkelsen, så et trygt valg er et avvik på +/- 5 %.\r\nNår du har dette på plass, kan du beregne utvalgsstørrelse. En mye brukt tilnærming er Cochranes formel: Nødvendig utvalgsstørrelse = ((Z-skår ^ 2) * paramaterestimat * (1 - paramaterestimat)) / feilmargin^2. Det ser veldig ut som en omregning av konfidensintervall-formelen. Merk at populasjonsstørrelsen ikke kommer inn - antallet en trenger å ha i et utvalg avhenger av ønska feilmargin, at parameterestimatet er ca. normalfordelt, og den faktiske verdien på populasjonsparameteret.\r\nSå hvis du har\r\nfunnet populasjonen din,\r\nantatt parameterestimat på 50 %,\r\nvalgt 95 % konfidensnivå (1,96 Z-verdi),\r\nvalgt utvalgsfeil på +/- 5 %,\r\nfår du følgende regnestykke:\r\n\r\n\r\nz_verdi = 1.96\r\np = 0.5\r\nfeilmargin  = 0.05\r\n\r\nutvalgs_str = ((z_verdi^2)*p*(1-p)) / (feilmargin^2)\r\nutvalgs_str\r\n\r\n[1] 384.16\r\n\r\nDa trenger du et utvalg på 385 personer (eller enheter), for å med 95 % sannsynlighet kunne si at andelen befinner seg mellom 45 % og 55% i populasjonen.\r\nFormelen er en omforming av den opprinnelige standardfeil-formelen:\r\n\r\n\r\np_hatt = 0.5\r\nsem = sqrt(p_hatt*(1-p_hatt))/sqrt(385)\r\n\r\n\r\nDet gir følgende konfidensintervall:\r\n\r\n\r\np_hatt - (sem * 1.96)\r\n\r\n[1] 0.4500546\r\n\r\np_hatt + (sem * 1.96)\r\n\r\n[1] 0.5499454\r\n\r\nDenne utvalgsstørrelsen gjelder imidlertid for store populasjoner. For mindre populasjoner, der vi trekker om lag 10 % eller mer av populasjonen i utvalget vårt, kan vi gjøre en justering, ved hjelp av den faktiske populasjonsstørrelsen.\r\nDen nye utvalgsstørrelsen = anbefalt utvalgsstørrelse fra den opprinnelige formelen, delt på 1 + ((anbefalinga - 1) / populasjonsstørrelse). Så i eksempelet over, hvis populasjonen vår er alle norske kommuner (i skrivende stund 356 stk), blir utregninga slik:\r\n\r\n\r\npop_str = 356\r\n\r\nkorrigert_utvalgsstr = utvalgs_str / (1 + ((utvalgs_str - 1) / pop_str))\r\nkorrigert_utvalgsstr\r\n\r\n[1] 185.0221\r\n\r\nFor å si at en estimert andel med 95 % sannsynlighet ligger +/- 5 prosentpoeng rundt andelen i utvalget, holder det med et utvalg på 186 kommuner.\r\nHvordan ser dette ut mer generelt? Vi generer noe data, og plotter den korrigerte nødvendige utvalgsstørrelsen mot størrelsen på populasjonen:\r\n\r\n\r\n\r\nHva hvis jeg skal gjøre en undersøkelse for å estimere et gjennomsnitt, ikke en andel? Framgangsmåten er ganske lik:\r\nFinn populasjonen din.\r\nGjør et anslag på standardavviket i populasjonen. Hvor stort er det gjennomsnittlige avviket +/- rundt gjennomsnittet?\r\nKonfidensnivå. 90 %, 95 % eller 99 %? 95 % med tilhørende z-skår 1,96 er standard.\r\nKonfidensintervall. Hvor nærme det faktiske gjennomsnittet ønsker du å ha det faktiske konfidensnivået på at du er?\r\nSiden dette avhenger mer av et faktisk estimat på standardavviket, enn andelsberegninga hvor vi bare kan legge 50 % til grunn, står jeg over å demonstrere dette.\r\nHva med frafall? En ting er å beregne nødvendig utvalgsstørrelse, en anna ting er å sikre at alle som er trukket ut, faktisk deltar.\r\nHva hvis jeg ønsker å gjøre undersøkelser av undergrupper her? Hvis du ønsker å gjøre analysere undergrupper (kvinner/menn, gamle/unge, institusjoner etter ulike størrelsesgrupper), trenger hver gruppe også et tilstrekkelig utvalg for at du skal nå den valgte sikkerheten for den gruppa.\r\nSi at vår populasjon av 356 kommuner kan deles i tre grupper: 180 stk. har ikke inngått interkommunalt samarbeid, 120 har inngått interkommunalt samarbeid og er deltakere, og 56 har inngått samarbeid og er vertskommuner. Hvilket utvalg skal til, for at vi med 95 % sannsynlighet kan si at en estimert andel ligger +/- 5 prosentpoeng fra den sanne verdien?\r\nFør korrigering for størrelse blir verdien den samme som over - 385 kommuner. Men så justerer vi dette for populasjonsstørrelse\r\n\r\n\r\nz_verdi = 1.96\r\np = 0.5\r\nfeilmargin  = 0.05\r\nutvalgs_str = ((z_verdi^2)*p*(1-p)) / (feilmargin^2)\r\n\r\nkorrigert_utvalgsstr = c(\r\n  utvalgs_str / (1 + ((utvalgs_str - 1) / 180)),\r\n  utvalgs_str / (1 + ((utvalgs_str - 1) / 120)),\r\n  utvalgs_str / (1 + ((utvalgs_str - 1) / 56))\r\n)\r\n\r\nkorrigert_utvalgsstr\r\n\r\n[1] 122.78713  91.61937  48.98661\r\n\r\nDa trengs det hhv. 123 kommuner uten IKS, 92 kommuner som deltar i IKS og 49 kommuner som er vertskommuner. Totalt 264 kommuner, en god del flere enn de 185 vi fant over.\r\nStratifisert utvalg\r\nHer er vi allerede godt på vei inn i stratifiserte utvalg. Når undergrupper i en populasjon har stor variasjon i verdiene sine, eller er interessante i seg selv, eller du allerede veit mye om noen grupper, kan det lønne seg å ta et stratifisert utvalg: dele populasjonen opp i grupper, og trekke tilfeldighetsutvalg fra hver gruppe.\r\nSnittet fra hver gruppe vektet med størrelsen på gruppa bør bli et bra anslag på gjennomsnittet for hele populasjonen, med mindre utvalgsfeil enn et enkelt utvalg.\r\nEn kan bruke litt ulike strategier for å trekke et stratifisert utvalg. Proporsjonal beregning bruker en utvalgsandel fra hver gruppe proporsjonal til andelen gruppa utgjør av den totale populasjonen. Hvis populasjonen har N totale individer, med m menn og k kvinner (slik at N = m + k), så skal den relative størrelsen på utvalgene være tilsvarende som andelen menn og andelen kvinner. Det forutsetter da selvsagt at du kjenner størrelsen på disse andelene.\r\nHer griper diskusjonen inn i diskusjonen over, om nødvendig størrelse på utvalget. Hvis du f.eks. ønsker å si noe om alle norske kommuner, men også skal sammenlikne store, middels og små kommuner på en egenskap, med samme konfidensintervall, så tilsier det at du ikke trekker en proporsjonal andel av hvert strata, men trekker større utvalg av mindre grupper, for å sikre at disse også kan inkluderes på en god måte i analysene dine.\r\nDette blir dermed litt innfløkt, og jeg må komme tilbake til dette på et seinere tidspunkt.\r\nNoen avsluttende betraktninger\r\nHer har vi sett på spørsmålet om hvor stort utvalg du trenger. Det er et ganske grunnleggende spørsmål, men på sett og vis også ett av de enklere spørsmålene ved utvalgsundersøkelser - det lar seg i stor grad beregne. Det er langt vanskeligere å håndtere ulike former for skjeivhet og feil som ikke er knytta til utvalget - og kan også være krevende å avveie ønsket om antallet undersøkelser med tid og kostnad. Det viktige er ikke hvor mange, men hvem.\r\n\r\n\r\n\r\n",
    "preview": "posts/2020-09-06-sample-size-calculation/sample-size-calculation_files/figure-html5/unnamed-chunk-6-1.png",
    "last_modified": "2023-11-25T07:55:08+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-07-05-power-kutte-forbruk-eller-kaste-selskap/",
    "title": "Strømforbruket del 2: mer å spare ved å bytte leverandør, enn å kutte forbruket?",
    "description": "Nylig flytta jeg inn i et større hus. Da vinteren slo inn, fikk jeg lett sjokk av ny strømregning. Er det mulig å analysere seg ut av dette?.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2020-07-05",
    "categories": [],
    "contents": "\r\nEnkelt, ja nesten banalt sagt, kan en kan få ned strømprisen på to måter: få en billigere strømpris, eller redusere strømforbruket. Nå ser jeg på kostnaden - forrige gang så jeg på strømforbruket.\r\nKort oppsummert: det ser ut til at å kutte utgiftene til strømleverandøren gir en større innsparing enn et kutt i forbruket på 10 %. Som så mange kjappe analyser gir det flere spørsmål: skyldes dette at leverandørene opererer med lokketilbud? Hvor stor strømsparing kan vi egentlig få til? Og hvorfor får jeg ikke strømprisene fra Nordpool til å matche med strømprisene i regninga mi?\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(here)\r\n\r\n#settings\r\ntheme_set(theme_minimal())\r\nset.seed(1106)\r\noptions(scipen = 100)\r\n\r\n#data\r\n\r\n#strømregninger\r\ndf_bill <- read_delim(\"bills.csv\", \";\", escape_double = FALSE, \r\n                 locale = locale(decimal_mark = \",\", grouping_mark = \"|\", encoding = \"ISO-8859-1\"),\r\n                 col_types = cols(\r\n                   periode_start = col_date(format = \"%d.%m.%Y\"), \r\n                   periode_stopp = col_date(format = \"%d.%m.%Y\")\r\n                   ),\r\n                 trim_ws = TRUE)\r\n\r\n#strømpriser\r\ntemp1 <- read_delim(\"nordpool_elspotprices_2019_hourly.csv\", \";\", escape_double = FALSE, locale = locale(decimal_mark = \",\",grouping_mark = \"|\", encoding = \"ISO-8859-1\"), trim_ws = TRUE)\r\n\r\ntemp2 <- read_delim(\"nordpool_elspotprices_2020_hourly.csv\", \";\", escape_double = FALSE, locale = locale(decimal_mark = \",\",grouping_mark = \"|\", encoding = \"ISO-8859-1\"), trim_ws = TRUE)\r\n\r\ndf_elpris = bind_rows(temp1, temp2) %>%\r\n  separate(Hours, into = c(\"hour_start\", NA), sep = 2) %>%\r\n  mutate(periode_start = paste0(...1, \"-\", hour_start, \":00\"),\r\n         periode_start = as.POSIXct(periode_start, format = \"%d.%m.%Y-%H:%M\"),\r\n         ore_kwh = round(Oslo/10, digits = 2)\r\n         ) %>%\r\n  select(periode_start, ore_kwh)\r\n\r\n#strømforbruk\r\nfiles= list.files(path = \"consumption\", pattern = \"*.csv\", full.names = TRUE) \r\ndf_consumption = map_df(files, read_delim, delim = \";\", escape_double = FALSE,\r\n  skip = 1,\r\n  col_names = c(\"fra\", \"til\", \"forbruk\"),\r\n  col_types = cols(\r\n    fra = col_datetime(format = \"%d.%m.%Y %H:%M\"), \r\n    til = col_datetime(format = \"%d.%m.%Y %H:%M\")\r\n    ), \r\n  locale = locale(decimal_mark = \",\", grouping_mark = \"\"), \r\n  trim_ws = TRUE)\r\n\r\ndf_consumption = select(df_consumption, fra, forbruk) %>%\r\n  distinct(., fra, .keep_all = TRUE)\r\n\r\nrm(files, temp1, temp2)\r\n\r\n\r\n\r\n\r\n\r\nKostnaden var lav i juli 2019, på 500 kroner. I november var det nærmere 1800 kroner. Over disse ni månedene har jeg totalt betalt 10 323 kroner i strømregninger.\r\nModell/teori/forforståelse:\r\nStrømregninga bestemmes av nettleie + strømleverandør:\r\nUtgiften til strømleverandøren kan bestemmes på ulike måter (fastpris, spotpris). Jeg har spotpris, som Forbrukerrådet anbefaler som billigst på sikt. Strømleverandørens strømpris er spotprisen på strøm i markedet, pluss et påslag. Påslaget inneholder også kostnaden til elsertifikat. I tillegg tar strømleverandøren en fast sum. Dvs. at kostnaden for strøm = fast_strømleverandør + strømleverandør_strømpris * strømforbruk. Etter en kikk i regningene fant jeg også ut at jeg fra oktober 2019 til mars 2020 betalte for en unødvendig garantiordning.\r\nNettleie har en fast komponent og en variabel del som avhenger av forbruket, altså nettleie = fast_nettleie + nettleie_strømpris * strømforbruk. Den variable komponenten henger sammen med netteiers variable kostnader, særlig knytta til tap fra nettet.\r\nTotalt sitter vi da igjen med at kostnad = nettleie_fast + (nettleie_strømpris * strømforbruk) + strømleverandør_fast + (strømleverandør_strømpris * strømforbruk).\r\nHer er det to observasjoner som er viktige:\r\n- nettleia kan ikke justeres ved å bytte leverandør, hverken den faste eller variable kostnaden. Den variable delen påvirkes av strømforbruket.\r\n- den faste delen av strømkostnaden blir ikke påvirka av strømforbruket, men kun av bytte av leverandør.\r\nSamla sett gir dette et litt uoversiktelig bilde. Hvis jeg ønsker lavere strømkostnader, hvor mye får jeg igjen for å bytte strømleverandør som bl.a. Forbrukerrådet anbefaler? Og hvor mye får jeg igjen for å spare på strømmen?\r\nData\r\nFor å svare på dette spørsmålet trenger jeg noen data på utgifter og strømbruk, satt opp på en slik måte at jeg kan teste ut ulike alternative mønstre.\r\nStrømprisene per time hentes fra Nordpool. Strømforbruket per time kan hentes fra Elhub. Strømregningene er fra min strømleverandør, og inkluderer også utgifter til nettleie.\r\n\r\n\r\n\r\nI utgangspunktet hadde jeg tenkt å bruke data i den høyeste tidsoppløsningen jeg kunne finne. Imidlertid viste en liten sjekk at jeg ikke klarte å regne ut månedsprisen på strømregninga ved hjelp av strømprisene og strømforbruket på timesnivå. Beregningene må dermed ta utgangspunkt i strømregninga, og det månedlige forbruket.\r\nNettleie er størst i 7 av 9 måneder\r\n\r\n\r\n\r\nI alle månedene unntatt november og desember er nettleia den største komponenten. Strømleverandøren tar fra 35 % til 55 %, og 150 til 1000 kr.\r\nPå månedsbasis ser utgiftene slik ut:\r\n\r\n\r\n\r\nStrømprisen per time\r\n\r\n\r\ntemp = mutate(df_elpris, \r\n  time = lubridate::hour(periode_start),\r\n  dag = lubridate::wday(periode_start, label = TRUE, abbr = FALSE),\r\n  ukedag = ifelse(dag %in% c(\"lørdag\", \"søndag\"), \"helg\", \"arbeidsdag\"))\r\n\r\nggplot(data = temp, aes(x = periode_start, y = ore_kwh)) + \r\n  geom_line() + \r\n  labs(title = \"Prisen per kwH har falt gjennom perioden\", x = \"Dato\", y = \"Øre pr. kwH\")\r\n\r\n\r\nggplot(data = temp, aes(x = time, y = ore_kwh)) + \r\n  geom_smooth() + \r\n  labs(title = \"Strømmen koster mest rundt kl. 9 og kl. 18\", subtitle = \"Øre pr. kwH gjennom døgnet\", x = \"Time\", y = \"Øre pr. kwH\")\r\n\r\n\r\n\r\nHvordan er fordelinga mellom faste og variable komponenter?\r\n\r\n\r\ntemp = group_by(df_bill, periode_start, produkt) %>%\r\n  summarise(kostnad = sum(sum)) %>%\r\n  mutate(`månedskostnad` = sum(kostnad),\r\n         kostnad_andel = kostnad/`månedskostnad`,\r\n         `måned` = lubridate::month(periode_start, label = TRUE)\r\n         )\r\n\r\nggplot(aes(x = fct_reorder(måned, periode_start), y = kostnad, colour = produkt, group = produkt), data = temp) + \r\n  geom_line() + \r\n  labs(x = \"Måned\", y = \"Kostnad\")\r\n\r\n\r\nggplot(aes(x = fct_reorder(måned, periode_start), y = kostnad_andel, colour = produkt, group = produkt), data = temp) + \r\n  geom_line() + \r\n  labs(x = \"Måned\", y = \"Andel av total kostnad\")\r\n\r\n\r\n\r\nDen faste delen av nettleia (“fastledd”) gikk opp fra 160 til 180 i fjor høst. Andelen av totalbeløpet faller rimelig nok med økte totalkostnader. Fastbeløpet til energiselskapet er mindre, og har ligget rundt 25 kroner i hele perioden. Men jeg hadde også en “trippelgaranti” på regninga mi, som var en unødvendig forsikringsordning. Det var også i praksis en fastkostnad, som fra oktober til mars kosta meg 50 kroner i måneden.\r\nEnergileddet i nettleia er en god del høyere, og utgjør fra 30 % til over 50 % av hele regninga. Innkjøpsprisen til strømselskapet utgjorde den største delen til og med desember i fjor, men etter det har den falt under energileddet. Som vi ser av figuren har strømprisen falt en del, og utgjør en stadig lavere andel av totalregninga.\r\n\r\n\r\ntemp = filter(df_bill, produkt == \"innkjøpspris\") %>%\r\n  mutate(kwh_pris_øre = (sum / forbruk_kwh)*100) %>%\r\n  arrange(periode_start)\r\n  \r\nggplot(aes(x = fct_reorder(periode, periode_start), y = kwh_pris_øre, group = 1), data = temp) + \r\n  geom_line() + \r\n  labs(x = \"måned\", y = \"kostnad\", title = \"Strømpris øre pr. kwh\")\r\n\r\n\r\n\r\nLitt simulering\r\nSå hvor stor del av kostnaden blir påvirket av strømforbruket, og hvor stor del blir påvirka av hvilket strømselskap en velger?\r\nI utgangspunktet kunne en jo sett for seg å svare på dette spørsmålet med en regresjonsanalyse eller liknende, f.eks. noe slikt der en modellerer den månedlige kostnaden som en funksjon av strømforbruket:\r\n\r\n\r\ntemp = select(df_bill, periode_start, forbruk_kwh) %>%\r\n  filter(is.na(forbruk_kwh) == FALSE) %>%\r\n  distinct(., .keep_all = TRUE)\r\n\r\ntemp_total = group_by(df_bill, periode_start) %>%\r\n  summarise(., totalkostnad = sum(sum))\r\n\r\ntemp = left_join(temp, temp_total)\r\n\r\nmodell_1 = lm(data = temp, totalkostnad ~ forbruk_kwh)\r\n\r\nsummary(modell_1)\r\n\r\n\r\nCall:\r\nlm(formula = totalkostnad ~ forbruk_kwh, data = temp)\r\n\r\nResiduals:\r\n    Min      1Q  Median      3Q     Max \r\n-307.14  -65.09   31.69  122.36  263.89 \r\n\r\nCoefficients:\r\n            Estimate Std. Error t value Pr(>|t|)    \r\n(Intercept) 208.0601   175.4550   1.186 0.274376    \r\nforbruk_kwh   0.9307     0.1613   5.769 0.000685 ***\r\n---\r\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r\n\r\nResidual standard error: 196.6 on 7 degrees of freedom\r\nMultiple R-squared:  0.8262,    Adjusted R-squared:  0.8014 \r\nF-statistic: 33.28 on 1 and 7 DF,  p-value: 0.0006849\r\n\r\ntemp = broom::augment(modell_1)\r\nggplot(data = temp) + \r\n  geom_line(aes(x = forbruk_kwh, y = totalkostnad)) +\r\n  geom_point(aes(x = forbruk_kwh, y = totalkostnad)) + \r\n  geom_line(aes(x = forbruk_kwh, y = .fitted), colour = \"grey\")\r\n\r\n\r\n\r\nDette er ikke den verste sammenhengen jeg har sett, med ca. 80 % forklart variasjon med forbruksleddet, og en sammenheng som tilsier at for hver brukte kilowatt-time, går kostnaden opp med 93 øre.\r\nMen det er også en regresjon med temmelig få observasjoner, og den gir meg ikke mulighet til å skille mellom ulike typer av faste kostnader: nettleie (som jeg ikke får endra), og utgifter til leverandøren (som jeg kan endre).\r\nFor å svare på det spørsmålet jeg er interessert i å besvare, trenger jeg derfor heller:\r\net datasett der jeg kan variere strømforbruket, og se konsekvensen av det.\r\nJeg må også se kostnadene ved valg av leverandør som kan påvirkes av å bytte til en anna strømleverandør. Dette er påslaget pr. kwH, og faste utgifter.\r\nMed litt plundring får jeg til det.\r\nHvor mye er det rimelig å tenke at en kan redusere strømforbruket sitt? Vanskelig å si - vi begynner med å gjette på 10 %.\r\nUt ifra Strømpris.no ser det ut til 7 strømselskaper faktisk betaler meg for å velge dem, og garanterer den prisen i et halvt år. Her inngår det da 0 kroner i fastbeløp til leverandøren, og et negativt påslag. For et første forsøk nuller vi denne utgiftsposten.\r\n\r\n\r\n\r\nSom vi ser av figuren over, er innsparingseffekten av å bytte strømleverandør til noen som ikke tar betalt utover strømprisen, mer lønnsomt enn å redusere strømforbruket med 10 %.\r\n\r\n\r\ninnsparing = group_by(temp, scenario) %>%\r\n  summarise(kostnad = sum(kostnad)) %>%\r\n  arrange(kostnad)\r\n\r\nknitr::kable(innsparing)\r\n\r\nscenario\r\nkostnad\r\nscenario_3_kostnad\r\n9345.638\r\nscenario_2_kostnad\r\n9501.317\r\nfaktisk_totalkostnad\r\n10323.090\r\n\r\nInnsparinga tilsvarer 1000 kroner over denne perioden vi ser på her, 9 måneder.\r\nKonklusjon\r\nUt ifra beregningene over, har vi sett at strømforbruket varierer en del, men også kostnadene. Kostnadene henger tett sammen med strømforbruket, men ettersom markedet for leverandører i dag er slik at strømselskaper betaler deg for å velge dem - så er det (med vårt forbruk over de siste ni månedene) mer å spare på å bytte strømleverandør enn å kutte forbruket med 10 %.\r\nSpørsmål jeg sitter igjen med:\r\nHvor mye kan jeg realistisk sett spare inn på strømforbruket? Tips fra f.eks. denne ENØK-sida sier at strømsparing er det mest lønnsomme. Stemmer det fortsatt? Den forrige gjennomgangen av strømforbruket ga et bilde av svingninger og variasjon. Men det er noe anna å gå derifra til å si noe om hvor mye av forbruket som kan kuttes eller reduseres. Hvor mye sparer vi f.eks. på å redusere alle varmeovner til 20 grader, dusje kortere, vaske større vaskemaskiner av gangen - og evt. smarthus-tiltak?\r\nHvorfor avviker strømprisen fra Nordpool så mye fra det jeg betaler i innkjøpspris til strømleverandøren? Har jeg ikke timespot, men en forbruksprofil-spot? Er det i så fall noe å tjene her?\r\n\r\n\r\n\r\n",
    "preview": "posts/2020-07-05-power-kutte-forbruk-eller-kaste-selskap/power-kutte-forbruk-eller-kaste-selskap_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2023-11-25T07:55:08+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-03-20-power-el-forbruket-som-tidsserie/",
    "title": "Strømforbruket som tidsserie - kan det hjelpe på strømregninga?",
    "description": "Nylig flytta jeg inn i et større hus. Da vinteren slo inn, fikk jeg lett sjokk av ny strømregning. Er det mulig å analysere seg ut av dette?.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2020-03-20",
    "categories": [],
    "contents": "\r\nModell/teori/forforståelse:\r\nStrømregninga bestemmes av nettleie + strømpris * strømforbruk. Det betyr at en kan få ned strømprisen på to måter: få en billigere strømpris, eller redusere strømforbruket. I første omgang skal jeg se på strømforbruket.\r\nStrømforbruk bestemmes i hovedsak av mengden strøm til oppvarming av vann og luft - dvs. vaskemaskin, oppvaskmaskin, dusj/bad, panelovner og golvvarme.\r\nBehovet for oppvarming inne er større når det er kaldt ute.\r\nBehovet for vasking av klær, tallerkner og egen kropp er antakeligvis forholdsvis konstant.\r\nStrømforbruket er en tidsserie. Den vil bestå av en trend-komponent, en (eller flere) sesong-komponent, en syklisk komponent - og div. variasjon. Kan vi finne en trend som driver høyere strømforbruk over tid, og i hvor stor grad er forbruket drevet av sesongvariasjon - innad i en dag eller innad i ei uke?\r\nDet følgende er inspirert av bl.a. Hyndman og Athanasopoulos (2020). Forecasting: Principles and Practice.\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(here)\r\nlibrary(tsibble)\r\nlibrary(fable)\r\nlibrary(feasts)\r\n\r\n#settings\r\ntheme_set(theme_minimal())\r\nset.seed(1106)\r\noptions(scipen = 100)\r\n\r\n\r\nData\r\nDataene har jeg lasta ned fra strømleverandør. Det mest fornuftige formatet var på data fra elhub.no. Kan ha alle mulige oppløsninger i tid - år, måned, dag og time.\r\nDette gir meg 4 584 observasjoner av tre variabler: start- og stopptidspunkt for måling over en times periode, og forbruket i denne perioden. Stopptidspunktet anser jeg inntil videre som overflødig. Det ser også ut til å være en duplikat her, med to målinger for 27. oktober 2019. Jeg fjerner en av dem.\r\nEn sentral utfordring når en ser på denne typen tidsserier, er å velge riktig tidsperiode å se på: er det mer relevant å se hvordan forbruket endrer seg time for time gjennom en dag, eller hvordan det endrer seg måned for måned? Med en tidsangivelse med dato og time er begge deler mulig.\r\n\r\n\r\n#gjør det om til en tsibble\r\ndf = as_tsibble(df, index = fra)\r\n\r\n#litt databearbeiding\r\ndf = mutate(df,\r\n  dato = as.Date(fra),\r\n  time = lubridate::hour(fra),\r\n  dag = lubridate::wday(fra, label = TRUE, abbr = FALSE),\r\n  ukedag = ifelse(dag %in% c(\"lørdag\", \"søndag\"), \"helg\", \"arbeidsdag\"),\r\n  uke = lubridate::week(fra),\r\n  month = lubridate::month(fra)\r\n)\r\n\r\n\r\nHva skjer om vi ganske enkelt plotter denne tidsserien, time for time? Dette:\r\n\r\n\r\nggplot(data = df, aes(x = fra, y = forbruk)) + \r\n    geom_line() \r\n\r\n\r\n\r\nHer er det mye variasjon, tilsynelatende mye av det om lag lik. Men det er også en svak trend til stigning i forbruk gjennom perioden - med unntak av slutten av året. Det er antakeligvis juleferien - og mye varme på når jeg kom hjem igjen.\r\nFor å få litt bedre forståelse for de ulike typene variasjon, ser jeg nærmere på variasjon innafor enkeltdager og enkeltuker.\r\nStrømforbruk etter timer - kikk på en enkelt dag\r\n\r\n\r\nggplot(data = df, aes(x = time, y = forbruk)) + \r\n    geom_smooth() \r\n\r\n\r\n\r\nDet er helt klart et mønster i strømforbruket gjennom et døgn: det er høyest fra rundt kl. 16 til kl. 21. Men det er også en topp mellom 7 og 9, på morgenen.\r\nMens trenden er tydelig, kan det også være greit å vite litt om variasjonen rundt denne trenden:\r\n\r\n\r\nggplot(data = df, aes(x = time, group = time, y = forbruk)) + \r\n    geom_boxplot()\r\n\r\n\r\n\r\nHer ser vi at også spredninga ser ut til å være større på de tidspunktene hvor forbruket er større.\r\nForskjeller på arbeidsdager og helgedager\r\nEt element det kan være viktig å tenke på her, er at dagene i ei uke ikke er like: noen dager er fridager.\r\n\r\n\r\nggplot(data = df, aes(x = time, y = forbruk, colour = ukedag)) + \r\n    geom_smooth() \r\n\r\n\r\n\r\nOver ser vi altså at det er et skille mellom forbruket på arbeidsdager og i helger: i helgene er det jevnt over høyere, og har også en topp rundt kl. 10 om morgenen.\r\nDen er imidlertid ikke slik at det er et massivt høyere strømforbruk i helgene - det er noe større i gjennomsnitt, og noe større ekstremverdier, men ikke veldig forskjellig. Kanskje det er mer vaskemaskiner og dusjing i helgene?\r\n\r\n\r\ntemp = index_by(df, dato) %>%\r\n  summarise(forbruk = sum(forbruk)) %>%\r\n  mutate(\r\n    dag = lubridate::wday(dato, label = TRUE, abbr = FALSE),\r\n    ukedag = ifelse(dag %in% c(\"lørdag\", \"søndag\"), \"helg\", \"arbeidsdag\")\r\n    )\r\n\r\n\r\nggplot(data = temp, aes(x = ukedag, y = forbruk)) + \r\n  geom_boxplot() + \r\n  geom_jitter(alpha = 0.1)\r\n\r\n\r\nggplot(data = temp, aes(x = forbruk)) + \r\n  geom_density(aes(fill = ukedag), alpha = 0.3)\r\n\r\n\r\n\r\nStrømforbruk etter dager - trend\r\nSå strømforbruket varierer innenfor en dag. Hvordan ser dette ut når vi summer opp forbruket for en enkelt dag, og ser på trenden fra juli til januar? Slik:\r\n\r\n\r\nggplot(data = temp) + \r\n  geom_line(aes(x = dato, y = forbruk)) \r\n\r\n\r\n\r\nDet er en trend til stigende forbruk over tid. Det ser også ut til å kunne være noe større variasjoner etter hvert som været blir kaldere.\r\nOppsummerte observasjoner\r\nDet er flere sesong-mønstre i disse dataene:\r\nStrømforbruket i løpet av en dag varierer\r\nDet er noe forskjeller på en arbeidsdag og en helgedag.\r\nHvis jeg hadde hatt en lengre periode ville jeg også sett variasjon med årstidene.\r\nDet kan kanskje også sies å være en syklisk komponent her, altså variasjon over tid uten fast samvariasjon med kalenderen: med jevne mellomrom faller strømforbruket tilsvarende ei langhelg eller noen uker. Dette er feriene. Her har jeg antakeligvis ikke nok data til å få noe fornuftig ut av det.\r\nDekomponering\r\nDet finnes ulike teknikker for å skille disse ulike komponentene fra hverandre. Her skiller en mellom additive og multiplikativ dekomponering. Det siste er det riktige å gjøre hvis hvis sesong-mønstrenes variasjon samvarierer med tid - altså hvis variasjonen øker med tida, som den gjør i dette tilfellet.\r\nJeg har rett og slett ikke helt forstått den multiplikative dekomponeringa enda (eller alternativet, å bruke en logtransformert serie), så da anvender jeg additiv dekomponering for å se hvordan det ser ut. Etter litt kjapp koding blir det seende slik ut:\r\n\r\n\r\ndekomponert <-  df %>%\r\n  model(STL(forbruk ~ season(period = \"1 day\") + season(period = \"1 week\")))\r\n\r\ncomponents(dekomponert) %>%\r\n  autoplot() + \r\n  labs(x = \"tid\")\r\n\r\n\r\n\r\nØverste figur viser forbruket over tid. Figuren på linje to viser den isolerte trenden, mens linje tre og fire viser sesong-mønstre innenfor en dag og ei uke. Nederste linje viser gjenstående variasjon.\r\nDen grå boksen på y-aksen til venstre trekker oppmerksomheten mot at y-aksene er ulike. Det er størst variasjon i restleddet og den opprinnelige serien, mens de tre komponentene har mindre variasjon innad i seg. Dette er nok et tegn på at det er et stort og uforklart restledd her, som ikke lar seg enkelt dekomponere til en trend eller relatert til konstant daglig eller ukentlig variasjon.\r\nDette blir enda tydeligere hvis vi plotter en sesongjustert graf av forbruket - dette gir ikke et mye tydeligere bilde enn den ujusterte grafen.\r\n\r\n\r\ndf %>%\r\n  autoplot(forbruk, color='gray') +\r\n  autolayer(components(dekomponert), season_adjust, color='blue') +\r\n  xlab(\"Tid\") + ylab(\"Forbruk\") +\r\n  ggtitle(\"Strømforbruk - sesongjustert\")\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2020-03-20-power-el-forbruket-som-tidsserie/power-el-forbruket-som-tidsserie_files/figure-html5/unnamed-chunk-4-1.png",
    "last_modified": "2023-11-25T07:55:08+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-01-03-rasker-2019-good-year/",
    "title": "Ble 2019 et bra løpeår?",
    "description": "Noen tanker om hvorfor treningsdata kan være interessant å se på, og så en kikk på noen nøkkeltall for 2019.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2020-01-03",
    "categories": [],
    "contents": "\r\n2019 er da godt overstått, og 2020 påbegynt. Det er som seg hør og bør et passende tidspunkt å gjøre opp status for det siste løpeåret (selv om nyttårsgrensa strengt tatt er temmelig arbitrær - trening bør du få deg hele året uansett, så hvilket som helst anna tidspunkt kunne også egna seg).\r\nJeg har tidligere tatt en kikk på løpsdataene fra Runtastic her og her.\r\nHvis det skal være interessant å se på løpsdata, må det ha en tydelig funksjon. Det er riktignok gøy å lage pene grafer med pene farger, men da kunne jeg likegodt gått tilbake til å finne SSB-data.\r\nMotivasjon gjennom å se hvordan det går\r\nFor det første kan det bidra til motivasjon: spillifisering av trening kan kanskje gjøre meg mer motivert, ved å vise hvor langt jeg har løpt, og inspirere meg til å løpe mer enn sist. Runtastic minner meg på at jeg skal løpe, gir meg oppdateringer på hvor langt jeg har løpt, med videre.\r\nDenne funksjonen vil bli langt mindre med en årsrapport, vil jeg tro - for å få full effekt av noe slikt trenger en hyppigere oppdateringer som holder deg i gang. Når det er gått et år er det for seint å finne ut at du har gjort fryktelig mye mindre enn året før. Et dashboard ville vært bedre for denne typen formål - og det finner jeg vel allerede i Runtastic.\r\nForståelse, som kan gjøre meg i stand til å løpe bedre\r\nFor andre kan det gi forståelse, som igjen gir meg rom for forbedringer: Gjennom den tidligere kikken på treningsdataene mine lærte jeg at aktiviteten har svingt mye i de årene jeg har løpt. Det er lite sesongvariasjon, men mer motivasjons- og livshendelsesvariasjon: datamønstrene på når jeg har løpt mer, lenger og raskere, samvarierer temmelig bra med større ting som har skjedd - som barn, nye jobber, og flytting. Når noe stort inntreffer, har jeg slutta å trene - og da har det tatt meg tid å begynne igjen.\r\nMotivasjon og vaner er i det hele tatt en komplisert affære. Jeg antar at jeg funker slik at jo mindre jeg må motivere meg selv hver eneste gang for å gå og trene, jo lettere er det å fortsette. Det vil si, jo mer innebygde vaner jeg klarer å gjøre det til (“alltid på en tirsdag”, “alltid på seminar”, osv.), jo lettere vil det bli. Forsøket med å se på treningsvarighet som forløp indikerte at det muligens kunne være slik - hvis jeg holder jevnlig trening i mer enn rundt to måneder, klarer jeg å holde på i langt flere måneder.\r\nFormodentlig er det da også slik at hvis jeg trapper ned treninga, så blir det tyngre å fortsette, og lettere å falle fra.Jeg lærte også at jeg er ganske langt unna målet mitt om 3 treningsøkter per uke.\r\nDet er vanskelig å si om løpsdeltakelse har en tydelig motiverende faktor - det ser ut til å kunne slå ulikt ut: av og til har jeg trent meg opp til et løp, og så trent drastisk mye mindre etterpå. Andre ganger har jeg fortsatt treninga. Andre ganger har jeg ikke trent noe særlig før et løp, men økt innsatsen i etterkant.\r\nPå den positive sida ser jeg at jeg over åra har klart å øke puls og hastighet på treningsøktene, noe jeg glatt tolker som at jeg har klart å få mer effekt ut av treningsøktene.\r\nHva så? Hva er de viktigste tingene å ta med seg fra løpsåret 2019?\r\nantall løpsaktiviteter: det viktigste er å få beveget seg, lite eller mye. Flere løpeturer er altså bra.\r\nantall kilometer løpt: grovt sett vil det være bra å løpe lengre, heller enn kortere.\r\nkvalitet: uker med mer enn 75 minutter løping, dvs. uker hvor jeg når Helsedirektoratets anbefaling til høy aktivitet.\r\nDataene\r\nAntall løpsaktiviter\r\n\r\n\r\nggplot(data = df) + \r\n  geom_bar(aes(x = as.factor(year))) + \r\n  labs(x = \"År\", y = \"Antall løpeturer\", title = \"I 2019 løp jeg 82 turer\", subtitle = \"Nesten like mange som i 2018\")\r\n\r\n\r\n\r\nAntall kilometer løpt\r\n\r\n\r\nggplot(data = df) + \r\n  geom_bar(aes(x = as.factor(year), weight = distance)) + \r\n  labs(x = \"År\", y = \"Hvor langt jeg løp\", title = \"I 2019 løp jeg ca. 700 kilometer\", subtitle = \"100 kilometer mindre enn 2018, men langt mer enn tidligere år\")\r\n\r\n\r\nggplot(data = df, aes(x = as.factor(year), y = distance)) + \r\n  geom_boxplot() + \r\n  geom_jitter(colour = \"steelblue\", alpha = 0.2) + \r\n  labs(x = \"År\", y = \"Hvor langt jeg løp\", title = \"Medianturen i 2019 var kortere enn i 2019\", subtitle = \"2019 lignet mer på 2017 i lengden på løpeturer\")\r\n\r\n\r\n\r\nKvalitet: Uker med mer enn 75 minutter løping\r\nI følge Helsedirektoratet bør voksne være i fysisk aktivitet i 150 minutter moderat intensitet i uka, eller 75 minutter med høy intensitet. Høy intensitet tilsvarer løping.\r\nVed opptelling ser jeg at mange av ukene med trening, har mer enn 75 minutter med trening i seg. Men de langt fleste ukene er imidlertid uten noen registrert trening.\r\n\r\n\r\ntemp = group_by(df, year, week) %>%\r\n  summarise(antall_minutter = sum(duration_min, na.rm = TRUE)) %>%\r\n  ungroup()\r\n\r\ntemp = left_join(expand(temp, year, week = 1:52), temp) %>%\r\n  mutate(yearweek = ifelse(nchar(week) == 1, paste0(0, week), week),\r\n         yearweek = paste0(year, yearweek),\r\n         id = seq_along(yearweek),\r\n         treningsdose = ifelse(antall_minutter >= 75, \"Over 75 min\", \"Under 75 min\")\r\n         )\r\n\r\ntemp$treningsdose[is.na(temp$treningsdose)] = \"Under 75 min\"\r\n\r\nggplot(data = temp) + \r\n  geom_bar(aes(x = treningsdose)) + \r\n  facet_wrap(~year) + \r\n  labs(x = \"Trening i over eller under 75 minutter i uka?\", y = \"Antall\", title = \"Tre av fem uker  er over Helsedirektoratets anbefaling\")\r\n\r\n\r\nggplot(data = temp, aes(x = id, y = antall_minutter)) + \r\n  geom_point(aes(colour = treningsdose)) + \r\n  geom_smooth() +\r\n  geom_hline(aes(yintercept = 75)) + \r\n  geom_vline(aes(xintercept = 52)) +\r\n  geom_vline(aes(xintercept = 104)) +\r\n  geom_vline(aes(xintercept = 156)) +\r\n  geom_vline(aes(xintercept = 208)) +\r\n  geom_vline(aes(xintercept = 260)) +\r\n  annotate(\"text\", label = \"2015\", x = 26, y = 350) + \r\n  annotate(\"text\", label = \"2017\", x = 130, y = 350) +\r\n  annotate(\"text\", label = \"2019\", x = 234, y = 350) +\r\n  labs(x = \"Tid\", y = \"Trening per uke (minutter)\", title = \"Mange uker når anbefalt treningsdose i 2019\", subtitle =\"Men nedadgående trend mot slutten av året\")\r\n\r\n\r\n\r\nHva tilsier dette at jeg skal klare å få til i 2020?\r\nHvert år, litt bedre, litt mer. Ut ifra dette vil jeg prøve å få til:\r\n- Opp mot 40 av 52 uker med anbefalt aktivitetsmengde,\r\n- Det tilsier også at jeg bør øke antallet løpeturer med en 10-12 flere enn i 2019,\r\n- Det burde også tilsi at jeg kan løpe omlag 70 kilometer lengre.\r\nMen! Etter en liten test av HelseNorges “Hvordan har du det?”-test, har jeg fått enda flere tips om at jeg bør innføre jevnlig styrketrening. Hvis jeg skal gjøre det, går det fort på bekostning av løping - og i hvert fall mer løping enn i dag.\r\n\r\n\r\n\r\n",
    "preview": "posts/2020-01-03-rasker-2019-good-year/rasker-2019-good-year_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2023-11-25T07:55:08+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-12-14-resultater-eliteserien-2019/",
    "title": "Resultater av Eliteserien 2019 - hvem kom nærmest?",
    "description": "Da var Eliteserien over for i år. Hvordan gikk det med [tippinga](https://suppe-og-analyse.netlify.com/post/eliteserien-2019-hvordan-blir-tabellen-til-slutt/) fra mars? Da bestemte jeg for å legge gjennomsnittet av oddssidenes tipping og avisenes ekspertkommentarer til grunn..",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2019-12-14",
    "categories": [],
    "contents": "\r\nHvordan ser dette ut opp i mot resultatet? Hvordan ble tabellen til slutt? Jo slik:\r\n\r\n\r\n\r\n\r\n\r\nkable(arrange(select(df, Lag, Resultat, MinPrognose = Prognose), Resultat)) \r\n\r\nLag\r\nResultat\r\nMinPrognose\r\nMolde\r\n1\r\n3.6\r\nBodø/Glimt\r\n2\r\n10.6\r\nRosenborg\r\n3\r\n5.0\r\nOdd\r\n4\r\n8.2\r\nViking\r\n5\r\n39.8\r\nKristiansund BK\r\n6\r\n7.8\r\nHaugesund\r\n7\r\n8.0\r\nStabæk\r\n8\r\n34.0\r\nBrann\r\n9\r\n9.0\r\nVålerenga\r\n10\r\n5.2\r\nStrømsgodset\r\n11\r\n27.2\r\nSarpsborg 08\r\n12\r\n15.6\r\nMjøndalen\r\n13\r\n39.0\r\nLillestrøm\r\n14\r\n8.4\r\nTromsø\r\n15\r\n28.2\r\nRanheim\r\n16\r\n33.6\r\n\r\nSom vi ser av tabellen: ikke veldig nærme - men heller ikke helt tilfeldig.\r\nHvordan ser dette ut i forhold til de forskjellige prognosene?\r\n\r\n\r\ntemp = gather(df, ID, prognose, Nettavisen:Prognose) %>%\r\n  mutate(type = ifelse(ID == \"Resultat\", \"Resultat\", \"Prognose\"))\r\n\r\nggplot() + \r\n  geom_count(data = filter(temp, type == \"Prognose\"), aes(x = prognose, y = Lag), colour = \"grey\") +\r\n  geom_point(data = filter(temp, type == \"Resultat\"), aes(x = prognose, y = Lag), colour = \"black\") +\r\n  geom_point(data = filter(temp, ID == \"Prognose\"), aes(x = prognose, y = Lag), colour = \"red\") +\r\n  labs(x = \"Plassering\", y = \"Lag\", colour = \"Prognose eller resultat?\")\r\n\r\n\r\n\r\nHvem er nærmest? Vi bruker RMSE som mål, den gir større straff til store feil:\r\n\r\n\r\n#RMSE\r\nrmse <- function(feil){\r\n    sqrt(mean(feil^2))\r\n}\r\n\r\ntemp = data.frame(ID = as.character(), rmse = as.numeric(), stringsAsFactors = FALSE)\r\n\r\nfeil = df$Resultat - df$Nettavisen\r\ntemp = bind_rows(temp, data.frame(ID = \"Nettavisen\", rmse = rmse(feil), stringsAsFactors = FALSE))\r\nfeil = df$Resultat - df$Oddschecker\r\ntemp = bind_rows(temp, data.frame(ID = \"Oddschecker\", rmse = rmse(feil), stringsAsFactors = FALSE))\r\nfeil = df$Resultat - df$Dagsavisen\r\ntemp = bind_rows(temp, data.frame(ID = \"Dagsavisen\", rmse = rmse(feil), stringsAsFactors = FALSE))\r\nfeil = df$Resultat - df$Dagbladet\r\ntemp = bind_rows(temp, data.frame(ID = \"Dagbladet\", rmse = rmse(feil), stringsAsFactors = FALSE))\r\nfeil = df$Resultat - df$Aftenposten\r\ntemp = bind_rows(temp, data.frame(ID = \"Aftenposten\", rmse = rmse(feil), stringsAsFactors = FALSE))\r\nfeil = df$Resultat - df$Prognose\r\ntemp = bind_rows(temp, data.frame(ID = \"MinPrognose\", rmse = rmse(feil), stringsAsFactors = FALSE))\r\n\r\nkable(arrange(temp, rmse))\r\n\r\nID\r\nrmse\r\nDagsavisen\r\n4.663690\r\nDagbladet\r\n5.267827\r\nOddschecker\r\n5.408327\r\nNettavisen\r\n5.488625\r\nMinPrognose\r\n14.755169\r\nAftenposten\r\n67.433300\r\n\r\nAftenposten var den beste ekspertpanelet her, fulgt av Dagsavisen. Dagbladet, Oddsen og Nettavisen gjør det alle dårligere. Men forskjellene er ikke veldig store.\r\n\r\n\r\n\r\n",
    "preview": "posts/2019-12-14-resultater-eliteserien-2019/resultater-eliteserien-2019_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2023-11-25T07:55:08+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-11-17-basic-statistical-conclusions/",
    "title": "Grunnleggende statistiske slutninger fra utvalgsundersøkelser",
    "description": "Hvorfor gjennomføre en utvalgsundersøkelse, hvordan et utvalg fra en populasjon forholder seg til populasjonen, og hvordan du kan si noe om hvor sikker du er på at estimatet ditt fra utvalget er i nærheten av det reelle tallet.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2019-11-17",
    "categories": [],
    "contents": "\r\nEn grunnleggende arbeidshest i en samfunnsviters verktøyboks er utvalgsundersøkelsen. En smarting fant på et tidspunkt ut at en ikke trengte å spørre alle i en populasjon et spørsmål, for å kunne si noe om hva hele populasjonen mente.\r\nI følge Ringdals “Enhet og mangfold” var dette en amerikansk nyvinning i mellomkrigstida som først slo igjennom etter andre verdenskrig (Ringdals bok er nå i sin fjerde utgave, ser jeg - selv er jeg den stolte eier av førsteutgaven, anmeldt bl.a. her). Her går historien til utvalgsundersøkelser hånd i hånd med historien til holdningsundersøkelser, drevet fram av bl.a. George Gallupp.\r\nRent umiddelbart er jeg litt skeptisk til denne framstillingen - for generaliseringer fra utvalg til populasjon må da ha vært vanlig også før dette? Om ikke i samfunnsvitenskapen, så på andre felt - som i bryggeribransjen? Nyvinningen var nok derfor heller at en brukte etablerte metoder fra andre områder, på samfunnsvitenskapelige sysler.\r\nUansett, i dag er utvalgsundersøkelsen en riktig så sterk arbeidshest for en samfunnsviter. Riktignok ikke så sterk som før - med eksplosjonen i tilgjengelighet de siste årene har fallende svarprosenter blitt et problem for alle, over alt.\r\nRundt denne formen for undersøkelser finnes det en hel skole av slutningslogikk: hvordan gjøre en slutning fra et utvalg, til en hel populasjon?\r\nvi lager noe eksempeldata for en hel populasjon\r\nvi tar ett utvalg fra populasjonen, og ser om det treffer.\r\nvi tar mange utvalg fra populasjonen, for å vise fram sannsynlighetsfordelinga til estimatet for gjennomsnittverdier.\r\nved hjelp av litt matte, beregner vi standardfeil for parameterestimatene fra utvalgene, som sier noe om usikkerheten vår.\r\nFramstillingen bygger først og fremst på Skogs “Å forklare sosiale fenomener”, når jeg har trengt litt fasit-assistanse.\r\n\r\n\r\nlibrary(tidyverse)\r\n\r\n#settings\r\ntheme_set(theme_minimal())\r\nset.seed(1106)\r\noptions(scipen = 100)\r\n\r\n\r\nPopulasjonens holdning til X!\r\nSi at vi har en populasjon med 1000 enheter, som vi ønsker å vite noe om holdningene til på noen spørsmål:\r\nett ja/nei-spørsmål (f.eks.: har du hest?)\r\nett spørsmål hvor svaret kan oppgis som en kontinuerlig variabel (f.eks.: hva er hesten verdt?)\r\nett holdningsspørsmål på en skala fra 1 til 5, fra svært dårlig via ok til svært god (f.eks.: hvor god er du til å ri på hest?).\r\nDessverre finner jeg ikke slike data liggende rundt, men jeg konstruerer de.\r\n\r\n\r\ndf = data.frame(\"ID\" = 1:1000, stringsAsFactors = FALSE)\r\n\r\n#binomisk sannsynlighet for holdning #1 \r\ndf$holdning_1 = rbinom(1000, 1, 0.5)\r\n\r\n#kontinuerlig normaltfordelt variabel på verdi holdning #2\r\ndf$holdning_2 = rnorm(1000, 12500, 2500)\r\n\r\n#diskret sannsynlighet\r\n#trekker denne fra en uniform fordeling, og runder av til nærmeste heltall\r\n#kunne egentlig også brukt sample() med replacement = TRUE?\r\ndf$holdning_3 = round(runif(1000, min = 1, max = 5))\r\n\r\n\r\nFordelingen av holdningene i populasjonen ser da slik ut:\r\n\r\n\r\n\r\nHer ser vi altså at\r\nja eller nei er temmelig likt fordelt i populasjonen (50,4 % sier ja)\r\nden kontinuerlige variabelen er normalfordelt rundt 12 500.\r\n2, 3 og 4 er de mest populære svarene på #3, med minst på 5 og noe fler på 1.\r\nDette er ikke overraskende, men følger av hvordan variablene er konstruerte. Noe mer støy kunne nok vært lagt inn, for å gjøre det litt mer interessant.\r\nDette er holdninger eller verdier i populasjonen vår, bestående av 1000 enheter. Hva så når vi skal gjøre et utvalg?\r\nUtvalgets holdning til X\r\nI de aller fleste tilfeller av slike holdningsundersøkelser kan vi imidlertid ikke undersøke hele populasjonens holdning til X. Det er for dyrt, for tidkrevende - og ofte også helt unødvendig. I stedet kan vi trekke et tilfeldig utvalg fra populasjonen. Dette går helt fint, gitt at:\r\nalle medlemmer har samme sannsynlighet for å komme med i utvalget, og\r\nsjansen for at en enhet kommer med, er uavhengig av om bestemte andre enheter kommer med\r\nSå hvordan ville fordelinga av holdninga sett ut i et sjanseutvalg på f.eks. 100 personer?\r\n\r\n\r\nutvalg = sample_n(df, 100, replace = FALSE)\r\n\r\n\r\nAntallet er åpenbart annerledes - men treffer utvalget på samme andeler?\r\n\r\n\r\n\r\nNaturlig nok - ikke helt. Men hvor nærme er dette? Og hvor nærme kunne vi sagt at det var, hvis vi ikke hadde kjent de rød verdiene - populasjonsverdiene?\r\nFor å svare på det, må vi en liten omtur om sannsynlighetsfordelinger:\r\nSannsynlighetsfordeling av gjennomsnittsverdier\r\nVi har nå en populasjon, og et utvalg fra denne populasjonen som ikke treffer helt på den sanne virkeligheten. Vanligvis kjenner du ikke populasjonens sanne fordeling, eller hvilke egenskaper den har. Så hvordan kan du gjøre slutninger basert på utvalget? Jo, via en teoretiske sannsynlighetsfordeling for egenskaper ved det du måler. Se for det at du trekker mange utvalg fra samme populasjon - hvordan ville denne fordelt seg?\r\nHvis vi trekker noen utvalg fra populasjonen vår, kan vi visualisere dette:\r\n\r\n\r\nutvalg = sample_n(df, 100, replace = FALSE)\r\nutvalg$utvalgsnummer = 1\r\n\r\nfor(i in 2:100){\r\n  temp = sample_n(df, 100, replace = TRUE)\r\n  temp$utvalgsnummer = i\r\n  utvalg = bind_rows(utvalg, temp)\r\n}\r\n\r\n\r\nVi kan begynne med det første spørsmålet - ja eller nei-spørsmålet, kodet som 0 og 1. Hvis vi beregner gjennomsnittlig andel som har besvart dette med ja i de ulike utvalgene, så kan vi vise hvordan gjennomsnittene i disse utvalgene fordeler seg.\r\n\r\n\r\n\r\nDen svarte linja viser fordelinga av gjennomsnittlig andel hesteeiere i 100 utvalg fra populasjonen. Den røde, blå og grønne viser henholdsvis 10, 20 og 50 utvalgsgjennomsnitt. Jo flere utvalg, jo mer bør den sentrere seg rundt der vi - fra over - veit at det faktiske gjennomsnittet ligger.\r\nTilsvarende øvelse kan gjentas for den kontinuerlige variabelen, og den diskrete variabelen.\r\n\r\n\r\n\r\nSå hva er poenget med dette? Deto flere utvalg en trekker fra en populasjon, jo flere av utvalgene vil ha gjennomsnitt i nærheten av det sanne utvalget. Dette gjelder særlig for større utvalg (over ca. 50?). For de fleste praktiske formål, hvor vi ikke kjenner populasjonsverdien, og vi ikke kan måle den direkte, er det også upraktisk å ta et stort antall utvalgsundersøkelser. Men fordi vi ser at parameterestimatene i et stort antall utvalg er om lag normalfordelt (også for verdier som ikke selv er normalfordelte), kan vi estimere hvor usikre vi er på at den sanne populasjonen ligger innafor et intervall rundt punktestimatet vårt.\r\nSlutninger om en andel\r\nDen unøyaktigheten vi får når vi bruker andelen fra et utvalg som estimat for andelen i en populasjon, kan måles med standardfeilen til estimatet. En vanlig tommelfingerregel for unøyaktighetsberegninger er ca. to ganger standardfeilen på hver side av parameterestimatet.\r\n\r\n\r\nutvalg = filter(utvalg, utvalgsnummer == 1)\r\n\r\n# Når populasjonsandelen er kjent\r\n\r\n#standardfeil for et estimat til en andel\r\np = sum(df$holdning_1/length(df$holdning_1)) #faktisk andel i populasjonen\r\nsem = sqrt(p*(1-p))/sqrt(length(utvalg$ID))\r\n\r\ntemp = data.frame(\"populasjonsparameter_kjent\" = FALSE, \"andel\" = p, \"standardfeil\" = sem)\r\n\r\n# Når populasjonsandelen er ukjent\r\n\r\n#standardfeil for et estimat til en andel\r\np_hat = sum(utvalg$holdning_1/length(utvalg$holdning_1)) #parameterestimatet fra utvalget\r\nsem = sqrt(p_hat*(1-p_hat))/sqrt(length(utvalg$ID))\r\n\r\ntemp = bind_rows(temp, data.frame(\"populasjonsparameter_kjent\" = FALSE, \"andel\" = p_hat, \"standardfeil\" = sem))\r\n\r\n\r\n\r\n\r\nknitr::kable(temp)\r\n\r\npopulasjonsparameter_kjent\r\nandel\r\nstandardfeil\r\nFALSE\r\n0.544\r\n0.0498060\r\nFALSE\r\n0.560\r\n0.0496387\r\n\r\nI mitt eksempel (som bør være det samme som eksempelet som vises her, siden jeg har brukt set.seed()) er andelen som har svart ja på holdningsspørsmål 1 54,4 % i populasjonen på 1000 personer. Som vi ser av formelen, avgjøres sikkerheten av størrelsen på utvalget og størrelsen på andelen i populasjonen: Jo nærmere den faktiske andelen er 50 %, jo større usikkerhet. Og jo større utvalg, destor mindre usikkerhet. I vårt tilfelle er andelen ganske nær 50 %, og utvalget er på 100 personer. Standardfeilen er derfor på ca. 5 %, eller mellom 44 % og 64 %\r\nI utvalget vi har tatt, har 53 % svart ja. Standardfeilen er veldig lik her, som i eksempelet over - faktisk kan en vel si helt lik, når de 8 første desimalene er like. Dvs. at standardfeilen tilsier at den sanne verdien ligger et sted mellom 43 % og 63 %.\r\nKontinuerlig variabel\r\n\r\n\r\n#når gjennomsnittet i populasjonen er kjent\r\n\r\n#standardfeil for estimatet til gjennomsnittet av en kontinuerlig, normalfordelt variabel\r\ns = mean(df$holdning_2) #gjennomsnitt i populasjonen\r\nsem = s/sqrt(length(utvalg$ID))\r\n\r\ntemp = data.frame(\"populasjonsparameter_kjent\" = TRUE, \"gjennomsnitt\" = s, \"standardfeil\" = sem)\r\n\r\n#når gjennomsnittet i populasjonen er ukjent\r\n\r\ns_hatt = mean(utvalg$holdning_2) #parameterestimatet for gjennomsnitt\r\nsem = s_hatt/sqrt(length(utvalg$ID))\r\n\r\ntemp = bind_rows(temp, data.frame(\"populasjonsparameter_kjent\" = FALSE, \"gjennomsnitt\" = s_hatt, \"standardfeil\" = sem))\r\n\r\n\r\n\r\n\r\nknitr::kable(temp)\r\n\r\npopulasjonsparameter_kjent\r\ngjennomsnitt\r\nstandardfeil\r\nTRUE\r\n12392.58\r\n1239.258\r\nFALSE\r\n12785.56\r\n1278.556\r\n\r\nHer er gjennomsnittsverdien i populasjonen 12 393 (kroner for en hest). Den beregnede standardfeilen for utvalg er 1 239, dvs. at ca. 95 % av utvalg vil være mellom 9 915 og 14 871.\r\nFor utvalget ser vi at gjennomsnittet er på 12 575 (kroner for en hest). Dette er ikke langt unna den sanne verdien - men det er helt tilfeldig. Et konfidensintervall rundt dette punktestimatet vil være fra 10 061 til 15 089. Dvs. et ganske stort sprang fra rundt 10 til 15 000 kroner.\r\nKategorisk variabel\r\nEn tilsvarende tilnærming som denne kan brukes for vårt holdningsspørsmål nr. 3. Her kunne vi både anslått standardfeil for andelsestimater (“hvor stor andel liker ikke hest?”), og for gjennomsnittsestimtatet (“hva er den gjennomsnittlige holdninga til hest?”). Matematikken følger samme mønster som over.\r\n\r\n\r\n\r\n",
    "preview": "posts/2019-11-17-basic-statistical-conclusions/basic-statistical-conclusions_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2023-11-25T07:55:08+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-11-03-too-many-books-on-data-analysis/",
    "title": "Alt for mange bøker om dataanalyse",
    "description": "Hylla mi er full av bøker - alt for mange bøker. Jeg snakker om de beste.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2019-11-03",
    "categories": [],
    "contents": "\r\nJeg plukka først opp R i 2010. Rett etter studiene i min første jobb, ble jeg satt til å gjøre div. analyser av data i AgriAnalyse. Med en del frihetsgrader til å selv velge metoder og formidlingsmåter, fant jeg raskt ut at datavisualiseringer var noe folk var gira på. Ikke at jeg var god på det - men noen raske internettsøk viste at R var et program mange brukte for å lage kart, og trekke ut data fra figurer slik at de kunne selv bruke figurene. Det hjalp også at vi ikke hadde råd til dyre SPSS-lisenser for alle ansatte.\r\nSiden da har det hopa seg opp med bøker i bokhylla mi, både den fysiske og den digitale. Nå har det gått noen år, og jeg trenger derfor å rydde litt opp i hylla mi. Her er resultatet av ryddinga - hva er det jeg kan tenke meg å beholde? Jeg skiller mellom fem kategorier/bokhyller:\r\nInnføringer i statistikk\r\nInnføring i R-programmering\r\nMer avanserte statistiske emner\r\nSpesifikke R-pakker\r\nGrafikk\r\nGrunnleggende innføring i statistikk\r\nSkog (2009). Å forklare sosiale fenomeneter. En regresjonsbasert tilnærming. Forlagsside her. En helt grunnleggende innføring i kvantitativ metode for samfunnsvitere. Skog er innom epistemologiske byggesteiner for kausale slutninger, grunnleggende sannsynlighetsteori og lineær og logistisk regresjon. Han knytter det sammen på en god måte, noe som gjør det mulig å forstå hvorfor en bør bruke metodene en blir lært å bruke.\r\nPoldrack (2019). Statistical Thinking for the 21st Century. Bookdown-bok her. En innføring i statistikk, som også viser til en del nyere utvikling i “data science”-delen av feltet. Det kanskje viktigste bidraget er at boka vektlegger virkelige dataeksempler, inkludert simuleringer og eksempler for de statistiske konseptene.\r\nPeng (2016). Exploratory Data Analysis with R. Bookdown-bok her. Alle statistikkbøker begynner med å si at du må se på dataene dine. Her er en grundig innføring i hvordan en kan gjøre det, med R.\r\nDalgaard (2008). Introductory statistics with R. God gammeldags bok, uten nettside og slikt. Dekker over både grunnleggende, klassisk R og grunnleggende statistiske metoder - fra deskriptiv statistikk og visualisering, til multivariat regresjon, testing og overlevelsesanalyse.\r\nGelman og Hill (2009). Data Analysis Using Regression and Multilevel/Hierarchical Models. Forfatternes bok-side her. Kjempegod innføring i regresjon og flernivå-analyse. Her er både matematisk formalisme og kode, forklart på en fornuftig og forståelig måte. Å kalle dette en grunnleggende innføring er delvis en løgn, for utover i boka tar det av med Bayesiansk flernivåanalyse, BUGS og i det hele tatt.\r\nLindeløv (2019). Common statistical tests are linear models (or: how to teach stats). Ikke en bok, men en ganske lang bloggpost. Lindeløv gjennomgår hvordan alle (nesten) statistiske tester kan oppsummeres som lineære modeller. Ideen er at studenter som skal lære statistikk bør lære regresjon og lineær modell først, som en grunnleggende byggestein. Ikke sist (eller kanskje mer i midten?) som i dag, etter at en lærer en hel haug med ulike tester for ulike kombinasjoner av variabeltyper. Ettersom jeg fortsatt ikke husker når jeg skal bruke ulike korrelasjoner, ensidig, tosidig, og med ulike fordelinger - så kan jeg like dette.\r\nCaffo (udatert). Statistical inference for data science. Leanpub-publikasjon som hører med til et kurs i Statistical Inference i Johns Hopkins “Data Science Specialization”-kurs på Coursera. Dette var ei kursrekke jeg prøvde meg på noen ganger, uten å komme i mål - og jeg falt helt av når Coursera lukket plattformen sin mer, og la mer opp til obligatorisk oppmøte, scanning av pass, og så videre. Boka er grei, men fungerer mer som en oppfriskning, ettersom den er mer som notater fra forelesninger enn ei faktisk bok.\r\nInnføring i R-programmering\r\nGrolemund og Wickham (udatert). R for Data Science. Bookdown her. Den definitive guiden til R-programmering med tidyverse-programmering, og tar deg fra arbeidsflyt, databearbeiding, programmering, og modellering til formidling.\r\nPeng (2019). R Programming for Data Science. Bookdown her. Roger Pengs (kjent fra Simply Statistics og Not So Standard Deviations-podcasten) innføring i hvordan en bruker R som programmeringsspråk. Var også en del av Coursera-kurset jeg tok.\r\nLong og Teetor (2019). R Cookbook. Bookdown her. Oppskrifter på en rekke utfordringer i R. Ikke en innføring i statistikk, men mange praktiske eksempler på hvordan problemer kan løses.\r\nWickham (udatert). Advanced R. Bookdown her. Wickhams innføring i R-programmering og R-språket.\r\nMer avanserte statistiske emner\r\nFriedman, Hastie og Tibshirani (2009). The Elements of Statistical Learning. Data Mining, Inference and Prediction. Springer-sida her. Mer avansert tilnærming til både supervised og unsupervised læring, på en forståelig måte. Jeg har særlig brukt kapittelet om Support Vector Machines, men også trærne.\r\nCoghlan (2012). Little Book of R for Time Series. Også tilgjengelig som nettside. En superenkel innføring i tidsserier for R, mer programmeringssida enn statistikk-sida.\r\nSpesifikke R-pakker\r\nKuhn (2019). The caret package.Her. Innføring i caret - classification and regression training, et sett av funksjoner som gjør prediktiv modellering lettere.\r\nSilge og Robinson (2019). Text Mining with R. A Tidy Approach. Bookdown her. En innføring i tekstanalyse med R, i et tidy format. Det er ganske grunnleggende, men svært nyttig og en god innføring.\r\nXie, Thomas og Hill (2019). blogdown: Creating Websites with R Markdown. Her. Innføring i blogdown-pakken og infrastrukturen en trenger for å etablere en RMarkdown-drevet blogg. Som denne.\r\nGrafikk\r\nChang (2019). R Graphics Cookbook, 2nd edition. Tilgjengelig her. En haug med oppskrifter på hvordan praktiske visualiseringsproblemer skal løses. Ofte finner jeg gode svar her, og jeg liker kodestilen - når jeg husker å lete. Ofte har jeg imidlertid andre problemer - jeg trenger et svar fort, og Google er da et bedre sted å spørre. Vanskeligere: når jeg vet hvilken oppgave jeg har, men ikke hvilken visualisering som er egnet for å løse den. Da er Unwins bok bedre.\r\nUnwin (2015). Graphical Data Analysis with R. Nettsida til boka ligger her. Boka er organisert etter oppgave (utforske kategoriske data, utforske tidsserier, vise sammenhenger, mm), og ikke graftype.\r\nBøker om praktisk dataarbeid\r\nBaker (udatert). Practical Data Cleaning. 19 Essential tips to scrub your dirty data and keep your boss happy. Leanpub-publikasjon. 19 fornuftige tips til arbeid med data, basert på Excel.\r\nLeek (udatert). The Elements of Data Analytic Style. Leanpub-publikasjon. Grei sjekkliste for data-analyseprosjekter. Ikke spesielt dyptpløyende, og ganske grunnleggende - men det er også kjekt.\r\nWickham (udatert). The tidyverse style guide. Her. Guide for kodestilen “tidyverse”.\r\nUtdaterte bøker\r\nKuhnert og Venables (2005). An introduction to R. Software for statistical modeling and computing. Tilgjengelig f.eks. her. Fin eksempel-basert introduksjon til R, som jeg brukte mest til å få et grunnleggende innblikk i hva dette programmet var, hvordan jeg kunne tenke om datatyper, kontrollstrukturer (dvs. programmeringsaspekter), og så videre. Den er fra 2005, før RStudio, tidyverse, RMarkdown - og også før Stackoverflow slo til og utkonkurrerte den ekstremt sinna R-help epostlista.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-25T07:55:08+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-10-29-rasker-survival-analysis/",
    "title": "Forløpsanalyse på treningsdata",
    "description": "Et forsøk på å skvise noe mer innsikt ut av treningsdataene med forløpsanalyse.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2019-10-29",
    "categories": [],
    "contents": "\r\nSist så jeg nærmere på treningsdataene mine, og fant litt ulike måter å visualisere dem på. Men kan de også kjøres gjennom en forløpsanalyse?\r\nHer finnes det to tilnærminger, og to interessante forløp å studere.\r\n- Den ene er tida mellom enkelttreninger, dvs. egentlig hvor lange pausene er, og hva som bidrar til kortere vs. lengre pausetider.\r\n- Den andre er tida i en lengre treningsperiode, bestående av flere treningsøkter, før den brytes opp.\r\nHva konklusjonen blir? Dette fungerer sånn passe godt som eksempel på en ide som ikke viser å gi stort, men ikke så mye mer.\r\nFor å få dette over på et forløpsformat, lager jeg en data.frame med alle datoer i rekka, før jeg joiner inn treningsdataene:\r\n\r\n\r\ndf_alle = data.frame(dato = seq(from = as.Date(ymd_hms(min(df$start_time))), to = as.Date(ymd_hms(max(df$start_time))), by = 1)) %>%\r\n  left_join(., df) %>%\r\n  arrange(dato) %>%\r\n  mutate(er_trening = ifelse(is.na(start_time), FALSE, TRUE)\r\n         ) \r\n#her må jeg også håndtere datoer som har to treningsøkter registrert.\r\n\r\n\r\nDagers pause\r\nSå kan jeg kartlegge hvor mange dagers pause jeg har mellom treningsøkter. I samme slengen legger jeg på en identifikator, som identifiserer hver treningsøkt + dagene med restitusjon som tilhørende til en “økt”.\r\n\r\n\r\ni = 1\r\nj = 0\r\n`økt` = 0 \r\n\r\ndf_alle$dager_siden_trening = NULL\r\ndf_alle$økt_id = NULL\r\n\r\n#faktisk\r\nfor(i in 1:length(df_alle$dato)){\r\n  if(df_alle$er_trening[[i]] == TRUE){\r\n    j = 0\r\n    `økt` = `økt` + 1\r\n    df_alle$dager_siden_trening[[i]] = j\r\n    df_alle$`økt_id`[[i]] = `økt`\r\n  }\r\n  if(df_alle$er_trening[[i]] == FALSE){\r\n    j = j+1\r\n    df_alle$dager_siden_trening[[i]] = j\r\n    df_alle$`økt_id`[[i]] = `økt`\r\n  }\r\n}\r\n\r\n#av en eller anna grunn, jeg forstår ikke hvorfor, blir variablene som redigeres her\r\n#lister. Dette er jo noe nytt R har begynt med siden jeg først lagde denne\r\n#unlister dem ganske enkelt ???\r\n\r\ndf_alle = mutate(df_alle,\r\n                 dager_siden_trening = unlist(dager_siden_trening),\r\n                 `økt_id` = unlist(`økt_id`)\r\n                 )\r\n\r\ntemp1 = group_by(df_alle, `økt_id`) %>%\r\n  summarise(dager_restitusjon = max(dager_siden_trening))\r\n\r\ntemp2 = ungroup(temp1) %>%\r\n  group_by(dager_restitusjon) %>%\r\n  summarise(antall = n())\r\n\r\nggplot(data = temp2) + \r\n  geom_col(aes(x = dager_restitusjon, y = antall))\r\n\r\n\r\n\r\nLangt de fleste resitusjonsperiodene er på 1-4 dager - nærmere 250 av de 292 treningsaktivitetene ble etterfulgt av ei slik pause. Men så dras snittet opp av de lengre periodene på ei uke, to uker og mer.\r\nMin teori er at det ikke er stort å hente her ved å se på dette som et forløp: alle pausene er avslutta med en ny treningsøkt, og sensurering av observasjoner er ikke et problem.\r\nDet er to grunnleggende biter informasjon jeg trenger for å se på dette i et forløps-oppsett: Tid til hendelse, og en indikator på hvilken hendelse som inntraff. Hendelsen er en ny treningsøkt. Tida er lengden på pausen mellom treningsøkter, i dager.\r\n\r\n\r\ndf_survival = ungroup(df_alle) %>%\r\n  select(dato, dager_siden_trening, økt_id, er_trening) %>%\r\n  group_by(økt_id) %>%\r\n  filter(dager_siden_trening == max(dager_siden_trening)) %>%\r\n  mutate(\r\n    pauselengde = dager_siden_trening,\r\n    hendelse = !er_trening\r\n    )\r\n\r\n#en kikk på Surv-objektet\r\ntrening_survival = survfit(Surv(pauselengde, hendelse == TRUE)~1, data = df_survival)\r\ntrening_survival\r\n\r\nCall: survfit(formula = Surv(pauselengde, hendelse == TRUE) ~ 1, data = df_survival)\r\n\r\n       n events median 0.95LCL 0.95UCL\r\n[1,] 292    286      2       2       2\r\n\r\ntemp = broom::tidy(trening_survival) %>%\r\n  filter(time < 50)\r\n\r\nggplot(data = temp, aes(x = time, y = estimate))+\r\n  geom_line() +\r\n  geom_ribbon(aes(ymin=conf.low,ymax=conf.high),alpha=0.2) +\r\n  labs(x = \"Dagers pause\", y = \"Sannsynlighet for å fortsette treningspausa\", title = \"Sannsynlighet for å fortsette treningspause, etter antall dager\", subtitle = \"Kaplan-Meier-kurve\")\r\n\r\n\r\n\r\nHer ser vi det samme mønsteret som i grafen over: langt de fleste pausene er korte, og sannsynligheten for å fortsette ei pause faller ganske bratt de første fire dagene. Deretter flater den ut, og faller langt langsommere etter det.\r\nJeg har ingen egentlig informasjon om pausen, utover lengden på den, og en dato som forteller noe om hvilken del av året pausen var i.\r\nTreningsperioder\r\nMens vi over så på hver enkelt pause, og sannsynligheten for å avbryte pausa og gå tilbake i trening, er det kanskje mer interessant å se på lengre bolker av trening: Det er ikke noe mål i seg selv å ha kortest mulig pauser mellom treningsøktene, også pausene er viktige.\r\nDerfor grupperer jeg disse i bolker av trening, der en tilstrekkelig lang pause gir “frafall” fra treninga. Hvor mange dagers pause gir fall i kondisjonen, slik at en ny oppstart kan sies å starte på et betraktelig lavere nivå enn der man slapp opp? Det spørs på intensiteten på treninga, men det ser (ifølge denne artikkelen) ut til å være slik at:\r\nkondisjonen raskt blir dårligere,\r\nden faller raskere enn den øker i treningsperioden,\r\neksperimenter har vist at alt fra 12 dager til 21 og 28 dager med ingen aktivitet gir betraktelig fall i kondisjon,\r\neffekten av nedtrening ser imidlertid ut til å stabiliere seg etter ei viss tid, ned på et grunnivå,\r\nforskerne antar at også 3-4 dagers pause kan gi fall i kondisjon, men her er det store variasjoner - både psykisk og genetisk. Et tips er å prøve å finne fram til den riktige balansen mellom for kort restitusjon, og for mange - da har en mulighet til å øke evnen sin.\r\nHvor mange ulike perioder snakker vi potensielt her om, hvis vi setter cutoffen et sted mellom 4 dager og 28 dager?\r\n\r\n\r\n#settings for loopen i pauselengder\r\ntemp = data.frame(pauselengde = 4:28, antall_perioder = NA)\r\n\r\nfor(a in min(temp$pauselengde):max(temp$pauselengde)){\r\n#settings for treningsloopen\r\ni = 1\r\ndf_alle$periode[[1]] = 1\r\nperiode = 1 \r\n\r\nfor(i in 2:length(df_alle$dato)){\r\n  if(df_alle$er_trening[[i]] == TRUE){\r\n    if(df_alle$dager_siden_trening[[i-1]] <= a-1){\r\n      df_alle$periode[[i]] = periode\r\n    }\r\n    if(df_alle$dager_siden_trening[[i-1]] > a-1){\r\n      periode = periode + 1\r\n      df_alle$periode[[i]] = periode\r\n    }\r\n  }\r\n  if(df_alle$er_trening[[i]] == FALSE){\r\n    df_alle$periode[[i]] = periode\r\n  }\r\n}\r\n df_alle$periode = unlist(df_alle$periode)\r\n temp[a - (min(temp$pauselengde)-1),2] = max(df_alle$periode)\r\n}\r\n\r\n\r\nggplot(data = temp) + \r\n  geom_line(aes(x = pauselengde, y = antall_perioder)) + \r\n  labs(title = \"Antall treningsperioder\", x = \"Dagers pause for ny periode\", y = \"Antall perioder\")\r\n\r\n\r\n\r\nHvis vi setter cut-off ved 4 dager, er jeg oppe i nærmere 70 distinkte treningsperioder. Antallet perioder avtar ganske bratt til rundt ca. 8 dagers pause, hvorfra det flater ut. Med 12 dagers pause er antallet treningsperioder 15, og 28 er det 6 perioder.\r\nVi går for 12 dager, den korteste pausa forskninga over henviser til som betraktelig dårlig:\r\n\r\n\r\n#settings for treningsloopen\r\ni = 1\r\ndf_alle$periode[[1]] = 1\r\nperiode = 1 \r\n\r\nfor(i in 2:length(df_alle$dato)){\r\n  if(df_alle$er_trening[[i]] == TRUE){\r\n    if(df_alle$dager_siden_trening[[i-1]] <= 11){\r\n      df_alle$periode[[i]] = periode\r\n    }\r\n    if(df_alle$dager_siden_trening[[i-1]] > 11){\r\n      periode = periode + 1\r\n      df_alle$periode[[i]] = periode\r\n    }\r\n  }\r\n  if(df_alle$er_trening[[i]] == FALSE){\r\n    df_alle$periode[[i]] = periode\r\n  }\r\n}\r\n\r\ndf_alle = group_by(df_alle, periode)%>%\r\n  mutate(dag_periode = seq_along(dato))\r\n\r\n#lager en dataframe med den nødvendige informasjonen\r\ndf_survival = ungroup(df_alle) %>%\r\n  select(dato, periode, dag_periode, er_trening) %>%\r\n  group_by(periode) %>%\r\n  filter(dag_periode == max(dag_periode)) %>%\r\n  mutate(\r\n    hendelse = !er_trening\r\n    )\r\n\r\n\r\nMens vi i analysen over så på tiden fra en treningsøkt og fram til neste pause, og sannsynligheten for å avslutte en restitusjonsperiode, ser vi her på lengden på en treningsperiode før den blir avbrutt av en 12-dagerspause - en pause så lang at det skjer et betraktelig fall i kondisjonen.\r\nDen lengste perioden ble avslutta i januar 2019, på nærmere 300 dager - store deler av 2018. Juni 2016 markerte slutten på en nesten like lang treningsperiode.\r\n\r\n\r\nggplot(data = df_survival) + \r\n  geom_point(aes(x = dag_periode, y = fct_reorder(as.factor(dato), dag_periode))) + \r\n  labs(x = \"Varighet på treningsperiode\", y = \"periode_id\", title = \"Lengde på periode\") + \r\n  scale_x_continuous(limits = c(0, 300))\r\n\r\n\r\n\r\nSå hvordan ser dette ut, når vi estimerer en kurve for sannsynligheten for treningsperiode-avbrudd?\r\n\r\n\r\n#en kikk på Surv-objektet\r\ntrening_survival = survfit(Surv(dag_periode, hendelse == TRUE)~1, data = df_survival)\r\ntrening_survival\r\n\r\nCall: survfit(formula = Surv(dag_periode, hendelse == TRUE) ~ 1, data = df_survival)\r\n\r\n      n events median 0.95LCL 0.95UCL\r\n[1,] 15     14     58      36     279\r\n\r\ntemp = broom::tidy(trening_survival)\r\n\r\nggplot(data = temp, aes(x = time, y = estimate))+\r\n  geom_line() +\r\n  geom_ribbon(aes(ymin=conf.low,ymax=conf.high),alpha=0.2) +\r\n  labs(x = \"Dagers varighet på treningsperiode\", y = \"Sannsynlighet for å fortsette trening\", title = \"Sannsynlighet for å fortsette en treningsperiode, etter antall dager\", subtitle = \"Kaplan-Meier-kurve\")\r\n\r\n\r\n\r\nSiden vi bare har 15 observasjoner, hvorav 1 er sensurert, blir sannsynligheten temmelig usikkert estimert. Den starter på mellom 80 % og 100 % rundt to ukers tid, faller ganske krapt fram til rundt to måneder - men faller så mer slakt av. Betyr det at om jeg klarer å holde en treningsperiode oppe i rundt to måneder, så er det blitt en mer innarbeida vane? Kanskje. For å finne ut av det burde jeg også få brukt treningsinformasjonen til noe fornuftig - men det får bli seinere.\r\n\r\n\r\n\r\n",
    "preview": "posts/2019-10-29-rasker-survival-analysis/rasker-survival-analysis_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2023-11-25T07:55:07+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-10-05-rasker-har-jeg-trent-mye/",
    "title": "Har jeg trent så mye som jeg tror (raskeR)?",
    "description": "En kikk på treningsdata fra de siste årenes pusting og pesing rundt med overvåkningsdingser festa til kroppen.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2019-10-05",
    "categories": [],
    "contents": "\r\nInspirert av forrige artikkels kikk på tider fra de 19 løpene jeg har deltatt i de siste årene, begynte jeg å lure på hvordan treningsøktene mine ser ut. Jeg har de siste årene løpt rundt med både div. treningsapper på smarttelefonen med GPS-utstyr, og pulsmåler. For tida er det Runtastic jeg bruker, etter en avsløring fra Forbrukerrådet om Runkeepeers datapraksis for noen år siden. Kan en få tak i dataene sine fra en slik app? Og er det i så fall mulig å si noe om:\r\nHvordan jeg har trent over de siste årene? Kan jeg se noe mønster i når jeg har trent - og når jeg ikke har trent?\r\nHvor ofte har jeg klart å nå målet mitt om (minst) tre treningsøkter i uka? Jeg mistenker at det ikke er så ofte?\r\nEr løpsdeltakelse noe jeg trener mot, eller noe jeg blir motivert til å trene av? Eller begge deler?\r\nDataene\r\nJa, data kan man få tak i - viser det seg at svaret er. Med en dump fra Runtastic-sida får en ut masse informasjon, inkludert\r\noppsummerende data for alle sessions som er registrert,\r\nhøydedata for hver enkelt session,\r\nGPS-data for hver enkelt session, og\r\npulsmålingsdata for hver enkelt session.\r\nJeg tok ut en dump per 22. september 2019. I utgangspunktet er - eller føles - mye av disse dataene nokså personsensitive. Her er både posisjonsdata, pulsfrekvenser og notater om hva jeg tenkt på etter treningsøkta. Med 292 oppføringer er også mengden temmelig overveldende. Jeg begynner derfor med et utvalg av de oppsummerende dataene - med 10 variabler\r\n\r\n\r\nglimpse(df)\r\n\r\nRows: 292\r\nColumns: 10\r\n$ start_time      <dbl> 1526840757000, 1540752043000, 1542223614000,…\r\n$ end_time        <dbl> 1526842946000, 1540754401000, 1542225937000,…\r\n$ duration        <int> 2187889, 2356854, 2323585, 2165512, 4937730,…\r\n$ pause_duration  <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 83250…\r\n$ distance        <int> 6596, 7094, 7187, 6456, 13608, 19025, 7212, …\r\n$ average_speed   <dbl> 10.853202, 10.835800, 11.135000, 10.732612, …\r\n$ max_speed       <dbl> 13.39172, 15.59690, 14.89338, 15.88270, 13.4…\r\n$ duration_per_km <int> 331699, 332232, 323303, 335426, 362855, 3631…\r\n$ pulse_avg       <int> 144, 0, 0, 153, 148, 154, 157, 161, 162, 0, …\r\n$ pulse_max       <int> 159, 0, 0, 182, 170, 175, 180, 181, 183, 0, …\r\n\r\nFørste utfordring er å finne ut hva tida og alt det andre her måles i. Etter litt roting oppdaget jeg at dette er lagret som antall tusendeler (millisekund?) siden 1. januar 1970. Distanses måles i meter.\r\nEn ekstra spennende øvelse her er jo at vi får sett nærmere på tid og datoer i R - en øvelse i seg selv. lubridate-pakken ser ut til å smøre arbeidet litt i et tidyverse-rammeverk, heldigvis:\r\nlubridate har funksjoner for å trekke ut informasjonsbiter fra POSIXct-objekter (year, month, week)\r\nlubridate gjør det også lettere å regne med perioder. Cheat-sheetet for pakka har en pen forklaring av dette.\r\n\r\n\r\ndf = mutate(df, \r\n            start_time = as.POSIXct(start_time/1000, origin=\"1970-01-01\"),\r\n            end_time = as.POSIXct(end_time/1000, origin=\"1970-01-01\"),\r\n         year = year(start_time),\r\n         month = month(start_time),\r\n         week = week(start_time),\r\n         duration_sec = round(duration/1000, 0),\r\n         duration_min = duration_sec/60,\r\n         duration_lubridate = as.duration(as.period(duration_sec, unit = \"seconds\")),\r\n         distance = distance / 1000, #konverterer distanse i meter til kilometer\r\n         duration_per_km_lubridate = as.duration(as.period(round(duration_per_km/1000, 0), unit = \"seconds\")),\r\n         duration_per_km = (duration_per_km/1000)/60,\r\n         puls_sone_snitt = cut(pulse_avg, breaks = c(0, 126, 141, 155, 170, 184, 210), labels = c(\"0\", \"Sone 1\", \"Sone 2\", \"Sone 3\", \"Sone 4\", \"Sone maks\")),\r\n         puls_sone_maks = cut(pulse_max, breaks = c(0, 126, 141, 155, 170, 184, 210), labels = c(\"0\", \"Sone 1\", \"Sone 2\", \"Sone 3\", \"Sone 4\", \"Sone maks\"))\r\n         )\r\n\r\n\r\nHvordan har jeg trent de siste årene?\r\nSå hva er det vi har i disse 292 observasjonene her? For det første er antallet treningsaktiviteter forskjellig over årene. Den første registrerte aktiviteten kom i slutten av september 2015. I 2015 registrerte jeg 35 aktiviteter i appen, 2016 opp mot 65, før det var litt lavere igjen i 2017. Det er ingen registreringer mellom slutten av august 2017 og mars 2018. I 2018 kom jeg over 80 registrerte aktiviteter.\r\n\r\n\r\nggplot(data = df) + \r\n  geom_bar(aes(x = year)) + \r\n  labs(x = \"År\", y = \"Antall\", title = \"Flest aktiviteter i 2018\", subtitle = \"Men 2019 er enda ikke over!\")\r\n\r\n\r\n\r\nFor å få en bedre forståelse av hva som ligger bak dette, er det greit å se på hvordan antallet aktiviteter varierer med tiden innafor et år: Er det sesongvariasjoner eller stabilitet i det som er registrert? Og kan jeg huske spesifikke hendelser som forklarer fall eller økning i aktivitet?\r\n\r\n\r\nggplot(data = temp) + \r\n  geom_line(aes(x = as.integer(month), y = antall, colour = as.factor(year))) +\r\n  scale_x_continuous(limits = c(1, 12), breaks = 1:12, minor_breaks = NULL) + \r\n  scale_y_continuous(limits = c(0, 12), breaks = seq(from = 1, to = 12, by = 3), minor_breaks = NULL) + \r\n  labs(x = \"Måned\", y = \"Antall\", colour = \"År\", title = \"Løpshistorikk - et sammensurium\", subtitle = \"Diverse ting skjer - og da blir det mindre løping\")\r\n\r\n\r\n\r\nI 2015 begynner registreringa utpå høsten.\r\nJevn fart inn i 2016, med fortsatt 2-3 økter i måneden fram til juni, hvor det faller - og faller - og faller utover høsten og flater ut på en tur i måneden mot slutten av året. Det er det en åpenbar grunn til!\r\nI 2017 starter jeg imidlertid sterkere, med 1-2 ganger per uka. Når sommeren er overstått, og etter august flater det imidlertid ut igjen. Barnehagestart og tilbake på jobb var tydeligvis hardt å få til.\r\nNår mars 2018 kommer, da stiger imidlertid ambisjonene - og det ganske brått. Fra 0 (registrerte) aktiviteter, til opp imot 3 ganger i uka (den jevne målsettinga), som jeg også klarte å vedlikeholde på høsten og inn mot vinteren - selv om dyppen i desember er ganske så skummel…\r\n2019 starta også sterkt, relativt sett, men falt brått etter april. Da slo ny jobb og flytteprosjekt antakeligvis inn. I juli kom det et lite hoppp, ettersom joggeskoa ble med på ferie, men så klarte jeg ikke å holde dette oppe inn i høsten.\r\nLitt overraskende for meg her er at det ikke er noen særlig tydelig sesongvariasjon. I stedet er det diverse livshendelser som plasserer treninga i baksetet.\r\nHvor langt har jeg løpt?\r\nOver disse øktene har jeg totalt løpt 2484 kilometer. Det er langt - litt lengre enn fra Oslo til Roma. Medianløpet er på 7,5 kilometer, det lengste løpet på 42,2 km (maraton!) - men 50 % av løpene er på mellom 6,5 kilometer og 10,2 kilometer. Histogrammet viser at det er langt flest løp på ca. 7 kilometer, fulgt av 10 og 6 kilometer. Dette er ikke spesielt ulikt for de ulike årene. I 2018 klarte jeg å løpe noe flere lengre løp, slik at medianen lå nærmere 10 kilometer.\r\n\r\n\r\n\r\nHvor fort har jeg løpt?\r\nDet raskeste jeg har løpt er 3 min 20 sek på kilometeren. Medianhastigheten er 6 min per kilometer. For det meste har jeg løpt (i gjennomsnitt) på mellom 5 minutt og 30 sekund og 6 minutt og 30 sekund per kilometer. Fordelinga er ganske pen og symmetrisk. De konsistent raskeste tidene kom i 2018, hvor jeg også trente mer spesifikt mot å løpe raskere på ti-kilometer. 2019 har vært litt treigere, men ikke egentlig fullt så varierende som 2015-2017. Riktignok har vi ikke kommet helt inn i vintersesongen enda, noe som nok godt kan ha noe med dette å gjøre.\r\n\r\n\r\n\r\nHva med pulsen da?\r\nFor en god del av turene mangler puls-data: For 92 av turene er gjennomsnittspulsen satt til 0, og for 76 er den manglende. Hovedforklaringa på manglende pulsdata er dermed Runtastic-bruken - jeg brukte Runkeeper og Polar-system før dette, og trodde jeg hadde fått importert over dataene. Men tydeligvis ikke. Det er heller ikke slik at dette dekker alle turene i denne perioden. I noen tilfeller har jeg i lite motiverte perioder løpt uten pulsutstyr. Men også alle løp jeg har deltatt i, har jeg etterregistrert i appen - og noen ganger har pulsutstyret feila eller gått tom for batteri. Og det er svinvanskelig å bytte batteri på polar-utstyret uten å ødelegge noe.\r\nDet gir oss 124 turer med pulsdata. Hvordan ser disse ut? Median-pulsen ligger på 152, 50 % av turene ligger mellom 148 og 156, og maks gjennomsnittlig puls er på 181. 2019-dataene har mer variasjon i pulsen. Hva vil dette si, siden puls er relativt til makspuls og hvilepuls? At det meste av treningen har foregått i pulssone 2, for fetbrenning, men også noe i aerob sone.\r\nMakspulsen er derimot på 176 i snitt, og ligger i 50 % av tilfellene mellom 170 og 180. Den høyest målte pulsen er 199. Det vil si at jeg i de fleste løpene har vært oppe i pulssone 4, anaerob sone.\r\n\r\n\r\n\r\nHvor mye trening har jeg fått i meg?\r\nI følge Helsedirektoratet bør voksne være i fysisk aktivitet i 150 minutter moderat intensitet i uka, eller 75 minutter med høy intensitet. Høy intensitet tilsvarer løping.\r\n\r\n\r\ntemp = group_by(df, year, week) %>%\r\n  summarise(antall_minutter = sum(duration_min, na.rm = TRUE)) %>%\r\n  ungroup()\r\n\r\ntemp = left_join(expand(temp, year, week = 1:52), temp) %>%\r\n  mutate(yearweek = ifelse(nchar(week) == 1, paste0(0, week), week),\r\n         yearweek = paste0(year, yearweek),\r\n         id = seq_along(yearweek),\r\n         treningsdose = as.factor(ifelse(antall_minutter >= 75, \"Over 75 min\", \"Under 75 min\"))\r\n         )\r\n\r\nqplot(data = df, x = duration_min, binwidth = 5) + \r\n  labs(x = \"Varighet i minutter\", y = \"Antall\", title = \"50 % av turene ligger mellom 40 og 60 minutter\")\r\n\r\n\r\nggplot(data = temp) + \r\n  geom_bar(aes(x = treningsdose)) + \r\n  labs(x = \"Trening i over eller under 75 minutter i uka?\", y = \"Antall\", title = \"To av tre uker med trening er over Helsedirektoratets anbefaling\", subtitle = \"Men de fleste mangler data\")\r\n\r\n\r\nggplot(data = temp, aes(x = id, y = antall_minutter)) + \r\n  geom_point(aes(colour = treningsdose)) + \r\n  geom_smooth() +\r\n  geom_hline(aes(yintercept = 75)) + \r\n  labs(x = \"Tid\", y = \"Trening per uke (minutter)\")\r\n\r\n\r\n\r\nFigurene viser altså at av de ukene hvor jeg har trent, så har to av tre vært over Helsedirektoratets anbefaling for høyere intensitet. Trendlinja ligger solid over den anbefalte mengden, men dypper seg faretruende nær undersida i det siste. Og for mange uker har jeg ikke trent, og da bør jeg ha dekka inn aktivitetskravet på anna vis, med 150 minutter moderat aktivitet i uka i stedet (altså 25 minutters gange hver dag).\r\nHvor ofte har jeg klart målet om tre ganger i uka?\r\nJeg liker egentlig å tro at jeg trener ca. 3 ganger i uka. Hvor ofte har det vært tilfelle her? Ikke veldig ofte - men mer enn ingenting:\r\n\r\n\r\n\r\nEr løpsdeltakelse noe jeg trener mot?\r\neller noe jeg blir motivert til å trene av? Eller begge deler?\r\n\r\n\r\nggplot(data = temp) + \r\n  geom_point(aes(x = dato, y = distanse_km, colour = treningsform))\r\n\r\n\r\n\r\nDet er vanskelig å si. Løpene er mer lagt til vår og høst, enn at de i seg selv påvirker treningsinnsatsen betydelig.\r\n\r\n\r\n\r\n",
    "preview": "posts/2019-10-05-rasker-har-jeg-trent-mye/rasker-har-jeg-trent-mye_files/figure-html5/unnamed-chunk-4-1.png",
    "last_modified": "2023-11-25T07:55:07+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-09-22-rasker-running-statistics/",
    "title": "RaskeRe - en kikk på løpsstatistikk med R",
    "description": "En rask kikk på løpetider fra de siste årenes løp.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2019-09-22",
    "categories": [],
    "contents": "\r\nLøping er gøy!\r\n\r\n\r\n\r\nUtgangspunktet var at jeg satte meg ned og prøvde å finne ut av hvor mange løp jeg har vært med på de siste årene, og hvordan jeg tidsmessig ligger an. Jeg fant at jeg totalt hadde vært med på 19 løp:\r\n\r\n\r\nruns = read_delim(\"runs_sept2019.csv\", \";\", escape_double = FALSE, col_types = cols(dato = col_character()), locale = locale(decimal_mark = \",\", grouping_mark = \"|\", encoding = \"ISO-8859-1\"), trim_ws = TRUE)\r\n\r\nruns = mutate(runs, \r\n              dato = as.Date(dato, format = \"%d.%m.%Y\"),\r\n              year = year(dato),\r\n              tid_test = hms(tid),\r\n              tid_minutter = as.period(tid_test, unit = \"minutes\")\r\n              )\r\n\r\nknitr::kable(arrange(select(runs, dato, `løp`, distanse_km, tid), dato))\r\n\r\ndato\r\nløp\r\ndistanse_km\r\ntid\r\n2006-05-04\r\nRåskinnet\r\n8.5\r\nNA\r\n2006-06-13\r\nBirkebeinerløpet\r\n21.1\r\n1.58.31\r\n2013-05-04\r\nRåskinnet\r\n8.5\r\n1.17.32\r\n2013-09-07\r\nTrondheim maraton\r\n21.1\r\n1.47.17\r\n2014-06-14\r\nBirkebeinerløpet\r\n21.1\r\n1.53.29\r\n2014-09-20\r\nOslo Maraton\r\n42.2\r\n4.18.55\r\n2015-04-22\r\nSentrumsløpet\r\n10.0\r\n0.50.38\r\n2015-09-05\r\nNordmarkstravern\r\n15.0\r\n1.28.54\r\n2015-09-19\r\nOslo Halvmaraton\r\n21.1\r\n1.44.27\r\n2015-10-03\r\nMidt i Mjøsa Maraton\r\n42.2\r\n4.55.26\r\n2016-04-23\r\nSentrumsløpet\r\n10.0\r\n0.43.57\r\n2016-05-21\r\nEcoTrail Oslo\r\n18.0\r\n1.35.44\r\n2017-04-29\r\nSentrumsløpet\r\n10.0\r\n0.46.48\r\n2018-04-21\r\nSentrumsløpet\r\n10.0\r\n0.45.47\r\n2018-06-16\r\nNordmarka Skogsmaraton\r\n21.1\r\n1.55.59\r\n2018-09-15\r\nOslo Halvmaraton\r\n21.1\r\n1.42.33\r\n2018-10-20\r\nHytteplanmila\r\n10.0\r\n0.43.39\r\n2019-02-02\r\nOslo Winterrun\r\n10.0\r\n0.53.32\r\n2019-09-22\r\n10 for Grete\r\n10.0\r\n0.49.44\r\n\r\nDette er ikke veldig imponerende, men jeg har løpt 2-4 løp i året siden 2013.\r\n\r\n\r\nggplot(data = runs) + \r\n  geom_bar(aes(x = year)) + \r\n  scale_x_continuous(breaks = 2006:2019) + \r\n  labs(title = \"2 - 4 løp i året siden 2013\", x = \"År\", y = \"Antall\")\r\n\r\n\r\n\r\nAv de 18 løpene er det 7 10-kilometere og 6 halvmaraton\r\n\r\n\r\nggplot(data = runs) + \r\n  geom_bar(aes(x = as.factor(distanse_km))) + \r\n  labs(title = \"Flest 10 km og halvmaraton\", x = \"Løpslengde i km\", y = \"Antall\")\r\n\r\n\r\n\r\nDe lengre løpene bruker jeg rimelig nok lengre tid på.\r\n\r\n\r\nggplot(data = runs) + \r\n  geom_point(aes(x = dato, y = tid_minutter, colour = as.factor(distanse_km))) +\r\n  scale_y_time() + \r\n  labs(title = \"Lengre tid på lengre løp\")\r\n\r\n\r\n\r\nHalvmaraton-tidene har blitt bedre, mens tikilometer-tidene er nokenlunde stabile. Ja, grafen spretter rundt en del, og det er en del som skiller tider rundt 44 min og 50 min, men ikke frykelig mye heller?\r\nFor å få et bedre bilde av det, kan en framstilling av gjennomsnittlig hastighet være bedre egna:\r\n\r\n\r\nggplot(data = runs) + \r\n  geom_point(aes(x = dato, y = tid_minutter, colour = as.factor(distanse_km))) + \r\n  geom_line(aes(x = dato, y = tid_minutter, colour = as.factor(distanse_km))) + \r\n  facet_wrap(~as.factor(distanse_km), scales = \"free_y\") +\r\n  scale_y_time() + \r\n  labs(title = \"Raskere halvmaraton, stabile tikilometere?\")\r\n\r\n\r\nggplot(data = runs) + \r\n  geom_point(aes(x = dato, y = `min/km`, colour = as.factor(distanse_km))) +\r\n  geom_line(aes(x = dato, y = `min/km`, colour = as.factor(distanse_km))) \r\n\r\n\r\n\r\nGir dette noe innsikt som kan hjelpe meg med å løpe raskere? Nei, ikke egentlig. År med mye aktivitet er raskere enn år med lite aktivitet, men det gir jo mening. Hastigheten på halvmaraton og ti-kilometer er ikke veldig ulik, i det store bildet, men i praksis vil jeg mene at forskjellen på 5 blank på kilometeren, og 4 min 30 sekunder er ganske så stor.\r\n\r\n\r\n\r\n",
    "preview": "posts/2019-09-22-rasker-running-statistics/rasker-running-statistics_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2023-11-25T07:55:07+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-09-17-hvor-like-er-to-variabler/",
    "title": "Hvor like er to variabler",
    "description": "En kikk på noen ulike teknikker for å sammenlikne variabler/caser, når du vil vite hvor god prognosa di var",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2019-09-17",
    "categories": [],
    "contents": "\r\nHva er den beste måte å sammenlikne dataserier på?\r\nSom eksempel lager jeg meg et datasett fra en prognosekonkurranse, der 10 personer har forsøkt å gjette på valgresultatet til 10 partier. Jeg har også resultatet - og to spørsmål:\r\nHvor like er folk?\r\nHvem er nærmest fasiten? Hvem hadde rett? Antakeligvis er tilfeldig tallgenerering ganske langt fra fasiten - men teknikkene kan brukes også på faktiske bidrag.\r\n\r\n\r\nsuppressPackageStartupMessages(library(tidyverse))\r\nlibrary(broom)\r\nlibrary(here)\r\n\r\n#settings\r\ntheme_set(theme_minimal())\r\nset.seed(1106)\r\n\r\n#data\r\nresultatliste = data.frame()\r\n\r\n#lite eksperiment med å generere tilfeldige valgresultater\r\nrand_nr = function(a, b, n, k){\r\n  #finner n tilfeldige heltall mellom a og b, som summerer til k\r\n  while(TRUE){\r\n    x = sample(1:(k - n*a), n - 1, replace = TRUE)\r\n    x = sort(x)\r\n    x = c(x, k-n*a) - c(0, x)\r\n    if(max(x) <= b-a) {return(a+x)}\r\n  }\r\n}\r\n\r\ntest_df = data.frame(parti = c(\"Rødt\", \"SV\", \"Ap\", \"Sp\", \"MDG\", \"KrF\", \"V\", \"H\", \"FrP\", \"Andre\"),\r\n                     resultat = c(0.038, 0.061, 0.248, 0.144, 0.068, 0.04, 0.039, 0.201, 0.082, 0.079)\r\n                     )\r\ntest_df$resultat = test_df$resultat*100\r\n\r\nfor(i in 1:10){\r\n  temp = data.frame(deltaker = rand_nr(0, 30, 10, 100))\r\n  names(temp) = paste0(\"deltaker_\", i)\r\n  test_df = bind_cols(test_df, temp)\r\n}\r\n\r\ndf = test_df\r\n\r\n\r\nHvor nærme var folk?\r\nRein visuell inspeksjon\r\n\r\nparti\r\nresultat\r\ndeltaker_1\r\ndeltaker_2\r\ndeltaker_3\r\ndeltaker_4\r\ndeltaker_5\r\ndeltaker_6\r\ndeltaker_7\r\ndeltaker_8\r\ndeltaker_9\r\ndeltaker_10\r\nRødt\r\n3,8\r\n6\r\n9\r\n30\r\n16\r\n22\r\n23\r\n13\r\n4\r\n25\r\n20\r\nSV\r\n6,1\r\n2\r\n3\r\n2\r\n4\r\n20\r\n13\r\n9\r\n17\r\n7\r\n27\r\nAp\r\n24,8\r\n29\r\n11\r\n12\r\n24\r\n16\r\n9\r\n7\r\n10\r\n6\r\n6\r\nSp\r\n14,4\r\n8\r\n18\r\n5\r\n4\r\n3\r\n5\r\n24\r\n5\r\n5\r\n1\r\nMDG\r\n6,8\r\n4\r\n0\r\n11\r\n25\r\n1\r\n30\r\n11\r\n15\r\n14\r\n5\r\nKrF\r\n4,0\r\n24\r\n15\r\n1\r\n8\r\n3\r\n1\r\n6\r\n5\r\n4\r\n4\r\nV\r\n3,9\r\n16\r\n16\r\n0\r\n1\r\n8\r\n6\r\n14\r\n3\r\n11\r\n19\r\nH\r\n20,1\r\n1\r\n8\r\n2\r\n2\r\n11\r\n4\r\n7\r\n11\r\n12\r\n1\r\nFrP\r\n8,2\r\n4\r\n0\r\n28\r\n9\r\n9\r\n0\r\n1\r\n20\r\n8\r\n17\r\nAndre\r\n7,9\r\n6\r\n20\r\n9\r\n7\r\n7\r\n9\r\n8\r\n10\r\n8\r\n0\r\n\r\nNoen ganske utenomjordiske gjettinger her, som forventa - men også ganske vanskelig å si hvilken av dem som har gjort det minst ille relativt til valgresultatet i den venstre kolonna.\r\nEn bedre måte å vise det på er grafisk med en graf:\r\n\r\n\r\ntemp = gather(df, person, prognose, resultat:deltaker_10) %>%\r\n  mutate(type = ifelse(person == \"resultat\", \"resultat\", \"prognose\"))\r\n\r\nggplot() + \r\n  geom_point(data = filter(temp, type == \"resultat\"), aes(x = prognose, y = fct_reorder(parti, prognose)), colour = \"black\") +\r\n  labs(x = \"Oppslutning\", y = \"Parti\", colour = \"Prognose eller resultat?\")\r\n\r\n\r\n\r\nAller først ser vi på de faktiske valgresultatene. Ap er størst, fulgt av Høyre og Senterpartiet. FrP er ganske små, og bolken “Andre” er temmelig svær. Rødt er minst, men ikke langt unna Venstre og KrF.\r\nHva så når vi legger på prognosene?\r\n\r\n\r\nggplot() + \r\n  geom_point(data = filter(temp, type == \"prognose\"), aes(x = prognose, y = fct_reorder(parti, prognose)), colour = \"grey\") +\r\n  geom_point(data = filter(temp, type == \"resultat\"), aes(x = prognose, y = fct_reorder(parti, prognose)), colour = \"black\") +\r\n  labs(x = \"Oppslutning\", y = \"Parti\", colour = \"Prognose eller resultat?\")\r\n\r\n\r\n\r\nSkikkelig tilfeldig spredning utover! Allikevel ser det ut til å være en del overplotting - det er få av linjene som har 10 hele grå punkter. Dermed lønner det seg å bruke en anne geome - en som teller opp litt. Små prikker er en observasjon, medium to og de største er tre observasjoner.\r\n\r\n\r\nggplot() + \r\n  geom_count(data = filter(temp, type == \"prognose\"), aes(x = prognose, y = fct_reorder(parti, prognose)), colour = \"grey\", show.legend = FALSE) +\r\n  geom_point(data = filter(temp, type == \"resultat\"), aes(x = prognose, y = fct_reorder(parti, prognose)), colour = \"black\") +\r\n  labs(x = \"Oppslutning\", y = \"Parti\", colour = \"Prognose eller resultat?\")\r\n\r\n\r\n\r\nVanskelig - for ikke å si umulig -å si med ett blikk hvem av de ti seriene som er nærmest fasiten, totalt sett. Vi trenger ett mål. Her går jeg igjennom:\r\nEvklidiansk distanse\r\nKorrelasjonsmatrise\r\nR2\r\nRMSE\r\nMAE\r\nEuklidiansk distanse\r\nEvklidiansk distanse er et fancy navn på avstand i et flatt plan mellom to punkter. For avstanden mellom to vektorer (eller to variabler) er denne definert som den kvardratroten av den kvadrerte forskjellen mellom punktene i de to seriene. Hvorfor kvadrere? Fordi summen av forskjeller mellom to serier ikke alltid er informativt, hvis negative og positive forskjeller nuller hverandre ut.\r\nLav avstand er bra, stor avstand er dårlig:\r\n\r\n\r\ntemp = t(select(df, -parti))\r\nevklid = dist(temp)\r\nprint(evklid, digits = 1)\r\n\r\n            resultat deltaker_1 deltaker_2 deltaker_3 deltaker_4\r\ndeltaker_1        32                                            \r\ndeltaker_2        30         28                                 \r\ndeltaker_3        41         48         46                      \r\ndeltaker_4        31         33         40         31           \r\ndeltaker_5        29         38         34         32         33\r\ndeltaker_6        40         46         42         37         23\r\ndeltaker_7        29         36         21         41         34\r\ndeltaker_8        27         40         37         33         29\r\ndeltaker_9        33         40         32         27         27\r\ndeltaker_10       44         45         44         37         42\r\n            deltaker_5 deltaker_6 deltaker_7 deltaker_8 deltaker_9\r\ndeltaker_1                                                        \r\ndeltaker_2                                                        \r\ndeltaker_3                                                        \r\ndeltaker_4                                                        \r\ndeltaker_5                                                        \r\ndeltaker_6          33                                            \r\ndeltaker_7          31         31                                 \r\ndeltaker_8          27         33         32                      \r\ndeltaker_9          22         22         25         28           \r\ndeltaker_10         23         38         36         31         29\r\n\r\nUt ifra dette målet ser vi at deltaker_4 var nærmest resultatet, fulgt av deltaker 1 og 3.\r\nHvis vi var interessert i alle forskjellene mellom alle, kunne dette vært visualisert med ett heatmap. Men det er vi ikke - vi er kun interessert i forskjellen mellom deltakerne og det faktiske resultatet.\r\n\r\n\r\ntemp = dist(t(select(df, -parti)))\r\ntemp = tidy(temp) %>%\r\n  filter(. , item2 == \"resultat\")\r\n\r\nggplot(data = temp) + \r\n  geom_col(aes(x = fct_reorder(item1, distance), y = distance)) +\r\n  labs(x = \"Hvor langt unna fasiten?\", y = \"Avstand\")\r\n\r\n\r\nresultatliste = select(temp, person = item1, evklid = distance)\r\n\r\n\r\nKorrelasjon (Pearson)\r\nMen evklidiansk distanse er ikke det eneste målet - vi har også klassikeren korrelasjon. Korrelasjon er ikke veldig ulikt et avstandsmål, men mens evklidiansk avstand forutsetter at de to vektorene (eller variablene) X og Y er på samme skala, skalerer korrelasjon (Pearsons, i dette tilfellet) først med standardavviket til X og Y. Pearson er i bunn og grunn et gjennomsnittlig produkt av x og Y.\r\n\r\n\r\ntemp = select(df, -parti)\r\nkorr_matrise = cor(temp)\r\n\r\ntemp = data.frame(korr_matrise) %>%\r\n  rownames_to_column(., var = \"id2\") %>%\r\n  gather(., \"id1\", \"korrelasjon\", resultat:deltaker_10) %>%\r\n  filter(., id1 == \"resultat\", id2 != \"resultat\")\r\n\r\nggplot(data = temp) + \r\n  geom_col(aes(x = fct_reorder(id2, korrelasjon), y = korrelasjon)) +\r\n  labs(x = \"Hvor langt unna fasiten?\", y = \"Korrelasjon\")\r\n\r\n\r\n\r\nDeltaker_4 og deltaker_1 er fortsatt nærmest. Her ser vi faktisk at deltaker_6 og deltaker_8 har en betydelig negativ korrelasjon.\r\nForklart variasjon - R2\r\nHer brukes også kvadrert R som et mål på forklart variasjon. Dette er jo bare den kvadrerte korrelasjonskoeffisienten fra Pearsons over, og rangeringa blir dermed ikke annerledes. Men merk! Her blir det en liten feil. Over så vi negative korrelasjoner. I tilfellet valgresultat er ikke det ønskelig - det betyr jo at når deltakeren har gjettet høyere, så har resultatet blitt lavere. I matematisk forstand kan dette fortsatt forklare variasjon, men ikke i noen meningsfull form her.\r\n\r\n\r\ntemp$r.kvadrert = temp$korrelasjon^2\r\n\r\nggplot(data = temp) + \r\n  geom_col(aes(x = fct_reorder(id2, r.kvadrert), y = r.kvadrert)) +\r\n  labs(x = \"Hvor langt unna fasiten?\", y = \"Forklart variasjon\")\r\n\r\n\r\nresultatliste = left_join(resultatliste, select(temp, -id1), by = c(\"person\" = \"id2\"))\r\n\r\n\r\nDeltaker_4 har i hvert fall klart å forklare noe av variasjonen i de faktiske valgresultatene.\r\nVanlige prognosemål - Root mean square error (RMSE) og Mean average error (MAE)\r\nRMSE gir større straff til store feil: hvis det å ta feil med 10 er mer enn dobbelt så ille som å ta feil med 5, så er RMSE riktig mål. Hvis det å ta feil med 10 er akkurat dobbelt så ille som å ta feil med 5, så er MAE riktigere.\r\n\r\n\r\n#RMSE\r\nrmse <- function(feil){\r\n    sqrt(mean(feil^2))\r\n}\r\n \r\n#MAE\r\nmae <- function(feil){\r\n    mean(abs(feil))\r\n}\r\n\r\n\r\nSjølve utregninga skjuler jeg - den er temmelig stygg, ettersom kopiering gikk raskere enn funksjoner.\r\n\r\n\r\nqplot(data = temp, x = fct_reorder(person, rmse), y = rmse, geom = \"col\") + \r\n  labs(x = \"Person\", y = \"RMSE\")\r\n\r\n\r\nqplot(data = temp, x = fct_reorder(person, mae), y = mae, geom = \"col\") + \r\n  labs(x = \"Person\", y = \"MAE\")\r\n\r\n\r\nresultatliste = left_join(resultatliste, temp)\r\n\r\n\r\nOppsummering\r\nSå for å oppsummere, hvem var best? Ut ifra de ulike målene vi har sett her, ser resultatene relativt entydige ut: deltaker_4 har en lavere evklidiansk avstand til resultatet, har en høyere korrelasjon, en høyere forklart variasjon, en lavere RMSE og en lavere MAE.\r\n\r\n\r\nknitr::kable(arrange(resultatliste, evklid), digits = 1)\r\n\r\nperson\r\nevklid\r\nkorrelasjon\r\nr.kvadrert\r\nrmse\r\nmae\r\n\r\nHvordan ser dette ut i plottet vårt fra over?\r\n\r\n\r\ntemp = gather(df, person, prognose, resultat:deltaker_10) %>%\r\n  mutate(type = ifelse(person == \"resultat\", \"resultat\", \"prognose\"))\r\n\r\nggplot() + \r\n  geom_count(data = filter(temp, type == \"prognose\"), aes(x = prognose, y = fct_reorder(parti, prognose)), colour = \"grey\", show.legend = FALSE) +\r\n  geom_point(data = filter(temp, type == \"resultat\"), aes(x = prognose, y = fct_reorder(parti, prognose)), colour = \"black\") +\r\n  geom_point(data = filter(temp, person == \"deltaker_4\"), aes(x = prognose, y = fct_reorder(parti, prognose)), colour = \"red\") +\r\n  labs(x = \"Oppslutning\", y = \"Parti\", colour = \"Prognose eller resultat?\")\r\n\r\n\r\n\r\nMen hvilke valgresultater var de ulike deltakerne nærmest?\r\nEn måte å snu på dette på, er ved å finne ut hvilke faktiske valgresultater de ulike deltakerne var nærmest. Valgresultatene hentes fra valgresultat.no.\r\nEtter litt bearbeiding får jeg denne tabellen:\r\n\r\nDeltaker\r\nNærmeste kommune\r\nAvstand\r\ndeltaker_1\r\n1874_Moskenes\r\n12.2\r\ndeltaker_2\r\n4633_Fedje\r\n23.8\r\ndeltaker_3\r\n1874_Moskenes\r\n18.7\r\ndeltaker_4\r\n1874_Moskenes\r\n16.2\r\ndeltaker_5\r\n3039_Flå\r\n15.2\r\ndeltaker_6\r\n3436_Nord-Fron\r\n15.3\r\ndeltaker_7\r\n4633_Fedje\r\n15.0\r\ndeltaker_8\r\n4643_Årdal\r\n20.6\r\ndeltaker_9\r\n3819_Hjartdal\r\n14.9\r\ndeltaker_10\r\n3039_Flå\r\n2.6\r\n\r\nDeltaker 3, 4 og 9 har lavest avstand til valgresultatet for hele landet. Avstanden er imidlertid ikke spesielt lav. 1, 2 og 5 ligger nærmest Flå. Deltaker 10 er veldig overraskende nærme tre små kommuner.\r\n\r\n\r\n\r\n",
    "preview": "posts/2019-09-17-hvor-like-er-to-variabler/hvor-like-er-to-variabler_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2023-11-25T07:55:07+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-09-04-stemningsanalyse-av-partiprogram/",
    "title": "Stemningsanalyse av partiprogram",
    "description": "En kikk på valgprogrammene for kommunevalget i Oslo, og hvilke stemninger som finnes der",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2019-09-04",
    "categories": [],
    "contents": "\r\nHvordan kan man maskinelt forstå en tekst? I den forrige artikkelen såg jeg på hvilke ord som var mest brukt, i ulike varianter. Hvor godt likner det på en menneskelig måte å lese noe på? Kanskje litt - en legger jo merke til hvilke ord som går igjen, og særlig når det er beskrivelser av emner.\r\nEn anna menneskelig måte å lese en tekst på, er å se på stemningen i en tekst: hvilke følelser brukes her - positive eller negative? Eller noe mer komplisert? Noe mer komplisert klarer jeg ikke her, så det snakker jeg ikke mer om.\r\nVi bruker AFINN-koda ordbok for å si noe om stemningen i partiprogrammene. Gitt at den ordboka gir et godt bilde av stemningen i programmene (noe som ikke er gitt), så ser vi på følgende:\r\nHva er den gjennomsnittlige stemninga i tekstene?\r\nHvordan ser variasjonen ut mellom partiene?\r\n\r\n\r\nsuppressPackageStartupMessages(library(tidyverse))\r\nlibrary(tidytext)\r\nlibrary(here)\r\nlibrary(tm)\r\n\r\n#settings\r\ntheme_set(theme_minimal())\r\nset.seed(1106)\r\n\r\n\r\n##Datagrunnlaget\r\nAlle partiene har PDF-filer av valgprogrammene sine for Oslo tilgjengelig. PDF-filer lar seg lese inn, men krever litt tygging for å få fjerna punktsetting, nummer og lignende.\r\n\r\n\r\n#med TM\r\n\r\n# lag et korpus fra pdf-filene\r\nconverted <- VCorpus(DirSource(\"valgprogram\"), readerControl = list(reader = readPDF, language = \"nb\")) %>% \r\n  DocumentTermMatrix(., control = list(language = \"nb\", \r\n                                       removePunctuation = TRUE,\r\n                                       removeNumbers = TRUE, \r\n                                       stopwords = stopwords(\"no\")\r\n                                       ))\r\n\r\n#opprydding\r\n#fjerner .pdf-suffixet\r\ndf_programmer = tidy(converted) %>%\r\n  mutate(., document = gsub(\".pdf\", \"\", document, fixed = TRUE))\r\n\r\n#setter bedre navn på variablene\r\nnames(df_programmer) = c(\"parti\", \"term\", \"antall\")\r\n\r\n\r\nEn tekst består av summen av ord, og en teksts stemning består av summen av ordenes stemning. For å fastslå stemning er en mulig tilnærming å bruke et leksikon eller ordbok: noen har koda et sett med ord, og hvilken stemning de utgjør. For norsk har jeg funnet Finn Årup Nielsens ordbok fra 2011 på Github, AFINN (fork her). Den kan leses inn på denne litt clunky måten (regex er ikke min sterke side).\r\nDisse dataene koder ord på en skala fra -5 (mest negativ) til +5 (mest positiv)\r\n\r\n\r\n#sentiment-data\r\nsentiment <- read_delim(\"AFINN-no-165.txt\", \"|\", escape_double = FALSE, col_names = FALSE, trim_ws = TRUE)\r\nsentiment$verdi = parse_number(sentiment$X1)\r\nsentiment$tekst = gsub(pattern = \"[-][012345]|[012345]\", replacement = \"\", x = sentiment$X1)\r\nsentiment$tekst = gsub(pattern = \"\\t\", replacement = \"\", x = sentiment$tekst)\r\nsentiment = select(sentiment, -X1)\r\n\r\n#fjerner litt krøll - manglende verdier og ett ord med verdi 8\r\nsentiment = filter(sentiment, is.na(verdi) == FALSE) %>%\r\n  filter(., verdi < 6)\r\n\r\n\r\nDet er 3 211 ord i ordboka. Tabellen under lister opp antallet ord i hver verdi-kategori. Det er kun 13 ord som er mest negative, og 4 ord i den mest positive kategorien. De fleste ordene er å finne i -2-kategorien. Faktisk ser det ut til at om lag 2 000 av ordene er negative, mens nærmere 1 000 er positive. Er dette en trend ved det norske språket, eller ved ordboka? Jeg vil anta det siste.\r\n\r\n\r\n\r\nVi tar et tilfeldig utvalg på ett ord fra hver verdikategori:\r\n\r\n\r\ntemp = group_by(sentiment, verdi) %>%\r\n  sample_n(., 1)\r\nknitr::kable(temp)\r\n\r\nverdi\r\ntekst\r\n-5\r\ntispe\r\n-4\r\nterningkast en\r\n-3\r\nskyld\r\n-2\r\ndruknet\r\n-1\r\ndump\r\n0\r\nnb\r\n1\r\nforlenge\r\n2\r\nbehagelig\r\n3\r\nriktig retning\r\n4\r\nrofl\r\n5\r\nbegeistret\r\n\r\nDette er definitivt ord som brukes - men i et politisk program? Neppe relevant med de mest negative ordene, i hvert fall, og neppe heller de mest positive. Ved første iterasjon fant jeg også at ordet “som” er kodet med +2. “Som” er jo ikke et spesielt positivt ord, det er et pauseord, et stoppord - og dermed må stoppordene fjernes også denne gangen.\r\nVed hjelp av en inner join smelter vi ordboka sammen med ordene i partiprogrammene:\r\n\r\n\r\ndf = inner_join(sentiment, df_programmer, by = c(\"tekst\" = \"term\"))\r\n\r\n#en utfordring her er at vi blander verdien på en variabel og antallet observasjoner\r\n#bør ekspanderes\r\ndf_utvida = uncount(df, antall)\r\n\r\n\r\n\r\n[1] 14434\r\n[1] 644\r\n\r\nAv de 3 211 ordene i AFINN-ordboka, er 644 ord i bruk i partiprogrammene. Sagt på en anna måte - av de 14 434 ordene i programmene, er det 644 ord som finnes igjen i AFINN. Gir de koda ordene et representativt utvalg? Tja, vanskelig å si - mange av ordene som ofte brukes kan antas å være ganske nøytrale. Men det kan også være at politisk sjargong er mer spesialisert, og har andre positive og negative ord enn det generelle språket. Det kan også være at det er har andre nyanser?\r\n##Hva er de mest stemningsladde ordene i partiprogrammene?\r\n\r\n\r\ntemp = count(df, tekst, sort = TRUE, wt = antall) %>%\r\n  left_join(., sentiment) %>% #hekter også på ordene igjen\r\n  top_n(., 10, n)\r\nknitr::kable(temp)\r\n\r\ntekst\r\nn\r\nverdi\r\nsikre\r\n503\r\n2\r\nbedre\r\n347\r\n2\r\nstyrke\r\n323\r\n2\r\ngod\r\n289\r\n3\r\nrette\r\n273\r\n2\r\nønsker\r\n254\r\n1\r\nviktig\r\n243\r\n2\r\nøke\r\n187\r\n1\r\nstørre\r\n181\r\n3\r\ngodt\r\n161\r\n3\r\n\r\nDe ti mest brukte ordene er positive. De mest brukte positive ordene er “sikre”, “bedre” og “styrke”, alle med en verdi på +2, mens god er koda som +3 (vurderinga som ligger bak at god er sterkere positivt enn bedre skal jeg ikke gå inn i).\r\n##Hva er den gjennomsnittlige stemninga i partiprogrammene?\r\nHvis vi så beregner gjennomsnittlig stemning i de ulike partienes programmer, og plotter denne, får vi den følgende figuren:\r\n\r\n\r\n\r\nHøyre er det gjennomsnittlig mest positive partiet, med +1,3 stemning. Forskjellen ned til KrF og SP er bitteliten. Rødt er det mest negative, på +0,6, men også de er positivt innstilt - sammen med SV (+0,8) og FrP (+0,9).\r\nSpennet fra Høyre ned til Rødt er på 0,7 stemning, altså under en hel stemningsverdi på kodeskalaen. Det er ikke mye - og med disse gjennomsnittene forsvinner mye av variasjonen. Hvordan ser spredninga ut for de enkelte partiene?\r\n\r\n\r\n#skal telle opp antall ord assosisert med hver enkelt følelses-verdi\r\ntemp = group_by(df_utvida, parti, verdi) %>%\r\n  summarise(., antall = n()) %>%\r\n  mutate(., andel = antall / sum(antall))\r\n\r\nggplot(data = temp) +\r\n  geom_col(aes(x = verdi, y = andel)) +\r\n  facet_wrap(~parti) +\r\n  scale_x_continuous(breaks = seq(from = -5, to = 5, by = 1))\r\n\r\n\r\n\r\nAlle partiene bruker positive ord +2 mest, fulgt av +1. Rødt, SV og FrP ser ut til å ha noe større andel negative ord i sine program. Det ser vi også i boksplottet under, hvor medianen for disse tre partiene ligger på ord med +1, mens den for de øvrige partiene ligger på +2. De negative følelsene er for uteliggere å regne (dvs. mer enn 1,5 ganger avstanden mellom første og tredje kvartil). De negative følelsene er innafor denne avstanden for Rødt, SV og FrP.\r\nDette gir mening - Rødt, SV og FrP er typisk mer kritisk til det bestående, og ønsker da kanskje relativt sett større endringer i Oslo enn andre partier. Det gir bittelitt mindre mening i et lokalvalg i Oslo, hvor Rødt og SV jo har utgjort en del av det bestående de siste fire årene. Men det samme kunne man jo sagt om FrP, som sitter i Regjering på sjette året. En anna vinkling på dette er at det er større variasjon i følelsene i FrP, SV og Rødt.\r\n\r\n\r\nggplot(data = df_utvida, aes(x = fct_reorder(parti, verdi, .fun = mean), y = verdi)) + \r\n  geom_jitter(colour = \"steelblue\", alpha = 0.1) + \r\n  geom_boxplot(alpha = 0.5) + \r\n  coord_flip() + \r\n  scale_y_continuous(breaks = seq(from = -5, to = 5, by = 1)) + \r\n  labs(x = \"Parti\", y = \"Stemning\")\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2019-09-04-stemningsanalyse-av-partiprogram/stemningsanalyse-av-partiprogram_files/figure-html5/unnamed-chunk-4-1.png",
    "last_modified": "2023-11-25T07:55:07+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-08-31-tidytext-analyse-av-partiprogram/",
    "title": "Hvordan lese ni partiprogram skikkelig fort? Tidytext-analyse av valgprogram",
    "description": "En kikk på valgprogrammene for kommunevalget i Oslo, med tidytext.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2019-08-31",
    "categories": [],
    "contents": "\r\nDet er høst, 2019, og på tide med LOKALVALG! En statsviters våte drøm? Ikke egentlig - plutselig får en spørsmål om Dhonts metode og slikt som en ikke lenger husker. Men det en kan gjøre er å sette seg inn i partiprogram, og diskutere hvem som er best.\r\nDet er ikke så lett. Alle mener selvsagt at de er best, og snakker av en eller anna grunn neste bare om ting en ikke kan være uenig i.\r\nKan tekstanalyse hjelpe oss litt på veien? For å undersøke det gjør jeg tre ting (som tatt ut av https://www.tidytextmining.com/index.html):\r\nHvilke ord bruker partiene i Oslo mest? Røpealarm: det er fine ord om seg selv.\r\nHvilke ord bruker hvert enkelt parti i større grad enn de andre partiene? Røpealarm: De snakker mer om politiske tema som de selv er opptatt av - men det er vanskelig å si hvor mye de er opptatt av det.\r\nHvilke temaer snakker de ulike partiene mest om? Røpealarm: Seg selv - det var ikke mulig å finne substansielle temaer som helse, eldre og barn - partiene er for det meste opptatt av seg selv\r\n\r\n\r\nsuppressPackageStartupMessages(library(tidyverse))\r\nlibrary(tidytext)\r\nlibrary(here)\r\nlibrary(tm)\r\nlibrary(topicmodels)\r\nlibrary(broom)\r\n\r\n#settings\r\ntheme_set(theme_minimal())\r\nset.seed(1106)\r\n\r\n\r\nDatagrunnlaget\r\nAlle partiene har PDF-filer av valgprogrammene sine for Oslo tilgjengelig. PDF-filer lar seg lese inn, men krever litt tygging for å få fjerna punktsetting, nummer og lignende.\r\nHelt til slutt fjerner jeg også stoppord - 176 vanlige ord i det norske språket som jevnt over brukes mye (i, og, jeg, det, …).\r\n\r\n\r\n#med TM\r\n\r\n# lag et korpus fra pdf-filene\r\nconverted <- VCorpus(DirSource(\"valgprogram\"), readerControl = list(reader = readPDF, language = \"nb\")) %>% \r\n  DocumentTermMatrix(., control = list(language = \"nb\", \r\n                                       removePunctuation = TRUE,\r\n                                       removeNumbers = TRUE,\r\n                                       stopwords = stopwords(\"no\") #fjerner stoppord \r\n                                       ))\r\n\r\n#opprydding\r\n#fjerner .pdf-suffixet\r\ndf = tidy(converted) %>%\r\n  mutate(., document = gsub(\".pdf\", \"\", document, fixed = TRUE))\r\n\r\n#setter bedre navn på variablene\r\nnames(df) = c(\"parti\", \"term\", \"antall\")\r\n\r\n\r\nHvem er mest ordrik?\r\nHer sitter vi da med en data.frame hvor hver rad er frekvensen til et ord i et partis partiprogram. Hvor ordrike er partiene i sine valgprogram?\r\n\r\n\r\n#litt enkel grafing \r\ntemp = group_by(df, parti) %>%\r\n  summarise(., antall_termer = n())\r\n\r\nggplot(data = temp, aes(x = fct_reorder(parti, antall_termer), y = antall_termer)) + \r\n  geom_col() + \r\n  coord_flip() + \r\n  labs(title = \"Rødt har flest unike termer i partiprogrammet\", subtitle = \"Partienes valgprogram for Oslo, 2019-2023\", y = \"Antall termer\",x = \"Parti\")\r\n\r\n\r\n\r\nHvilke ord er mest brukt i valgprogrammene?\r\n\r\n\r\ntemp = group_by(df, term) %>%\r\n  summarise(., antall = sum(antall)) %>%\r\n  top_n(., 10, antall)\r\n\r\nggplot(data = temp, aes(x = fct_reorder(term, antall), y = antall)) + \r\n  geom_col() + \r\n  coord_flip() + \r\n  labs(title = \"Oslo det mest brukte ordet i Oslo-valgkampen\", y = \"Antall ganger brukt\",x = \"Ord\")\r\n\r\n\r\n\r\nDe øvrige ordene er heller ikke spesielt overraskende: Gode, trygge, sikre honnørord, som antakeligvis brukes til å beskrive både innsatsen i forrige periode, innsatsen framover, og hvordan kommunen vil bli med akkurat Dette Partiet ved roret. Det eneste subsansielle som kommer fram her er barn - noe som ikke er rart, en sentral del av kommunepolitikk handler nettopp om barna.\r\nHva er de viktigste ordene for de ulike partiene?\r\nEn ganske usofistikert måte å måle dette på er ved å ganske enkelt telle opp alle ordene, og så se hvilke ord hvert enkelt parti bruker mest.\r\n\r\n\r\ntemp = group_by(df, parti) %>%\r\n  top_n(10, wt = antall) %>%\r\n  arrange(., antall)\r\n\r\nggplot(data = temp, aes(x = reorder_within(term, antall, parti), y = antall, fill = parti)) + \r\n  geom_col(show.legend = FALSE) + \r\n  facet_wrap(~parti, scales = \"free\", ncol = 2) + \r\n  scale_x_reordered() + \r\n  coord_flip() + \r\n  labs(title = \"Oslo og eget parti langt det mest vanlige å omtale\", subtitle = \"Ti mest brukte ord i  valgprogrammet for 2019-2023\", x = \"Parti\", y = \"Antall ganger ordet er nevnt\")\r\n\r\n\r\n\r\nOrdene skiller seg ikke veldig fra hverandre. Alle snakker mest om Oslo.\r\nAp snakker om seg selv. FrP snakker om kommune-kommune-kommune.\r\nHøyre vil ha flere gode og enda bedre barn.\r\nDet vil også KrF, men de vil ha flere sikre løsninger for disse barna.\r\nMDG vil sikre en grønn by.\r\nRødt er opptatt av hva kommunale ansatte bør gjøre.\r\nSp er opptatt av seg og sitt eget bystyreprogram.\r\nSV vil …sikre kommune gjennom ny kommune?\r\nVenstre slår seg også løs med sikring av noe bedre.\r\nHva skriver partiene om, som de andre ikke nevner?\r\nIkke så stort å lære av dette, egentlig. En potensielt nyttigere tanke er å finne fram til unike ord for hvert parti, som i mindre grad brukes av de andre partiene. Dette er såkalte tf_idf-ord, hvor ord som brukes mye på tvers av dokumenter (her, partiprogram) får lavere vekt, mens ord som brukes lite på tvers får høyere vekt.\r\n\r\n\r\nprogram_ord = bind_tf_idf(df, term, parti, antall)\r\n\r\ntemp = group_by(program_ord, parti) %>%\r\n  top_n(10, wt = tf_idf)\r\n\r\nggplot(data = temp, aes(x = reorder_within(term, tf_idf, parti), y = tf_idf, fill = parti)) + \r\n  geom_col(show.legend = FALSE) + \r\n  facet_wrap(~parti, scales = \"free\", ncol = 2) + \r\n  scale_x_reordered() + \r\n  coord_flip() + \r\n  labs(title = )\r\n\r\n\r\n\r\n(Merk her at top_n()-funksjonen tar med flere ord hvis rangeringa er uavgjort - så arbeiderpartiet får flere ord)\r\nIkke overraskende snakker fortsatt alle partiene mest om seg.\r\nAp snakker mer om fengsel, lønnstilskudd, språkkunnskaper og anstendighet enn de andre.\r\nFrP vil helt klart konkurranseutsette, og er opptatt av rusken, gravplasser, utviklingshemmede og hva folk kler seg i.\r\nHøyre snakker om introduksjonsprogrammet, yrkesfag, barnehage og oppvekst.\r\nKrF er opptatt av seniorer og formodentlige både kristne og humanistiske verdier.\r\nMDG snakker om bærekraft, forbruk og dyrevelferd.\r\nRødt er overaskende opptatt av foto, kvinner og millioner - kanskje noe mindre informativt enn de andre. Sp er veldig opptatt av seg selv - og sosialfaget.\r\nSV er mer enn de andre opptatt av samer, turveier, kvinner , ulikhet og rasisme.\r\nVenstre - de vil ha småhus, sexarbeidere, rusbrukere og skolebibliotek.\r\nDenne indikatoren plukka opp på en god måte hva de ulike partiene er opptatt av, og skriver mer om enn andre partier. Men gir det en pekepinn på hva en skal stemme? Nja. En bedre indikator hadde vært om en kunne identifisert mer substansielle temaer på tvers av partiprogrammene, som f.eks. skole, slik at en kunne sett hvor mye hvert enkelt partiprogram bidro til dette temaet.\r\nHvilke temaer tar programmene opp?\r\nOg det kan vi - kanskje. Med LDA - Latent Dirichlet Allocation - kan en estimere hvordan ett dokument består av flere tema, og ett tema består av flere ord på tvers av dokumenter. Så dermed kunne en - kanskje - se om f.eks. partiprogrammene tematiserer skole i ulik grad.\r\nAlgoritmen tar en DocumentTermMatrix, så vi finner igjen denne fra lenger oppe.\r\n\r\n\r\nmodel_1 = LDA(converted, k = 9)\r\n\r\ntema = tidy(model_1, matrix = \"beta\")\r\n\r\ntema_topp = group_by(tema, topic) %>%\r\n  top_n(10, beta) %>%\r\n  ungroup() %>%\r\n  arrange(topic, -beta)\r\n\r\nggplot(data = tema_topp, aes(reorder_within(term, beta, topic) , beta, fill = factor(topic))) + \r\n  geom_col(show.legend = FALSE) + \r\n  facet_wrap(~topic, scales = \"free\") +\r\n  coord_flip() + \r\n  scale_x_reordered()\r\n\r\n\r\n\r\nViser seg at denne algoritmen identifiserer partiene, heller enn temaene innad i partiprogrammene. Dette gjelder uansett hvilken k vi setter på LDA-funksjonen: Det mest gjenkjennelige i dokumenthaugen er skillene mellom partiprogrammene.\r\nHvis vi snur på flisa, og ser på sannsynlighetene for at en spesifikk tema hører til et spesifikt dokuments, ser vi dette veldig tydelig:\r\n\r\n\r\ntema_dokument = tidy(model_1, matrix = \"gamma\")\r\n\r\nggplot(data = tema_dokument, aes(factor(topic), gamma)) +\r\n  geom_boxplot() +\r\n  facet_wrap(~document)\r\n\r\n\r\n\r\nBildet er riktignok ikke helt 100 % krystallklart: Høyres partiprogram har biter som også er identifisert i KrFs partiprogram\r\nOppsummert\r\nNår ulike algoritmer raskt lar seg kjøre, og outputen enkelt lar seg plotte, så er det lett å glemme det viktigste i en slik analyse: Selve analysen. Hva er det vi har sett her?\r\nDe mest brukte ordene skiller seg ikke veldig fra hverandre, men alle partiene er selvsagt mest opptatt av seg selv. Det gjør også at når vi prøver å finne tverrgående tema, så feiler det - vi finner kun igjen partiprogrammene (med en interessant overlapp mellom H og KrF). Det kan ganske enkelt skyldes at datagrunnlaget er for lite - men det kan også tenkes at selv om de alle er like i de mest brukte ordene, så har de ulike nok ordvalg til at de framstår som distinkte.\r\nAlle partiene har også mer unike saker, som de andre i mindre grad snakker om. Det er imidlertid uklart fra denne gjennomgangen hvor stor plass f.eks. samisk politikk tar for Oslo SV - men antakeligvis er bærekraftsmålene en viktig komponent hos MDG.\r\n\r\n\r\n\r\n",
    "preview": "posts/2019-08-31-tidytext-analyse-av-partiprogram/tidytext-analyse-av-partiprogram_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2023-11-25T07:55:07+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-08-02-visualisering-og-sammenlikning-av-fordelinger-i-ggplot2/",
    "title": "Visualisering og sammenlikning av fordelinger i ggplot2",
    "description": "Hvordan visualisere fordelinger på tvers av kategorier, med eksempler fra deltakelse i skolefritidsordninga i norske kommuner",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2019-08-02",
    "categories": [],
    "contents": "\r\nDet har vært en del oppstuss rundt skolefritidsordninga - SFO, eller AKS her i Oslo - de siste dagene. NTNU Samfunnsforskning har levert en evalueringsrapport som i følge NRK peker på enorme forskjer i pris og tilbud. Det er særlig en NTB-melding som har blitt trykt opp rundt omkring, i følge med en datavisualisering fra nyhetsgrafikk.no. Den skal være limt inn under.\r\nUtklipp fra Dagsavisen 2. august 2019Grafikken har masse informasjon, men er allikevel ikke spesielt informativ. Hvorfor ikke? Etter min mening prøver den å dekke over for mye på en gang. Tittelen antyder at den handler om at flest bybarn bruker SFO. Men figurene viser oss andel barn som bruker SFO etter fylke - og ikke byer vs. ikke-byer. Videre trekker den inn gjennomsnittlig månedspris på fylkesnivå, og de ti dyreste og billigste SFO-kommunene - og hvor disse ligger i landet. Altså heller ikke relatert til overskriften.\r\nHva ville vært en bedre måte å vise dette på? Ved å angripe det som tittelen sier at grafikken skal si noe om - sammenhengen mellom å bo i by, og å bruke SFO.\r\nUnder ser vi kjapt på noen enkle måter å visualisere fordelinger på, ved hjelp av R og GGplot2-biblioteket.\r\nDatagrunnlaget\r\nSFO-deltakelse hentes fra SSBs statistikkbank (KOSTRA), tabell 11975. Den gir oss andel av barn fra og med 6 år til og med 9 år som i 2018 brukte kommunal eller privat SFO i en kommune. Dataene hentes fra APIet hos SSB.\r\nHva vil det si at noen bor i en by? I Norge er det ingen offisiell definisjon av en by - det eneste er en gammel veiledende definisjon fra 1997, som tilsier at en kommune med 5000 innbyggere og “sentrale tjenester” kan kalle seg by. Et mål på hva som er en by finner vi derfor i SSBs sentralitetsindeks. Denne indeksen sier noe om hvor mange arbeidsplasser og servicetjenester folk i kommunen kan nå med bil på 90 minutter. Dette er målet vårt på hvor urbant du bor.\r\n\r\n\r\n#SFO\r\nsfo_data = ApiData(\"https://data.ssb.no/api/v0/no/table/11975\",\r\n                   KOKkommuneregion0000 = TRUE,\r\n                   ContentsCode = \"KOSandsfo69kp0000\",\r\n                   Tid = \"2018\"\r\n                   )\r\n\r\ndf = sfo_data[[2]] %>%\r\n  select(., -ContentsCode, -Tid, -NAstatus) %>% #fjerner variabler med kun 1 verdi (konstanter)\r\n  filter(., nchar(KOKkommuneregion0000) == 4) #filtrer ut alle regioner som ikke har 4 karakterer\r\n\r\nnames(df) = c(\"knr_2018\",\"value\")\r\n\r\n#sentralitet\r\nsentralitet = read.csv2(\"sentralitet_2018.csv\", stringsAsFactors = FALSE, colClasses = c(\"character\", \"integer\", \"integer\"))\r\n\r\nsentralitet$sklasse_2018 = factor(sentralitet$sklasse_2018, labels = c(\"Mest sentral\", \"2\", \"3\", \"4\", \"5\", \"Minst sentral\"))\r\n\r\ndf = left_join(df, sentralitet) %>%\r\n    filter(., is.na(value) == FALSE, is.na(sklasse_2018) == FALSE)\r\n\r\n\r\nEn enkel fordeling\r\nFordelinger er veldig viktig, og å kikke på dem kan gi mye innsikt. En fordeling gir deg et bilde på om det er feil eller mangler i dataene, om modellering bør ta høyde til spesifikke ting, og til slutt - fordelinger viser et mye bedre bilde enn enkle punkt-oppsummeringer, som gjennomsnitt og standardavvik.\r\nDet er i hovedsak to teknikker som er mye brukt for å vise fordelinger: histogram og “kernel density estimates”. Histogrammet er bra for enkle fordelinger. De er intuitive for leseren, og lette å tolke. Men nedsida er at bøtte-klassifiserng har mye å si for hvordan det blir seende ut, og små datamengder kan fort bli seende rart ut. Folk som registrer data har også gjerne preferanser for noen dataverdier.\r\nHar du mer enn 150 observasjoner? Bruk bins=100. For mindre n, eksperimenter rundt.\r\nHar du data med naturlige brytninger? Utnytt dem\r\nBruk binwidth, gjerne sammen med center som forteller hva som er midtpunktet for en bøtte.\r\n\r\n\r\nggplot(data = df, aes(value)) + \r\n  geom_histogram(binwidth = 5, center = 2.5) + \r\n  labs(y = \"Antall kommuner\", x = \"Andel barn i SFO\", title = \"De fleste kommuner har rundt 40 - 60 % deltakelse i SFO\")\r\n\r\n\r\n\r\nDet ser altså ut til å være en stor haug med kommuner i midten, og så en del kommuner ute på sidene - ganske så normalfordelt, egentlig.\r\nSammenlikne fordelinger\r\nHvis en skal sammenlikne om to populasjoner eller måloppnåelser er like, må en sammenlikne fordelinger. Histogram med fasetter er ikke plass-effektive, og får mye akser og linjer fort. Det gjelder særlig med mange grupper for sammenlikning.\r\nEn bruker derfor i stedet et boksplot. Hvis en har mye data, er beeswarm bedre. Hvis en har enda mer data, er violin-plot bedre. Hvis det en sammenlikner over er en ordinal variabel, kan ridgeline-plot være best.\r\nI tilfellet med SFO-dataene er ikke gruppene egentlig så mange, slik at histogrammer kanskje kan være egnet - evt. slektningen “freqpoly”. Men som vi kjapt ser, så er det neimen ikke lett å bli spesielt klok av dette. De mest sentrale kommunene ser ut til å ha størst deltakelse i SFO, men det er også på alle måter færrest av disse. Vi trenger et mer relativt mål.\r\n\r\n\r\nggplot(data = df, aes(value, colour = sklasse_2018)) + \r\n  geom_freqpoly(binwidth = 5, center = 2.5) + \r\n  labs(y = \"Antall kommuner\", x = \"Andel barn i SFO\", colour = \"Sentralitet\", title = \"Andelen barn i SFO varierer med en kommunes sentralitet\")\r\n\r\n\r\n\r\nEn mer kompakt måte å vise dette på er da med et boksplott. Relativt gjenkjenbart (selv om en ofte må markere hva som vises - median, grense for første og tredje kvartil - dvs. at 50 % av dataene er innafor boksen), og gir kompakt informasjon. Nedsida er at informasjonen er for kompakt, og viser ikke egentlig fordelinga. En måte å få mer av fordelinga med på, er ved å bruke geom_jitter(). Denne plotter hver enkelt observasjon.\r\n\r\n\r\nggplot(data = df, aes(x = sklasse_2018, y = value)) + \r\n  geom_jitter(colour = \"steelblue\", alpha = 0.3) + \r\n  geom_boxplot(alpha = 0) + \r\n  labs(x = \"Sentralitet\", y = \"Andel barn i SFO\", title = \"De mest sentrale kommunene har høyere deltakelse i SFO\")\r\n\r\n\r\n\r\nDenne visualiseringa får også helt tydelig fram at vel er det slik at de mer sentrale kommunene har høyere SFO-deltakelse, men spredninga er også langt større blant de mindre sentrale kommunene.\r\nBeeswarm og violin er ikke spesielt aktuelt for oss - men ridgeline kan være det. Ridgeline passer der en har en ordinal variabel, altså har informasjon om rekkefølge. Farge på biler har ikke en slik sortering - men f.eks. måneder i et år har det, eller sentralitet på en kommune.\r\nDette er KDE-plot som plottes nærmere enn andre plots. Det gir også svakhetene - de kan overplottes, og kernel-valg er vanskelig når det er mange fordelinger.\r\n\r\n\r\nggplot(data = df, aes(x = value, y = sklasse_2018)) + \r\n  geom_density_ridges(alpha = 0.7) + \r\n  scale_x_continuous(limits = c(0, 100), expand = c(0,0)) + \r\n  theme(axis.ticks.y = element_blank()) + \r\n  labs(x = \"Andel i SFO\", y = \"Sentralitet\")\r\n\r\n\r\n\r\nEr det en sammenheng mellom sentralitet og SFO-deltakelse?\r\nSentralitet er også målt som en kontinuerlig variabel hos SSB. Dette gir oss muligheten til å også bruke et scatterplot, og estimere en trendlinje.\r\n\r\n\r\nggplot(data = df, aes(x = sindeks_2018, y = value)) + \r\n  geom_jitter(alpha = 0.3) + \r\n  geom_smooth()\r\n\r\n\r\n\r\nHva er anbefalinga her?\r\nSå hva hadde vært en bedre måte å vise at flere bybarn bruker SFO? Anbefalingen her må være å bruke boksplot-tilnærmingen. Det krever nok god annotering, men det får de allerede til med kartet.\r\n\r\n\r\nggplot(data = df, aes(x = sklasse_2018, y = value)) + \r\n  geom_jitter(colour = \"steelblue\", alpha = 0.3) + \r\n  geom_boxplot(alpha = 0) + \r\n  labs(x = \"Sentralitet\", y = \"Andel barn i SFO\", title = \"Flest bybarn bruker SFO\") + \r\n  annotate(\"text\", x = 1.5, y = 80, label = \"3. kvartil\") + \r\n  annotate(\"text\", x = 1.5, y = 70, label = \"Median\") + \r\n  annotate(\"text\", x = 1.5, y = 65, label = \"1. kvartil\")\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2019-08-02-visualisering-og-sammenlikning-av-fordelinger-i-ggplot2/visualisering-og-sammenlikning-av-fordelinger-i-ggplot2_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2023-11-25T07:55:07+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-04-23-visualisering-og-sammenlikning-av-antall-i-ggplot2/",
    "title": "visualisering og sammenlikning av antall i ggplot2",
    "description": "Hvordan visualisere antall og sammenlikne kategorier med ggplot2 i R, ved hjelp av søylediagram og punktdiagram",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2019-04-23",
    "categories": [],
    "contents": "\r\nVi har tidligere sett på hvordan andeler bør visualiseres. Denne gangen skal vi se på noe enda mer grunnleggende - antall. Veldig ofte er vi interessert i et enkelt tall eller en observasjon, for eksempel et gjennomsnitt eller en maksverdi. Vi ønsker også å sammenlikne denne verdien på tvers av ulike kategorier, som kjønn, typer biler eller geografisk enhet.\r\nDet er i hovedsak to standard måter å visualisere denne typen data på: stolpediagram (eller søylediagram), og punktdiagram.\r\n\r\n\r\n\r\n###Eksempeldata fra SSBs åpne API.\r\nOgså denne gangen bruker vi eksempeldata fra SSB. Ut ifra publiseringsoversikten ser jeg at det nylig er lagt ut kulturstatistikk, også dette fra KOSTRA. Besøk på folkebibliotek i landets kommuner fra 2015 til 2018 kan kanskje være interessant.\r\n\r\n\r\nalle_data = ApiData(\"https://data.ssb.no/api/v0/no/table/13135\",\r\n             KOKkommuneregion0000 = TRUE,\r\n             ContentsCode = \"KOSbesokbiblinnb0000\",\r\n             Tid = TRUE\r\n)\r\n\r\n#ApiData() returnerer både koder og menneskelesbar tekst, jeg går for tekst denne gangen\r\ndf <- alle_data[[1]] %>%\r\n  select(.,-statistikkvariabel) #filtrerer ut unødvendig info\r\n\r\n\r\nDet viser seg at 2018-tallene er tomme, så vi må begrense oss til 2015-2017.\r\nStolpediagram / søylediagram\r\nDisse figurene er superenkle. For mange er dette standard-diagrammet en tenker på, når en tenker på en graf. De er lettvinte å lage, og ofte lette å forstå - for svært mange. Men: hvis kakediagram er mer nyttig enn ryktet tilsier, så er søyler mindre nyttige en ryktet. Mer om det om litt.\r\nGgplot2 har to geoms for søylediagram: geom_bar og geom_col. geom_col er for bruk når du har tallet som skal mappes, mens geom_bar inkluderer en beregning.\r\nMed geom_col kan vi se nærmere på de ti stedene med de høyeste besøkstallene (per innbygger) i 2017.\r\n\r\n\r\ntemp = filter(df, `år`==\"2017\") %>%\r\n  arrange(., desc(value)) %>%\r\n  slice(., 1:10) %>%\r\n  mutate(., region = as.factor(region), region = fct_reorder(region, value))\r\n\r\nggplot(data = temp, aes(x = region, y = value))+\r\n  geom_col() +\r\n  coord_flip() + \r\n  labs(title =\"Lesehestene i Stjørdal besøkte folkebiblioteket mest\", subtitle =\"I gjennomsnitt 24 ganger i 2017\", x = \"Antall besøk per innbygger\", y = \"Kommune\")\r\n\r\n\r\n\r\nStjørdal kommune har altså flest besøk i folkebiblioteket per innbygger, med 24 besøk i 2017.\r\nSøylediagram må alltid starte på 0. Dette er en av få absolutte regler i visualisering av data. Det skyldes at det vi gjør når vi leser et søylediagram, er å se på lengden av diagrammet. Hvis vi skal sammenlikne flere søyler, sammenlikner vi lengder. Hvis vi da starter på noe annet enn 0, får vi feil lengde. R håndterer dette automatisk for oss.\r\nSiden diagrammet får litt overplotting, må vi også rotere aksene for å lese alle kommunenavnene.\r\nDataene bør alltid være fornuftig sortert, slik at de er lette for leseren å forstå. Siden dette er en topp-ti-liste, kan vi sortere dem fra stor til liten. Anbefalingen fra Grolemund og Wickhams R for Data Science er å ta kompliserte omorganiseringer ut av ggplot-funksjonen og inn i en egen mutate-funksjon, for å gjøre koden lettere å lese-\r\nGeom_bar er en funksjon som gjør litt beregninger og opptellinger selv. Standardinnstillingen er å telle opp antallet observasjoner for hver x-posisjon - i tilfellet over er det region. Den tar også et vekt-argument, som bestemmer hvor mye hver observasjon skal telle med. Dermed kan vi kjapt se hvem som har størst summert gjennomsnittlig besøk blant de 10 første kommunene (over de fire siste årene)\r\n\r\n\r\n#geom_bar\r\ntemp = mutate(df, region = as.factor(region)) %>%\r\n  slice(1:40)\r\n\r\nggplot(data = temp, aes(x = region, weight = value))+\r\n  geom_bar()\r\n\r\n\r\n\r\nHva er problemene med søylediagram? De bør først og fremst brukes på ting som gir en meningsfull kumulering, altså slik at de kan stables (som penger): folk oppfatter gjerne ting under toppen av søyla som inkludert i søyla, og ting over søyla som ikke inkludert i søyla. Så hvis en f.eks. skal angi at noe har en presis verdi, og ikke en annen verdi, så er søylediagram uegna. Eksempler kan være persentiler, temperaturer, ikke-lineære verdier (log).\r\nPunkt-diagram\r\nEksempelet over, med flere stablede gjennomsnitt i et søylediagram, er også uegna, ettersom gjennomsnitt i tre ulike år ikke gir mening å kumulere. Løsninga på dette kan være å plotte dem hver for seg - men også et punktdiagram kan hjelpe. Et punkt-diagram erstatter søylen med et punkt på verdien. Det er plasseffektivt, lett å lese og enkelt.\r\n\r\n\r\n#geom_bar\r\ntemp = mutate(df, region = as.factor(region)) %>%\r\n  slice(1:40) %>%\r\n  mutate(., region = fct_reorder(region, value))\r\n\r\nggplot(data = temp, aes(x = region, y = value))+\r\n  geom_point() + \r\n  coord_flip() +\r\n  labs(title = \"Besøk til folkebiblioteket varierer mer mellom kommuner enn over år\", x = \"Kommune\", y = \"Antall besøk per innbygger\")\r\n\r\n\r\n\r\nHer kommer vi imidlertid også inn på behov for å se på fordelinger og endringer over tid. I det helt grunnleggende eksempelet har vi bare noen tall vi ønsker å kikke på.\r\n\r\n\r\n#trekker et tilfeldig utvalg av enheter\r\ntemp = filter(df, `år` == \"2017\") %>%\r\n  sample_n(., 15) %>%\r\n  mutate(., region = as.factor(region), region = fct_reorder(region, value))\r\n\r\n#punktdiagram\r\nggplot(data = temp) + \r\n  geom_point(aes(x = region, y = value)) + \r\n  coord_flip() + \r\n  labs(title = \"Gjennomsnittlige besøk per innbygger i 2017\", subtitle = \"Tilfeldig utvalgte kommuner\", x = \"Kommune\", y = \"Antall besøk per innbygger\")\r\n\r\n\r\n\r\nAndre tall som lettere lar seg vise med et punktdiagram er logaritmer, eller prosentvise endringer. Et eksempel på en slik størrelse er. “log fold change”. Fold change er forholdet mellom startverdi og sluttverdi, som en kan ta log2-av. Tallet en får da vil da vise hvor mye større/mindre sluttverdien er enn startverdien: 1 betyr dobbelt så stor, 2 fire ganger så stort, -1 betyr dobbelt så liten.\r\n0 er skille mellom økning og nedgang. Når dataene har et så tydelig brudd-punkt, bør det også framgå av visualiseringa. En kan også vurdere å fjerne flere av støttelinjene , som de horisontale.\r\n\r\n\r\n#beregner logFoldChange fra 2015 til 2017\r\n#her er jeg implisitt avhengig av sorteringa av dataene som kommer inn. Dårlig praksis.\r\ntemp = filter(df, `år` == \"2017\"|`år` == \"2015\") %>%\r\n  slice(., 1:30) %>%\r\n  spread(., `år`, value, sep = \"_\") %>%\r\n  mutate(., logFoldChange = log2(`år_2017`/`år_2015`)) %>%\r\n  mutate(., region = as.factor(region), region = fct_reorder(region, logFoldChange))\r\n\r\n#punktdiagram\r\nggplot(data = temp, aes(x = logFoldChange, y = region)) +\r\n  geom_point(size = 2) + \r\n  geom_vline(xintercept=0) +\r\n  labs(title = \"Hvaler og Råde har størst økning i gjennomsnittlig biblo-besøk\", subtitle = \"Fra 2015 til 2017\", y = \"Kommune\") +\r\n  theme(\r\n  panel.grid.major.y = element_blank()\r\n  )\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2019-04-23-visualisering-og-sammenlikning-av-antall-i-ggplot2/visualisering-og-sammenlikning-av-antall-i-ggplot2_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2023-11-25T07:55:07+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-04-05-norsk-data-science/",
    "title": "Data science på norsk",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2019-04-05",
    "categories": [],
    "contents": "\r\n“Data science” eller datavitenskap er den nye vinen. Eller, det skulle man i hvert fall tro når til og med staten arrangerer fagforum for “kunstig intelligens og data science”. Men hva er det? Hva er det på norsk? Og er det viktig?\r\nHva er datavitenskap?\r\nFor det aller første, så er det åpenbart et engelsk begrep som klinger dårlig i norske ører. Jeg har imidlertid ikke funnet noen god norsk oversettelse så langt. Avanserte analyser høres et hakk bedre ut, men mulig det ikke gir helt de riktige konnotasjonene enda.\r\nFramveksten av datavitenskap (i Norge) henger tett sammen med framveksten av kunstig intelligens.\r\n\r\n\r\n#sett inn figuren fra disse dataene\r\n#https://trends.google.com/trends/explore?date=all&geo=NO&q=data%20science,Kunstig%20intelligens\r\ndf = read.csv(\"google_searches_ds_ai.csv\", skip = 2, stringsAsFactors = FALSE, fileEncoding = \"UTF-8\")\r\n\r\nnames(df) = c(\"dato\", \"datascience\", \"kunstig intelligens\")\r\ndf = gather(df, searchterm, verdi, datascience:`kunstig intelligens`)\r\ndf$dato = as.Date(paste0(df$dato,\"-\",\"01\"), \"%Y-%m-%d\") #aner ikke hvorfor jeg må legge til en dag, men det fungerer\r\n\r\nqplot(data = df, x = dato, y = verdi, colour = searchterm, group = searchterm, geom = \"line\")+\r\n  labs(colour = \"søkeord\", title =\"Google-søk etter datavitenskap og AI følger hverandre tett\")\r\n\r\n\r\n\r\nEn måte å framstille dette på ble laget allerede i 2010 av Drew Conway, i det etterhvert MYE delte data science vendiagrammet:\r\ndatascience venn diagramDet er altså tre områder som må kombineres i datavitenskap: teknisk kunnskap, statistikk og domeneekspertise. Conway selv har seinere sagt at han ikke tror på enhjørningen - den perfekte utøveren som er ekspert på alle tre. Snarere handler det om å sette sammen et team som er gode på alle områdene. Men den enkelte bør forstå viktigheten av de andre områdene. I hodet mitt er følgende inndeling nyttig:\r\nanalyser med avanserte metoder. Men også standard-analyser kan bruke avanserte metoder.\r\nutvikling av digitale tjenester som bruker kvantitative metoder for å klassifisere eller predikere, og som kjører i “produksjon”.\r\nLittebitt hype…?\r\nGartner har utvikla en “hype cycle”, som (i følge dem selv) skal fortelle noe om fasene en teknologi o.l. går igjennom: innovasjon, for høye forventninger, desillusjon, opplysning og produktivt platå. For data science ser det slik ut:\r\nGartner hype cycle - from trigger through peak expectations, trough of disillusionment, onto the plateau of realismHvor er vi nå? Antakeligvis på hype-stedet fortsatt, i hvert fall i amerikansk forstand. Men hva med Norge? I 2017 starta UMB på Ås som første norske universitet en master i datavitenskap. Ser du på et google-søk også her, ser det ut til å være godt diskutert i diverse medier og bransjeblader de siste årene.\r\nTrender i utlysninger?\r\nMen ta helst ikke mitt ord for det - se på noen data. NAV har publisert historiske stillingsutlysninger, med både vasket stillingstittel, og de 4000 første tegnene av stillingsbeskrivelsen. Strengt tatt er disse også tilgjengelig gjennom et API, men det har jeg sålangt ikke helt funnet ut av (dokumentasjonen sender meg hit.\r\noppdatert 2021: dette datasettet ligger ikke lenger på denne adressa.\r\n\r\n\r\n# henter data fra https://data.nav.no/dataset/utlysningstekster-ledige-stillinger-historikk/resource/882e3e0f-cd3c-4d3a-8072-be7ba7b3d272\r\n\r\n#df = read.csv2(\"https://data.nav.no/dataset/408fc52c-b50e-4ee7-a620-305eaa5d56e7/resource/882e3e0f-cd3c-4d3a-8072-be7ba7b3d272/download/stillingstekster-2018.csv\", stringsAsFactors = FALSE, header = TRUE, fileEncoding = \"UTF-8\")\r\n\r\n#temp = filter(df, grepl(\"data science\", Stillingsbeskrivelse.vasket))\r\n#str(temp)\r\n\r\n\r\n142 stillinger av 212 011? Ikke veldig hype - men heller ikke veldig grundig søkt i teksten.\r\n\r\n\r\n\r\n",
    "preview": "posts/2019-04-05-norsk-data-science/norsk-data-science_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2023-11-25T07:55:07+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-03-31-prognosekonkurranse-eliteserien-2019/",
    "title": "Eliteserien 2019 - hvordan blir tabellen til slutt?",
    "description": "Noen enkle eksplorerende analyser av ekspertmeninger for en konkurranse om å gjette plasseringer i eliteserien 2019.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2019-03-31",
    "categories": [],
    "contents": "\r\nHvert år arrangerer noen på kontoret en Eliteserie-tippeligakonkurranse. Jeg veit lite om fotball-lagene, og har aldri tippet noe særlig - men pleier å gjøre det greit, basert på andres harde arbeid: eksperter og odds.\r\nHer bruker jeg tidyverse, knitr og here-pakka, og en egenprodusert tabell over ulike tips til tabellplasseringer. Her har jeg også lagt på et superenkelt gjennomsnitt av lagene, for å ha noe å sortere dem etter.\r\n\r\nLag\r\nNettavisen\r\nOddschecker\r\nDagsavisen\r\nDagbladet\r\nAftenposten\r\nResultat\r\ngjennomsnitt\r\nMolde\r\n2\r\n2\r\n1\r\n1\r\n1.2\r\n1\r\n1.44\r\nRosenborg\r\n1\r\n1\r\n2\r\n3\r\n1.8\r\n3\r\n1.76\r\nBrann\r\n3\r\n3\r\n5\r\n2\r\n3.2\r\n9\r\n3.24\r\nSarpsborg 08\r\n4\r\n4\r\n3\r\n5\r\n6.2\r\n12\r\n4.44\r\nVålerenga\r\n5\r\n5\r\n4\r\n4\r\n8.0\r\n10\r\n5.20\r\nKristiansund BK\r\n6\r\n9\r\n7\r\n9\r\n8.0\r\n6\r\n7.80\r\nHaugesund\r\n7\r\n7\r\n10\r\n8\r\n8.0\r\n7\r\n8.00\r\nOdd\r\n8\r\n10\r\n9\r\n6\r\n8.0\r\n4\r\n8.20\r\nLillestrøm\r\n10\r\n11\r\n6\r\n7\r\n8.0\r\n14\r\n8.40\r\nStrømsgodset\r\n9\r\n6\r\n15\r\n12\r\n9.4\r\n11\r\n10.28\r\nBodø/Glimt\r\n15\r\n12\r\n8\r\n10\r\n8.0\r\n2\r\n10.60\r\nTromsø\r\n11\r\n8\r\n13\r\n15\r\n9.4\r\n15\r\n11.28\r\nStabæk\r\n13\r\n14\r\n11\r\n14\r\n11.8\r\n8\r\n12.76\r\nRanheim\r\n12\r\n15\r\n16\r\n11\r\n11.4\r\n16\r\n13.08\r\nViking\r\n14\r\n13\r\n12\r\n16\r\n14.4\r\n5\r\n13.88\r\nMjøndalen\r\n16\r\n16\r\n14\r\n13\r\n13.6\r\n13\r\n14.52\r\n\r\nKilder:\r\nNordicBet\r\n- Nettavisen\r\n- Tidens Krav\r\n- Oddschecker\r\n- Dagsavisen\r\n- Dagbladet\r\n- Aftenposten.\r\nAftenposten-plasseringa er litt annerledes enn de øvrige, ettersom de har spurt fem eksperter om topp tre og bunn tre. Jeg har bare tatt gjennomsnittene av dette.\r\nI en ideell verden skulle jeg også gjerne hatt med lagenes budsjetter. Det har jeg imidlertid ikke klart å skrape sammen, så det får være en god ide til seinere.\r\nEn måte å vise plasseringene på, er med en fargelagt tabell. Her ser vi enklere enn med de rene tallene at det er nokenlunde stor enighet om de øverste fire-fem lagene, og de fire-fem nederste. Hvilke lag som blir plassert hvor blant de seks i midten varierer imidlertid mer.\r\n\r\n\r\n#eksperiment med en heatmap-table\r\ntemp = gather(df,kilde,plassering,Nettavisen:gjennomsnitt)\r\n\r\nggplot(data = temp, aes(x=as.factor(kilde), y = fct_reorder(as.factor(Lag), plassering, .fun = mean, .desc = TRUE)))+\r\n  geom_tile(aes(fill = plassering))+\r\n  labs(x = \"Kilde\", y = \"Lag\", title = \"Molde og Rosenborg i topp, Mjøndalen og Viking i bunn\")+\r\n  scale_fill_gradient2(low = \"steelblue\", mid = \"grey\", high = \"orange\", midpoint = 8)\r\n\r\n\r\n\r\nHer har jeg altså 16 lag med fem tips per lag. Varmekartet gir et raskt overblikk, menen ganske diffus oversikt over de faktiske spredningene for de enkelte lagene.\r\n\r\n\r\nggplot(data = filter(temp, kilde != \"gjennomsnitt\"), aes(x = fct_reorder(as.factor(Lag), plassering, .fun = mean, .desc = TRUE), y = plassering)) + \r\n  #her bruker vi et boksplot for å vise variasjonen i plasseringer for hvert enkelt lag, men gjør det gjennomsiktig\r\n  geom_boxplot(alpha=0) +\r\n  #det er heller ikke flere punkter for hvert enkelt lag enn at en kan vise alle.\r\n  geom_jitter(color=\"steelblue\",alpha=0.3) +\r\n  labs(x = \"Lag\", y = \"Plassering\", title = \"Stor variasjon i tips for lag midt på tabellen\", subtitle = \"Større enighet om topp og bunn\") + \r\n  coord_flip()\r\n\r\n\r\n\r\nHer ser vi tydeligere at konsensusen er størst om de øverste lagene. De lavere lagene på den nedre halvdelen av tabellen har større spredning i tabellposisjoner. Det ser en av spredningen på punktene, og størrelsen på boksene. Særlig Strømsgodset splitter folk.\r\nBoksplottene viser medianen som midtpunkt. Her får en fram at Ranheim havner på kvalifiseringsplass om en legger gjennomsnitt til grunn, fordi en av ekspertene har svært lave forventninger til laget. Medianen legger dem imidlertid på fjerde siste plass, og lar Stabøk gå ned i stedet. Er det mer fornuftig å la ekstre stemmer telle likt, eller skal en heller legge vekt på konsensuspunktet?\r\n…\r\nJeg har ikke den fjerneste anelse. Da velger jeg det enkleste, og går for gjennomsnittet som mitt innspill til årets tippekonkurranse.\r\n\r\n\r\n\r\n",
    "preview": "posts/2019-03-31-prognosekonkurranse-eliteserien-2019/prognosekonkurranse-eliteserien-2019_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2023-11-25T07:55:07+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-03-24-eksempler-p-bruk-av-imdis-api/",
    "title": "Eksempler på bruk av IMDis API",
    "description": "Dette var en innføring i bruk av IMDis udokumenterte API. Siden det er uklart om de fortsatt støtter slik udokumentert fremferd, er koden tatt vekk.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2019-03-24",
    "categories": [],
    "contents": "\r\nIMDis tall og statistikk-nettsider henter dataene sine om innvandring og integrering i kommuner, fylker og Norge fra et API.\r\nAPIet er dessverre ikke dokumentert, men lar seg enkelt utforske ved hjelp av en nettleser-konsoll, f.eks. i Chrome. Her kommer et kort forsøk på litt forklaring. Datasettet bruker NLOD-lisensen. (Det gjorde i hvert fall det i 2019, men sjekk gjerne med IMDis nettsider om det har skjedd endringer).\r\nInnhold i datasettet\r\nDatasettet har informasjon om innvandrere og integrering på en rekke områder i norske kommuner, næringsregioner, fylker, hele landet og bydeler i Oslo, og er tilgjengelig med NLOD-lisens (se nederst for lisens-betingelser). Noe kommer fra IMDi, men mesteparten kommer fra Statistisk sentralbyrå (SSB).\r\nIMDi tilgjengeliggjør dataene fra nettsidene i et krysstabellformat som er uhensiktsmessig for analyseformål, og dataene tilgjengeliggjøres derfor her (som et privat prosjekt) i et flatt format.\r\nEn advarsel: Datasettene er kodet, og kodeboka er foreløpig ikke en del av dette repoet. Beskrivelser av data skal egentlig være tilgjengelig fra et API fra IMDi.no (“http://imdi.no/api/indikatorcarddescriptions” og “http://imdi.no/api/indikatordimensions”), men det ser p.t. ikke ut til å være tilfelle.\r\nResten av innholdet fjernet.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-25T07:55:07+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-03-17-visualisering-av-andeler-i-ggplot2/",
    "title": "visualisering av andeler med ggplot2",
    "description": "Presentasjon av ggplot2-kode for å visualisere andeler som kakediagram, vaffeldiagram og stabla søylediagram",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2019-03-17",
    "categories": [],
    "contents": "\r\nEn vanlig feil i datavisualiseringer er å bruke teknikker ment for andelsdata, på data som ikke er andeler. Visualiseringer som er egna for andeler er blant annet:\r\nkakediagram/paidiagram: brukes når du vil ha en kompakt framvisning av andeler for inntil 3 kategorier på en variabel.\r\nvaffeldiagram: brukes hvis du vil ha framvisning av andeler for flere enn 3 kategorier på en variabel\r\nstablede søylediagram: brukes hvis du vil ha en framvisning av andeler for inntil 3 kategorier for flere grupper.\r\nSå hva gjør du med andeler hvis du har flere enn 3 kategorier som du vil se for flere ulike grupper eller over tid? Da må du bare prøve deg fram.\r\n\r\n\r\n\r\n###Eksempeldata fra SSBs åpne API.\r\nEksempeldataene henter jeg fra ssb.no, hvor jeg ser at fylkeskommunale regnskapstall er tilgjengelig. Byråkrathurra! Jeg har ikke stor peiling på fylkeskommunale regnskap, men ser at en kan få ut brutto driftsutgifter fordelt på generelle tjenesteområder, for de ulike regionene. I disse regionreform-tider er vel fylkeskommunal pengebruk et hett tema? Kanskje ikke - jeg vil tippe det er mye vei, transport, videregående skole og kanskje littebitt tannlege her.\r\n\r\n\r\n#henter data med PxWebApiData::ApiData\r\nalle_data = ApiData(\"https://data.ssb.no/api/v0/no/table/12163\",\r\n             KOKfylkesregion0000 = TRUE,\r\n             KOKfunksjon0000 = c(\"FGF1a\", \"FGF1b\", \"FGF1c\", \"FGF2\", \"FGF3\", \"FGF4\", \"FGF5\", \"FGF6a\", \"FGF7\", \"FGF8\"), \r\n             KOKart0000 = \"AGD10\",\r\n             ContentsCode = \"KOSandel3501\",\r\n             Tid = \"2018\"\r\n)\r\n\r\n#ApiData() returnerer både koder og menneskelesbar tekst, jeg går for tekst denne gangen\r\ndf <- alle_data[[1]] %>%\r\n  select(.,-art,-statistikkvariabel,-`år`) #filtrerer ut unødvendig info\r\n\r\n\r\n##Kakediagram (paidiagram / sektordiagram)\r\nDet første en lærer når en begynner å kikke mer på datavisualisering er at kakediagram er onde. Imidlertid har nyere (2016-ish) forskning vist at de ikke er så dårlige som ryktet skal ha det til. De blir gjerne beskyldt for å kode data som vinkler, noe folk ikke er gode på å se. Forskninga til Kosara sitert i forrige lenke viser at det enten er området eller en eller annen lengde som leses, kanskje en kombinasjon - og at de gjør det bedre enn andre alternativ.\r\n\r\n\r\n#I tråd med pai-hatet, mangler det en egen geom_pie i ggplot. \r\n#For å få det til må du derfor summere opp ting til totale antall, \r\n#plotte dette som et søylediagram med x=1, \r\n#og så justere coord_polar til y. \r\n\r\ntemp <- filter(df,region==\"Landet uten Oslo\")\r\n\r\nggplot(data = temp, aes(x = 1, y = value, fill = funksjon)) +\r\n  geom_col()+\r\n  coord_polar(theta=\"y\")+\r\n  theme_void()+\r\n  ggtitle(\"Fylkeskommunal pengebruk etter område\", subtitle = \"Alle unntatt Oslo\")\r\n\r\n\r\n\r\nDet virker rimelig å si at om du har mer enn noen få biter (tre ser ut til å være et tips), så blir figuren vanskelig å lese. Over ser vi tydelig at videregående opplæring og samferdsel er de største postene, antakeligvis fulgt av eiendomsforvaltning. Men så? Siden det er vanskelig å lese dem presist, egner de seg ikke for svært (men ikke helt) like andeler.\r\nFordelen er at de er kompakte og intuitive, når de brukes riktig:\r\n\r\n\r\n\r\n##Vaffeldiagram\r\nEt vaffeldiagram (waffel chart) kan være mer presist enn et kakediagram, og koder helt klart data som område, ikke vinkler eller vinkler i kombinasjon med noe annet.\r\nFiguren tåler ikke urimelige mengder klasser. Den tar også litt mer plass enn paien, men det er jo fordi en viser mer informasjon.\r\nEksempelet her har 10x10 ruter. Det trenger andelene direkte, så om du ikke har de, må du regne dem ut - eller som i mitt tilfelle, om du har avrudningsfeil, må du komme deg rundt det på no vis.\r\n\r\n\r\n#litt databearbeiding først - filtrering, sortering og avrunding\r\ntemp <- filter(df,region==\"Landet uten Oslo\")%>%\r\n  arrange(.,desc(value))%>%\r\n  mutate(.,andel = round(value,0))\r\n\r\n#waffle() tar en \"named vector\"\r\nandel_utgifter = temp$andel\r\nnames(andel_utgifter) = temp$funksjon\r\n\r\n#så selve plottinga\r\nwaffle(andel_utgifter, \r\n        colors=qualitative_hcl(10,\"Dark 3\"), \r\n        xlab=\"1 rute = 1 prosent\", \r\n        title= \"Fylkeskommunale utgifter etter område\", \r\n        legend_pos=\"right\")\r\n\r\n\r\n\r\nPå grunn av fargevalget er ikke denne mye lettere å lese. Men med litt tid på seg til å velge ut 10 forskjellige farger (eller noe mer sammenslåing av kategorier), kunne det blitt lettere å se at\r\n44 prosent av utgiftene for fylkeskommuner er i snitt til videregående,\r\nlike over 30 prosent går til samferdsel,\r\nderetter kommer eiendomsforvaltning med 6 prosent,\r\ntannhelse og administrasjon ligger på 4 prosent,\r\nnæringsforvaltning og div andre kommer på 2 prosent,\r\nmer administrative utgifter ligger på 1 prosent.\r\nStablet søylediagram\r\nMed kakediagram kommer en langt med å se på andeler på en variabel. Men hva hvis en vil sammenlikne andelene mellom ulike grupper? Du kunne prøvd deg med flere paidiagram eller vaffeldiagram etter hverandre - men de er bygd for intern sammenlikning, ikke sammenlikning på tvers, og tar en del plass.\r\nStablede søylediagram egner seg her. De kan gi mer kompakt informasjon av andeler innenfor ulike grupper mellom ulike enheter (som f.eks. andelen med sykdom x i land A og B) enn det kakediagram og vaffeldiagram kan.\r\nMed tittelen “Stacked bars are the worst!” mer enn antyder Kosara hva han synes om slike diagrammer. Forskningen han siterer ser ut til å handle om bruk av stablede søyler for verdier som ikke er prosenter, men det betyr ikke at de er veldige gode bare fordi dette er prosenter.\r\nDet er altså vanskelig å vurdere flere ulike grupper mot hverandre innad i samme enhet (som f.eks. andelen med sykdom x, y og z i land A). Bruk dem ikke alene for en gruppe, bruk ikke mange ulike (men nesten like) kategorier innad i hver stabla søyle. Og siste tips: Pass på hvilke kategorier som får verdifull plass nederst og øverst, hvor det er mulig å lese ut størrelsen. Det kan gjøres ved å endre rekkefølgen på kategorier som faktorer.\r\n\r\n\r\n#litt databearbeiding først\r\n#her er vi interessert i alle fylkeskommunene og gjennomsnittet for landet uten Oslo,\r\n#vi vil også ha maks tre kategorier, \r\n#og sortert slik (via factor-levels) at videregående kommer nederst\r\n#regionene skal være sortert etter størrelsen på budsjettet til vgs\r\n#litt usikker på hvordan fct_reorder2 får til det, men det virker\r\n\r\ntemp <- filter(df, grepl(\"fylkeskommune\",region)|region==\"Landet uten Oslo\") %>%\r\n  mutate(.,\r\n         funksjon_summert = ifelse(funksjon %in% c(\"Videregående opplæring samlet\", \"Samferdsel, fylkeskommune\"), funksjon, \"Andre\"),\r\n         funksjon_summert = factor(funksjon_summert,levels=c(\"Andre\",\"Samferdsel, fylkeskommune\",\"Videregående opplæring samlet\")),\r\n         region = str_replace(region,fixed(\"fylkeskommune\"),replacement=\" \")\r\n         )%>%\r\n  group_by(.,region,funksjon_summert) %>%\r\n  summarise(.,andel = sum(value)) \r\n\r\n# %>% ungroup() %>%\r\n#   mutate(., region = fct_reorder2(region, as.numeric(funksjon_summert), andel))\r\n\r\nggplot(data=temp)+\r\n  geom_col(aes(x=region,y=andel,fill=funksjon_summert),position=\"fill\") +\r\n  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + \r\n  labs(fill=\"Funksjon\")\r\n\r\n\r\n\r\nOslo er et særtilfelle, som gjør figurverdien misvisende - andelene utgifter i fylket summerer til 11 prosent, i motsetning til de fleste andre. Men position=“fill” gjør at alle settes til å fylle opp til 100 % i figuren.\r\nHva lærer vi av dette? Kanskje ikke så mye. Noen fylker ligger over landssnittet på 44 % av utgiftene til videregående, og noen ligger ganske langt under - og da er det hovedsaklig samferdsel som tar plassen som største utgiftspost. At det dermed er flate Østlands- og sørlandsfylker som bruker en større del på videregående, og vestlands- og Nord-Norge som bruker mer på samferdsel virker intuitivt rimelig.\r\n\r\n\r\n\r\n",
    "preview": "posts/2019-03-17-visualisering-av-andeler-i-ggplot2/visualisering-av-andeler-i-ggplot2_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2023-11-25T07:55:07+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-03-16-introduksjon-til-materiale-om-datavisualsering/",
    "title": "Hvordan lære datavisualisering?",
    "description": "Noen pekere til hva som kan være kvalitetskriterier for vurdering av læremateriell om datavisualisering.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2019-03-16",
    "categories": [],
    "contents": "\r\nInteressert i å lære grunnleggende data-visualisering, enten i R eller i et anna verktøy? Ser du etter bøker eller nettkurs? Min erfaring er at det følgende er viktige kriterier for om noe skal være bra:\r\nDet må være kunnskapsbasert. Selv om det er helt voldsomt mye gratis tilgjengelig et google-søk unna, betyr det også at det kan ta tid å luke ut det gode fra det vonde, skille snørr og kanel, og så videre. Når du skal velge et kurs, pass på at kurset har referanser til ny forskningslitteratur og en begrunna “beste praksis”.\r\nDet må være oppdatert. Etter hvert begynner en del tutorials å bli utdaterte. Særlig ggplot2 og tidyverse har utvikla seg med årene, og tidlige eksempler bruker gjerne bare base-funksjoner (uten at jeg skal starte den diskusjonen).\r\nDet kan gjerne være redskaps-agnostisk.\r\nOppgavefokusert, ikke teknikk-fokusert- Det bør være fokusert på oppgavene du skal gjøre, og ikke teknikken. At du kan tegne linjediagram er flott, men i en praktisk setting sitter du med data som har visse egenskaper - og ønsker å se på disse egenskapene.\r\nOppdatering april 2019: Bruk tida di et annet sted enn på DataCamp.\r\nSelskapet har problemer med seksuell trakasering, og rutinere for å håndtere det. R Weekly har noen lenker her og her om saken. Det viser seg at DataCamp her prøver å løse et problem med en svært problematisk blogg, mens de burde endra policy. Julia Silge og RStudio er blant de som har reagert - for ikke å glemme instruktøren for kurset jeg lenker til over, Nick Strayer.\r\nStrayer har har via Twitter oppfordra folk til å gå et annet sted. Han anbefaler Claus Wilkes bok Fundamentals of Data Vizualization, som er åpent tilgjengelig på internett (via bookdown).\r\nJeg har ikke sett på denne boka, men den ser ut til å oppfylle kravene mine for et godt visualiseringskurs:\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-25T07:55:07+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-03-05-grunnleggende-overlevelsesanalyse/",
    "title": "Grunnleggende overlevelsesanalyse",
    "description": "Helt grunnleggende teknikker for det som er kjent som survival-analyse, forløpsanalyse eller event history -analyse.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2019-03-05",
    "categories": [],
    "contents": "\r\nOverlevelsesanalyse, eller survival, eller event history analysis er en analyse av tid-til-hendelse (time-to-event). Med denne metoden kan en estimere sannsynligheten for at en hendelse vil inntreffe på tidspunkt T. Det er ikke bare overlevelse eller død dette egner seg for, men de fleste ulike typer hendelse. Det klassiske ikke-sykdomseksempelet ser ut til å være tidspunkt for når en maskin bryter sammen (eller dør, om du vil).\r\nDen følgende teksten er inspirert av “Steps to perform survival analysis in R og MainDonald og Braun (2003) “Data analysis and graphics using R”. Den ble skrevet litt før jeg deltok på et lengre kurs, så det er litt grunnleggende.\r\nKort om overlevelsesanalyse\r\nOverlevelsesfunksjonen til en variabel X er definert som sannsynligheten for at variabelen er større enn x. X er gjerne tid, slik at overlevelsesfunksjonen gir sannsynligheten for at en person eller et objekt vil “overleve” lenger enn et gitt tidspunkt, i betydningen ikke få en eller annen status/hendelse, som tar enheten ut av observasjonsrekken.\r\nEn kunne sett for seg å løse dette med klassisk regresjon. Men Hastie (2013) beskriver survival analysis som et spesialtilfelle av regresjon for avhengige variabler som kun delvis er observert for noen individer - dvs. data som er “censored”. F.eks. kan en se for seg en studie som har fulgt individer fra dag 0 til dag 200. Individ A fikk f.eks. oppvåkning på dag 72. Individ B hadde enda ikke fått noen oppvåkning på dag 200. Denne observasjonen er da “right censored” - vi kjenner ikke forløpet til høyre (på en tidsakse fra venstre mot høyre) for denne enheten, men ønsker fortsatt å bruke informasjonen fra individet i studien. I et datasett for klassisk regresjon ville disse observasjonene vært missing - vi vet jo ikke hvor lenge de faktisk har overlevd.\r\nEn del av de samme antakelsene og utfordringene møter denne analyseformen, som klassisk regresjon: antakelser om uavhengige individer, og at censoring er ikke-informativt: det er ingen forskjeller i sannsynlighet for utfallet mellom personer som censoreres og ikke-censoreres\r\nDet er noen ulike teknikker som er relevante:\r\nKaplan-Meier-kurve for å estimere overlevelsesfunksjonen\r\nCox proportional hazard model for å estimere overlevelse med kontinuerlige variabler\r\nestimering av survival-funksjon med trær eller forest\r\nlog-rank-test\r\nVi bruker pbc-datasettet fra survival-pakken som eksempeldata.\r\n\r\n\r\n#survival-pakken er grunnleggende, og kommer med R\r\nlibrary(survival)\r\nsuppressPackageStartupMessages(library(tidyverse))\r\n\r\n#eksempel-datasettet Primary Biliary Cirrhosis (pbc)\r\n?pbc\r\npbc = pbc\r\nstr(pbc)\r\n\r\n'data.frame':   418 obs. of  20 variables:\r\n $ id      : int  1 2 3 4 5 6 7 8 9 10 ...\r\n $ time    : int  400 4500 1012 1925 1504 2503 1832 2466 2400 51 ...\r\n $ status  : int  2 0 2 2 1 2 0 2 2 2 ...\r\n $ trt     : int  1 1 1 1 2 2 2 2 1 2 ...\r\n $ age     : num  58.8 56.4 70.1 54.7 38.1 ...\r\n $ sex     : Factor w/ 2 levels \"m\",\"f\": 2 2 1 2 2 2 2 2 2 2 ...\r\n $ ascites : int  1 0 0 0 0 0 0 0 0 1 ...\r\n $ hepato  : int  1 1 0 1 1 1 1 0 0 0 ...\r\n $ spiders : int  1 1 0 1 1 0 0 0 1 1 ...\r\n $ edema   : num  1 0 0.5 0.5 0 0 0 0 0 1 ...\r\n $ bili    : num  14.5 1.1 1.4 1.8 3.4 0.8 1 0.3 3.2 12.6 ...\r\n $ chol    : int  261 302 176 244 279 248 322 280 562 200 ...\r\n $ albumin : num  2.6 4.14 3.48 2.54 3.53 3.98 4.09 4 3.08 2.74 ...\r\n $ copper  : int  156 54 210 64 143 50 52 52 79 140 ...\r\n $ alk.phos: num  1718 7395 516 6122 671 ...\r\n $ ast     : num  137.9 113.5 96.1 60.6 113.2 ...\r\n $ trig    : int  172 88 55 92 72 63 213 189 88 143 ...\r\n $ platelet: int  190 221 151 183 136 NA 204 373 251 302 ...\r\n $ protime : num  12.2 10.6 12 10.3 10.9 11 9.7 11 11 11.5 ...\r\n $ stage   : int  4 3 4 4 3 3 3 3 2 4 ...\r\n\r\nPBC-datasettet har 418 observasjoner av 20 variabler. 312 personer deltok i en RCT, mens data ble også samlet om 106 personer til (6 personer falt fra).\r\nstatus: censored (0), transplant (1), dead (2)\r\ntime: dager mellom registrering og endelig status\r\n\r\n\r\nqplot(time,data=pbc)\r\n\r\n\r\nqplot(as.factor(status),data=pbc)\r\n\r\n\r\nqplot(as.factor(status),time,data=pbc,geom=\"boxplot\",group=status)\r\n\r\n\r\n\r\nKaplan-Meier\r\nStarter med Surv()-funksjonen, som lager et survival-objekt som kan brukes som avhengig variabel i en modell. survfit()-funksjonen kan så brukes til å finne Kaplan-Meier-estimatoren og plotte en survival-kurve. (språkbruk?)\r\n\r\n\r\n#en kikk på Surv-objektet\r\npbc_survival = Surv(pbc$time,pbc$status==2)\r\nstr(pbc_survival)\r\n\r\n 'Surv' num [1:418, 1:2]  400  4500+ 1012  1925  1504+ 2503  1832+ 2466  2400    51  ...\r\n - attr(*, \"dimnames\")=List of 2\r\n  ..$ : NULL\r\n  ..$ : chr [1:2] \"time\" \"status\"\r\n - attr(*, \"type\")= chr \"right\"\r\n\r\n#så survfit\r\nsurvival_func=survfit(Surv(time,status==2)~1,data=pbc)\r\nsurvival_func\r\n\r\nCall: survfit(formula = Surv(time, status == 2) ~ 1, data = pbc)\r\n\r\n       n events median 0.95LCL 0.95UCL\r\n[1,] 418    161   3395    3090    3853\r\n\r\nHer får vi ut n, antall positive statuser (død - så språket mister litt mening her etter hvert, når modelleringsspråk kolliderer med vanlige betydninger), median tid-til-event (3 395 dager til død), og 95 % konfidensintervaller rundt medianen. Vi kan plotte funksjonen med base plot.\r\n\r\n\r\nplot(survival_func)\r\n#dessverre ingen enkel mulighet for å plott survfit-objektet direkte. Prøver survminer-pakken.\r\nsurvminer::ggsurvplot(survival_func)\r\n\r\n\r\n#dette viser seg å være temmelig unødig, det kan likegreit fikses med broom og ggplot2\r\n\r\nggplot(data = broom::tidy(survival_func), aes(x = time, y = estimate))+\r\n  geom_line() +\r\n  geom_ribbon(aes(ymin=conf.low,ymax=conf.high),alpha=0.2)+\r\n  ggtitle(\"Kaplan-Meier survival curve\")\r\n\r\n\r\n\r\nY-aksen viser sannsynlighet for overlevelse (ikke oppleve status==2), mens x-aksen viser tid i dager. Sannsynligheten for å overleve går ned med tid (og sannsynligheten for å dø går opp). F.eks. er sannsynligheten for å overleve mer enn 1000 dager ca. 80 %.\r\nDenne bygger på antakelsen om at individene er uavhengige, og er en estimering av den underliggende overlevelsesfunksjonen, som teoretisk sett er glatt.\r\nCox proportional hazard model\r\nForskjellen mellom survfit()/Kaplan-Meier og Cox Proportional Hazard Model er…\r\nCox-modellen aksepterer ikke missing-verdier.\r\n\r\n\r\n#kan estimere en cox-model med kun intercept også\r\ncox_model = coxph(Surv(time,status==2)~1,data=pbc)\r\nsummary(cox_model)\r\n\r\nCall:  coxph(formula = Surv(time, status == 2) ~ 1, data = pbc)\r\n\r\nNull model\r\n  log likelihood= -873.4721 \r\n  n= 418 \r\n\r\n#for å lage en survival kurve fra en cox-model må den mates inn i survfit()\r\ncox_curve_0 = survfit(cox_model)\r\ncox_curve_0\r\n\r\nCall: survfit(formula = cox_model)\r\n\r\n       n events median 0.95LCL 0.95UCL\r\n[1,] 418    161   3395    3090    3853\r\n\r\nplot(cox_curve_0)\r\n\r\n\r\n\r\nMen cox-modellen kan også brukes til å estimere en modell. Her er en enkel kjøkkenvask-modell (alle variabler som uavhengige variabler) for pbc-datasettet.\r\n\r\n\r\ncox_model = coxph(Surv(time,status==2)~.,data=pbc)\r\nsummary(cox_model)\r\n\r\nCall:\r\ncoxph(formula = Surv(time, status == 2) ~ ., data = pbc)\r\n\r\n  n= 276, number of events= 111 \r\n   (142 observations deleted due to missingness)\r\n\r\n               coef  exp(coef)   se(coef)      z Pr(>|z|)   \r\nid       -2.729e-03  9.973e-01  1.462e-03 -1.866  0.06203 . \r\ntrt      -1.116e-01  8.944e-01  2.156e-01 -0.518  0.60476   \r\nage       3.191e-02  1.032e+00  1.200e-02  2.659  0.00784 **\r\nsexf     -3.822e-01  6.824e-01  3.074e-01 -1.243  0.21378   \r\nascites   6.321e-02  1.065e+00  3.874e-01  0.163  0.87038   \r\nhepato    6.257e-02  1.065e+00  2.521e-01  0.248  0.80397   \r\nspiders   7.594e-02  1.079e+00  2.448e-01  0.310  0.75635   \r\nedema     8.860e-01  2.425e+00  4.078e-01  2.173  0.02980 * \r\nbili      8.038e-02  1.084e+00  2.539e-02  3.166  0.00155 **\r\nchol      5.151e-04  1.001e+00  4.409e-04  1.168  0.24272   \r\nalbumin  -8.511e-01  4.270e-01  3.114e-01 -2.733  0.00627 **\r\ncopper    2.612e-03  1.003e+00  1.148e-03  2.275  0.02290 * \r\nalk.phos -2.623e-05  1.000e+00  4.206e-05 -0.624  0.53288   \r\nast       4.239e-03  1.004e+00  1.941e-03  2.184  0.02894 * \r\ntrig     -1.228e-03  9.988e-01  1.334e-03 -0.920  0.35741   \r\nplatelet  7.272e-04  1.001e+00  1.177e-03  0.618  0.53660   \r\nprotime   1.895e-01  1.209e+00  1.128e-01  1.680  0.09289 . \r\nstage     4.468e-01  1.563e+00  1.784e-01  2.504  0.01226 * \r\n---\r\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r\n\r\n         exp(coef) exp(-coef) lower .95 upper .95\r\nid          0.9973     1.0027    0.9944     1.000\r\ntrt         0.8944     1.1181    0.5862     1.365\r\nage         1.0324     0.9686    1.0084     1.057\r\nsexf        0.6824     1.4655    0.3736     1.246\r\nascites     1.0653     0.9387    0.4985     2.276\r\nhepato      1.0646     0.9393    0.6495     1.745\r\nspiders     1.0789     0.9269    0.6678     1.743\r\nedema       2.4253     0.4123    1.0907     5.393\r\nbili        1.0837     0.9228    1.0311     1.139\r\nchol        1.0005     0.9995    0.9997     1.001\r\nalbumin     0.4270     2.3422    0.2319     0.786\r\ncopper      1.0026     0.9974    1.0004     1.005\r\nalk.phos    1.0000     1.0000    0.9999     1.000\r\nast         1.0042     0.9958    1.0004     1.008\r\ntrig        0.9988     1.0012    0.9962     1.001\r\nplatelet    1.0007     0.9993    0.9984     1.003\r\nprotime     1.2086     0.8274    0.9690     1.508\r\nstage       1.5634     0.6397    1.1020     2.218\r\n\r\nConcordance= 0.849  (se = 0.018 )\r\nLikelihood ratio test= 171.3  on 18 df,   p=<2e-16\r\nWald test            = 172.5  on 18 df,   p=<2e-16\r\nScore (logrank) test = 286.1  on 18 df,   p=<2e-16\r\n\r\ncox_curve = survfit(cox_model)\r\nplot(cox_curve)\r\n\r\n\r\n\r\nHvordan skal survival-plottet her forstås? Det er fortsatt avtakende sannsynlighet for overlevelse med tid, men med større konfidensintervaller mot slutten (naturlig, ettersom nesten halvparten av observasjonene faller bort som missing). Men for hvilke verdier av de uavhengige variablene? De faktiske verdiene?\r\nSurvival in the forest\r\nLitt usikker på hva som vil være fordeler og ulemper med å benytte trær og random forest-estimering her, så lar det ligge til jeg har forstått det grunnleggende ellers. Et grunnleggende skille vil jo være at cox-regresjon antar en lineær modell, mens trær ikke gjør det.\r\nSammenligning av modeller\r\n\r\n\r\n#kunne vært en ide å bruke broom her for å rydde litt...?\r\n#merk at det som i survfit-objektet er surv, er estimate i broom-dfen\r\ntest = data.frame(cox_curve$surv,broom::tidy(cox_curve)$estimate)\r\nhead(test)\r\n\r\n  cox_curve.surv broom..tidy.cox_curve..estimate\r\n1      0.9990059                       0.9990059\r\n2      0.9978760                       0.9978760\r\n3      0.9966940                       0.9966940\r\n4      0.9955020                       0.9955020\r\n5      0.9942870                       0.9942870\r\n6      0.9930705                       0.9930705\r\n\r\n#setter de sammen\r\nmodeller = bind_rows(cox_0 = broom::tidy(cox_curve_0),cox_alle = broom::tidy(cox_curve),km = broom::tidy(survival_func),.id=\"modell\")\r\n\r\nggplot(data = modeller, aes(x = time, y = estimate, color = modell))+\r\n  geom_line() +\r\n  geom_ribbon(aes(ymin=conf.low,ymax=conf.high),alpha=0.2)+\r\n  ggtitle(\"Sammenlikning av Survival Curves\")\r\n\r\n\r\n\r\nCox-modellen med alle variablene har en høyere sannsynlighet for overlevelse i starten, men den faller brattere, og har større konfidensintervaller. Null-modellen med cox er så godt som lik Kaplan-Meier-kurven.\r\n\r\n\r\n\r\n",
    "preview": "posts/2019-03-05-grunnleggende-overlevelsesanalyse/grunnleggende-overlevelsesanalyse_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2023-11-25T07:55:07+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2019-03-01-halvmigrering-til-huga/",
    "title": "Halvmigrering til Huga",
    "description": "Migrering av poster fra wordpress til Blogdown.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2019-03-01",
    "categories": [],
    "contents": "\r\nEtter å ha latt bloggen min Kontext ligge i regneregne fem og et halvt år, våknet jeg opp en morgen og tenkte: på tide å skrive noe på internett!\r\nNår jeg kikka på GitHub-repoene mine, innså jeg at flere av dem begynte å likne på blogg-artikler om ymse temaer. I morgen-ørska på bussen snubla jeg så over en artikkel om å flytte bloggen din til Blogdown. Siden jeg allerede bruker R som go-to-verktøy for ymse ting, virket dette rimelig.\r\nSkulle jeg da migrere alle de gamle postene fra wordpress-bloggen? En liten kikk i blogdown-dokumentasjonen tilsa nei. Jeg kopierte derfor heller over de tekstene jeg var spesielt fornøgd med, heller enn å finne igjen gamle innloggingsdetaljer og kaste meg over en aldri så liten terskel i Python-basert XML-rensing.\r\nSiden denne bloggen p.t. redigeres i RStudio med blogdown, pushes til GitHub, hvor den så auto-synces med Netlify, er den basert på RMarkdown. Det er et flott tekstverktøy som tillater innebygde R-skrevne analyser. Så derfor heter bloggen noe med analyser.\r\nTittelen, sier du? Hvor kommer suppa inn? Vel, egentlig var jeg også på utkikk etter et sted å legge alle de ørten matoppskriftene jeg har samla opp. Det ser enn så lenge ikke ut til at dette Hugo-temaet åpner for så mye fancy i den retningen. Vi får se.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-25T07:55:07+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2013-09-03-fordeling-av-mandater-ved-stortingsvalg/",
    "title": "Hvordan fordeles mandater ved stortingsvalg?",
    "description": "En liten gjennomgang av mandatfordelinger i anledning valget.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2013-09-03",
    "categories": [],
    "contents": "\r\nDemokrati er som vi alle veit vanskelig på flere plan – ikke minst når en snakker om praktisk gjennomføring. For hvordan fungerer egentlig Stortingsvalget? Med kun seks små dager igjen til valget, kan det være greit å ta noen skritt tilbake og huske på hvordan et valg faktisk ser ut.\r\nFor det første: Alle som stemmer, stemmer i fylket hvor de er folkeregistrerte. Osloborgere velger en liste fra et parti som stiller til valg i Oslo, trøndere velger på lister som stilles i Sør- eller Nord-Trøndelag.Du stemmer altså ikke på landsbasis, men på fylkesbenken din.\r\nFor det andre: Mandatene fordeles med en matematisk metode. Når stemmene til de ulike partiene i et fylke er talt opp, fordeles disse ved hjelp av den såkalte St. Laguës modifiserte metode. Hvert enkelt partis totale antall stemmer deles på tallene 1.4, 3, 5, 7, 9, osv (kalt delingstall). Mandatene fra et fylke går så til partiene med de høyeste tallene. Et eksempel, basert på stemmetall fra Oslo i 2009:\r\nFor det tredje, kandidater kan strykes og flyttes på lista. For at dette skal ha en effekt, må halvparten av partiets velgere i fylket ha gjort samme endring med samme kandidat. Det skal MYE til for at dette skjer.\r\nFor det fjerde, det finnes ingen absolutt sperregrense ved valg i Norge – det vi kaller sperregrensa angir hvilke partier som kan kjempe om utjevningsmandater. Utjevningsmandater fordeles mellom partier med over 4 % oppslutning på landsbasis. 19 av de totalt 169 stortingsmandatene er utjevningsmandater.\r\nUtjevningsmandatene fordeles ved at alle 169 mandatene (fratrukket mandater til partier under sperregrensa og mandater til partier som ikke ville fått seter ved en nasjonal gjennomgang) fordeles med samme metode som på fylkesnivå. Utjevningsmandatene fordeles så for å dekke opp differansen mellom gjennomgangen på fylkesnivå og gjennomgangen på nasjonalt nivå.\r\nFor det femte, det kan være greit å vite at antallet representater fra hvert fylke er satt på forhånd – og er svært ulikt. I følge Grunnloven (en endring innført i 2003) beregnes antallet representanter utifra areal og folketall. Dette har gitt følgende fordeling:\r\nNerde-note: Delingstallet er viktig. Dette er utledet fra formelen (2*antall tildelte mandater+1). Det vil altså si at når et parti får tildelt et mandat, kalkuleres delingstallet på nytt. I den umodifiserte versjonen er det første delingstallet 1 (ikke 1,4), noe som favoriserer mindre partier – hvis vi beregner mandatfordelinga for Oslo med 1 som første delingstall, ser vi at Høyre får en representant mindre og at Rødt får inn en kandidat.\r\nDette kan sammenliknes med D’Hondts metode, hvor delingstallene beregnes med formelen 1+mandater, dvs. 1,2,3,4,5,6, osv. Også denne favoriserer større partier, men som vi ser hadde det ikke gitt utslag på antallet mandater til de ulike partiene fra Oslo i 2009 – men rekkefølgen av mandattildelingen er svært annerledes, og Ap er veldig nær ved å kapre det 16. mandatet fra SV.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-25T07:55:07+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2013-08-20-rammer-eller-stordriftsfordeler-for-jordbruket/",
    "title": "Rammevilkår viktigere enn størrelse",
    "description": "Dette innlegget sto på trykk i Nationen fredag 9. august, og er basert på en ny rapport jeg har skrevet for AgriAnalyse på oppdrag fra Geno, Nortura og Tine.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2013-08-20",
    "categories": [],
    "contents": "\r\nDebatten om størrelsesutvikling på norske gårdsbruk har gått i sommer. 48 kyr eller 60 kyr per bruk, tallene fra ulike utredninger kastes rundt og ikke minst Høyre har vært i senter. Svein Flåtten i Høyre står for et foreløpig siste bidrag når han (i Aftenposten 30. juli) uttaler at «når arealet er gitt og matproduksjonen må opp, må hvert bruk bli noe større».\r\nDette er i og for seg logisk, men eksempler fra våre naboland viser at det ikke er størrelsen alene som er viktig om en skal øke matproduksjonen. Det spiller også en rolle hvor mye større hvert bruk blir, hvordan denne veksten finansieres, hvordan produksjonen organiseres og ikke minst hvilken lønnsomhet bonden sitter igjen med. Dette handler om den enkelte bondens tilpasning til rammevilkårene i næringa. Tilpasningen har igjen konsekvenser for hvordan landbruket utvikler seg.\r\nSvenske mjølkebruk – effektive og store…\r\nFor å belyse dette nærmere ser AgriAnalyse i en ny rapport på utviklingstrender i storfeholdet i Norge og Sverige. I begge land har en kombinert produksjon av mjølk og kjøtt basert på grovfôrressurser historisk vært viktig, blant annet fordi det har gitt effektiv ressursutnyttelse og bedre økonomi.\r\nI løpet av de siste 20 årene har mjølkeprodusentene i Sverige blitt mange færre, mye større og mer spesialiserte. Mens det i 1990 var 25 921 melkebruk i Sverige, var antallet sunket med 80 % til 4 968 i 2012. Det svenske gjennomsnittsbruket har gått fra 22 mjølkekyr i 1990, til 70 mjølkekyr i 2012. Hver svenske ku ga i 2011 fra seg 9 210 liter melk – en ytelse blant de høyeste i verden. Tilsvarende tall for utvikling i Norge er 12 mjølkekyr i 1990 og 24 mjølkekyr i 2012, og en ytelse per ku på 7 132 liter i 2011.\r\nTil tross for denne effektiviseringa og størrelsesøkninga har Sverige siden 2004 sett et fall i produksjonen av mjølk, etter å ha ligget rett under den nasjonale EU-kvoten på 3,3 millioner tonn fra EU-medlemskapet ble inngått i 1995. I dag er produksjonen 2,9 millioner tonn.\r\n…men fortsatt ikke konkurransedyktige\r\nSentralt for denne utviklingen er det fallende forbruket av drikkemelk. Hvis avsetningsnivået skal opprettholdes, må avsetningen skje i andre kanaler som ost eller yoghurt. På disse markedene er konkurransen høy, og da særlig i Sverige som er medlem av det indre markedet i EU. Siden 1990 har markedsandelen for svensk ost og syrnede produkter falt med 20 prosentpoeng. Høyere konkurranse gir lavere priser, som sammen med høyere kostnader har gitt svenske mjølkebønder dårligere økonomi.\r\nKonsekvensen er tydelig: Bøndene vil ikke produsere til de prisene som tilbys, og nedleggelsene fortsetter i høyt tempo. Svensk TV kunne i mai melde at hvis utviklingen fortsatte, ville den siste melkebonde slutte i 2050.\r\nMindre mjølk = mindre kjøtt\r\nReduksjonen i antallet mjølkekyr har gitt fall i kjøttproduksjonen siden 2000 i Sverige og 2008 i Norge, gjennom færre kyr til slakt og gjennom færre kalver. Sammen med en kraftig økning i forbruket per person og befolkningsøkningen har dette gitt fallende dekning av det nasjonale markedet for storfekjøtt. Svensk storfekjøtt dekker nå 55 % av det nasjonale forbruket. Økningen i antallet ammekyr har ikke vært i nærheten av å kompensere for fallet i melkekyr.\r\nHvilken politikk velger vi?\r\nEr det mulig å kombinere færre, større og mer spesialiserte gårdsbruk med økt matproduksjon til en voksende befolkning? Dette spørs på rammevilkårene for matproduksjonen. Vi kan framheve tre elementer fra den svenske erfaringen som det er viktig å forholde seg til.\r\nFor det første ser vi at en stor del av problemet svenskene har opplevd kan knyttes til økte problemer med avsetning i det nasjonale markedet, spesielt på ost og syrnede produkter. Svenske produsenter kan av ulike årsaker ikke konkurrere med kostnadsnivået hos andre produsenter i EU. Utviklinga i Norge er ikke ulik, men Norge har mer beskyttelse enn Sverige gjennom sitt nasjonale tollvern. Et effektivt tollvern på primærprodukter er svært viktig for kjøtt- og mjølkebransjen, som debattert i ostetollsaken.\r\nFor det andre ser vi at den fallende kombinerte storfekjøttproduksjonen til nå ikke har blitt møtt med økt ammekuproduksjon. Det skal en stor vekst i antallet ammekyr til for å erstatte et fall i mjølkeproduksjonen, noe som har vist seg å være krevende i Sverige. Heller ikke Norge har til nå klart dette, og som Ekspertgruppa for storfekjøttproduksjon tidligere i år satte fokus på er det en voldsom økning som må til for å nå målet.\r\nFor det tredje hjelper det ikke med vekst i størrelse og mer spesialisert produksjon, hvis ikke nok bønder ser det lønnsomt å drive produksjon. Sverige viser oss at større enheter og økt spesialisering ikke alene holder produksjonen oppe, noe Norge har som målsetning å gjøre. Lønnsomheten for den enkelte bonde er avgjørende. Det bør alle partier som ønsker å styrke primærproduksjonen, næringsmiddelindustrien og sikre norsk matforsyning ta med seg inn i valgkampen.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-25T07:55:07+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2013-08-07-handelsavtale-mellom-eu-og-usa/",
    "title": "Om en mulig handelsavtale mellom EU og USA",
    "description": "Kort og faktatungt notat om TTIP-forhandlingene mellom EU og USA.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2013-08-07",
    "categories": [],
    "contents": "\r\nVerdens største handelspartnere, EU og USA, begynte mandag 8. juli 2013 formelt første runde i forhandlingene om en frihandelsavtale, Transatlantic Trade and Investment Partnership (TTIP). Runden fant sted i Washington DC, og skulle gå igjennom alle områder som kan komme til å bli omfattet av avtalen.\r\nHer følger litt info om forhandlingene, og noen kjappe betraktninger rundt mulige konsekvenser. Dette bygger på et orienteringsnotat jeg skrev for noen uker siden, så det er ganske faktatungt.\r\nDette er avtale som har vært snakket om en stund, i følge EU-observerer har handelsbyråkrater i EU ønsket seg dette de siste 20 årene. Den kommer etter at en High-Level Working Group (HLWG) fra Transatlantic Economic Council anbefalte en slik avtale, etter å ha sett på muligheten for å øke handel og investeringer fra 2011 til 2013. Grunndokumentet fra denne gruppa ligger til grunn for forhandlingene. Neste runde finner sted 7. oktober i Brüssel.\r\nEUObserverer sier at begge sider ønsker en avtale før slutten av 2014 (datoer å holde øye med er nyvalget av president for kommisjonen september 2014 og midterm-valg av kongress november 2014). Dette omtales av observatører, ministre og forhandlingsledere som å være veldig ambisiøst. Til sammenligning har forhandlinger om en frihandelsavtale mellom Canada og EU foregått siden 2010.\r\nNUPI-direktør Sverdrup går i Dagens Næringsliv 24. juni hardt ut og kaller avtalen «et transatlantisk EØS», og referer også til betegnelser som «et økonomisk NATO» og «mother of all FTAs». Forventningene til omfanget er altså store. Det kan være verdt å merke seg at TTIP kommer samtidig med at USA forhandler om en Trans-Pacific Partnership in Asia med bl.a. Japan, (ikke Kina). Obama må være ute etter å skrive seg inn i historiebøkene før 2016.\r\nMandat og omfang\r\nHandelsministrene i EU godkjente forhandlingsmandatet 14. juni. En lekket versjon av mandatet fastslår at målet med avtalen er å oppnå «gjensidig liberalisering av handel med varer og tjenester, så vel som handelsrelaterte regler, med et høyt ambisjonsnivå over eksisterende forpliktelser i WTO». Offentlig tilgjengelig info bekrefter dette, EU har mandat til å framforhandle en avtale som omhandler 1) markedsadgang, 2) konvergens av regler og 3) handelsregler for «delte globale utfordringer». Mandatet inkluderer dermed toll, opphavsregler, tjenester, investeringer, offentlige innkjøp, tekniske handelshindringer, sanitære forhold, IP, og geografisk opphavsbetegnelser på alle områder. (For ytterligere info har Kommisjonen publisert en rekke posisjonsdokumenter med tekniske posisjoner).\r\nPå den amerikanske sida melder EUObserver at en avtale til nå har støtte i Kongressen. Til nå er det lite tilgjengelig informasjon om mandatet, informasjonen som ligger ute framhever overfladisk studert det samme som infoen fra EU og HLWG.\r\nDe involverte partene og analytikere sier gjerne at det generelle tollnivået mellom EU og USA allerede er svært lavt (i følge Kommisjonen/WTO i snitt ca. 5,2 % i EU og 3.5 % i USA). De største gevinstene antas derfor å måtte innebære en konvergens i reguleringer. Dette kan innebære harmonisering av regler, eller gjensidig godkjennelse av regler.\r\nEUObserver forventer at finanstjenester, mat og landbruk kan bli blant de vanskeligste områdene. I tillegg forventer de mer overordna at konvergens av reguleringer vil bli et vanskelig tema. Transporttjenester, offentlig innkjøp og standarder i farmasiindustiren har også vært kontroversielle i forhandlinger mellom EU og USA tidligere.\r\nGodkjenning av en endelig avtale\r\nEn avtale må godkjennes av Kongressen før den kan ratifiseres – og Kongressen har også rett til å vedta endringer, noe som gjør handelsavtaler vanskelig. Obama kan få tillatelse til å «Fast track»/»trade promotion authority», som innebærer at Kongressen kun kan si ja eller nei, og har ytret håp om å få til dette. Verdt å merke at representantenes hus og 1/3 av Senatet skal på valg november 2014.\r\nMandatet er tildelt Kommisjonen (DG Trade, DGT) fra Rådet. Et forhandlingsresultat må godkjennes av Rådet og Parlamentet, før det blir bindende. Kommunikasjon mellom DGT, EC og EP under forhandlingene blir dermed sentralt. En skal ikke undervurdere skillelinjer mellom de 28 EU-landene. Før det første forhandlingsmandatet ble godkjent, var Frankrike ute og krevde at audiovisuelle tjenester skal være utenfor forhandlingsmandatet, «l’exeption culturelle». EUObserverer mener dette kan være symbolsk motstand, basert på en dypere skepsis mot frihandelsavtaler.\r\nLandbruk en del av avtalen?\r\nEU og USA er verdens største importører og eksportører av landbruksvarer. Handel med jordbruksprodukter forventes å bli et at de vanskeligste forhandlingsområdene i TTIP, men lite er kjent om konkrete posisjoner enda. Diskusjonene om ikke-tollbaserte handelshindre forventes å bli problematiske (kapittelet om Sanitære og phytosanitære spørsmål, SPS, ser ut til å være sentralt). Disse omfatter bl. a. nasjonale lover og regler, krav til dokumentasjon og bruk av standarder. Eksempler på forskjeller som kan være krevende er:\r\nGenetisk modifiserte organismer (GMO)\r\nBruk og anerkjennelse av merkeordningen «beskyttede betegnelser», lovbeskytte IP/produktbetegnelser på næringsmidler\r\nRegelverk knyttet til bruk av veksthormoner i produksjon (Disputt i WTOs tvisteløsningssystem)\r\nVasking av kylling med klor.\r\nI tillegg har vi spørsmål som dyrevelferd, eksportsubsidier.\r\nKonsekvenser av avtalen for omverdenen – økonomi\r\nHåp om økonomisk vekst som konsekvens kan være en viktig drivmotor for disse forhandlingene,. særlig for veksthungrige EU-politikere. Det er flere estimater på hva en slik avtale kan gi av gevinster. Euobserver siterer en utredning fra Kommisjonen, som slår fast at en avtale kan øke Eus eksport til USA med 28 %, og være verdt 119 milliarder euro per år for EU totalt (0.5%-0.4% høyere BNP). USA kan få 80 milliarder euro per år og 2 millioner nye jobber. Hvis avtalen ikke omfatter annet enn toll, anslås det at fordelene vil være betraktelig lavere (tollnivået mellom de to landene er allerede svært lave på en rekke varer).\r\nDet finnes flere økonomiske analyser av konsekvensene av en slik avtale. En studie som har fått spalteplass i Aftenposten og DN via NUPI ble utført av Ifo, og publisert av Bertelsmann-stiftung. Studien gjør estimater (computational general equilibrium) av effekter av fjerning av all toll, og fjerning av ikke-tollbaserte handelshindringer på EU, USA og tredjeland. Konklusjonen her er USA og EU-land vil kunne tjene på avtalen (særlig en dyptgripende avtale), mens land som står utenfor (som Norge), vil kunne tape. Norge vil på lengre sikt kunne miste 11 500 arbeidsplasser hvis liberaliseringen går langt (gitt en rekke forutsetninger, og usikkerhetsmomentene tatt i betraktning er det lite vits å henge seg opp i tallet, og heller fokusere på retningen). Dette er gitt en rekke forutsetninger, blant annet «alt annet likt». En større standardisering mellom EU og USA vil sannsynligvis kunne påvirke Norge gjennom EØS-avtalen.\r\nDenne typen beregninger er også blitt kritisert for å gjøre urealistiske antakelser om dynamiske effekter av handel, og det er gjort få studier tidligere av reduksjoner av ikke-tollbaserte handelshindringer – studien ser ut til å anta at disse blir store, basert på andre avtaler.\r\nEt minst like interessant spørsmål enn hvem som vil tjene på den og hvem som vil tape på den. I en artikkel på Euobserverer kommenterer Ferdi de Ville at Sør-Europa etter innførselen av Euroen har sett økende handelsunderskudd og forholdsvis lav eksportandel av BNP, mens Nord-Europa (og særlig Tyskland) har hatt overskudd på handelsbalansen. Hun kommenterer at det er lite trolig at dette vil endres, selv med økt markedsadgang til USA (i motsetning til Ifo, som finner store fordeler særlig for Sør-Europa).\r\nKeynesiansk sett bygger de positive anslagene på at økt eksport skal gjøre opp for fallet i etterspørsel drevet av kuttpolitikk. Kan både EU og USA frihandle seg til økonomisk vekst gjennom positiv handelsbalanse samtidig? Har intern devaluering i Sør-Europa gått så langt at de er konkurransedyktige på internasjonale (og nasjonale) markeder?\r\nAndre konsekvenser\r\nNasjonale myndigheters suverenitet vil også bli påvirket. Hvor mye avhenger av omfanget i endringer, tilpasninger eller godkjenninger av ulike reguleringer. EU-Mandatet legger opp til en dynamisk avtale, hvor målet er å utvikle øke harmoniseringen av regler gradvis over tid – altså bygge inn en gjensidig forpliktelse til regel-konvergens. Her er det også verdt å se etter hvorvidt en ISDS-mekanisme inkluderes i avtalen (ISDS: Investor-state dispute settlement – private firmaer gis mulighet til å gå til sak mot visse typer inngripen fra nasjonale myndigheter).\r\nOmfattende forhandlinger kan også åpne opp rom for forsøk på endringer av regler i EU, slik f.eks. forventninger om sluttføring av Doha-runden har bidratt til endringer i CAP.\r\nMer geopolitisk/strategisk kan TTIP sees som et forsøk på å demme opp for Kina og Indias innflytelse, sette en ny standard for hva som omfattes i handelsavtaler, samt etablere felles europeiske og amerikanske standarder som gjeldende i internasjonal handel. Hvis da EU og USA forhandler seg sammen om posisjoner, hvor de tidligere hadde ulike syn, kan dette også påvirke forhandlinger i WTO – eller sette nye standarder for internasjonal handel.\r\nKonsekvenser for sosiale standarder? Forskjeller i f.eks. ratifiserte ILO-konvensjoner? EU-dokumentene slår fast at de ikke ønsker å fire på standardene, men hvis forskjeller godkjenner, betyr det at dårligere praksis på f.eks. arbeidsrettigheter godkjennes. I hvilken grad kan slikt gi konkurransefordeler innenfor et åpent marked?\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-25T07:55:07+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2013-05-05-effekt-av-spekulering-i-mat/",
    "title": "Effekt av matfest på børsen",
    "description": "Hvorvidt matvarespekulasjon har en effekt på priser eller ikke er fortsatt en het debatt. Denne analysen ser næmere på hvordan spekulasjon i matvarer kan tenkes å påvirke prisen på matvarer.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2013-05-05",
    "categories": [],
    "contents": "\r\nTeksten er skrevet for Utveier 1/2013. En versjon med fine bilder og figurer ligger på Issuu, og teksten følger under.\r\nDere har stilt spørsmålet “Bidrar investorer til prisøkninger på energi og mat?” Mitt entydige svar er ja. Michael W. Masters, hedgefond-forvalter\r\nDen 20. mai 2008 var Michael W. Masters et av vitnene i en offentlig høring i det amerikanske senatet. Matvareprisene hadde steget mye, og var fortsatt på vei opp. Hedgefond-direktøren tok opp et tema som til da hadde blitt lite drøftet, spekulasjon, en aktivitet han selv hadde vært involvert i.\r\nMasters var ikke alene om å peke på finansmarkedene. Etter at matprisene fra 2007 til i dag både har økt kraftigere og svingt mer enn tidligere, har det pågått en kraftig debatt blant akademikere og aktivister om rollen til matvarespekulasjon. Fører spekulasjonen til kraftig økende priser og uforutsigbare svingninger? Eller må en se etter årsakene til disse fenomenene andre steder, som i befolkningsvekst og klimaendringer?\r\nKorn og mais blir verdipapirer\r\nFor å forstå denne debatten må vi skille mellom realøkonomien i det fysiske markedet, og finansøkonomien på verdipapirmarkedet. På det fysiske markedet, også kalt spotmarkedet, kjøpes og selges det faktiske matvarer: En handler kan kjøpe 100 tonn korn av en kornbonde for å selge det videre.\r\nVerdipapirmarkedet er mer komplisert. Dette markedet fungerer i utgangspunktet som et forsikringssystem basert på kontrakter mellom bonden og kjøpere av landbruksprodukter. Hvis bonden lover å selge 100 tonn hvete for 100 kroner om fire måneder, er bonden garantert denne prisen for avlinga si. Hvis markedsprisen faller under den avtalte prisen har bonden tjent penger. Hvis markedsprisen stiger over den avtalte prisen, har forsikreren tjent penger. Slike kontrakter kan inngås for å sikre en pris og et leveringsvolum, med ulike tidsfrister og ulike vilkår. En kaller gjerne forsikringene for derivater, fordi verdien skal være avledet fra de underliggende fysiske varene.\r\nLand uten tradisjoner for bondeeid industri, samvirkebedrifter, mangler gjerne ordninger hvor industrien er forpliktet til å hente sine medlemmers produkter – bøndenes produkter – til avtalte priser. Da kan derivater være et gode både for bønder og for industri, i det kontraktene sikrer leveringer, sikrer priser og gjør det mulig for bonden å tenke langsiktig.\r\nI utgangspunktet er altså bonden og kommersielle landbruksinteresser involvert i handelen med matvarederivater. Det har også vært noen aktører, spekulanter, på dette markedet, uten direkte interesser for de faktiske tomatene og agurkene. Denne balansen mellom realøkonomien og finansøkonomien har med årene forskjøvet seg til finansøkonomiens fordel. Det er en vanlig oppfatning at antallet spekulanter vokst seg større enn antallet som faktisk trenger forsikring på matvaremarkedene de siste 15 årene. Automatisert høyfrekvenshandel – såkalt robothandel – har gjort at omsetningen har økt kolossalt. I tillegg flyktet mange spekulanter fra risikable verdipapirer i eiendom når finanskrisa starta i USA, og inn i tryggere matvarederivater.\r\nI 2012 ble det i følge Timothy Wise ved Tufts University omsatt for omtrent ni trillioner dollar i råvarederivater, med investerte beløp på derivatmarkedet på om lag 130 milliarder dollar. Wise anslår at 80 – 90 prosent av denne handelen er såkalt «over the counter». Dette innebærer at den foregår mellom en kjøper og selger, uten offentlig innsyn og uten krav til standardiserte kontrakter: Kontrakten trenger ikke lenger å se ut som eksempelet over, men kan være noe helt annet.\r\nFeil priser, svingende priser\r\nSpørsmålet er om spekulasjon i verdipapirer basert på matvarer er med på å påvirke prisene på mat. Hensikten med verdipapirmarkedet på mat er ikke kun å kjøpe og selge forsikring, men også å gi informasjon om prisen til de som kjøper og selger fysiske varer. Hvordan kan kjøpere og selgere vite hva som er god pris for kornet, når avlingene er usikre og konkurransen på markedet uklar? De ser til verdipapirmarkedene, og bruker prisen på verdipapirer som utgangspunkt for å bestemme matprisen.\r\nProblemet er at prisene på det finansielle markedet ikke lenger avgjøres av tilbud og etterspørsel på det fysiske markedet, hevder de som mener at spekulasjonen er skadelig. Det finansielle markedet gjenspeiler altså ikke den riktige matvareprisen. I stedet settes verdipapirprisene på bakgrunn av en rekke andre faktorer, som for eksempel investorenes behov for sikring mot svingninger andre steder, hvorvidt andre spekulanter tror prisene vil stige eller falle og bevegelser i prisene på andre varer. Særlig de storstilte investeringene i såkalte indeksfond blir trukket fram som forstyrrende av spekulasjonskritikerne.\r\nEt indeksfond for råvarer er i utgangspunktet kun et gitt forhold mellom ulike verdipapirer, basert på råvarer, som olje, mineraler og mat. Investerer man ukelønnen sin i en råvareindeks, fordeles pengene mellom varene etter det på forhånd bestemte forholdet. Fondet tjener penger hvis varene inkludert i indeksen øker totalt, og taper penger hvis prisene på varene faller totalt. Hvis prisene på de større varegruppene i indeksen, som olje og metall, går opp, går indeksen opp. Siden indeksfondet må holde det gitte forholdet mellom de ulike verdipapirene, vil dette også føre til oppkjøp av matvareverdipapirer. Dermed kan prisene på verdipapirene på olje og metaller bli styrende for prisene på verdipapirene for mat. Går indeksen opp, kan flere aktører med mer kapital strømme til fondet, noe som forsterker etterspørselen etter verdipapirene. I følge utviklingsnettverket World Development Movement satt indeksfond i 2011 på over halvparten av alle verdier på verdipapirmarkedet.\r\nKonsekvensen er at etterspørselen etter verdipapirer basert på mat svinger basert på investeringer i indeksfond, og følger prisene på produkter som olje og metall. Den økte kapitalmengden skaper også større svingninger i prisene på verdipapirene basert på mat. Økte og endrede priser på verdipapirmarkedet forplanter seg så til de fysiske markedene. Særlig FNs spesialrapportør for matvaresikkerhet, Olivier de Schutter, har tydelig advart mot en slik effekt.\r\nSmitte til mat\r\nNår prisene på verdipapirene ikke lenger informerer om tilbud og etterspørsel på jordbruksvarer, men om prisbevegelser i andre råvarer og om spekulantenes framtidstro, vil prissetting basert på verdipapirpriser bli feil. Selv om hovedtrenden fortsatt er basert på hendelser som tørke og etterspørselsøkning, kan spekulasjonen dermed være være med på å forklare hvorfor svingningene i prisene har vært så store og hurtige siden 2007.\r\nNår prisen på verdipapirmarkedet øker, vil en selger av fysiske varer ønske å ta ut denne framtidige prisen på sine reelle varer. Aktørene på de fysiske markedene vil ha de samme prisene som på finansmarkedet! Selgeren venter derfor med å selge varene sine, noe som gir færre varer på markedet, og dermed høyere priser. Kjøperen av varene vil derimot sikre seg mot framtidige prisøkninger, og etterspørselen etter verdipapirer vil stige. Hva skjer så? Med større etterspørsel enn tilbud stiger prisene på det fysiske markedet. Papirene vil igjen øke i verdi, og prosessen starter dermed på nytt.\r\nMotargumentene\r\nEr du overbevist av forklaringen på økte matvarepriser? Det er ikke helt sikkert at du burde være det, for her finnes en rekke motargumenter:\r\nStjerneøkonom Paul Krugman er blant de som avviser at prisene på verdipapirer smitter over på matprisene. I utgangspunktet skal ikke prisene på verdipapirene kunne påvirke prisene på de underliggende produktene, mener han. Det blir som om et utfall av hesteveddeløp i dag skulle bli påvirket av de som har satset på travløpet om fire uker. Prisen på tomater settes på det fysiske markedet for tomater, ikke verdipapirmarkedet. Dermed reduseres spørsmålet om spekulasjon til et spørsmål om hvorvidt noen har holdt tilbake store kvanta landbruksprodukter fra markedet for å drive prisene opp. Dette ser det ikke ut til å være gode bevis for.\r\nKritikernes motsvar her er at fordi tomatmarkedet (blant andre) er uoversiktelig, med lite informasjon om prisene, så vil prisene på verdipapirer påvirke hva som sees som en god pris. Selv om grunnleggende trender driver prisen, vil spekulasjonen forsterke uheldige trender og øke prisene enda mer.\r\nMen prisen på finansmarkedet er en god tilnærming til den virkelige prisen, er innvendingen fra finansforsvaret. Jo flere aktører på et marked, jo mer informasjon bringes til torgs, og desto riktigere blir sluttprisen. Hvis du satser på å spekulere på stigende priser på verdipapirene, hevder disse, vil du raskt bli loppet for penger av spekulanter som kjenner den egentlige prisen på mat bedre. Mot dette kommer påstander fra blant andre World Development Movement (WDM) om bobletankegang, flokkoppførsel og indeksfondenes manglende tanker om underliggende forhold i tomatmarkedet. Spekulantene følger ikke informasjon i markededene, de følger hverandre, sier WDM.\r\nBanker med samvittighet?\r\nFinansmarkeder er komplekse, og det er vanskelig å sette seg inn i hva som skjer der – noe som stadig trekkes fram som en av årsakene til finanskrisen. Selv topptrente regulatorer visste ikke når de skulle trykke på den store røde reguleringsknappen. Imidlertid kan det være en indikasjon at størrelser som FNs mat- og landbruksorganisasjon, FAO, uttaler at dette har hatt en effekt. Det største finanskonsernet i Norden, Nordea, har trukket spareprodukt hvor de tilbød privatkunder blant annet investering i matvareindekser. Også Finans Norge sa i debatt med Attac at disse produktene ikke egner seg for privatkunder. De står ikke alene: Commerzbank har fjernet landbruksprodukter fra et av sine indeksfond, østerrikske Volksbank likeså, og nylig ga giganten Barcalys beskjed om at de ikke lenger ønsket å handle i jordbruksråvarer med hedgefond.\r\nFøre-var-prinsipp\r\nNår spekulasjon som teori entret scenen i 2008, hadde mange andre faktorer blitt vurdert, uten at de virket som uttømmende forklaringer på de store prisøkningene. Når en hensyntar spekulasjon kommer en noe nærmere en god forklaring, særlig på de store svingningene, men som vi har sett har også denne forklaringen sine svakheter. Som andre innlegg i denne utgaven av Utveier viser til, er det mange andre faktorer som kan påvirke prisen på mat. Kun å fokusere på spekulasjon blir ikke riktig. Men som argumentene viser kan det være viktig, og det er en debatt for viktig til å overlates finansøkonomene.\r\nEnn så lenge virker det sikreste å gjøre som Financial Times forslår: Så lenge ingen kan forsikre oss om at matvarespekulasjon ikke påvirker prisene, er de potensielle konsekvensene av uregulert spekulasjon sult. Dette er en utvikling vi kan gjøre noe med. I stedet for å bidra til hungersnød, burde de enorme summene spekulantene forvalter gå til investeringer i global matproduksjon.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-25T07:55:07+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2013-02-27-kunnskap-om-banken-din/",
    "title": "Veit du hva banken din gjør?",
    "description": "Uttalelse og lesebrev fra Attac Norges landsmøte i 2013.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2013-02-27",
    "categories": [],
    "contents": "\r\nAttac har i lengre tid arbeidet med bankenes rolle i finanskrisa, og blant annet fått utredet en rapport om bankenes tilknytning til skatteparadis og uetiske investeringer (se Attac.no-oppslaget her). Jeg skrev utkast til en uttalelse som, med noen endringer, ble vedtatt på Attac Norges landsmøte 27. februar, og som senere har blitt sent ut som leserbrev.\r\nEuropa er rammet av en gjeldskrise med massearbeidsledighet, kutt i offentlig velferd og angrep på sosiale rettigheter som resultat. Gjeldskrisa ble utløst da de europeiske bankenes skadelige spekulasjon og tvilsomme utlånspraksis slo tilbake på bankene. De kom da løpende til staten for å bli reddet fra de frie markedskreftene og konkurs.\r\nAttac Norge mener at bankene har et ansvar overfor samfunnet som helhet til å fordele ressursene slik at de på best mulig måte støtter opp under hensyn til sosiale rettigheter, miljø og menneskerettigheter. Vi har dokumentert at de største norske bankene ikke tar sitt samfunnsansvar på alvor. I en gjennomgang av utlån og investeringer fra DNB, Nordea, Danske Bank og Handelsbanken fant vi at alle bankene har tilknytning til flere skatteparadis, finansierer våpenproduksjon og miljøverstinger. Noen hadde også tilknytning til matvarespekulasjon og selskaper involvert i korrupsjon.\r\nMed kontorer og filialer i skatteparadiser som Luxembourg, Sveits, Cayman Islands og City of London mener vi at det ikke er tvil om at norske banker støtter et system som bidrar til hemmelighold, tilrettelegger for skatteunndragelser, og hemmer utvikling i Sør. Ti ganger verdien av verdens bistandsmidler forsvinner fra fattige land på grunn av dette systemet. Verdier tilsvarende 35 oljefond er gjemt bort i slike jurisdiksjoner, midler som trengs sårt i disse vanskelige økonomiske tider. Dette systemet kan ikke norske banker være med på å opprettholde.\r\nVi er imidlertid ikke maktesløse, og Attac Norge vil derfor oppfordre:\r\nDeg til å spørre banken din om hva den gjør med pengene dine, hvorfor den er aktiv i skatteparadis, og hvem den låner ut penger til. Er du ikke fornøyd med svarene, bytt bank.\r\nBanker og finansforetak til å støtte opp under sosiale rettigheter, miljø og menneskerettigheter, gå ut av skatteparadis, og følge samme regler for samfunnsansvar for utlån som for investeringer.\r\nNorske myndigheter til å kreve at bankene offentliggjør mottakerne av større utlån, og kreve land-for-land-rapportering av norsk finansnæring.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-25T07:55:07+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2013-02-07-slipp-bonden-fri/",
    "title": "Slipp bonden fri!",
    "description": "Bør vi lære av Danmark i landbrukspolitikken? Innlegget er skrevet sammen med Christian Anton Smedshaug, og sto blant annet på trykk i Klassekampen 7. februar 2013.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2013-02-07",
    "categories": [],
    "contents": "\r\n«Slipp bonden fri» er blitt et begrep for en deregulert landbrukspolitikk der eiendomsregelverk fjernes og begrensninger på størrelse oppheves. Slik skal enhetene bli større, og de offentlige utgifter mindre. Argumentet er at de gjenværende bønder endelig vil få lønn for strevet, mens de overflødige må legge ned og ta seg jobber i andre deler av økonomien. Men er erfaringen den at deregulering gir bonden bedre lønnsomhet og samfunnet mindre kostnader?\r\nInnenfor rammene av den felleseuropeiske landbrukspolitikken har danskene med årene liberalisert sitt eiendomsregelverk og opphevet direkte begrensninger på størrelse. Dette har bidratt til en kraftig strukturutvikling: Fra 1982 har antallet bruk blitt mer enn halvert til dagens rundt 40.000. Gjennomsnittlig driftsstørrelser i samme periode har økt fra 27 melkekyr, 62 purker og 180 dekar korn til henholdsvis 139 melkekyr, 902 purker og 510 dekar kornareal. Disse tallene skjuler en stor spredning, siden over halvparten av gårdsbrukene drives på deltid, og produksjonen er konsentrert på de største gårdene: Den største tidelen dyrker derfor over 40 prosent av kornet og dretter opp mer enn 40 prosent av slaktegrisene. I 2011 leverte de omtrent tre ganger så mye melk, høstet åtte ganger så mye korn og drettet opp tjue ganger så mange svin som norske bønder.\r\nDanskene har et av Europas mest endringsvillige jordbruk med dyktige bønder og sterk produksjonskultur. Om noe land skulle lykkes med å sette bonden fri fra størrelsesbegrensninger, så er det Danmark, med gode naturgitte forutsetninger for landbruksproduksjon.\r\nTil tross for store enheter og stor produksjon har ikke lønnsomheten fulgt med. Fra 2007 til 2010 gikk det danske landbruket som helhet med underskudd hvert år, noe som vil si at danske bønder i snitt ikke kunne ta ut lønn for eget arbeid disse fire årene. Resultatene var ikke mye bedre i 2011 og 2012. Selv med gjennomsnittlig EU-støtte på 7,5 milliarder kroner i siden 2007, har vederlag til eget arbeid og egen kapital i snitt for disse seks årene vært på minus 923 millioner. Et av Europas mest deregulerte jordbruk taper penger i markedet, og må ha støtte, men selv da kommer de ikke i pluss.\r\nDette problemet har vært kjent lenge i Danmark, og for å bedre lønnsomheten har danske bønder søkt å ta ut stordriftsfordeler, og politikerne har fjernet begrensningene på størrelse. Tallmaterialet tyder på at større gårder i snitt har noe bedre netto driftsresultat enn mindre. Men denne tendensen er ikke større enn at mindre bruk kan like god lønnsomhet som større. Sagt med andre ord, størrelse er ingen garanti for suksess, men kan også gi store tap og store svingninger i resultatene fra år til år, særlig i situasjoner med nedgangskonjunktur.\r\nHvordan kan de danske bøndene holde det gående? Her som mange steder ellers i samfunnet er det gjeld som har erstattet lønnsomheten. I 2011 var den totale gjelda på 343 milliarder danske kroner, med et gjennomsnitt for gårder drevet på heltid på 21,7 millioner kroner. Dette utgjorde fire og en halv gang av total inntekt fra produksjonen i 2011, altså at hele produksjonsinntekta fra fire og et halvt år måtte dekke hele gjelda. Renteutgiftene utgjorde 15 prosent av produksjonsinntektene. Til sammenligning utgjorde driftsrelatert gjeld 1,8 ganger årlige produksjonsinntekter i Norge og renteutgiftene fem prosent.\r\nDen danske erfaringen lærer oss at investeringer i større produksjon må gjøres på bakgrunn av reelle stordriftsfordeler og en maktbalanse i markedet som kan gi økte inntektsmuligheter for bonden. Danske bønder har i perioden med sterk vekst i størrelse fått lavere lønnsomhet og måttet basere driften på økende gjeld og store underskudd på drifta. Det har ikke vært til gavn verken for bonden eller samfunnet.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-25T07:55:07+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2013-01-14-biofuel-or-food/",
    "title": "Biobränsle eller mat - ett dilemma att lösa",
    "description": "Leserinnlegg i svensk avis om konflikten mellom biodrivstoff og mat",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2013-01-14",
    "categories": [],
    "contents": "\r\nBehovet av ekonomisk tillväxt, minskning av utsläppen växthusgaser och säker energiförsörjning gör att stora västerländska företag i dag fokuserar på förnybar energi. Det ger upphov till ett dilemma mellan bränsle och livsmedel.\r\nUSA täcker för närvarande 55 procent av sitt råoljebehov genom import. Ökad användning av biobränslen är en av åtgärderna på vägen till att bli oberoende av oljeimport på lång sikt. För att uppnå detta mål kommer man att använda samma mark där det för närvarande produceras livsmedel, för att producera biobränslen. Myndigheterna i USA menar man kan skörda mat två gånger, och låta den tredje grödan användas till produktion av biodiesel och bioetanol. Detta anses vara möjligt eftersom energigrödor inte behöver innehålla vitaminer, mineraler och proteiner utan bara energi. För att realisera detta mål stödjer USA produktion av bioenergi, bland annat genom Farm Bill, USA:s lantbruksbudget.\r\nEU stöder i likhet med USA sin produktion av bioenergi, men unionen har reducerat sina ambitioner för att produktion av energi inte ska genomföras på bekostnad av produktion av mat. Problemet är att första generations bioenergi produceras av livsmedel eller i områden som kan användas för livsmedel. Under 2011 blev 15 procent av världens majsproduktion använt till bränsle, vilket kan ge stigande matpriser.\r\nUtvecklingen av andra generationens biobränslen (2G-bränsle) baserade på trä och träavfall och andra bioresurser som inte kan ätas, kan vara en långsiktig lösning. Produktionen och konsumtionen av 2G-bränsle har inte haft en så bra utveckling som förväntat, och det finns fortfarande ett behov av offentligt stöd till forskning och utveckling.\r\nHär har Sverige och Norge som länder med stora skog sresurser en viktig roll att spela. Vi har goda erfarenheter av samarbetet med gröna certifikat. Norge har som en av världens största exportörer av olja och gas både resurser och\r\nett moraliskt ansvar för att minska utsläppen. I Sverige finns lång erfarenhet av åtgärder och användning av biobränslen, särskilt etanol.\r\nObligatorisk blandning av 2G-bränsle och riktat forskningsstöd för etanol som produceras av cellulosa är två möjliga åtgärder.\r\nDen norska staten har fyrdubblat stödet till spjutspetsteknik inom förnybar energi genom en statligt finansierad energifond. Fonden är på 35 miljarder norska kronor och ska öka till 50 miljarder före 2016. Borregård i Norge tillverkar miljövänlig bioetanol baserad på grantimmer. Tyvärr är dessa initiativ för små. Men tillsammans med Sverige kan vi uppnå målen. Därför skulle en gemensam svensk-norsk forskningsinsats kunna göra Sverige-Norge världsledande på produktion och användning av 2G-bränsle.\r\n(Dette innlegget ble skrevet sammen med Margaret Eide Hillestad, og sto på trykk i ATL ca. 14. januar 2013)\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-25T07:55:07+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2012-09-23-kunnskapsbasert-policy/",
    "title": "Theories of Change og hva som gir policy-impact for forskning ",
    "description": "Anbefaling av Duncan Green og Matt Wood",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2012-09-23",
    "categories": [],
    "contents": "\r\nDuncan Green, seniorrådgiver hos Oxfam, skriver på «From poverty to power» om «Theories of Change» og hvordan forskere kan bruke teori for å øke effektiviteten til mottakere av forskningsstøtte. Med andre ord, et teoretisk blikk på hvordan forholdet mellom forskere og beslutningstakere ser ut, og hvordan organisasjoner som gir støtte til forskning og tiltak i NGOer kan bidra til å «optimaliseres» NGOers forskning. «Theories of Change» ser ut til å referere til dette rammeverket for å skape endring.\r\nI tråd med dette rammeverket foreslår Green at 1) forskere ikke har insentiver til å legge tydelig fram sine antakelser om politisk endring, noe de burde gjøre 2) at forskere/NGOer må bedre forstå hvordan beslutningstakere tar til seg og bruker informasjon, 3) at endring er avhengig av «mulighetsvinduer», og dermed må NGOer kunne reagere kjapt, 4) at mål og midler må defineres tydelig. Å «endre diskursen» er ikke et mål for et prosjekt.\r\nEn annen som tar for seg lignende utfordringer er Matt Wood, som på LSE-bloggen tar for seg hvilke krav byråkratiet stiller til statsvitere og andre for at deres forskning skal være relevant. Bevisene er anekdotiske, men virker rimelige og velkjente: Byråkrater ønsker seg mer forskning som kan brukes i praksis, og ønsker seg også bedre metodisk kunnskap. Dette er vanskelig, i det universitetsforskning tar lang tid, mens beslutningstakere trenger hurtig input. Dette gir rom for tenketanker og andre institutter som spesialiserer seg på å levere hurtig. Videre er kvantitative bevis det mest ønskelige – men hva da med kvalitativ forskning?\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-25T07:55:07+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2012-08-05-masteroppgaven-del-2/",
    "title": "Velferdsdualisme i nyhetene",
    "description": "Bør en innføre begrensninger i rettigheter til ytelser basert på landbakgrunn?",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2012-08-05",
    "categories": [],
    "contents": "\r\nEn god (og grunnleggende) huskeregel når en gjør større prosjekter er å ta en lengre pause mot slutten. Etter et par ukers tid med andre oppgaver kan en da se om den røde tråden gir like mye mening som en trodde. Dette tipset er aldri lett å følge, og en kan trenge lange tidsperioder før «oppgave-blindheten» forsvinner.\r\nSom jeg forsøkte å beskrive i denne posten er masteroppgaven min et forsøk på et stort prosjekt, som integrerer en analyse av konsekvensene av innvandring for ulike faktorer (økonomi, valgadferd) og en analyse av hvordan disse endringene påvirker politiske beslutningstakere. Å konsentrere på en av delene hadde gjort det lettere å få fram den røde tråden, og hadde nok gjort at omfanget hadde blitt mer håndterlig (ikke full monografilengde).Hvis jeg hadde fulgt mitt eget tips, kunne jeg kanskje ha oppnådd dette. På den andre siden hadde det gjort prosjektet noe kjedeligere, og det ene kan ikke sees på hvis en ikke ser på det andre. Sensuren jeg fikk var også svært god, med få innvendinger.\r\nDermed er det artig å se at nå som agurktiden langsomt er på veg ut, dukker spørsmålet om eksport av kontantstøtte igjen opp. Dagsavisen/NTB kan fortelle at Torbjørn Røe Isaksen (H) og Høyre ønsker å se på tiltak for å redusere eksport av velferdsordninger innenfor rammene av EØS-avtalen. Et mulig tiltak er boplikt. Hvis han ser på danske erfaringer i oppgava mi (som kan lastes ned herifra), heller enn å kun lese Brochmann-utvalgets NOU vil han se at det finnes muligheter.\r\nJeg vil selvsagt ikke stemme på dette forslaget, som jeg har skrevet om før: Et botidskrav vil være et steg bort fra universelle ytelser, og vil innebære behov for mer kontroll og håndheving. For noen småbarnsforeldre med kort botid er barnetrygd en viktig ytelse. Og disse problemene er, i den store sammenhengen, svært små, ikke minst hvis en i tillegg skulle begynne å se på skatteinntektene fra arbeiderne som arbeider i Norge. Betaler man inn, kan man få ut. Innsparing får en ta andre steder.\r\nSå lenge «eksport-problemet» presenteres som et økonomisk problem ser jeg få grunner til at dette vil bli innført. Symbolpolitikken i det kan derimot være sterkere, hvis argumentasjonen flyttes over til «grensene for velferd går ved nasjonens grenser».\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-25T07:55:07+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2012-06-03-masteroppgaven-del-1/",
    "title": "Masteroppgaven del 1",
    "description": "Fører innvandring til velferdsdualisme? Del 1 av masteroppgava mi.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2012-06-03",
    "categories": [],
    "contents": "\r\nFor noen uker siden fullførte jeg en mastergrad i statsvitenskap, etter noen hundre timer ved datamaskina. Oppgaven, «Fører innvandring til velferdsdualisme? En studie av innvandringens effekter på barnetrygd og kontantstøtte i Skandinavia», vil bli tilgjengelig på Universitet i Oslos digitale portal DUO etter sensur.\r\nSelv om Wordle-skyen er fin, gir den ikke et helt godt inntrykk av hva det dreier seg om. Siden å forklare dette vil være viktig for meg de neste månedene, kommer det her et kort sammendrag av hva jeg har drevet med de siste månedene. Å skulle klemme alt datamaterialet og alle betraktningene etter et halvt års arbeid inn i en enkel bloggpost er vanskelig, og dette blir derfor en serie med innlegg.\r\nFørst må det takkes – de fleste faktisk involvert ble behørig takket i forordet til oppgava. Men takk også til RescueTime for å ha holdt oversikt over hva jeg drev med, og minne meg på at 2 timer daglig på facebook ikke er spesielt produktivt. Dessverre manglet gratisversjonen av programmet muligheten til å eksportere dataene på en meningsfull måte. En skryteframstilling av de to siste månedenes 320 timer i OpenOffice, Endnote og på wwww.stortinget.no hadde gjort seg. På den andre sida betyr det at de timene på facebook, spotify, og twitter heller ikke kommer fram. Tekniske hindringer ligger heldigvis fortsatt i veien for total selvfremstilling.\r\nOppgaven ser på hvorvidt innvandring og det som kanskje kan kalles egenskaper ved innvandrerbefolkningen kan forklare utviklingen av forskjeller mellom «policydesignet» på barnetrygd og kontantstøtte i Norge, Sverige og Danmark fra ca. 1996 til 2011. Utgangspunktet er at noen teoretikere (og øvrige samfunnsdebattanter) mener at økt innvandring til generøse velferdsstater vil føre til omfattende endringer av disse velferdsstatene, enten i form av kutt av velferdsordninger, eller ved at det utvikles en form for velferdsdualisme: Velferd kun til de med riktig nasjonalitet og/eller etnisitet.\r\nTidligere forskning har en rekke forslag til hvorfor dette skjer, og jeg har forsøkt å se nærmere på noen av disse forklaringene, oppsummert i et snasent forenklet årsaksdiagram.\r\nDiagrammet viser en noe komplisert versjon av hva som kan skje ved innvandring til en skandinav velferdsstat: Majoritetsbefolkningen kan, av ulike grunner, mislike innvandrerbefolkningen, og stemme på partier som ønsker å redusere velferd til innvandrere eller velferd generelt. Partiene spiller mest sannsynlig en viktig rolle her, i det tidligere forskning gjerne viser hvordan særlig høyrepartier utnytter og lager spenninger mellom ulike grupper for å kunne gjennomføre reformer.\r\nIkke alle er enige i dette dystre bildet: Integrering av ulike innvandrergrupper kan hindre spenninger mellom grupper, velferdsordninger er populære hos mange, og de skandinaviske landene har alle, kanskje med unntak av Sverige, gjennomført innstramminger i innvandringspolitikken (altså kontrollen med hvem som har tilgang til landet). I tillegg er det å snakke om minoritet vs. majoritet en grov overforenkling.\r\nFor å undersøke om innvandring har hatt noe å si, har jeg derfor sett på beslutninger om generøsiteten og krav som stilles til mottaker i barnetrygd og kontantstøtte i Norge, Sverige og Danmark fra 1996 til 2011. Kort oppsummert dreier dette seg om at mens den norske barnetrygden har så godt som ingen (nye) krav til mottaker, men en fallende realverdi siden 1996, og den svenske ingen krav, og en delvis opprettholdt realverdi (ihvertfall hvis en tar hensyn til økninger i tilskudd til familier med flere barn), har danskene innført krav til botid, men i liten grad rørt generøsiteten. For der nordmenn og svensker justerer sine ytelser i statsbudsjettet hvert år, har danskene helt siden 1987 latt «børnechecken» indekseres automatisk.\r\nAt alle landene også hadde kontantstøtteordninger var egentlig noe overraskende, siden kontantstøtten gjerne blir oppfattet som noe særnorskt. Både Sverige og Danmark gir tilskudd på kommunalt plan til familier som ikke ønsker å benytte offentlig barnehagetilbud. Her er det ikke gjort mange endringer siden ytelsene ble innført, men det er interessante forskjeller i hvilke krav som stilles til mottakerne: En av de to danske tilskuddene stiller strenge krav til botid, og det svenske «kommunale vårdnadsbidraget» stiller en rekke krav til at mottakeren ikke kan benytte seg av ytelsene.\r\nVed å samle inn en haug av sammenlignbare data har jeg forsøkt å gjøre koblinger mellom disse ulike beslutningene og variabler som forskjeller i arbeidsmarkedsdeltakelse mellom innvandrerbefolknignen og majoritetsbefolkningen, forskjeller i landbakgrunn, og forskjeller i arbeidsløshet. Selv om landene er like, og dermed forholdsvis lette å sammenligne, er ikke dette en helt sikker analysemetode. Derfor har jeg også gjort 14 eliteintervjuer med politikere og byråkrater i alle tre land, samt detaljerte dokumentstudier, som jeg bruker til fire mindre studier av beslutninger.\r\nJeg konkluderer med at egenskaper ved innvandrerbefolkningen i liten grad ser ut til å kunne forklare forskjellene i design mellom land. Det er en viss mulighet for at den relativt lavere deltakelsen på arbeidsmarkedet hos utenlandsfødte kvinner kan ha hatt noe å si for innførselen av opptjeningskrav ved to nyere\r\nkontantstøtteordninger, men forskjellen mellom kvinner og menns arbeidsmarkedsdeltakelse virker like relevant. Å kun se på regjeringspartienes plassering på en høyre/venstre-dimensjon virker også i liten grad forklarende.\r\nHva kan forklare forskjellene? Når det gjelder utviklingen peker både sammenligningen og en case-studie av det danske botidskravet i barnetrygden på regimet for trygdekoordinering i EU som en viktig faktor. Dette er regler bestemt av EU for hvordan sosiale rettigheter skal koordineres når arbeidskraft i Europa har rett til å bevege seg fritt. Dette regimet har per definisjon den største og tydeligste effekten, siden det utvider gyldighetområdet for de nasjonale ytelsene, til dels betraktelig, og endrer definisjonen av kravene til mottaker samt muligheten for å stille slike krav.\r\nRegimet kan i seg selv ikke forklare de ulike tilpasningene til dette regimer, noe det er noen tilfeller av. Jeg mener at forskjellige beslutninger ikke kan forklares med omfanget av eksporten, manifestasjonen av regimets økonomiske konsekvenser. Informasjon jeg henter inn tyder på at det er mer fruktbart å se spørsmålet prinsipielt i lys av hvem som skal få velferd, enn som økonomiske bekymringer.\r\nFører så innvandring til velferdsdualisme? Dataene jeg har studert tyder ikke på det, i hvert fall ikke direkte. Det lille steget mot velferdsdualisme som kan observeres innen barnetrygden bør heller sees som en respons på at EUs regler utvider målgruppen for ytelsen utover det som var tiltenkt, noe nasjonale politiske aktører har forsøkt å stoppe i Danmark. Det kan derfor være vel så viktig å se på hvordan politiske beslutningstakere vurderer EU-regler og hvem som fortjener en ytelse, som egenskaper ved minoriteten. Dermed er det egenskaper ved politikerne og majoriteten som har valgt dem som bør stå i fokus, ikke minoritetene. Det er tross alt majoriteten som kan gjøre beslutninger om endringer.\r\nI et bredere perspektiv er det interessant å notere seg at den danske sosialhjelpen (fram til regjeringsskiftet høsten 2011) hadde blitt lagt om, tydelig for å ramme innvandrere. Det er også interessant at Axel West Pedersen i en ny kronikk peker på at også reformen av den norske uføretrygden ser ut til å innebære en viss form for dualisme.\r\n«Passiv velferdsdualisme» kan også være problematisk – det faktum at svært mange av de sentrale ytelsene i de skandinaviske velferdsstaten er tilrettelagt folk som lever livet sitt i ett land, gjennom f.eks. krav til deltakelse på det nasjonale arbeidsmarkedet. At ytelser som barnetrygden blir knyttet til bostatus kan i en slik sammenheng være uheldig.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-25T07:55:07+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2011-11-06-robin-hood-finansminister-johnsen/",
    "title": "Vær en Robin Hood, finansminister Johnsen!",
    "description": "Brev til finansministeren om viktigheten av finansskatt.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2011-11-06",
    "categories": [],
    "contents": "\r\nKjære finansminister Sigbjørn Johnsen.\r\nFinansskatt er idag ansett som et sentralt virkemiddel for å redusere mengden skadelig spekulasjon, samtidig som den vil skape skatteinntekter. Det internasjonale pengefondet IMF har sagt at det er gjennomførbart. EU-parlamentet og EUkommisjonen vil ha skatten. Tyskland, Frankrike, Brasil, India, Kina og Sør-Afrika er med på laget. Da bør Europas mest radikale regjering, med Johnsen i spissen, kjenne sin besøkelsestid og gå inn for verdens mest populære skatt idag.\r\nDenne uka er presidenter, statsministere og andre toppolitikere fra verdens 19 største økonomier og EU samlet på G20-møte i Cannes. Krisesituasjonen i den internasjonale økonomien står i sentrum. En av sakene som kommer til å bli tatt opp er skatt på finanstransaksjoner, også kjent som Tobinskatt, Robin Hood-skatt eller finansskatt. Kjært barn har mange navn, som man sier.\r\nOg kjært barn, det er det – også i G20. Tysklands kansler Merkel, Frankrikes president Sarkozy, EU-kommisjonens president Manuel Barrosso og Storbritannias tidligere statsminister Gordon Brown er alle tilhengere, for å nevne noen. Paven, som nok trygt kan sies å være stokk konservativ, sto nylig fram som tilhenger av skatten. Det bør derfor være trygt å si at finansskatt er er verdens mest populære skatt. I Norge har blant annet LO, SV og 28 frivillige organisasjoner gått inn for innføring av skatten.\r\nFra finansminister Sigbjørn Johnsen mangler det imidlertid til nå tydelige utspill. Norge gikk riktignok i fjor inn for en global finansskatt i FN, men holdningen til en løsning med færre land har til nå vært lunken. Det er imidlertid med støtte i økonomisk forskning at den tyske finansministeren nå foreslår at en koalisjon av villige land kan gå foran og innføre skatte. Senere kan en så utvide antallet involverte land, slik en har gjort med f.eks. flyskatten. Her bør altså finansministeren fra Næs stå på trygg nok grunn til å henge seg på.\r\nArgumentasjonen for å innføre den lille skatten er veldig enkel. Det er ikke snakk om en stor skatt, kun 0,05% av verdien på handlede aksjer, valuta, obligasjoner eller derivater. Den vil derfor ikke hindre langsiktige investeringer eller reell handel. Allikevel vil en kunne samle inn store beløp: EUkommisjonen snakker om 57 milliarder euro i året. Mange av G20-tilhengerne ser nok fram til å bruke disse pengene på å rette opp skadeskutte budsjettbalanser og i den pågående gjeldskrisen i Europa. Her har imidlertid Robin Hood-aksjonen, kjent over hele Europa, argumentert for at skatteinntektene bør fordeles mellom flere gode formål: En del bør gå til opprettholdelse og styrking av velferdspolitiske tiltak i landene som samler inn skatten. Den andre delen bør gå som friske midler til utviklingsformål.\r\nDette er virkelig ikke annet enn rettferdig: Bankene og finansindustrien utløste i 2007 enorme redningspakker – vi snakker 4600 milliarder euro i EU – etter å ha skutt seg selv i begge føttene med kompliserte finansprodukter. Slik saftig støtte for å drive med skadelig virksomhet er det få næringer som kan smykke seg med. Det gikk også hardt utover land i sør. Mange av de mindre utviklede landene har også i de senere år blitt offer for finanssektorens spekulasjon i matvarepriser, med katastrofale følger.\r\nDet viktigste argumentet er imidlertid at en finanskatt vil være sand i maskineriet på finansnæringa. Daglig handles det for omtrent 3000 milliarder dollar på verdensbasis. Av dette utgjør handel med reelle varer og tjenester under 3%. Resten er finansnæringa, og en forvokst andel av det står kortsiktig spekulasjon for. Ved å legge en liten skatt på alle finanstransaksjoner vil en kunne dempe muligheten for gevinst på skadelig spekulasjon. Dermed vil vi kunne hindre ting som ødeleggende svingninger i valutakurser, galopperende renter på statsgjeld og eksploderende matvarepriser, for ikke å snakke om at vi vil kunne forhindre finanskriser.\r\nKjære Johnsen. Finanskatt er ikke en vidundermedisin. Det løser ikke alle problemer i verden. Men det er et sted å starte.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-25T07:55:07+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2011-09-16-kritisk-borgerjournalistikk/",
    "title": "Kritisk borgerjournalistikk",
    "description": "Om viktigheten av kritisk journalistikk og den femte statsmakt.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2011-09-16",
    "categories": [],
    "contents": "\r\nInternettet er stort, svært, gigantisk. Noen bør sortere ut et par ting som kan være verdt å lese. Denne uken har jeg valgt ut noen kilder om journalisme.\r\nI et demokrati har Journalisten den svært viktige oppgaven det er å holde oversikt med hvem som får hvilke ressurser, når og hvordan, samt hvorfor dette skjer – for så å informere et størst mulig publikum om det etterpå. Etter å ha jobbet med PR for studentfestivalen ISFiT – verdensstørstestudentfestivalmedtematiskfokus, værsågod – og blant annet fått pressemeldinger direkte skrevet av på dagbladet.no og lest opp på NRK Midt-Norges nyhetssending, så ville jeg vært litt treig hvis jeg ikke ble litt skeptisk til hvordan mediene arbeider. Som Niels Christian Geelmuyden liker å si: ««VIL DERE VITE hva en nyhet er for noe», spurte en kjent amerikansk journalist en gang i tiden. «En nyhet er noe som et eller flere mennesker svært nødig vil at andre skal få kjennskap til.» «Vil dere vite hva resten er», spurte han og viftet med en avis. «Resten er reklame.» (I Aftenposten 2011, om WikiLeaks).\r\nDette har også Ignacio Ramonet tematisert i uttrykket «den femte statsmakt», som kanskje ble brukt for første gang i et tysk foredrag mai 2005: Den fjerde statsmakt, mediene, har mislykkes i sin rolle som maktkritikere, gravere og sannhetsvoktere, og har blitt sammenblandet med mektige politiske og økonomiske aktører – staten og kapitalen og mediene sitter i samme båt, om du vil.\r\nEn svært dyktig journalist som har brukt å si høylydt hva han mener om dette er Robert Fisk (av Vice Magazine betegnet som «A Journalistic God«. Fylt med rettferdig vrede har han langet ut fra Beirut, blant annet mot hvordan utenriksdekning i vestlige (i hovedsak engelske og amerikanske) medier overtar statlige synspunkt og statlig språk, og blir dermed et verktøy for reprodusering av England og USAs propanganda rundt Afghanistan, Irak, Palestina, Israle – eller for Tyrkias fornektelse av folkemordet på armenerne. The New York Times kunne vært omdøpt til «Official say» uttalte han under et foredrag en gang.\r\nHerman og Chomskys «Manufacturing Consent» fra 1988 tar for seg hvordan profittorientering, maktkonsentrering, annonsørenes makt, store aktørers informasjonsmakt, protester, interesseorganisasjoner og antikommunisme eller krigen mot terror hindrer mediene i å oppfylle sitt egentlige oppdrag. Joakim Møllersen, styremedlem i Radikalt Økonominettverk, hadde i mars i år en god artikkel om problemstillingen på Dagsavisens «Nye Meninger»-side.\r\nRamonets forslag til en løsning på problemene som han, Herman og Chomsky skisserer er kritisk borgerjournalisme, muliggjort blant annet gjennom informasjonsrevolusjonen og bloggen. Dette ble også plukket opp av Civitas daværende nestleder Finn Bergersen, som riktignok mente uttrykket kom fra CNN (og ikke radikaleren Ramonet): Bergersen snakker blandt annet om hvordan bloggen er iferd med å innta rampelyset som viktig journalistisk verktøy, og anbefaler nordmenn å ta en titt på dette nye fenomenet. Seks år er tydeligvis mange år på internett – men ikke for mange, Bergersens tips om å kikke på Global Voices (en blogg med bloggere som rapporterer om innholdet i blogger i hele verden) er fortsatt et godt tips.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-25T07:55:07+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2011-08-26-generasjon-praktikum/",
    "title": "Generasjon Praktikum",
    "description": "Om generasjonen av tysk ungdom som jobber gratis i praksis.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2011-08-26",
    "categories": [],
    "contents": "\r\nPraktikum (n). Subst., praksis (m), praksisperiode (m), praktikanttjeneste (m) (1). Et praksisopphold mange tyske studenter må gjennom for å få godkjent gradene sine, måtte det være bachelor- eller mastergrad, eller noe mer utdatert som magister eller diplom. Mange som ikke må p.g.a. studiet gjør det allikevel for å få hardt tiltrengt arbeidserfaring i et land hvor arbeidsløsheten de siste tolv månedene har ligget på rundt 7% (og underansettelsen på over 10%) (Kilde: SpiegelOnline)\r\nSå pregende for Tyskland er dette at det inngikk i testen jeg tok for å kunne studere i Tyskland (Test Deutsch als Fremdsprache). Og resultatet? Tusenvis av unge studenter arbeider gratis i hele Tyskland. Det har gitt opphav til et eget begrep: «Generasjon Praktikum». Begrepet, først brukt av ZeitOnline i 2005, viser til hvordan studenter som egentlig er på jakt etter en fast jobb ser seg nødt til å ta den ene ubetalte praksisperioden etter den andre. For hvem vil vel ha en CV full av hull?\r\nI og for seg er ikke en praksisperiode noe negativt – en får yrkeserfaring og en mulighet til å prøve en jobb. Hvilken statsviter har vel ikke drømt om en praksisplass hos SSB, eller kanskje hos en avis, et handelskammer, eller kanskje et mindre kontor? Gjennom å normalisere slike praksisopphold kan det tenkes at selv små bedrifter med små midler kan ta seg råd til å ta ombord en praktikant. Slik vil tilbudet av relevante praksisplasser kunne øke.\r\nMen hvis tilbudet på kvalifisert arbeidskraft fra høyskoler og universiteter øker mer, da kan firmaenes lovnader om nødvendig arbeidserfaring fort gli over til utbytting av billig og kvalifisert arbeidskraft. Hvorfor ansette noen fast, når en nyutdanna person er villig til å gjøre jobben gratis eller for sultelønn? Kvalifisert overskuddsarbeidskraft med utdanning, som mer enn alt annet ønsker seg en jobb – kanskje for å betale tilbake lån opptatt under studiene, kanskje for å få litt status.\r\nBare synd at ikke alle er istand til å ta slike jobber – ikke alle har foreldre som kan finansiere kost og/eller losji, mens den lovende spiren jager arbeidserfaring. Resultatet burde dermed bli økte forskjeller mellom barn av rike foreldre og fattigere foreldre. Ifølge representanter for et streikeforsøk i 2009 gjelder dette særlig høyskolestudenter (SpiegelOnline).\r\nArgumentene for og imot er greie nok – men hvordan ser situasjonen ut? Den tyske diskusjonen var fram til 2007 basert på anekdoter eller ikke-representative tall. En undersøkelse fra Hochschuls-Informations-System fant at kjedepraksisopphold ikke var et vanlig fenomen, at det var mer utbredt blandt humanister, samfunns- og medievitere enn blant teknisk-naturvitenskapelige fag, og at en mer fruktbar problemstilling ville være å se på kortfristig og underbetalt ansettelse.\r\nEn liknende undersøkelse ble i 2011 gjennomført i Østerrike, og resultatet var liknende: Kjedepraksis og langtidsarbeidsløshet etter endt studium er uvanlig. En organisasjon som kaller seg «Generation Praktikum» gikk ut mot undersøkelsen. De påpekte at det takk og pris ikke var slik, men at undersøkelsens ønske om å avmytifisere Generasjon Praktikum-begrepet ikke holdt mål: Den fokuserte ikke på studentenes betingelse rett etter endt studium, men først på de som hadde vært ute på arbeidsmarkedet i 2-6 år, mente organisasjonen. De hevdet at nylig utstuderte arbeidstakere måtte tåle lav lønn og dårligere arbeidsbetingelser, og at dette gjaldt noen (i undersøkelsen ikke undersøkte) yrkesgrupper som kunstnere mer enn f.eks. ingeniører (kilde: Generation Praktikum).\r\nI Italia er visstnok situasjonen verre, fordi arkitekter, revisorer, advokater o.l. må avlegge lange praksisopphold for å få lisensene sine), men her fant jeg ingen konkrete tall (kilde: Wikipedia). I England gikk «Institute for Public Policy Resarch» ut i The Telegraph og pekte på at ubetalte og kost-og-losji-baserte «internships» med en varighet over seks måneder og/eller arbeidsoppgaver som kan defineres som «normale», normalt sett ville være ulovlig – minstelønnregler må respekteres, også her. Dette betyr langt ifra at det er unormalt – The Guardian hadde i slutten av juli 2011 en sak om hvordan kjendiser auksjonerte bort praksisopphold til høystbydende, og noen av uttalelsene i denne artikkelen tyder på at selv om store selskaper som ansetter akademikere betaler praktikantene sine, gjør små og mellomstore bedrifter det ikke. Flere artikler hos The Guardian.\r\nTall for Norge hadde også vært kjekt – et kjapt google-søk gir bare et upresist anslag: I Norge er «internships» som regel moderat lønnet, ifølge Aftenposten. Det får være en idé til framtidig blogging.\r\nHva jeg synes? Richard Cobbett, freelancende journalist og tidligere redaktør, kan siteres på at «If it’s worth printing, it’s worth paying». Det er en mening jeg deler – hvis utført arbeid er verdt å bruke, så er det verdt å betale for (Kilde: Funambulism).\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-25T07:55:07+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2011-10-03-wto-fra-alfa-til-omega/",
    "title": "WTO fra alfa til omega",
    "description": "Grunnleggende artikkel om WTO fra Attacs medlemsblad Taklinger.",
    "author": [
      {
        "name": "Eivind Hageberg",
        "url": "https://suppe-og-analyse.netlify.app"
      }
    ],
    "date": "2007-10-03",
    "categories": [],
    "contents": "\r\nWTO – Hva nytt kan man si?\r\nnovember 1999. Regnet høljer ned i Seattle. I gatene utenfor noen møtelokaler er 100 000 demonstranter samlet for å protestere mot urettferdighet. Kamprop, faner og protestmarsj. Til tross for tåregass, gummikuler og politivold er protestene så høylydte at ministerkonferansen i Verdens Handelsorganisasjon bryter sammen, ute av stand til å sette i gang en ny forhandlingsrunde.\r\nAttac og WTO er begge barn av den økonomiske globaliseringen, men er langtifra glade i hverandre. Setter en seg ned og leser en artikkel om WTO med Attac-vinkling kan en fort få inntrykk av at det er djevelen som blir omtalt i særdeles lite smigrende ordlag. Det kan derfor være på tide å ta et skritt tilbake, og se på hva Verdens Handelsorganisasjon egentlig er.\r\nWTO fra A til Å\r\nWTO (uttales dåbbeltveteo), Verdens Handelsorganisasjon, ble oppretta i januar 1995 som en avløsning av GATT. GATT var den internasjonal hovedavtalen om handel og toll som ble innført i 1948. Sammen med en rekke andre tiltak skulle GATT sørge for at de internasjonale økonomiske kreftene skapte vekst, enighet og fred, ikke kollaps, uenighet, og krig.\r\nHvorvidt perioden fra 1940 til 1990 var preget av enighet og fred kan selvsagt diskuteres, men vekst og endring var så absolutt tilstede. Teknologiske framskritt gjorde verden mindre, handelen økte, og ønsket om økt handel økte enda mer. Med økt handel ble land mer gjensidige avhengig av hverandre. Denne prosessen er den økonomisk globaliseringa.\r\nI forsøket på å håndtere den økonomiske globaliseringa utviklet GATT, opprinnelig kun et avtaleverk, seg etterhvert til en semi-institusjon. Denne semi-institusjonen var imidlertid hverken sterk eller omfattende nok til å håndtere det stadig økende ønsket om internasjonal handel. Et vilkår for at internasjonal handel skal fungere, er nemlig trygghet og stabilitet i det internasjonale markedet. Internasjonal handel vil dermed være tjent med internasjonale institusjoner, som kan forhandle fram avtaler, håndheve regler og fungere som legitime møteplasser. Både stater, transnasjonale selskap og økonomer innså dermed at det trengtes et nytt mutilateralt avtaleverk for frihandel som var bedre tilpasset den økte økonomiske globaliseringa. Dermed ble WTO opprettet.\r\nI dag er så godt som alle verdens handlende land medlem av WTO. Organisasjonen har hovedkvarter og sekretariat i Geneve, med rundt 500 ansatte. Det viktigste organet er ministermøtet som blir avholdt annethvert år. WTOs arbeidsoppgaver er å forvalte og overvåke handelsreglene, løse handelskonflikter og være et forum for videre forhandlinger av handelsregler.\r\nWTOs formål\r\nWTOs mål er ifølge vedtektene deres å øke den økonomiske veksten i alle medlemsland gjennom å redusere toll og andre handelshindringer, liberalisere verdenshandelen og skape et forutsigbart, regelbasert handelssystem basert på ikke-diskriminering. Ikke-diskriminering vil på norsk si likebehandling av nasjonale og utenlandske bedrifter, og at alle land skal ha like vilkår.\r\nDet internasjonale handelsregelverket WTO regulerer er utviklet gjennom åtte forhandlingsrunder. Dette regelverket innbefatter GATT, handel med varer, GATS, handel med tjenester, og TRIPS, intellektuell eiendomsrett, også kjent som patenter. Det er mange som mener at WTO ved sin rolle i det internasjonale økonomiske systemet er en av de absolutt mektigste internasjonale organisasjonene.\r\nWTOs rolle er dermed å sørge for at alle følger, og bli behandlet likt av, reglene i det internasjonale markedet. Uten en slik garantist vil det være svært fristende for ett land å sette i gang proteksjonistiske tiltak, og dermed tjene penger på handel uten å måtte gi fra seg markedsandeler til andre land. I det flere land tyr til en slik proteksjonistisk strategi, vil det internasjonale økonomiske systemet kunne kollapse.\r\nInteresser\r\nEt av det viktigste poengene ved WTO er at det er en plattform hvor medlemslandene kan forhandle fram handelsavtaler. Disse medlemslandene har selvsagt svært sprikende interesser, og vil gjerne eksportere mer av det de kan konkurrere med, men nødig importere mer på de områdene der konkurranseevnen mangler. Et av de virkelige store problemene med WTO er mangelen på sammenfallende interesser.\r\nEn type interesser som kan antas å ha relativt stor gjennomslagskraft er de internasjonale storkonsernene. Store selskaper som Coca Cola, Kraft, og General Motors som har større sluttsummer i regnskapene sine enn flere land. Et eksempel på storselskapenes betydning ser en i TRIPS-reguleringene. TRIPS, eller Handelsrelaterte Aspekter ved Intellektuell Eiendomsrett, er patentlovgivning som er ment å sikre insentiver til utvikling av ny teknologi. Gjennom disse avtalene stiller statene som godkjenner avtalen seg bak kravet fra selskapene om at den som gjør en oppdagelse/oppfinnelse, skal kunne patentere denne, få monopol på ideen og dermed kunne tjene inn igjen det det har kostet å oppdage/oppfinne ideen.\r\nKritikere hevder imidlertid at dette kan sees som monopolisering av kunnskap. Denne monopoliseringen kan imidlertid være skadelig for U-land, siden den minsker muligheten de har til å tilegne seg teknologi. Det at disse rettighetene er så sterke som de faktisk er, kan tyde på at transnasjonale selskaper og storkonsern har en betydelig innflytelse.\r\nGlobal rettferd\r\n80% av verdens befolkning må dele 20% av verdens kake. 20% av verdens befolkning har kontroll over 80% av verdens verdier. Rundt en milliard mennesker lever på under én dollar dagen, gudene vet hvor mange som lever på under to, eller tre. Afrika sør for Sahara opplever fortsatt økonomisk stillstand eller tilbakegang. Halvparten av verdens befolkning har aldri holdt en telefon.\r\nHandel blir av mange sett på som et godt verktøy for å rette på situasjonen. WTO har jo da også som mål å skape økt økonomisk vekst i alle sine medlemsland gjennom å liberalisere verdenshandelen. Som en nøkkelinstitusjon og plattform når det kommer til internasjonal handel, burde dermed WTO i teorien kunne bidra til positiv utvikling for de fattigste landene.\r\nI 2001 ble det i Doha, hovedstaden i Quatar, vedtatt en niende forhandlingsrunde, den såkalte utviklingsrunden. En rapport utgitt av SEATINI, Sør og Østafrikansk Handelsinstitutt, som analyserer hvorvidt Doha-runden er en reell utviklingsrunde konkluderer med et rungende «Nei!» De hevder at siden WTO er bygd på prinsippet om likebehandling og gjensidige ytelser mellom medlemslandene, så kan ikke urettferdigheten rettes opp. Skal u-landenes interesser ivaretas, må disse landene særbehandles. Dette har til nå ikke skjedd.\r\nSpørsmålet blir dermed, slik WTO fungerer i dag, hvilke interesser som får gjennomslag og om disse interessene har interesse av at fattige land skal tjene på frihandelsregimet.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2023-11-25T07:55:07+01:00",
    "input_file": {}
  }
]
